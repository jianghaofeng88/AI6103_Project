{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"e14be1a884ab45b8add1610551e09fc8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_176b9df4a60d4af0b9182515888b9c98","IPY_MODEL_ed3d77cb1a484476a2da3be787d82aee","IPY_MODEL_6ee540cd75394c6798893971e0ca0ba9"],"layout":"IPY_MODEL_1fcc0f34fac14353b7891c932d1d9c40"}},"176b9df4a60d4af0b9182515888b9c98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8586c2d318d4b16a79440ce9ada27f3","placeholder":"​","style":"IPY_MODEL_2c22802709604e8bbc24abe6f57f9153","value":"100%"}},"ed3d77cb1a484476a2da3be787d82aee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b51ec16feec04a1a9fa6ba295e89c8cf","max":182040794,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ccd3910921a54b879692aced89502c94","value":182040794}},"6ee540cd75394c6798893971e0ca0ba9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5aaf356942974bafbae00709518642ca","placeholder":"​","style":"IPY_MODEL_21735001403240cb947a4a1916459927","value":" 182040794/182040794 [00:10&lt;00:00, 13252305.78it/s]"}},"1fcc0f34fac14353b7891c932d1d9c40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8586c2d318d4b16a79440ce9ada27f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c22802709604e8bbc24abe6f57f9153":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b51ec16feec04a1a9fa6ba295e89c8cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccd3910921a54b879692aced89502c94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5aaf356942974bafbae00709518642ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21735001403240cb947a4a1916459927":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b4442a4aff4467ea96d1a9b48eb13e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dafa55a9b2ec49f0bc688f848e6aed91","IPY_MODEL_4c2ded1116b04dd78a77551b8aa79380","IPY_MODEL_bede0f0281d54e4ba19051a5e728a788"],"layout":"IPY_MODEL_9a51ea636aca4c48ade66e8070a80e9e"}},"dafa55a9b2ec49f0bc688f848e6aed91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_097dcc7d6cb546d38f4800b9bc91b447","placeholder":"​","style":"IPY_MODEL_627fa52859014a978c66da7e54ff3a31","value":"100%"}},"4c2ded1116b04dd78a77551b8aa79380":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_186b7157b5604785bc59b35fd80ab85d","max":64275384,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3291acdd4f6b4c3abf475042e4b4033b","value":64275384}},"bede0f0281d54e4ba19051a5e728a788":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a4d711676764e8d9885dfefae775b9b","placeholder":"​","style":"IPY_MODEL_901cd98efa0c47fb99dbd2c07ec89b1a","value":" 64275384/64275384 [00:04&lt;00:00, 13537176.15it/s]"}},"9a51ea636aca4c48ade66e8070a80e9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"097dcc7d6cb546d38f4800b9bc91b447":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"627fa52859014a978c66da7e54ff3a31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"186b7157b5604785bc59b35fd80ab85d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3291acdd4f6b4c3abf475042e4b4033b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a4d711676764e8d9885dfefae775b9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"901cd98efa0c47fb99dbd2c07ec89b1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"id":"XfGrai_Qt7Ny","executionInfo":{"status":"ok","timestamp":1668308978495,"user_tz":-480,"elapsed":2625,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}}},"source":["# import all libraries\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import os\n","import argparse\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# ## Source code for unpickle function: https://www.cs.toronto.edu/~kriz/cifar.html\n","# def unpickle(file):\n","#     import pickle\n","#     with open(file, 'rb') as fo:\n","#         dict = pickle.load(fo, encoding='bytes')\n","#     return dict\n","\n","# import numpy as np\n","# def get_mean_color():\n","#     d=unpickle('./data/cifar-10-batches-py/data_batch_1')\n","#     channels = d[b'data']\n","#     for i in range(2,6):\n","#         d=unpickle('./data/cifar-10-batches-py/data_batch_'+str(i))\n","#         channels=np.concatenate((channels, d[b'data']), axis=0)\n","#     r=np.mean(channels[:,:1024])/255  \n","#     g=np.mean(channels[:,1024:2048])/255\n","#     b=np.mean(channels[:,2048:])/255\n","#     return(r,g,b)\n","# get_mean_color()"],"metadata":{"id":"8ntKy6oKQGJv","executionInfo":{"status":"ok","timestamp":1668308978495,"user_tz":-480,"elapsed":4,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["e14be1a884ab45b8add1610551e09fc8","176b9df4a60d4af0b9182515888b9c98","ed3d77cb1a484476a2da3be787d82aee","6ee540cd75394c6798893971e0ca0ba9","1fcc0f34fac14353b7891c932d1d9c40","a8586c2d318d4b16a79440ce9ada27f3","2c22802709604e8bbc24abe6f57f9153","b51ec16feec04a1a9fa6ba295e89c8cf","ccd3910921a54b879692aced89502c94","5aaf356942974bafbae00709518642ca","21735001403240cb947a4a1916459927","4b4442a4aff4467ea96d1a9b48eb13e9","dafa55a9b2ec49f0bc688f848e6aed91","4c2ded1116b04dd78a77551b8aa79380","bede0f0281d54e4ba19051a5e728a788","9a51ea636aca4c48ade66e8070a80e9e","097dcc7d6cb546d38f4800b9bc91b447","627fa52859014a978c66da7e54ff3a31","186b7157b5604785bc59b35fd80ab85d","3291acdd4f6b4c3abf475042e4b4033b","9a4d711676764e8d9885dfefae775b9b","901cd98efa0c47fb99dbd2c07ec89b1a"]},"id":"VgAiImV0uURP","outputId":"6a8082bb-e828-488e-d774-2efbfc2608df","executionInfo":{"status":"ok","timestamp":1668308997995,"user_tz":-480,"elapsed":19503,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}}},"source":["# these are commonly used data augmentations\n","# random cropping and random horizontal flip\n","# lastly, we normalize each channel into zero mean and unit standard deviation\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    \n","    transforms.ToTensor(),\n","    #transforms.RandomErasing(value=get_mean_color()),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = torchvision.datasets.SVHN(\n","    root='./data', split='train', download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(\n","    trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.SVHN(\n","    root='./data', split='test', download=True, transform=transform_test)\n","\n","# we can use a larger batch size during test, because we do not save \n","# intermediate variables for gradient computation, which leaves more memory\n","testloader = torch.utils.data.DataLoader(\n","    testset, batch_size=256, shuffle=False, num_workers=2)\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/182040794 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e14be1a884ab45b8add1610551e09fc8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data/test_32x32.mat\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/64275384 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b4442a4aff4467ea96d1a9b48eb13e9"}},"metadata":{}}]},{"cell_type":"code","source":["classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n","print(len(trainset), len(testset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wO2fleA52Aex","outputId":"bebcafc9-1b10-4fcb-e3eb-04079bcde5a0","executionInfo":{"status":"ok","timestamp":1668308997996,"user_tz":-480,"elapsed":13,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["73257 26032\n"]}]},{"cell_type":"markdown","metadata":{"id":"Te71lQ17B1L_"},"source":["#Data Augmentation\n","Data augmentation performs random modifications of the image as a preprocessing step. It serves the following purposes:\n","1. It increases the amount of data for training.\n","2. By deleting features, it prevents the network from relying on a narrow set of features, which may not generalize.\n","3. By changing features while maintaining the same output, it helps the network become tolerant of changes that do not change the image lab. \n","\n","In short, data augmentation desensitivizes the network, so it extracts features that are invariant to changes that should not affect the prediction. \n","\n","We showcase a few random data augmentation provided by PyTorch."]},{"cell_type":"code","metadata":{"id":"RyG26xoJC0Pa","executionInfo":{"status":"ok","timestamp":1668308997996,"user_tz":-480,"elapsed":12,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}}},"source":["# import torch.nn as nn\n","# transforms = torch.nn.Sequential(\n","#     T.Resize(256), # resize the short edge to 256.\n","#     T.RandomCrop(224), #randomly crop a 224x224 region from the image\n","#     T.RandomErasing(p=1, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)\n","#     #T.ColorJitter(brightness=0.3, contrast=0.2, saturation=0.1, hue=0.1)\n","#     #T.AutoAugment()\n","# )\n","\n","# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# dog1 = dog1.to(device)\n","# # dog2 = dog2.to(device)\n","\n","# # transformed_dog1 = transforms(dog1)\n","# transformed_dog1 = transforms(dog1)\n","# show([transformed_dog1])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"hldipDVsv-Jt","executionInfo":{"status":"ok","timestamp":1668308997996,"user_tz":-480,"elapsed":11,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}}},"source":["# Training\n","def train(epoch, net, criterion, trainloader, scheduler):\n","    device = 'cuda'\n","    print('\\nEpoch: %d' % epoch)\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","        if (batch_idx+1) % 50 == 0:\n","          print(\"iteration : %3d, loss : %0.4f, accuracy : %2.2f\" % (batch_idx+1, train_loss/(batch_idx+1), 100.*correct/total))\n","\n","    scheduler.step()\n","    return train_loss/(batch_idx+1), 100.*correct/total"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vgyCI0U08i2h"},"source":["Test performance on the test set. Note the use of `torch.inference_mode()`"]},{"cell_type":"code","metadata":{"id":"VkooK-hQu4a6","executionInfo":{"status":"ok","timestamp":1668308997996,"user_tz":-480,"elapsed":11,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}}},"source":["def test(epoch, net, criterion, testloader):\n","    device = 'cuda'\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.inference_mode():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","    return test_loss/(batch_idx+1), 100.*correct/total\n","\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEj8J7xqwAxD","executionInfo":{"status":"ok","timestamp":1668308997997,"user_tz":-480,"elapsed":12,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}}},"source":["def save_checkpoint(net, acc, epoch):\n","    # Save checkpoint.\n","    print('Saving..')\n","    state = {\n","        'net': net.state_dict(),\n","        'acc': acc,\n","        'epoch': epoch,\n","    }\n","    if not os.path.isdir('checkpoint'):\n","        os.mkdir('checkpoint')\n","    torch.save(state, './checkpoint/ckpt.pth')\n","\n","\n","\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"vlCAjBEWwXNo","executionInfo":{"status":"ok","timestamp":1668308997997,"user_tz":-480,"elapsed":12,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}}},"source":["# defining resnet models\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(\n","            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n","                               stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion *\n","                               planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        # This is the \"stem\"\n","        # For CIFAR (32x32 images), it does not perform downsampling\n","        # It should downsample for ImageNet\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        # four stages with three downsampling\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2, 2, 2, 2])\n","\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3, 4, 6, 3])\n","\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3, 4, 6, 3])\n","\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3, 4, 23, 3])\n","\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3, 8, 36, 3])\n","\n","\n","def test_resnet18():\n","    net = ResNet18()\n","    y = net(torch.randn(1, 3, 32, 32))\n","    print(y.size())\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# partition the trainset\n","torch.manual_seed(0)\n","np.random.seed(0)\n","new_trainset, validationset= torch.utils.data.random_split(trainset,\n","  [len(trainset)-len(testset), len(testset)], generator=torch.Generator().manual_seed(0))\n","class_freq = np.zeros(10)\n","for i in range(len(new_trainset)):\n","  class_freq[new_trainset[i][1]]+=1\n","class_prop = class_freq/(len(new_trainset))\n","print(class_freq)\n","print(class_prop)\n","\n","# plot the proportion\n","ax = plt.figure(figsize=(10,5)).add_subplot(111)\n","plt.plot(list(classes),class_prop, '.', ms=8)\n","plt.xlabel(\"Classes\")\n","plt.ylabel(\"Proportion\")\n","for i,j in zip(list(classes),class_prop):\n","    ax.annotate(i+'\\n'+str(round(j*100,3))+'%',xy=(i,j))\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"odLHjfkTzzaJ","outputId":"cf545a13-451a-4d28-d13c-04761b3731cf","executionInfo":{"status":"ok","timestamp":1668309014715,"user_tz":-480,"elapsed":16730,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[3234. 8926. 6868. 5501. 4828. 4429. 3753. 3516. 3233. 2937.]\n","[0.06848068 0.18901006 0.14543145 0.11648491 0.10223399 0.09378507\n"," 0.07947062 0.07445209 0.0684595  0.06219164]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["sum(class_freq)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CaGDVy1s3i7J","outputId":"136b989f-2759-44a2-fb46-55be84f392b8","executionInfo":{"status":"ok","timestamp":1668309014716,"user_tz":-480,"elapsed":7,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}}},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["47225.0"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"ArgupDVRwB8i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668313159714,"user_tz":-480,"elapsed":4145002,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}},"outputId":"04f89d88-f374-421e-9c0f-68e4e6ed811b"},"source":["# main body\n","config = {\n","    'lr': 0.001,\n","    'weight_decay': 0\n","}\n","\n","\n","trainloader = torch.utils.data.DataLoader(\n","        new_trainset, batch_size=128, shuffle=True, num_workers=2)\n","testloader = torch.utils.data.DataLoader(\n","        validationset, batch_size=128, shuffle=False, num_workers=2)\n","net = ResNet18().to('cuda')\n","criterion = nn.CrossEntropyLoss().to('cuda')\n","optimizer = optim.Adam(net.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n","#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n","#scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer, factor=1)\n","#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30)\n","scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, total_iters=300)\n","\n","train_loss_list=[] \n","train_acc_list=[]\n","test_loss_list=[]\n","test_acc_list=[]\n","\n","for epoch in range(1, 301):\n","    train_loss, train_acc = train(epoch, net, criterion, trainloader, scheduler)\n","    test_loss, test_acc = test(epoch, net, criterion, testloader)\n","    \n","    train_loss_list.append(train_loss) \n","    train_acc_list.append(train_acc)\n","    test_loss_list.append(test_loss)\n","    test_acc_list.append(test_acc)\n","    print((\"Epoch : %3d, training loss : %0.4f, training accuracy : %2.2f, test loss \" + \\\n","      \": %0.4f, test accuracy : %2.2f\") % (epoch, train_loss, train_acc, test_loss, test_acc))\n"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch: 1\n","iteration :  50, loss : 2.2629, accuracy : 19.09\n","iteration : 100, loss : 2.0071, accuracy : 28.93\n","iteration : 150, loss : 1.7155, accuracy : 39.86\n","iteration : 200, loss : 1.4762, accuracy : 48.68\n","iteration : 250, loss : 1.2985, accuracy : 55.09\n","iteration : 300, loss : 1.1735, accuracy : 59.54\n","iteration : 350, loss : 1.0810, accuracy : 62.96\n","Epoch :   1, training loss : 1.0505, training accuracy : 64.05, test loss : 0.6002, test accuracy : 81.17\n","\n","Epoch: 2\n","iteration :  50, loss : 0.4500, accuracy : 86.11\n","iteration : 100, loss : 0.4446, accuracy : 86.12\n","iteration : 150, loss : 0.4345, accuracy : 86.31\n","iteration : 200, loss : 0.4331, accuracy : 86.35\n","iteration : 250, loss : 0.4196, accuracy : 86.78\n","iteration : 300, loss : 0.4127, accuracy : 87.09\n","iteration : 350, loss : 0.4123, accuracy : 87.10\n","Epoch :   2, training loss : 0.4103, training accuracy : 87.15, test loss : 0.4387, test accuracy : 86.57\n","\n","Epoch: 3\n","iteration :  50, loss : 0.3501, accuracy : 88.92\n","iteration : 100, loss : 0.3578, accuracy : 88.84\n","iteration : 150, loss : 0.3490, accuracy : 89.22\n","iteration : 200, loss : 0.3443, accuracy : 89.33\n","iteration : 250, loss : 0.3408, accuracy : 89.48\n","iteration : 300, loss : 0.3417, accuracy : 89.49\n","iteration : 350, loss : 0.3408, accuracy : 89.52\n","Epoch :   3, training loss : 0.3402, training accuracy : 89.55, test loss : 0.3231, test accuracy : 90.26\n","\n","Epoch: 4\n","iteration :  50, loss : 0.3134, accuracy : 90.44\n","iteration : 100, loss : 0.3094, accuracy : 90.53\n","iteration : 150, loss : 0.3017, accuracy : 90.76\n","iteration : 200, loss : 0.3070, accuracy : 90.66\n","iteration : 250, loss : 0.3079, accuracy : 90.65\n","iteration : 300, loss : 0.3058, accuracy : 90.69\n","iteration : 350, loss : 0.3036, accuracy : 90.77\n","Epoch :   4, training loss : 0.3039, training accuracy : 90.76, test loss : 0.3437, test accuracy : 89.47\n","\n","Epoch: 5\n","iteration :  50, loss : 0.2614, accuracy : 91.69\n","iteration : 100, loss : 0.2686, accuracy : 91.62\n","iteration : 150, loss : 0.2729, accuracy : 91.50\n","iteration : 200, loss : 0.2777, accuracy : 91.35\n","iteration : 250, loss : 0.2807, accuracy : 91.38\n","iteration : 300, loss : 0.2763, accuracy : 91.55\n","iteration : 350, loss : 0.2769, accuracy : 91.60\n","Epoch :   5, training loss : 0.2767, training accuracy : 91.62, test loss : 0.3047, test accuracy : 90.87\n","\n","Epoch: 6\n","iteration :  50, loss : 0.2607, accuracy : 92.61\n","iteration : 100, loss : 0.2611, accuracy : 92.31\n","iteration : 150, loss : 0.2612, accuracy : 92.24\n","iteration : 200, loss : 0.2571, accuracy : 92.36\n","iteration : 250, loss : 0.2593, accuracy : 92.21\n","iteration : 300, loss : 0.2571, accuracy : 92.23\n","iteration : 350, loss : 0.2556, accuracy : 92.29\n","Epoch :   6, training loss : 0.2539, training accuracy : 92.33, test loss : 0.2850, test accuracy : 91.78\n","\n","Epoch: 7\n","iteration :  50, loss : 0.2339, accuracy : 92.84\n","iteration : 100, loss : 0.2466, accuracy : 92.65\n","iteration : 150, loss : 0.2480, accuracy : 92.54\n","iteration : 200, loss : 0.2475, accuracy : 92.65\n","iteration : 250, loss : 0.2437, accuracy : 92.80\n","iteration : 300, loss : 0.2433, accuracy : 92.80\n","iteration : 350, loss : 0.2431, accuracy : 92.87\n","Epoch :   7, training loss : 0.2429, training accuracy : 92.87, test loss : 0.2638, test accuracy : 92.39\n","\n","Epoch: 8\n","iteration :  50, loss : 0.2315, accuracy : 93.19\n","iteration : 100, loss : 0.2322, accuracy : 92.93\n","iteration : 150, loss : 0.2323, accuracy : 93.02\n","iteration : 200, loss : 0.2332, accuracy : 93.05\n","iteration : 250, loss : 0.2335, accuracy : 93.09\n","iteration : 300, loss : 0.2360, accuracy : 93.03\n","iteration : 350, loss : 0.2323, accuracy : 93.12\n","Epoch :   8, training loss : 0.2313, training accuracy : 93.14, test loss : 0.2683, test accuracy : 92.26\n","\n","Epoch: 9\n","iteration :  50, loss : 0.2252, accuracy : 93.20\n","iteration : 100, loss : 0.2199, accuracy : 93.38\n","iteration : 150, loss : 0.2212, accuracy : 93.38\n","iteration : 200, loss : 0.2238, accuracy : 93.24\n","iteration : 250, loss : 0.2226, accuracy : 93.23\n","iteration : 300, loss : 0.2230, accuracy : 93.24\n","iteration : 350, loss : 0.2228, accuracy : 93.24\n","Epoch :   9, training loss : 0.2221, training accuracy : 93.26, test loss : 0.2729, test accuracy : 92.23\n","\n","Epoch: 10\n","iteration :  50, loss : 0.2114, accuracy : 94.03\n","iteration : 100, loss : 0.2071, accuracy : 94.06\n","iteration : 150, loss : 0.2073, accuracy : 94.05\n","iteration : 200, loss : 0.2081, accuracy : 93.96\n","iteration : 250, loss : 0.2099, accuracy : 93.89\n","iteration : 300, loss : 0.2090, accuracy : 93.85\n","iteration : 350, loss : 0.2130, accuracy : 93.79\n","Epoch :  10, training loss : 0.2128, training accuracy : 93.82, test loss : 0.2532, test accuracy : 92.61\n","\n","Epoch: 11\n","iteration :  50, loss : 0.1880, accuracy : 94.70\n","iteration : 100, loss : 0.1965, accuracy : 94.52\n","iteration : 150, loss : 0.1928, accuracy : 94.53\n","iteration : 200, loss : 0.1942, accuracy : 94.43\n","iteration : 250, loss : 0.2000, accuracy : 94.24\n","iteration : 300, loss : 0.1996, accuracy : 94.19\n","iteration : 350, loss : 0.2000, accuracy : 94.23\n","Epoch :  11, training loss : 0.2002, training accuracy : 94.24, test loss : 0.2536, test accuracy : 92.72\n","\n","Epoch: 12\n","iteration :  50, loss : 0.1799, accuracy : 94.84\n","iteration : 100, loss : 0.1837, accuracy : 94.75\n","iteration : 150, loss : 0.1943, accuracy : 94.38\n","iteration : 200, loss : 0.1956, accuracy : 94.38\n","iteration : 250, loss : 0.1939, accuracy : 94.39\n","iteration : 300, loss : 0.1931, accuracy : 94.39\n","iteration : 350, loss : 0.1909, accuracy : 94.40\n","Epoch :  12, training loss : 0.1927, training accuracy : 94.36, test loss : 0.2578, test accuracy : 92.74\n","\n","Epoch: 13\n","iteration :  50, loss : 0.1906, accuracy : 94.58\n","iteration : 100, loss : 0.1915, accuracy : 94.52\n","iteration : 150, loss : 0.1952, accuracy : 94.45\n","iteration : 200, loss : 0.1919, accuracy : 94.52\n","iteration : 250, loss : 0.1882, accuracy : 94.56\n","iteration : 300, loss : 0.1878, accuracy : 94.57\n","iteration : 350, loss : 0.1865, accuracy : 94.58\n","Epoch :  13, training loss : 0.1852, training accuracy : 94.61, test loss : 0.2382, test accuracy : 93.29\n","\n","Epoch: 14\n","iteration :  50, loss : 0.1763, accuracy : 95.05\n","iteration : 100, loss : 0.1764, accuracy : 94.95\n","iteration : 150, loss : 0.1746, accuracy : 95.03\n","iteration : 200, loss : 0.1783, accuracy : 94.96\n","iteration : 250, loss : 0.1796, accuracy : 94.89\n","iteration : 300, loss : 0.1813, accuracy : 94.76\n","iteration : 350, loss : 0.1821, accuracy : 94.73\n","Epoch :  14, training loss : 0.1822, training accuracy : 94.74, test loss : 0.2410, test accuracy : 93.27\n","\n","Epoch: 15\n","iteration :  50, loss : 0.1557, accuracy : 95.45\n","iteration : 100, loss : 0.1602, accuracy : 95.33\n","iteration : 150, loss : 0.1615, accuracy : 95.27\n","iteration : 200, loss : 0.1675, accuracy : 95.06\n","iteration : 250, loss : 0.1685, accuracy : 95.07\n","iteration : 300, loss : 0.1716, accuracy : 94.99\n","iteration : 350, loss : 0.1721, accuracy : 95.02\n","Epoch :  15, training loss : 0.1728, training accuracy : 95.01, test loss : 0.2385, test accuracy : 93.41\n","\n","Epoch: 16\n","iteration :  50, loss : 0.1704, accuracy : 94.97\n","iteration : 100, loss : 0.1694, accuracy : 95.04\n","iteration : 150, loss : 0.1636, accuracy : 95.17\n","iteration : 200, loss : 0.1620, accuracy : 95.21\n","iteration : 250, loss : 0.1646, accuracy : 95.15\n","iteration : 300, loss : 0.1658, accuracy : 95.16\n","iteration : 350, loss : 0.1676, accuracy : 95.09\n","Epoch :  16, training loss : 0.1676, training accuracy : 95.09, test loss : 0.2288, test accuracy : 93.58\n","\n","Epoch: 17\n","iteration :  50, loss : 0.1721, accuracy : 95.11\n","iteration : 100, loss : 0.1625, accuracy : 95.29\n","iteration : 150, loss : 0.1554, accuracy : 95.41\n","iteration : 200, loss : 0.1575, accuracy : 95.35\n","iteration : 250, loss : 0.1583, accuracy : 95.32\n","iteration : 300, loss : 0.1595, accuracy : 95.29\n","iteration : 350, loss : 0.1606, accuracy : 95.29\n","Epoch :  17, training loss : 0.1608, training accuracy : 95.26, test loss : 0.2459, test accuracy : 93.14\n","\n","Epoch: 18\n","iteration :  50, loss : 0.1507, accuracy : 95.92\n","iteration : 100, loss : 0.1613, accuracy : 95.61\n","iteration : 150, loss : 0.1539, accuracy : 95.70\n","iteration : 200, loss : 0.1500, accuracy : 95.80\n","iteration : 250, loss : 0.1517, accuracy : 95.72\n","iteration : 300, loss : 0.1525, accuracy : 95.67\n","iteration : 350, loss : 0.1523, accuracy : 95.69\n","Epoch :  18, training loss : 0.1527, training accuracy : 95.67, test loss : 0.2407, test accuracy : 93.36\n","\n","Epoch: 19\n","iteration :  50, loss : 0.1410, accuracy : 96.27\n","iteration : 100, loss : 0.1429, accuracy : 95.95\n","iteration : 150, loss : 0.1457, accuracy : 95.83\n","iteration : 200, loss : 0.1440, accuracy : 95.79\n","iteration : 250, loss : 0.1449, accuracy : 95.78\n","iteration : 300, loss : 0.1470, accuracy : 95.72\n","iteration : 350, loss : 0.1497, accuracy : 95.65\n","Epoch :  19, training loss : 0.1504, training accuracy : 95.61, test loss : 0.2365, test accuracy : 93.61\n","\n","Epoch: 20\n","iteration :  50, loss : 0.1271, accuracy : 96.30\n","iteration : 100, loss : 0.1359, accuracy : 96.02\n","iteration : 150, loss : 0.1407, accuracy : 95.84\n","iteration : 200, loss : 0.1394, accuracy : 95.89\n","iteration : 250, loss : 0.1413, accuracy : 95.81\n","iteration : 300, loss : 0.1403, accuracy : 95.86\n","iteration : 350, loss : 0.1436, accuracy : 95.77\n","Epoch :  20, training loss : 0.1446, training accuracy : 95.74, test loss : 0.2352, test accuracy : 93.47\n","\n","Epoch: 21\n","iteration :  50, loss : 0.1384, accuracy : 96.00\n","iteration : 100, loss : 0.1382, accuracy : 96.09\n","iteration : 150, loss : 0.1335, accuracy : 96.22\n","iteration : 200, loss : 0.1347, accuracy : 96.16\n","iteration : 250, loss : 0.1363, accuracy : 96.10\n","iteration : 300, loss : 0.1367, accuracy : 96.05\n","iteration : 350, loss : 0.1362, accuracy : 96.01\n","Epoch :  21, training loss : 0.1379, training accuracy : 95.99, test loss : 0.2393, test accuracy : 93.55\n","\n","Epoch: 22\n","iteration :  50, loss : 0.1267, accuracy : 96.30\n","iteration : 100, loss : 0.1335, accuracy : 96.17\n","iteration : 150, loss : 0.1315, accuracy : 96.22\n","iteration : 200, loss : 0.1315, accuracy : 96.11\n","iteration : 250, loss : 0.1308, accuracy : 96.15\n","iteration : 300, loss : 0.1307, accuracy : 96.17\n","iteration : 350, loss : 0.1304, accuracy : 96.23\n","Epoch :  22, training loss : 0.1307, training accuracy : 96.23, test loss : 0.2398, test accuracy : 93.74\n","\n","Epoch: 23\n","iteration :  50, loss : 0.1321, accuracy : 96.09\n","iteration : 100, loss : 0.1243, accuracy : 96.37\n","iteration : 150, loss : 0.1251, accuracy : 96.29\n","iteration : 200, loss : 0.1261, accuracy : 96.33\n","iteration : 250, loss : 0.1238, accuracy : 96.40\n","iteration : 300, loss : 0.1254, accuracy : 96.34\n","iteration : 350, loss : 0.1262, accuracy : 96.31\n","Epoch :  23, training loss : 0.1265, training accuracy : 96.30, test loss : 0.2286, test accuracy : 93.78\n","\n","Epoch: 24\n","iteration :  50, loss : 0.1236, accuracy : 96.52\n","iteration : 100, loss : 0.1252, accuracy : 96.34\n","iteration : 150, loss : 0.1211, accuracy : 96.41\n","iteration : 200, loss : 0.1193, accuracy : 96.48\n","iteration : 250, loss : 0.1195, accuracy : 96.55\n","iteration : 300, loss : 0.1176, accuracy : 96.60\n","iteration : 350, loss : 0.1207, accuracy : 96.52\n","Epoch :  24, training loss : 0.1236, training accuracy : 96.46, test loss : 0.2504, test accuracy : 93.21\n","\n","Epoch: 25\n","iteration :  50, loss : 0.1032, accuracy : 96.69\n","iteration : 100, loss : 0.1057, accuracy : 96.70\n","iteration : 150, loss : 0.1084, accuracy : 96.57\n","iteration : 200, loss : 0.1116, accuracy : 96.56\n","iteration : 250, loss : 0.1141, accuracy : 96.49\n","iteration : 300, loss : 0.1173, accuracy : 96.45\n","iteration : 350, loss : 0.1189, accuracy : 96.44\n","Epoch :  25, training loss : 0.1196, training accuracy : 96.43, test loss : 0.2523, test accuracy : 93.30\n","\n","Epoch: 26\n","iteration :  50, loss : 0.1070, accuracy : 96.75\n","iteration : 100, loss : 0.1067, accuracy : 96.86\n","iteration : 150, loss : 0.1077, accuracy : 96.89\n","iteration : 200, loss : 0.1113, accuracy : 96.79\n","iteration : 250, loss : 0.1113, accuracy : 96.82\n","iteration : 300, loss : 0.1129, accuracy : 96.78\n","iteration : 350, loss : 0.1157, accuracy : 96.65\n","Epoch :  26, training loss : 0.1150, training accuracy : 96.65, test loss : 0.2286, test accuracy : 94.07\n","\n","Epoch: 27\n","iteration :  50, loss : 0.0974, accuracy : 97.06\n","iteration : 100, loss : 0.1065, accuracy : 96.93\n","iteration : 150, loss : 0.1105, accuracy : 96.83\n","iteration : 200, loss : 0.1115, accuracy : 96.85\n","iteration : 250, loss : 0.1119, accuracy : 96.84\n","iteration : 300, loss : 0.1095, accuracy : 96.91\n","iteration : 350, loss : 0.1089, accuracy : 96.88\n","Epoch :  27, training loss : 0.1092, training accuracy : 96.87, test loss : 0.2523, test accuracy : 93.47\n","\n","Epoch: 28\n","iteration :  50, loss : 0.0887, accuracy : 97.25\n","iteration : 100, loss : 0.0917, accuracy : 97.20\n","iteration : 150, loss : 0.0954, accuracy : 97.17\n","iteration : 200, loss : 0.1006, accuracy : 96.99\n","iteration : 250, loss : 0.1046, accuracy : 96.91\n","iteration : 300, loss : 0.1056, accuracy : 96.88\n","iteration : 350, loss : 0.1048, accuracy : 96.89\n","Epoch :  28, training loss : 0.1055, training accuracy : 96.87, test loss : 0.2344, test accuracy : 94.05\n","\n","Epoch: 29\n","iteration :  50, loss : 0.0866, accuracy : 97.50\n","iteration : 100, loss : 0.0918, accuracy : 97.37\n","iteration : 150, loss : 0.0988, accuracy : 97.26\n","iteration : 200, loss : 0.1027, accuracy : 97.11\n","iteration : 250, loss : 0.1035, accuracy : 97.08\n","iteration : 300, loss : 0.1027, accuracy : 97.07\n","iteration : 350, loss : 0.1023, accuracy : 97.07\n","Epoch :  29, training loss : 0.1015, training accuracy : 97.09, test loss : 0.2511, test accuracy : 93.74\n","\n","Epoch: 30\n","iteration :  50, loss : 0.0869, accuracy : 97.50\n","iteration : 100, loss : 0.0909, accuracy : 97.40\n","iteration : 150, loss : 0.0896, accuracy : 97.39\n","iteration : 200, loss : 0.0925, accuracy : 97.28\n","iteration : 250, loss : 0.0928, accuracy : 97.28\n","iteration : 300, loss : 0.0947, accuracy : 97.22\n","iteration : 350, loss : 0.0982, accuracy : 97.14\n","Epoch :  30, training loss : 0.0975, training accuracy : 97.16, test loss : 0.2367, test accuracy : 93.90\n","\n","Epoch: 31\n","iteration :  50, loss : 0.0886, accuracy : 97.64\n","iteration : 100, loss : 0.0868, accuracy : 97.52\n","iteration : 150, loss : 0.0882, accuracy : 97.43\n","iteration : 200, loss : 0.0884, accuracy : 97.42\n","iteration : 250, loss : 0.0926, accuracy : 97.31\n","iteration : 300, loss : 0.0935, accuracy : 97.28\n","iteration : 350, loss : 0.0952, accuracy : 97.25\n","Epoch :  31, training loss : 0.0945, training accuracy : 97.26, test loss : 0.2577, test accuracy : 93.45\n","\n","Epoch: 32\n","iteration :  50, loss : 0.0806, accuracy : 97.66\n","iteration : 100, loss : 0.0858, accuracy : 97.43\n","iteration : 150, loss : 0.0862, accuracy : 97.42\n","iteration : 200, loss : 0.0860, accuracy : 97.44\n","iteration : 250, loss : 0.0889, accuracy : 97.37\n","iteration : 300, loss : 0.0889, accuracy : 97.39\n","iteration : 350, loss : 0.0905, accuracy : 97.34\n","Epoch :  32, training loss : 0.0910, training accuracy : 97.34, test loss : 0.2464, test accuracy : 93.92\n","\n","Epoch: 33\n","iteration :  50, loss : 0.0778, accuracy : 97.70\n","iteration : 100, loss : 0.0757, accuracy : 97.75\n","iteration : 150, loss : 0.0760, accuracy : 97.76\n","iteration : 200, loss : 0.0800, accuracy : 97.66\n","iteration : 250, loss : 0.0851, accuracy : 97.47\n","iteration : 300, loss : 0.0869, accuracy : 97.40\n","iteration : 350, loss : 0.0871, accuracy : 97.35\n","Epoch :  33, training loss : 0.0877, training accuracy : 97.35, test loss : 0.2499, test accuracy : 93.74\n","\n","Epoch: 34\n","iteration :  50, loss : 0.0798, accuracy : 97.77\n","iteration : 100, loss : 0.0783, accuracy : 97.87\n","iteration : 150, loss : 0.0826, accuracy : 97.71\n","iteration : 200, loss : 0.0832, accuracy : 97.64\n","iteration : 250, loss : 0.0819, accuracy : 97.62\n","iteration : 300, loss : 0.0842, accuracy : 97.51\n","iteration : 350, loss : 0.0838, accuracy : 97.51\n","Epoch :  34, training loss : 0.0835, training accuracy : 97.51, test loss : 0.2596, test accuracy : 93.66\n","\n","Epoch: 35\n","iteration :  50, loss : 0.0820, accuracy : 97.50\n","iteration : 100, loss : 0.0775, accuracy : 97.52\n","iteration : 150, loss : 0.0804, accuracy : 97.46\n","iteration : 200, loss : 0.0818, accuracy : 97.46\n","iteration : 250, loss : 0.0837, accuracy : 97.45\n","iteration : 300, loss : 0.0826, accuracy : 97.52\n","iteration : 350, loss : 0.0838, accuracy : 97.52\n","Epoch :  35, training loss : 0.0842, training accuracy : 97.51, test loss : 0.2510, test accuracy : 93.99\n","\n","Epoch: 36\n","iteration :  50, loss : 0.0721, accuracy : 97.73\n","iteration : 100, loss : 0.0727, accuracy : 97.86\n","iteration : 150, loss : 0.0721, accuracy : 97.89\n","iteration : 200, loss : 0.0715, accuracy : 97.91\n","iteration : 250, loss : 0.0736, accuracy : 97.87\n","iteration : 300, loss : 0.0752, accuracy : 97.78\n","iteration : 350, loss : 0.0759, accuracy : 97.75\n","Epoch :  36, training loss : 0.0754, training accuracy : 97.77, test loss : 0.2564, test accuracy : 93.98\n","\n","Epoch: 37\n","iteration :  50, loss : 0.0813, accuracy : 97.84\n","iteration : 100, loss : 0.0820, accuracy : 97.73\n","iteration : 150, loss : 0.0801, accuracy : 97.77\n","iteration : 200, loss : 0.0780, accuracy : 97.81\n","iteration : 250, loss : 0.0766, accuracy : 97.82\n","iteration : 300, loss : 0.0748, accuracy : 97.85\n","iteration : 350, loss : 0.0768, accuracy : 97.75\n","Epoch :  37, training loss : 0.0771, training accuracy : 97.73, test loss : 0.2515, test accuracy : 93.96\n","\n","Epoch: 38\n","iteration :  50, loss : 0.0610, accuracy : 98.22\n","iteration : 100, loss : 0.0682, accuracy : 98.12\n","iteration : 150, loss : 0.0668, accuracy : 98.10\n","iteration : 200, loss : 0.0694, accuracy : 98.05\n","iteration : 250, loss : 0.0692, accuracy : 98.00\n","iteration : 300, loss : 0.0728, accuracy : 97.87\n","iteration : 350, loss : 0.0734, accuracy : 97.87\n","Epoch :  38, training loss : 0.0732, training accuracy : 97.88, test loss : 0.2636, test accuracy : 93.98\n","\n","Epoch: 39\n","iteration :  50, loss : 0.0642, accuracy : 98.02\n","iteration : 100, loss : 0.0648, accuracy : 98.02\n","iteration : 150, loss : 0.0675, accuracy : 97.94\n","iteration : 200, loss : 0.0692, accuracy : 97.91\n","iteration : 250, loss : 0.0712, accuracy : 97.85\n","iteration : 300, loss : 0.0724, accuracy : 97.82\n","iteration : 350, loss : 0.0716, accuracy : 97.83\n","Epoch :  39, training loss : 0.0715, training accuracy : 97.83, test loss : 0.2691, test accuracy : 93.89\n","\n","Epoch: 40\n","iteration :  50, loss : 0.0575, accuracy : 98.45\n","iteration : 100, loss : 0.0618, accuracy : 98.23\n","iteration : 150, loss : 0.0625, accuracy : 98.14\n","iteration : 200, loss : 0.0675, accuracy : 97.99\n","iteration : 250, loss : 0.0681, accuracy : 97.94\n","iteration : 300, loss : 0.0685, accuracy : 97.97\n","iteration : 350, loss : 0.0691, accuracy : 97.96\n","Epoch :  40, training loss : 0.0687, training accuracy : 97.97, test loss : 0.2728, test accuracy : 93.93\n","\n","Epoch: 41\n","iteration :  50, loss : 0.0497, accuracy : 98.48\n","iteration : 100, loss : 0.0565, accuracy : 98.23\n","iteration : 150, loss : 0.0579, accuracy : 98.26\n","iteration : 200, loss : 0.0610, accuracy : 98.16\n","iteration : 250, loss : 0.0627, accuracy : 98.10\n","iteration : 300, loss : 0.0651, accuracy : 98.05\n","iteration : 350, loss : 0.0657, accuracy : 98.01\n","Epoch :  41, training loss : 0.0659, training accuracy : 98.00, test loss : 0.2878, test accuracy : 93.68\n","\n","Epoch: 42\n","iteration :  50, loss : 0.0557, accuracy : 98.33\n","iteration : 100, loss : 0.0605, accuracy : 98.16\n","iteration : 150, loss : 0.0574, accuracy : 98.25\n","iteration : 200, loss : 0.0575, accuracy : 98.25\n","iteration : 250, loss : 0.0587, accuracy : 98.22\n","iteration : 300, loss : 0.0603, accuracy : 98.18\n","iteration : 350, loss : 0.0598, accuracy : 98.17\n","Epoch :  42, training loss : 0.0602, training accuracy : 98.17, test loss : 0.2628, test accuracy : 94.33\n","\n","Epoch: 43\n","iteration :  50, loss : 0.0578, accuracy : 98.25\n","iteration : 100, loss : 0.0582, accuracy : 98.15\n","iteration : 150, loss : 0.0571, accuracy : 98.27\n","iteration : 200, loss : 0.0573, accuracy : 98.20\n","iteration : 250, loss : 0.0567, accuracy : 98.20\n","iteration : 300, loss : 0.0572, accuracy : 98.18\n","iteration : 350, loss : 0.0594, accuracy : 98.17\n","Epoch :  43, training loss : 0.0600, training accuracy : 98.14, test loss : 0.2891, test accuracy : 93.60\n","\n","Epoch: 44\n","iteration :  50, loss : 0.0528, accuracy : 98.48\n","iteration : 100, loss : 0.0564, accuracy : 98.30\n","iteration : 150, loss : 0.0557, accuracy : 98.30\n","iteration : 200, loss : 0.0614, accuracy : 98.16\n","iteration : 250, loss : 0.0636, accuracy : 98.07\n","iteration : 300, loss : 0.0625, accuracy : 98.11\n","iteration : 350, loss : 0.0623, accuracy : 98.11\n","Epoch :  44, training loss : 0.0618, training accuracy : 98.12, test loss : 0.2637, test accuracy : 94.10\n","\n","Epoch: 45\n","iteration :  50, loss : 0.0530, accuracy : 98.34\n","iteration : 100, loss : 0.0606, accuracy : 98.05\n","iteration : 150, loss : 0.0572, accuracy : 98.17\n","iteration : 200, loss : 0.0552, accuracy : 98.22\n","iteration : 250, loss : 0.0548, accuracy : 98.22\n","iteration : 300, loss : 0.0545, accuracy : 98.24\n","iteration : 350, loss : 0.0569, accuracy : 98.20\n","Epoch :  45, training loss : 0.0571, training accuracy : 98.19, test loss : 0.2719, test accuracy : 94.15\n","\n","Epoch: 46\n","iteration :  50, loss : 0.0518, accuracy : 98.28\n","iteration : 100, loss : 0.0475, accuracy : 98.49\n","iteration : 150, loss : 0.0480, accuracy : 98.47\n","iteration : 200, loss : 0.0499, accuracy : 98.41\n","iteration : 250, loss : 0.0519, accuracy : 98.38\n","iteration : 300, loss : 0.0525, accuracy : 98.40\n","iteration : 350, loss : 0.0524, accuracy : 98.39\n","Epoch :  46, training loss : 0.0530, training accuracy : 98.37, test loss : 0.3082, test accuracy : 93.80\n","\n","Epoch: 47\n","iteration :  50, loss : 0.0556, accuracy : 98.19\n","iteration : 100, loss : 0.0571, accuracy : 98.19\n","iteration : 150, loss : 0.0585, accuracy : 98.15\n","iteration : 200, loss : 0.0602, accuracy : 98.07\n","iteration : 250, loss : 0.0594, accuracy : 98.10\n","iteration : 300, loss : 0.0585, accuracy : 98.15\n","iteration : 350, loss : 0.0579, accuracy : 98.17\n","Epoch :  47, training loss : 0.0571, training accuracy : 98.20, test loss : 0.2854, test accuracy : 94.17\n","\n","Epoch: 48\n","iteration :  50, loss : 0.0473, accuracy : 98.64\n","iteration : 100, loss : 0.0446, accuracy : 98.73\n","iteration : 150, loss : 0.0480, accuracy : 98.61\n","iteration : 200, loss : 0.0489, accuracy : 98.57\n","iteration : 250, loss : 0.0491, accuracy : 98.56\n","iteration : 300, loss : 0.0506, accuracy : 98.49\n","iteration : 350, loss : 0.0526, accuracy : 98.44\n","Epoch :  48, training loss : 0.0531, training accuracy : 98.44, test loss : 0.3029, test accuracy : 93.64\n","\n","Epoch: 49\n","iteration :  50, loss : 0.0526, accuracy : 98.47\n","iteration : 100, loss : 0.0513, accuracy : 98.38\n","iteration : 150, loss : 0.0503, accuracy : 98.41\n","iteration : 200, loss : 0.0518, accuracy : 98.37\n","iteration : 250, loss : 0.0526, accuracy : 98.35\n","iteration : 300, loss : 0.0527, accuracy : 98.31\n","iteration : 350, loss : 0.0525, accuracy : 98.34\n","Epoch :  49, training loss : 0.0527, training accuracy : 98.34, test loss : 0.2886, test accuracy : 94.00\n","\n","Epoch: 50\n","iteration :  50, loss : 0.0476, accuracy : 98.56\n","iteration : 100, loss : 0.0487, accuracy : 98.48\n","iteration : 150, loss : 0.0492, accuracy : 98.44\n","iteration : 200, loss : 0.0495, accuracy : 98.44\n","iteration : 250, loss : 0.0491, accuracy : 98.45\n","iteration : 300, loss : 0.0500, accuracy : 98.42\n","iteration : 350, loss : 0.0507, accuracy : 98.41\n","Epoch :  50, training loss : 0.0508, training accuracy : 98.42, test loss : 0.3013, test accuracy : 93.57\n","\n","Epoch: 51\n","iteration :  50, loss : 0.0509, accuracy : 98.48\n","iteration : 100, loss : 0.0475, accuracy : 98.57\n","iteration : 150, loss : 0.0472, accuracy : 98.53\n","iteration : 200, loss : 0.0471, accuracy : 98.50\n","iteration : 250, loss : 0.0486, accuracy : 98.44\n","iteration : 300, loss : 0.0486, accuracy : 98.45\n","iteration : 350, loss : 0.0487, accuracy : 98.44\n","Epoch :  51, training loss : 0.0485, training accuracy : 98.43, test loss : 0.2918, test accuracy : 94.00\n","\n","Epoch: 52\n","iteration :  50, loss : 0.0381, accuracy : 98.80\n","iteration : 100, loss : 0.0432, accuracy : 98.67\n","iteration : 150, loss : 0.0458, accuracy : 98.65\n","iteration : 200, loss : 0.0458, accuracy : 98.60\n","iteration : 250, loss : 0.0452, accuracy : 98.58\n","iteration : 300, loss : 0.0461, accuracy : 98.53\n","iteration : 350, loss : 0.0468, accuracy : 98.50\n","Epoch :  52, training loss : 0.0470, training accuracy : 98.49, test loss : 0.3129, test accuracy : 93.67\n","\n","Epoch: 53\n","iteration :  50, loss : 0.0518, accuracy : 98.47\n","iteration : 100, loss : 0.0451, accuracy : 98.63\n","iteration : 150, loss : 0.0442, accuracy : 98.67\n","iteration : 200, loss : 0.0450, accuracy : 98.65\n","iteration : 250, loss : 0.0467, accuracy : 98.61\n","iteration : 300, loss : 0.0466, accuracy : 98.57\n","iteration : 350, loss : 0.0474, accuracy : 98.55\n","Epoch :  53, training loss : 0.0470, training accuracy : 98.56, test loss : 0.3016, test accuracy : 93.96\n","\n","Epoch: 54\n","iteration :  50, loss : 0.0347, accuracy : 98.84\n","iteration : 100, loss : 0.0428, accuracy : 98.60\n","iteration : 150, loss : 0.0435, accuracy : 98.61\n","iteration : 200, loss : 0.0437, accuracy : 98.59\n","iteration : 250, loss : 0.0455, accuracy : 98.55\n","iteration : 300, loss : 0.0470, accuracy : 98.48\n","iteration : 350, loss : 0.0462, accuracy : 98.50\n","Epoch :  54, training loss : 0.0465, training accuracy : 98.49, test loss : 0.3364, test accuracy : 93.51\n","\n","Epoch: 55\n","iteration :  50, loss : 0.0357, accuracy : 99.00\n","iteration : 100, loss : 0.0407, accuracy : 98.85\n","iteration : 150, loss : 0.0400, accuracy : 98.82\n","iteration : 200, loss : 0.0393, accuracy : 98.80\n","iteration : 250, loss : 0.0417, accuracy : 98.71\n","iteration : 300, loss : 0.0424, accuracy : 98.67\n","iteration : 350, loss : 0.0427, accuracy : 98.67\n","Epoch :  55, training loss : 0.0427, training accuracy : 98.67, test loss : 0.3023, test accuracy : 94.00\n","\n","Epoch: 56\n","iteration :  50, loss : 0.0414, accuracy : 98.88\n","iteration : 100, loss : 0.0393, accuracy : 98.85\n","iteration : 150, loss : 0.0404, accuracy : 98.81\n","iteration : 200, loss : 0.0402, accuracy : 98.77\n","iteration : 250, loss : 0.0419, accuracy : 98.70\n","iteration : 300, loss : 0.0416, accuracy : 98.69\n","iteration : 350, loss : 0.0425, accuracy : 98.66\n","Epoch :  56, training loss : 0.0430, training accuracy : 98.65, test loss : 0.3010, test accuracy : 94.33\n","\n","Epoch: 57\n","iteration :  50, loss : 0.0317, accuracy : 98.95\n","iteration : 100, loss : 0.0387, accuracy : 98.76\n","iteration : 150, loss : 0.0395, accuracy : 98.67\n","iteration : 200, loss : 0.0401, accuracy : 98.68\n","iteration : 250, loss : 0.0412, accuracy : 98.64\n","iteration : 300, loss : 0.0412, accuracy : 98.64\n","iteration : 350, loss : 0.0403, accuracy : 98.69\n","Epoch :  57, training loss : 0.0402, training accuracy : 98.69, test loss : 0.3161, test accuracy : 93.98\n","\n","Epoch: 58\n","iteration :  50, loss : 0.0380, accuracy : 98.62\n","iteration : 100, loss : 0.0354, accuracy : 98.75\n","iteration : 150, loss : 0.0373, accuracy : 98.73\n","iteration : 200, loss : 0.0378, accuracy : 98.73\n","iteration : 250, loss : 0.0377, accuracy : 98.73\n","iteration : 300, loss : 0.0377, accuracy : 98.74\n","iteration : 350, loss : 0.0375, accuracy : 98.77\n","Epoch :  58, training loss : 0.0378, training accuracy : 98.77, test loss : 0.3240, test accuracy : 93.78\n","\n","Epoch: 59\n","iteration :  50, loss : 0.0354, accuracy : 98.94\n","iteration : 100, loss : 0.0340, accuracy : 98.93\n","iteration : 150, loss : 0.0342, accuracy : 98.90\n","iteration : 200, loss : 0.0376, accuracy : 98.78\n","iteration : 250, loss : 0.0374, accuracy : 98.77\n","iteration : 300, loss : 0.0393, accuracy : 98.74\n","iteration : 350, loss : 0.0401, accuracy : 98.70\n","Epoch :  59, training loss : 0.0404, training accuracy : 98.69, test loss : 0.2896, test accuracy : 94.17\n","\n","Epoch: 60\n","iteration :  50, loss : 0.0435, accuracy : 98.64\n","iteration : 100, loss : 0.0426, accuracy : 98.71\n","iteration : 150, loss : 0.0408, accuracy : 98.72\n","iteration : 200, loss : 0.0420, accuracy : 98.66\n","iteration : 250, loss : 0.0433, accuracy : 98.64\n","iteration : 300, loss : 0.0426, accuracy : 98.66\n","iteration : 350, loss : 0.0429, accuracy : 98.63\n","Epoch :  60, training loss : 0.0428, training accuracy : 98.65, test loss : 0.2885, test accuracy : 94.10\n","\n","Epoch: 61\n","iteration :  50, loss : 0.0282, accuracy : 99.11\n","iteration : 100, loss : 0.0246, accuracy : 99.27\n","iteration : 150, loss : 0.0296, accuracy : 99.06\n","iteration : 200, loss : 0.0328, accuracy : 98.91\n","iteration : 250, loss : 0.0334, accuracy : 98.89\n","iteration : 300, loss : 0.0358, accuracy : 98.82\n","iteration : 350, loss : 0.0367, accuracy : 98.79\n","Epoch :  61, training loss : 0.0360, training accuracy : 98.82, test loss : 0.3081, test accuracy : 94.16\n","\n","Epoch: 62\n","iteration :  50, loss : 0.0357, accuracy : 98.73\n","iteration : 100, loss : 0.0361, accuracy : 98.76\n","iteration : 150, loss : 0.0379, accuracy : 98.77\n","iteration : 200, loss : 0.0389, accuracy : 98.71\n","iteration : 250, loss : 0.0390, accuracy : 98.72\n","iteration : 300, loss : 0.0400, accuracy : 98.72\n","iteration : 350, loss : 0.0391, accuracy : 98.74\n","Epoch :  62, training loss : 0.0389, training accuracy : 98.74, test loss : 0.3103, test accuracy : 94.16\n","\n","Epoch: 63\n","iteration :  50, loss : 0.0335, accuracy : 98.98\n","iteration : 100, loss : 0.0329, accuracy : 98.97\n","iteration : 150, loss : 0.0320, accuracy : 98.93\n","iteration : 200, loss : 0.0339, accuracy : 98.85\n","iteration : 250, loss : 0.0342, accuracy : 98.82\n","iteration : 300, loss : 0.0341, accuracy : 98.84\n","iteration : 350, loss : 0.0344, accuracy : 98.82\n","Epoch :  63, training loss : 0.0346, training accuracy : 98.82, test loss : 0.3132, test accuracy : 94.06\n","\n","Epoch: 64\n","iteration :  50, loss : 0.0344, accuracy : 98.94\n","iteration : 100, loss : 0.0332, accuracy : 98.88\n","iteration : 150, loss : 0.0334, accuracy : 98.90\n","iteration : 200, loss : 0.0356, accuracy : 98.82\n","iteration : 250, loss : 0.0367, accuracy : 98.82\n","iteration : 300, loss : 0.0359, accuracy : 98.83\n","iteration : 350, loss : 0.0348, accuracy : 98.87\n","Epoch :  64, training loss : 0.0348, training accuracy : 98.87, test loss : 0.3205, test accuracy : 94.12\n","\n","Epoch: 65\n","iteration :  50, loss : 0.0223, accuracy : 99.34\n","iteration : 100, loss : 0.0250, accuracy : 99.20\n","iteration : 150, loss : 0.0282, accuracy : 99.12\n","iteration : 200, loss : 0.0319, accuracy : 99.00\n","iteration : 250, loss : 0.0329, accuracy : 98.99\n","iteration : 300, loss : 0.0341, accuracy : 98.95\n","iteration : 350, loss : 0.0349, accuracy : 98.91\n","Epoch :  65, training loss : 0.0355, training accuracy : 98.88, test loss : 0.3239, test accuracy : 94.13\n","\n","Epoch: 66\n","iteration :  50, loss : 0.0394, accuracy : 98.67\n","iteration : 100, loss : 0.0379, accuracy : 98.65\n","iteration : 150, loss : 0.0363, accuracy : 98.68\n","iteration : 200, loss : 0.0360, accuracy : 98.71\n","iteration : 250, loss : 0.0354, accuracy : 98.76\n","iteration : 300, loss : 0.0360, accuracy : 98.76\n","iteration : 350, loss : 0.0351, accuracy : 98.78\n","Epoch :  66, training loss : 0.0350, training accuracy : 98.79, test loss : 0.3075, test accuracy : 94.16\n","\n","Epoch: 67\n","iteration :  50, loss : 0.0354, accuracy : 98.77\n","iteration : 100, loss : 0.0333, accuracy : 98.95\n","iteration : 150, loss : 0.0332, accuracy : 98.92\n","iteration : 200, loss : 0.0333, accuracy : 98.95\n","iteration : 250, loss : 0.0338, accuracy : 98.91\n","iteration : 300, loss : 0.0338, accuracy : 98.89\n","iteration : 350, loss : 0.0341, accuracy : 98.89\n","Epoch :  67, training loss : 0.0335, training accuracy : 98.90, test loss : 0.3133, test accuracy : 94.18\n","\n","Epoch: 68\n","iteration :  50, loss : 0.0282, accuracy : 99.05\n","iteration : 100, loss : 0.0289, accuracy : 99.06\n","iteration : 150, loss : 0.0302, accuracy : 99.00\n","iteration : 200, loss : 0.0316, accuracy : 98.98\n","iteration : 250, loss : 0.0320, accuracy : 98.93\n","iteration : 300, loss : 0.0329, accuracy : 98.90\n","iteration : 350, loss : 0.0341, accuracy : 98.88\n","Epoch :  68, training loss : 0.0337, training accuracy : 98.90, test loss : 0.3123, test accuracy : 94.18\n","\n","Epoch: 69\n","iteration :  50, loss : 0.0245, accuracy : 99.19\n","iteration : 100, loss : 0.0256, accuracy : 99.15\n","iteration : 150, loss : 0.0285, accuracy : 99.05\n","iteration : 200, loss : 0.0294, accuracy : 99.05\n","iteration : 250, loss : 0.0292, accuracy : 99.04\n","iteration : 300, loss : 0.0295, accuracy : 99.03\n","iteration : 350, loss : 0.0311, accuracy : 98.98\n","Epoch :  69, training loss : 0.0315, training accuracy : 98.97, test loss : 0.3266, test accuracy : 94.19\n","\n","Epoch: 70\n","iteration :  50, loss : 0.0359, accuracy : 98.91\n","iteration : 100, loss : 0.0315, accuracy : 99.03\n","iteration : 150, loss : 0.0309, accuracy : 99.07\n","iteration : 200, loss : 0.0299, accuracy : 99.07\n","iteration : 250, loss : 0.0297, accuracy : 99.07\n","iteration : 300, loss : 0.0301, accuracy : 99.04\n","iteration : 350, loss : 0.0306, accuracy : 99.00\n","Epoch :  70, training loss : 0.0309, training accuracy : 98.98, test loss : 0.3649, test accuracy : 94.03\n","\n","Epoch: 71\n","iteration :  50, loss : 0.0292, accuracy : 99.14\n","iteration : 100, loss : 0.0269, accuracy : 99.14\n","iteration : 150, loss : 0.0285, accuracy : 99.08\n","iteration : 200, loss : 0.0294, accuracy : 99.04\n","iteration : 250, loss : 0.0298, accuracy : 99.03\n","iteration : 300, loss : 0.0295, accuracy : 99.04\n","iteration : 350, loss : 0.0306, accuracy : 98.99\n","Epoch :  71, training loss : 0.0310, training accuracy : 98.98, test loss : 0.3290, test accuracy : 94.14\n","\n","Epoch: 72\n","iteration :  50, loss : 0.0308, accuracy : 99.08\n","iteration : 100, loss : 0.0317, accuracy : 99.01\n","iteration : 150, loss : 0.0284, accuracy : 99.08\n","iteration : 200, loss : 0.0285, accuracy : 99.06\n","iteration : 250, loss : 0.0278, accuracy : 99.11\n","iteration : 300, loss : 0.0292, accuracy : 99.09\n","iteration : 350, loss : 0.0303, accuracy : 99.04\n","Epoch :  72, training loss : 0.0303, training accuracy : 99.04, test loss : 0.3448, test accuracy : 93.90\n","\n","Epoch: 73\n","iteration :  50, loss : 0.0220, accuracy : 99.25\n","iteration : 100, loss : 0.0248, accuracy : 99.13\n","iteration : 150, loss : 0.0271, accuracy : 99.08\n","iteration : 200, loss : 0.0267, accuracy : 99.10\n","iteration : 250, loss : 0.0285, accuracy : 99.06\n","iteration : 300, loss : 0.0296, accuracy : 99.03\n","iteration : 350, loss : 0.0301, accuracy : 99.00\n","Epoch :  73, training loss : 0.0299, training accuracy : 99.01, test loss : 0.3452, test accuracy : 93.81\n","\n","Epoch: 74\n","iteration :  50, loss : 0.0323, accuracy : 98.94\n","iteration : 100, loss : 0.0295, accuracy : 99.00\n","iteration : 150, loss : 0.0279, accuracy : 99.06\n","iteration : 200, loss : 0.0259, accuracy : 99.15\n","iteration : 250, loss : 0.0252, accuracy : 99.16\n","iteration : 300, loss : 0.0262, accuracy : 99.14\n","iteration : 350, loss : 0.0262, accuracy : 99.12\n","Epoch :  74, training loss : 0.0265, training accuracy : 99.12, test loss : 0.3562, test accuracy : 93.93\n","\n","Epoch: 75\n","iteration :  50, loss : 0.0216, accuracy : 99.23\n","iteration : 100, loss : 0.0232, accuracy : 99.14\n","iteration : 150, loss : 0.0236, accuracy : 99.15\n","iteration : 200, loss : 0.0260, accuracy : 99.07\n","iteration : 250, loss : 0.0272, accuracy : 99.03\n","iteration : 300, loss : 0.0284, accuracy : 99.01\n","iteration : 350, loss : 0.0302, accuracy : 98.99\n","Epoch :  75, training loss : 0.0307, training accuracy : 98.99, test loss : 0.3455, test accuracy : 94.00\n","\n","Epoch: 76\n","iteration :  50, loss : 0.0243, accuracy : 99.17\n","iteration : 100, loss : 0.0247, accuracy : 99.19\n","iteration : 150, loss : 0.0254, accuracy : 99.15\n","iteration : 200, loss : 0.0256, accuracy : 99.14\n","iteration : 250, loss : 0.0250, accuracy : 99.17\n","iteration : 300, loss : 0.0256, accuracy : 99.12\n","iteration : 350, loss : 0.0263, accuracy : 99.12\n","Epoch :  76, training loss : 0.0268, training accuracy : 99.11, test loss : 0.3508, test accuracy : 93.98\n","\n","Epoch: 77\n","iteration :  50, loss : 0.0299, accuracy : 99.03\n","iteration : 100, loss : 0.0249, accuracy : 99.20\n","iteration : 150, loss : 0.0251, accuracy : 99.21\n","iteration : 200, loss : 0.0254, accuracy : 99.19\n","iteration : 250, loss : 0.0257, accuracy : 99.18\n","iteration : 300, loss : 0.0270, accuracy : 99.14\n","iteration : 350, loss : 0.0279, accuracy : 99.10\n","Epoch :  77, training loss : 0.0284, training accuracy : 99.09, test loss : 0.3557, test accuracy : 93.97\n","\n","Epoch: 78\n","iteration :  50, loss : 0.0371, accuracy : 98.83\n","iteration : 100, loss : 0.0342, accuracy : 98.91\n","iteration : 150, loss : 0.0313, accuracy : 99.01\n","iteration : 200, loss : 0.0310, accuracy : 99.00\n","iteration : 250, loss : 0.0304, accuracy : 99.02\n","iteration : 300, loss : 0.0293, accuracy : 99.04\n","iteration : 350, loss : 0.0290, accuracy : 99.06\n","Epoch :  78, training loss : 0.0290, training accuracy : 99.05, test loss : 0.3487, test accuracy : 94.06\n","\n","Epoch: 79\n","iteration :  50, loss : 0.0291, accuracy : 98.98\n","iteration : 100, loss : 0.0327, accuracy : 98.94\n","iteration : 150, loss : 0.0292, accuracy : 99.04\n","iteration : 200, loss : 0.0280, accuracy : 99.10\n","iteration : 250, loss : 0.0272, accuracy : 99.11\n","iteration : 300, loss : 0.0268, accuracy : 99.12\n","iteration : 350, loss : 0.0268, accuracy : 99.12\n","Epoch :  79, training loss : 0.0269, training accuracy : 99.12, test loss : 0.3626, test accuracy : 94.00\n","\n","Epoch: 80\n","iteration :  50, loss : 0.0232, accuracy : 99.30\n","iteration : 100, loss : 0.0233, accuracy : 99.27\n","iteration : 150, loss : 0.0227, accuracy : 99.27\n","iteration : 200, loss : 0.0225, accuracy : 99.29\n","iteration : 250, loss : 0.0234, accuracy : 99.26\n","iteration : 300, loss : 0.0242, accuracy : 99.24\n","iteration : 350, loss : 0.0258, accuracy : 99.20\n","Epoch :  80, training loss : 0.0258, training accuracy : 99.19, test loss : 0.3257, test accuracy : 94.26\n","\n","Epoch: 81\n","iteration :  50, loss : 0.0248, accuracy : 99.20\n","iteration : 100, loss : 0.0254, accuracy : 99.16\n","iteration : 150, loss : 0.0267, accuracy : 99.09\n","iteration : 200, loss : 0.0267, accuracy : 99.08\n","iteration : 250, loss : 0.0270, accuracy : 99.09\n","iteration : 300, loss : 0.0272, accuracy : 99.08\n","iteration : 350, loss : 0.0273, accuracy : 99.07\n","Epoch :  81, training loss : 0.0271, training accuracy : 99.09, test loss : 0.3328, test accuracy : 94.42\n","\n","Epoch: 82\n","iteration :  50, loss : 0.0219, accuracy : 99.30\n","iteration : 100, loss : 0.0236, accuracy : 99.23\n","iteration : 150, loss : 0.0248, accuracy : 99.16\n","iteration : 200, loss : 0.0250, accuracy : 99.17\n","iteration : 250, loss : 0.0267, accuracy : 99.11\n","iteration : 300, loss : 0.0266, accuracy : 99.10\n","iteration : 350, loss : 0.0267, accuracy : 99.10\n","Epoch :  82, training loss : 0.0269, training accuracy : 99.10, test loss : 0.3503, test accuracy : 94.02\n","\n","Epoch: 83\n","iteration :  50, loss : 0.0254, accuracy : 99.11\n","iteration : 100, loss : 0.0248, accuracy : 99.12\n","iteration : 150, loss : 0.0253, accuracy : 99.12\n","iteration : 200, loss : 0.0254, accuracy : 99.11\n","iteration : 250, loss : 0.0265, accuracy : 99.11\n","iteration : 300, loss : 0.0264, accuracy : 99.12\n","iteration : 350, loss : 0.0261, accuracy : 99.12\n","Epoch :  83, training loss : 0.0270, training accuracy : 99.09, test loss : 0.3597, test accuracy : 93.78\n","\n","Epoch: 84\n","iteration :  50, loss : 0.0244, accuracy : 99.09\n","iteration : 100, loss : 0.0219, accuracy : 99.23\n","iteration : 150, loss : 0.0227, accuracy : 99.19\n","iteration : 200, loss : 0.0243, accuracy : 99.16\n","iteration : 250, loss : 0.0263, accuracy : 99.09\n","iteration : 300, loss : 0.0263, accuracy : 99.11\n","iteration : 350, loss : 0.0262, accuracy : 99.13\n","Epoch :  84, training loss : 0.0264, training accuracy : 99.13, test loss : 0.3399, test accuracy : 94.15\n","\n","Epoch: 85\n","iteration :  50, loss : 0.0195, accuracy : 99.28\n","iteration : 100, loss : 0.0202, accuracy : 99.26\n","iteration : 150, loss : 0.0226, accuracy : 99.19\n","iteration : 200, loss : 0.0249, accuracy : 99.15\n","iteration : 250, loss : 0.0265, accuracy : 99.08\n","iteration : 300, loss : 0.0268, accuracy : 99.08\n","iteration : 350, loss : 0.0261, accuracy : 99.11\n","Epoch :  85, training loss : 0.0262, training accuracy : 99.11, test loss : 0.3275, test accuracy : 94.26\n","\n","Epoch: 86\n","iteration :  50, loss : 0.0187, accuracy : 99.45\n","iteration : 100, loss : 0.0205, accuracy : 99.41\n","iteration : 150, loss : 0.0185, accuracy : 99.48\n","iteration : 200, loss : 0.0180, accuracy : 99.47\n","iteration : 250, loss : 0.0180, accuracy : 99.47\n","iteration : 300, loss : 0.0191, accuracy : 99.42\n","iteration : 350, loss : 0.0208, accuracy : 99.36\n","Epoch :  86, training loss : 0.0213, training accuracy : 99.34, test loss : 0.3569, test accuracy : 94.05\n","\n","Epoch: 87\n","iteration :  50, loss : 0.0268, accuracy : 99.12\n","iteration : 100, loss : 0.0233, accuracy : 99.23\n","iteration : 150, loss : 0.0228, accuracy : 99.23\n","iteration : 200, loss : 0.0240, accuracy : 99.20\n","iteration : 250, loss : 0.0233, accuracy : 99.23\n","iteration : 300, loss : 0.0237, accuracy : 99.23\n","iteration : 350, loss : 0.0236, accuracy : 99.23\n","Epoch :  87, training loss : 0.0239, training accuracy : 99.23, test loss : 0.3664, test accuracy : 93.90\n","\n","Epoch: 88\n","iteration :  50, loss : 0.0227, accuracy : 99.28\n","iteration : 100, loss : 0.0223, accuracy : 99.25\n","iteration : 150, loss : 0.0221, accuracy : 99.22\n","iteration : 200, loss : 0.0214, accuracy : 99.24\n","iteration : 250, loss : 0.0220, accuracy : 99.22\n","iteration : 300, loss : 0.0221, accuracy : 99.23\n","iteration : 350, loss : 0.0227, accuracy : 99.19\n","Epoch :  88, training loss : 0.0234, training accuracy : 99.18, test loss : 0.3611, test accuracy : 93.97\n","\n","Epoch: 89\n","iteration :  50, loss : 0.0230, accuracy : 99.28\n","iteration : 100, loss : 0.0231, accuracy : 99.19\n","iteration : 150, loss : 0.0248, accuracy : 99.16\n","iteration : 200, loss : 0.0248, accuracy : 99.16\n","iteration : 250, loss : 0.0244, accuracy : 99.16\n","iteration : 300, loss : 0.0238, accuracy : 99.16\n","iteration : 350, loss : 0.0258, accuracy : 99.11\n","Epoch :  89, training loss : 0.0263, training accuracy : 99.10, test loss : 0.3437, test accuracy : 94.13\n","\n","Epoch: 90\n","iteration :  50, loss : 0.0321, accuracy : 98.95\n","iteration : 100, loss : 0.0281, accuracy : 99.13\n","iteration : 150, loss : 0.0264, accuracy : 99.14\n","iteration : 200, loss : 0.0268, accuracy : 99.15\n","iteration : 250, loss : 0.0259, accuracy : 99.19\n","iteration : 300, loss : 0.0253, accuracy : 99.17\n","iteration : 350, loss : 0.0248, accuracy : 99.18\n","Epoch :  90, training loss : 0.0244, training accuracy : 99.20, test loss : 0.3434, test accuracy : 94.41\n","\n","Epoch: 91\n","iteration :  50, loss : 0.0218, accuracy : 99.28\n","iteration : 100, loss : 0.0202, accuracy : 99.26\n","iteration : 150, loss : 0.0202, accuracy : 99.27\n","iteration : 200, loss : 0.0203, accuracy : 99.27\n","iteration : 250, loss : 0.0207, accuracy : 99.28\n","iteration : 300, loss : 0.0209, accuracy : 99.28\n","iteration : 350, loss : 0.0210, accuracy : 99.28\n","Epoch :  91, training loss : 0.0211, training accuracy : 99.27, test loss : 0.3388, test accuracy : 94.21\n","\n","Epoch: 92\n","iteration :  50, loss : 0.0232, accuracy : 99.12\n","iteration : 100, loss : 0.0232, accuracy : 99.16\n","iteration : 150, loss : 0.0213, accuracy : 99.24\n","iteration : 200, loss : 0.0214, accuracy : 99.25\n","iteration : 250, loss : 0.0213, accuracy : 99.27\n","iteration : 300, loss : 0.0220, accuracy : 99.25\n","iteration : 350, loss : 0.0224, accuracy : 99.24\n","Epoch :  92, training loss : 0.0226, training accuracy : 99.24, test loss : 0.3383, test accuracy : 94.31\n","\n","Epoch: 93\n","iteration :  50, loss : 0.0206, accuracy : 99.33\n","iteration : 100, loss : 0.0185, accuracy : 99.45\n","iteration : 150, loss : 0.0178, accuracy : 99.45\n","iteration : 200, loss : 0.0201, accuracy : 99.38\n","iteration : 250, loss : 0.0213, accuracy : 99.33\n","iteration : 300, loss : 0.0218, accuracy : 99.31\n","iteration : 350, loss : 0.0229, accuracy : 99.25\n","Epoch :  93, training loss : 0.0229, training accuracy : 99.25, test loss : 0.3589, test accuracy : 93.77\n","\n","Epoch: 94\n","iteration :  50, loss : 0.0216, accuracy : 99.22\n","iteration : 100, loss : 0.0221, accuracy : 99.23\n","iteration : 150, loss : 0.0259, accuracy : 99.10\n","iteration : 200, loss : 0.0272, accuracy : 99.06\n","iteration : 250, loss : 0.0268, accuracy : 99.06\n","iteration : 300, loss : 0.0263, accuracy : 99.08\n","iteration : 350, loss : 0.0266, accuracy : 99.08\n","Epoch :  94, training loss : 0.0267, training accuracy : 99.08, test loss : 0.3676, test accuracy : 93.86\n","\n","Epoch: 95\n","iteration :  50, loss : 0.0196, accuracy : 99.27\n","iteration : 100, loss : 0.0186, accuracy : 99.34\n","iteration : 150, loss : 0.0204, accuracy : 99.30\n","iteration : 200, loss : 0.0201, accuracy : 99.30\n","iteration : 250, loss : 0.0198, accuracy : 99.32\n","iteration : 300, loss : 0.0196, accuracy : 99.33\n","iteration : 350, loss : 0.0207, accuracy : 99.28\n","Epoch :  95, training loss : 0.0215, training accuracy : 99.27, test loss : 0.3818, test accuracy : 93.78\n","\n","Epoch: 96\n","iteration :  50, loss : 0.0265, accuracy : 99.14\n","iteration : 100, loss : 0.0227, accuracy : 99.25\n","iteration : 150, loss : 0.0209, accuracy : 99.28\n","iteration : 200, loss : 0.0197, accuracy : 99.34\n","iteration : 250, loss : 0.0215, accuracy : 99.28\n","iteration : 300, loss : 0.0219, accuracy : 99.26\n","iteration : 350, loss : 0.0223, accuracy : 99.25\n","Epoch :  96, training loss : 0.0226, training accuracy : 99.24, test loss : 0.3554, test accuracy : 94.22\n","\n","Epoch: 97\n","iteration :  50, loss : 0.0231, accuracy : 99.30\n","iteration : 100, loss : 0.0217, accuracy : 99.29\n","iteration : 150, loss : 0.0201, accuracy : 99.32\n","iteration : 200, loss : 0.0193, accuracy : 99.34\n","iteration : 250, loss : 0.0195, accuracy : 99.33\n","iteration : 300, loss : 0.0198, accuracy : 99.32\n","iteration : 350, loss : 0.0202, accuracy : 99.32\n","Epoch :  97, training loss : 0.0203, training accuracy : 99.31, test loss : 0.3528, test accuracy : 94.33\n","\n","Epoch: 98\n","iteration :  50, loss : 0.0124, accuracy : 99.62\n","iteration : 100, loss : 0.0159, accuracy : 99.44\n","iteration : 150, loss : 0.0173, accuracy : 99.40\n","iteration : 200, loss : 0.0167, accuracy : 99.43\n","iteration : 250, loss : 0.0164, accuracy : 99.44\n","iteration : 300, loss : 0.0179, accuracy : 99.37\n","iteration : 350, loss : 0.0189, accuracy : 99.33\n","Epoch :  98, training loss : 0.0192, training accuracy : 99.32, test loss : 0.3716, test accuracy : 93.97\n","\n","Epoch: 99\n","iteration :  50, loss : 0.0232, accuracy : 99.33\n","iteration : 100, loss : 0.0249, accuracy : 99.18\n","iteration : 150, loss : 0.0253, accuracy : 99.17\n","iteration : 200, loss : 0.0254, accuracy : 99.15\n","iteration : 250, loss : 0.0245, accuracy : 99.19\n","iteration : 300, loss : 0.0248, accuracy : 99.20\n","iteration : 350, loss : 0.0249, accuracy : 99.18\n","Epoch :  99, training loss : 0.0246, training accuracy : 99.19, test loss : 0.3585, test accuracy : 94.20\n","\n","Epoch: 100\n","iteration :  50, loss : 0.0231, accuracy : 99.27\n","iteration : 100, loss : 0.0244, accuracy : 99.23\n","iteration : 150, loss : 0.0230, accuracy : 99.24\n","iteration : 200, loss : 0.0218, accuracy : 99.26\n","iteration : 250, loss : 0.0213, accuracy : 99.27\n","iteration : 300, loss : 0.0224, accuracy : 99.24\n","iteration : 350, loss : 0.0223, accuracy : 99.24\n","Epoch : 100, training loss : 0.0219, training accuracy : 99.25, test loss : 0.3432, test accuracy : 94.43\n","\n","Epoch: 101\n","iteration :  50, loss : 0.0146, accuracy : 99.47\n","iteration : 100, loss : 0.0150, accuracy : 99.49\n","iteration : 150, loss : 0.0152, accuracy : 99.47\n","iteration : 200, loss : 0.0158, accuracy : 99.45\n","iteration : 250, loss : 0.0159, accuracy : 99.46\n","iteration : 300, loss : 0.0164, accuracy : 99.45\n","iteration : 350, loss : 0.0174, accuracy : 99.42\n","Epoch : 101, training loss : 0.0175, training accuracy : 99.41, test loss : 0.3687, test accuracy : 94.20\n","\n","Epoch: 102\n","iteration :  50, loss : 0.0183, accuracy : 99.36\n","iteration : 100, loss : 0.0173, accuracy : 99.41\n","iteration : 150, loss : 0.0176, accuracy : 99.44\n","iteration : 200, loss : 0.0190, accuracy : 99.38\n","iteration : 250, loss : 0.0192, accuracy : 99.38\n","iteration : 300, loss : 0.0185, accuracy : 99.39\n","iteration : 350, loss : 0.0190, accuracy : 99.38\n","Epoch : 102, training loss : 0.0193, training accuracy : 99.36, test loss : 0.3779, test accuracy : 94.18\n","\n","Epoch: 103\n","iteration :  50, loss : 0.0209, accuracy : 99.41\n","iteration : 100, loss : 0.0191, accuracy : 99.41\n","iteration : 150, loss : 0.0183, accuracy : 99.42\n","iteration : 200, loss : 0.0183, accuracy : 99.40\n","iteration : 250, loss : 0.0189, accuracy : 99.36\n","iteration : 300, loss : 0.0187, accuracy : 99.37\n","iteration : 350, loss : 0.0185, accuracy : 99.37\n","Epoch : 103, training loss : 0.0192, training accuracy : 99.35, test loss : 0.3841, test accuracy : 93.82\n","\n","Epoch: 104\n","iteration :  50, loss : 0.0194, accuracy : 99.30\n","iteration : 100, loss : 0.0244, accuracy : 99.16\n","iteration : 150, loss : 0.0260, accuracy : 99.11\n","iteration : 200, loss : 0.0272, accuracy : 99.11\n","iteration : 250, loss : 0.0257, accuracy : 99.12\n","iteration : 300, loss : 0.0254, accuracy : 99.12\n","iteration : 350, loss : 0.0247, accuracy : 99.16\n","Epoch : 104, training loss : 0.0245, training accuracy : 99.16, test loss : 0.3522, test accuracy : 94.38\n","\n","Epoch: 105\n","iteration :  50, loss : 0.0078, accuracy : 99.70\n","iteration : 100, loss : 0.0114, accuracy : 99.64\n","iteration : 150, loss : 0.0119, accuracy : 99.62\n","iteration : 200, loss : 0.0127, accuracy : 99.61\n","iteration : 250, loss : 0.0135, accuracy : 99.58\n","iteration : 300, loss : 0.0145, accuracy : 99.54\n","iteration : 350, loss : 0.0149, accuracy : 99.52\n","Epoch : 105, training loss : 0.0151, training accuracy : 99.52, test loss : 0.3621, test accuracy : 94.31\n","\n","Epoch: 106\n","iteration :  50, loss : 0.0111, accuracy : 99.56\n","iteration : 100, loss : 0.0122, accuracy : 99.55\n","iteration : 150, loss : 0.0160, accuracy : 99.47\n","iteration : 200, loss : 0.0172, accuracy : 99.42\n","iteration : 250, loss : 0.0184, accuracy : 99.38\n","iteration : 300, loss : 0.0196, accuracy : 99.34\n","iteration : 350, loss : 0.0201, accuracy : 99.33\n","Epoch : 106, training loss : 0.0204, training accuracy : 99.32, test loss : 0.3745, test accuracy : 94.13\n","\n","Epoch: 107\n","iteration :  50, loss : 0.0198, accuracy : 99.44\n","iteration : 100, loss : 0.0199, accuracy : 99.43\n","iteration : 150, loss : 0.0206, accuracy : 99.39\n","iteration : 200, loss : 0.0215, accuracy : 99.32\n","iteration : 250, loss : 0.0216, accuracy : 99.31\n","iteration : 300, loss : 0.0216, accuracy : 99.30\n","iteration : 350, loss : 0.0223, accuracy : 99.27\n","Epoch : 107, training loss : 0.0220, training accuracy : 99.28, test loss : 0.3749, test accuracy : 94.18\n","\n","Epoch: 108\n","iteration :  50, loss : 0.0183, accuracy : 99.36\n","iteration : 100, loss : 0.0161, accuracy : 99.46\n","iteration : 150, loss : 0.0166, accuracy : 99.44\n","iteration : 200, loss : 0.0172, accuracy : 99.42\n","iteration : 250, loss : 0.0182, accuracy : 99.40\n","iteration : 300, loss : 0.0189, accuracy : 99.38\n","iteration : 350, loss : 0.0187, accuracy : 99.38\n","Epoch : 108, training loss : 0.0188, training accuracy : 99.37, test loss : 0.3660, test accuracy : 94.28\n","\n","Epoch: 109\n","iteration :  50, loss : 0.0180, accuracy : 99.39\n","iteration : 100, loss : 0.0193, accuracy : 99.34\n","iteration : 150, loss : 0.0201, accuracy : 99.31\n","iteration : 200, loss : 0.0206, accuracy : 99.29\n","iteration : 250, loss : 0.0196, accuracy : 99.32\n","iteration : 300, loss : 0.0192, accuracy : 99.34\n","iteration : 350, loss : 0.0195, accuracy : 99.34\n","Epoch : 109, training loss : 0.0194, training accuracy : 99.35, test loss : 0.3686, test accuracy : 94.15\n","\n","Epoch: 110\n","iteration :  50, loss : 0.0172, accuracy : 99.44\n","iteration : 100, loss : 0.0179, accuracy : 99.44\n","iteration : 150, loss : 0.0161, accuracy : 99.48\n","iteration : 200, loss : 0.0167, accuracy : 99.47\n","iteration : 250, loss : 0.0180, accuracy : 99.40\n","iteration : 300, loss : 0.0194, accuracy : 99.36\n","iteration : 350, loss : 0.0195, accuracy : 99.36\n","Epoch : 110, training loss : 0.0191, training accuracy : 99.37, test loss : 0.3717, test accuracy : 94.31\n","\n","Epoch: 111\n","iteration :  50, loss : 0.0146, accuracy : 99.36\n","iteration : 100, loss : 0.0160, accuracy : 99.37\n","iteration : 150, loss : 0.0162, accuracy : 99.36\n","iteration : 200, loss : 0.0166, accuracy : 99.37\n","iteration : 250, loss : 0.0169, accuracy : 99.39\n","iteration : 300, loss : 0.0174, accuracy : 99.37\n","iteration : 350, loss : 0.0179, accuracy : 99.36\n","Epoch : 111, training loss : 0.0178, training accuracy : 99.36, test loss : 0.3697, test accuracy : 94.41\n","\n","Epoch: 112\n","iteration :  50, loss : 0.0142, accuracy : 99.47\n","iteration : 100, loss : 0.0166, accuracy : 99.43\n","iteration : 150, loss : 0.0170, accuracy : 99.40\n","iteration : 200, loss : 0.0175, accuracy : 99.39\n","iteration : 250, loss : 0.0174, accuracy : 99.39\n","iteration : 300, loss : 0.0179, accuracy : 99.40\n","iteration : 350, loss : 0.0178, accuracy : 99.41\n","Epoch : 112, training loss : 0.0174, training accuracy : 99.43, test loss : 0.3781, test accuracy : 94.35\n","\n","Epoch: 113\n","iteration :  50, loss : 0.0150, accuracy : 99.59\n","iteration : 100, loss : 0.0167, accuracy : 99.46\n","iteration : 150, loss : 0.0177, accuracy : 99.40\n","iteration : 200, loss : 0.0194, accuracy : 99.34\n","iteration : 250, loss : 0.0194, accuracy : 99.31\n","iteration : 300, loss : 0.0212, accuracy : 99.25\n","iteration : 350, loss : 0.0219, accuracy : 99.23\n","Epoch : 113, training loss : 0.0218, training accuracy : 99.22, test loss : 0.3566, test accuracy : 94.10\n","\n","Epoch: 114\n","iteration :  50, loss : 0.0206, accuracy : 99.27\n","iteration : 100, loss : 0.0198, accuracy : 99.34\n","iteration : 150, loss : 0.0191, accuracy : 99.38\n","iteration : 200, loss : 0.0181, accuracy : 99.41\n","iteration : 250, loss : 0.0185, accuracy : 99.41\n","iteration : 300, loss : 0.0183, accuracy : 99.41\n","iteration : 350, loss : 0.0179, accuracy : 99.42\n","Epoch : 114, training loss : 0.0179, training accuracy : 99.42, test loss : 0.3536, test accuracy : 94.33\n","\n","Epoch: 115\n","iteration :  50, loss : 0.0122, accuracy : 99.56\n","iteration : 100, loss : 0.0117, accuracy : 99.60\n","iteration : 150, loss : 0.0137, accuracy : 99.54\n","iteration : 200, loss : 0.0158, accuracy : 99.48\n","iteration : 250, loss : 0.0169, accuracy : 99.42\n","iteration : 300, loss : 0.0164, accuracy : 99.45\n","iteration : 350, loss : 0.0175, accuracy : 99.41\n","Epoch : 115, training loss : 0.0180, training accuracy : 99.39, test loss : 0.4062, test accuracy : 93.75\n","\n","Epoch: 116\n","iteration :  50, loss : 0.0195, accuracy : 99.36\n","iteration : 100, loss : 0.0176, accuracy : 99.41\n","iteration : 150, loss : 0.0182, accuracy : 99.41\n","iteration : 200, loss : 0.0168, accuracy : 99.45\n","iteration : 250, loss : 0.0166, accuracy : 99.46\n","iteration : 300, loss : 0.0162, accuracy : 99.47\n","iteration : 350, loss : 0.0165, accuracy : 99.46\n","Epoch : 116, training loss : 0.0164, training accuracy : 99.46, test loss : 0.3737, test accuracy : 94.24\n","\n","Epoch: 117\n","iteration :  50, loss : 0.0147, accuracy : 99.50\n","iteration : 100, loss : 0.0183, accuracy : 99.39\n","iteration : 150, loss : 0.0179, accuracy : 99.40\n","iteration : 200, loss : 0.0178, accuracy : 99.40\n","iteration : 250, loss : 0.0176, accuracy : 99.39\n","iteration : 300, loss : 0.0176, accuracy : 99.39\n","iteration : 350, loss : 0.0178, accuracy : 99.40\n","Epoch : 117, training loss : 0.0178, training accuracy : 99.39, test loss : 0.3697, test accuracy : 94.29\n","\n","Epoch: 118\n","iteration :  50, loss : 0.0131, accuracy : 99.61\n","iteration : 100, loss : 0.0187, accuracy : 99.39\n","iteration : 150, loss : 0.0187, accuracy : 99.38\n","iteration : 200, loss : 0.0193, accuracy : 99.33\n","iteration : 250, loss : 0.0189, accuracy : 99.36\n","iteration : 300, loss : 0.0192, accuracy : 99.32\n","iteration : 350, loss : 0.0190, accuracy : 99.33\n","Epoch : 118, training loss : 0.0190, training accuracy : 99.34, test loss : 0.3746, test accuracy : 93.95\n","\n","Epoch: 119\n","iteration :  50, loss : 0.0129, accuracy : 99.56\n","iteration : 100, loss : 0.0143, accuracy : 99.52\n","iteration : 150, loss : 0.0138, accuracy : 99.55\n","iteration : 200, loss : 0.0128, accuracy : 99.58\n","iteration : 250, loss : 0.0140, accuracy : 99.53\n","iteration : 300, loss : 0.0149, accuracy : 99.51\n","iteration : 350, loss : 0.0150, accuracy : 99.50\n","Epoch : 119, training loss : 0.0158, training accuracy : 99.48, test loss : 0.4071, test accuracy : 93.89\n","\n","Epoch: 120\n","iteration :  50, loss : 0.0202, accuracy : 99.50\n","iteration : 100, loss : 0.0195, accuracy : 99.38\n","iteration : 150, loss : 0.0225, accuracy : 99.31\n","iteration : 200, loss : 0.0215, accuracy : 99.33\n","iteration : 250, loss : 0.0209, accuracy : 99.35\n","iteration : 300, loss : 0.0213, accuracy : 99.33\n","iteration : 350, loss : 0.0221, accuracy : 99.30\n","Epoch : 120, training loss : 0.0226, training accuracy : 99.28, test loss : 0.3882, test accuracy : 93.83\n","\n","Epoch: 121\n","iteration :  50, loss : 0.0215, accuracy : 99.31\n","iteration : 100, loss : 0.0212, accuracy : 99.35\n","iteration : 150, loss : 0.0205, accuracy : 99.33\n","iteration : 200, loss : 0.0210, accuracy : 99.32\n","iteration : 250, loss : 0.0197, accuracy : 99.35\n","iteration : 300, loss : 0.0198, accuracy : 99.36\n","iteration : 350, loss : 0.0195, accuracy : 99.36\n","Epoch : 121, training loss : 0.0193, training accuracy : 99.36, test loss : 0.3734, test accuracy : 94.08\n","\n","Epoch: 122\n","iteration :  50, loss : 0.0102, accuracy : 99.70\n","iteration : 100, loss : 0.0117, accuracy : 99.66\n","iteration : 150, loss : 0.0141, accuracy : 99.57\n","iteration : 200, loss : 0.0141, accuracy : 99.58\n","iteration : 250, loss : 0.0141, accuracy : 99.59\n","iteration : 300, loss : 0.0142, accuracy : 99.58\n","iteration : 350, loss : 0.0147, accuracy : 99.56\n","Epoch : 122, training loss : 0.0148, training accuracy : 99.56, test loss : 0.3670, test accuracy : 94.37\n","\n","Epoch: 123\n","iteration :  50, loss : 0.0095, accuracy : 99.67\n","iteration : 100, loss : 0.0112, accuracy : 99.59\n","iteration : 150, loss : 0.0119, accuracy : 99.54\n","iteration : 200, loss : 0.0128, accuracy : 99.55\n","iteration : 250, loss : 0.0129, accuracy : 99.55\n","iteration : 300, loss : 0.0141, accuracy : 99.54\n","iteration : 350, loss : 0.0149, accuracy : 99.51\n","Epoch : 123, training loss : 0.0150, training accuracy : 99.50, test loss : 0.3697, test accuracy : 94.17\n","\n","Epoch: 124\n","iteration :  50, loss : 0.0178, accuracy : 99.39\n","iteration : 100, loss : 0.0170, accuracy : 99.42\n","iteration : 150, loss : 0.0188, accuracy : 99.38\n","iteration : 200, loss : 0.0187, accuracy : 99.41\n","iteration : 250, loss : 0.0182, accuracy : 99.41\n","iteration : 300, loss : 0.0187, accuracy : 99.39\n","iteration : 350, loss : 0.0185, accuracy : 99.40\n","Epoch : 124, training loss : 0.0185, training accuracy : 99.42, test loss : 0.3702, test accuracy : 94.45\n","\n","Epoch: 125\n","iteration :  50, loss : 0.0136, accuracy : 99.55\n","iteration : 100, loss : 0.0174, accuracy : 99.45\n","iteration : 150, loss : 0.0187, accuracy : 99.41\n","iteration : 200, loss : 0.0189, accuracy : 99.37\n","iteration : 250, loss : 0.0193, accuracy : 99.35\n","iteration : 300, loss : 0.0187, accuracy : 99.36\n","iteration : 350, loss : 0.0179, accuracy : 99.39\n","Epoch : 125, training loss : 0.0181, training accuracy : 99.39, test loss : 0.3819, test accuracy : 94.15\n","\n","Epoch: 126\n","iteration :  50, loss : 0.0144, accuracy : 99.48\n","iteration : 100, loss : 0.0127, accuracy : 99.57\n","iteration : 150, loss : 0.0132, accuracy : 99.55\n","iteration : 200, loss : 0.0138, accuracy : 99.55\n","iteration : 250, loss : 0.0135, accuracy : 99.57\n","iteration : 300, loss : 0.0138, accuracy : 99.57\n","iteration : 350, loss : 0.0138, accuracy : 99.56\n","Epoch : 126, training loss : 0.0141, training accuracy : 99.55, test loss : 0.3749, test accuracy : 94.38\n","\n","Epoch: 127\n","iteration :  50, loss : 0.0129, accuracy : 99.55\n","iteration : 100, loss : 0.0141, accuracy : 99.52\n","iteration : 150, loss : 0.0145, accuracy : 99.53\n","iteration : 200, loss : 0.0150, accuracy : 99.52\n","iteration : 250, loss : 0.0149, accuracy : 99.53\n","iteration : 300, loss : 0.0154, accuracy : 99.51\n","iteration : 350, loss : 0.0157, accuracy : 99.50\n","Epoch : 127, training loss : 0.0160, training accuracy : 99.49, test loss : 0.3891, test accuracy : 94.22\n","\n","Epoch: 128\n","iteration :  50, loss : 0.0169, accuracy : 99.30\n","iteration : 100, loss : 0.0168, accuracy : 99.36\n","iteration : 150, loss : 0.0169, accuracy : 99.39\n","iteration : 200, loss : 0.0172, accuracy : 99.41\n","iteration : 250, loss : 0.0177, accuracy : 99.39\n","iteration : 300, loss : 0.0180, accuracy : 99.40\n","iteration : 350, loss : 0.0183, accuracy : 99.37\n","Epoch : 128, training loss : 0.0181, training accuracy : 99.38, test loss : 0.3678, test accuracy : 94.22\n","\n","Epoch: 129\n","iteration :  50, loss : 0.0113, accuracy : 99.56\n","iteration : 100, loss : 0.0154, accuracy : 99.48\n","iteration : 150, loss : 0.0160, accuracy : 99.46\n","iteration : 200, loss : 0.0158, accuracy : 99.48\n","iteration : 250, loss : 0.0159, accuracy : 99.47\n","iteration : 300, loss : 0.0161, accuracy : 99.47\n","iteration : 350, loss : 0.0164, accuracy : 99.47\n","Epoch : 129, training loss : 0.0161, training accuracy : 99.48, test loss : 0.3668, test accuracy : 94.53\n","\n","Epoch: 130\n","iteration :  50, loss : 0.0120, accuracy : 99.62\n","iteration : 100, loss : 0.0124, accuracy : 99.59\n","iteration : 150, loss : 0.0138, accuracy : 99.55\n","iteration : 200, loss : 0.0140, accuracy : 99.54\n","iteration : 250, loss : 0.0148, accuracy : 99.52\n","iteration : 300, loss : 0.0150, accuracy : 99.52\n","iteration : 350, loss : 0.0150, accuracy : 99.51\n","Epoch : 130, training loss : 0.0148, training accuracy : 99.52, test loss : 0.3927, test accuracy : 94.15\n","\n","Epoch: 131\n","iteration :  50, loss : 0.0111, accuracy : 99.62\n","iteration : 100, loss : 0.0114, accuracy : 99.63\n","iteration : 150, loss : 0.0127, accuracy : 99.60\n","iteration : 200, loss : 0.0118, accuracy : 99.63\n","iteration : 250, loss : 0.0123, accuracy : 99.61\n","iteration : 300, loss : 0.0126, accuracy : 99.60\n","iteration : 350, loss : 0.0139, accuracy : 99.56\n","Epoch : 131, training loss : 0.0139, training accuracy : 99.55, test loss : 0.4038, test accuracy : 94.16\n","\n","Epoch: 132\n","iteration :  50, loss : 0.0148, accuracy : 99.52\n","iteration : 100, loss : 0.0180, accuracy : 99.41\n","iteration : 150, loss : 0.0171, accuracy : 99.46\n","iteration : 200, loss : 0.0168, accuracy : 99.47\n","iteration : 250, loss : 0.0177, accuracy : 99.44\n","iteration : 300, loss : 0.0175, accuracy : 99.45\n","iteration : 350, loss : 0.0183, accuracy : 99.42\n","Epoch : 132, training loss : 0.0181, training accuracy : 99.42, test loss : 0.4014, test accuracy : 93.91\n","\n","Epoch: 133\n","iteration :  50, loss : 0.0211, accuracy : 99.23\n","iteration : 100, loss : 0.0186, accuracy : 99.37\n","iteration : 150, loss : 0.0178, accuracy : 99.42\n","iteration : 200, loss : 0.0176, accuracy : 99.43\n","iteration : 250, loss : 0.0170, accuracy : 99.47\n","iteration : 300, loss : 0.0167, accuracy : 99.48\n","iteration : 350, loss : 0.0172, accuracy : 99.46\n","Epoch : 133, training loss : 0.0173, training accuracy : 99.45, test loss : 0.3804, test accuracy : 93.98\n","\n","Epoch: 134\n","iteration :  50, loss : 0.0201, accuracy : 99.25\n","iteration : 100, loss : 0.0188, accuracy : 99.33\n","iteration : 150, loss : 0.0181, accuracy : 99.32\n","iteration : 200, loss : 0.0166, accuracy : 99.41\n","iteration : 250, loss : 0.0161, accuracy : 99.43\n","iteration : 300, loss : 0.0148, accuracy : 99.48\n","iteration : 350, loss : 0.0142, accuracy : 99.52\n","Epoch : 134, training loss : 0.0143, training accuracy : 99.52, test loss : 0.3879, test accuracy : 94.28\n","\n","Epoch: 135\n","iteration :  50, loss : 0.0142, accuracy : 99.48\n","iteration : 100, loss : 0.0171, accuracy : 99.43\n","iteration : 150, loss : 0.0173, accuracy : 99.43\n","iteration : 200, loss : 0.0157, accuracy : 99.46\n","iteration : 250, loss : 0.0150, accuracy : 99.49\n","iteration : 300, loss : 0.0145, accuracy : 99.51\n","iteration : 350, loss : 0.0153, accuracy : 99.49\n","Epoch : 135, training loss : 0.0157, training accuracy : 99.47, test loss : 0.3762, test accuracy : 94.20\n","\n","Epoch: 136\n","iteration :  50, loss : 0.0174, accuracy : 99.34\n","iteration : 100, loss : 0.0201, accuracy : 99.23\n","iteration : 150, loss : 0.0188, accuracy : 99.31\n","iteration : 200, loss : 0.0185, accuracy : 99.32\n","iteration : 250, loss : 0.0181, accuracy : 99.36\n","iteration : 300, loss : 0.0173, accuracy : 99.40\n","iteration : 350, loss : 0.0167, accuracy : 99.42\n","Epoch : 136, training loss : 0.0166, training accuracy : 99.42, test loss : 0.3729, test accuracy : 94.21\n","\n","Epoch: 137\n","iteration :  50, loss : 0.0119, accuracy : 99.58\n","iteration : 100, loss : 0.0140, accuracy : 99.55\n","iteration : 150, loss : 0.0135, accuracy : 99.56\n","iteration : 200, loss : 0.0139, accuracy : 99.56\n","iteration : 250, loss : 0.0138, accuracy : 99.55\n","iteration : 300, loss : 0.0142, accuracy : 99.53\n","iteration : 350, loss : 0.0142, accuracy : 99.53\n","Epoch : 137, training loss : 0.0143, training accuracy : 99.53, test loss : 0.3661, test accuracy : 94.33\n","\n","Epoch: 138\n","iteration :  50, loss : 0.0173, accuracy : 99.45\n","iteration : 100, loss : 0.0154, accuracy : 99.45\n","iteration : 150, loss : 0.0169, accuracy : 99.43\n","iteration : 200, loss : 0.0152, accuracy : 99.49\n","iteration : 250, loss : 0.0147, accuracy : 99.51\n","iteration : 300, loss : 0.0161, accuracy : 99.46\n","iteration : 350, loss : 0.0168, accuracy : 99.43\n","Epoch : 138, training loss : 0.0170, training accuracy : 99.41, test loss : 0.3800, test accuracy : 93.98\n","\n","Epoch: 139\n","iteration :  50, loss : 0.0166, accuracy : 99.44\n","iteration : 100, loss : 0.0163, accuracy : 99.45\n","iteration : 150, loss : 0.0154, accuracy : 99.46\n","iteration : 200, loss : 0.0141, accuracy : 99.52\n","iteration : 250, loss : 0.0138, accuracy : 99.53\n","iteration : 300, loss : 0.0143, accuracy : 99.50\n","iteration : 350, loss : 0.0144, accuracy : 99.49\n","Epoch : 139, training loss : 0.0146, training accuracy : 99.49, test loss : 0.3786, test accuracy : 94.19\n","\n","Epoch: 140\n","iteration :  50, loss : 0.0129, accuracy : 99.59\n","iteration : 100, loss : 0.0129, accuracy : 99.57\n","iteration : 150, loss : 0.0121, accuracy : 99.58\n","iteration : 200, loss : 0.0139, accuracy : 99.54\n","iteration : 250, loss : 0.0146, accuracy : 99.54\n","iteration : 300, loss : 0.0161, accuracy : 99.49\n","iteration : 350, loss : 0.0168, accuracy : 99.47\n","Epoch : 140, training loss : 0.0168, training accuracy : 99.47, test loss : 0.3903, test accuracy : 94.03\n","\n","Epoch: 141\n","iteration :  50, loss : 0.0155, accuracy : 99.39\n","iteration : 100, loss : 0.0160, accuracy : 99.45\n","iteration : 150, loss : 0.0152, accuracy : 99.48\n","iteration : 200, loss : 0.0135, accuracy : 99.54\n","iteration : 250, loss : 0.0136, accuracy : 99.53\n","iteration : 300, loss : 0.0135, accuracy : 99.53\n","iteration : 350, loss : 0.0140, accuracy : 99.52\n","Epoch : 141, training loss : 0.0137, training accuracy : 99.53, test loss : 0.3959, test accuracy : 94.28\n","\n","Epoch: 142\n","iteration :  50, loss : 0.0090, accuracy : 99.72\n","iteration : 100, loss : 0.0093, accuracy : 99.67\n","iteration : 150, loss : 0.0095, accuracy : 99.65\n","iteration : 200, loss : 0.0105, accuracy : 99.64\n","iteration : 250, loss : 0.0114, accuracy : 99.62\n","iteration : 300, loss : 0.0119, accuracy : 99.60\n","iteration : 350, loss : 0.0125, accuracy : 99.58\n","Epoch : 142, training loss : 0.0125, training accuracy : 99.57, test loss : 0.4233, test accuracy : 93.83\n","\n","Epoch: 143\n","iteration :  50, loss : 0.0146, accuracy : 99.52\n","iteration : 100, loss : 0.0155, accuracy : 99.48\n","iteration : 150, loss : 0.0159, accuracy : 99.52\n","iteration : 200, loss : 0.0145, accuracy : 99.54\n","iteration : 250, loss : 0.0153, accuracy : 99.51\n","iteration : 300, loss : 0.0157, accuracy : 99.49\n","iteration : 350, loss : 0.0155, accuracy : 99.49\n","Epoch : 143, training loss : 0.0155, training accuracy : 99.49, test loss : 0.4184, test accuracy : 94.12\n","\n","Epoch: 144\n","iteration :  50, loss : 0.0098, accuracy : 99.62\n","iteration : 100, loss : 0.0117, accuracy : 99.58\n","iteration : 150, loss : 0.0128, accuracy : 99.55\n","iteration : 200, loss : 0.0125, accuracy : 99.55\n","iteration : 250, loss : 0.0130, accuracy : 99.55\n","iteration : 300, loss : 0.0131, accuracy : 99.54\n","iteration : 350, loss : 0.0133, accuracy : 99.54\n","Epoch : 144, training loss : 0.0136, training accuracy : 99.54, test loss : 0.4038, test accuracy : 94.02\n","\n","Epoch: 145\n","iteration :  50, loss : 0.0163, accuracy : 99.47\n","iteration : 100, loss : 0.0145, accuracy : 99.55\n","iteration : 150, loss : 0.0154, accuracy : 99.51\n","iteration : 200, loss : 0.0159, accuracy : 99.50\n","iteration : 250, loss : 0.0162, accuracy : 99.48\n","iteration : 300, loss : 0.0152, accuracy : 99.51\n","iteration : 350, loss : 0.0151, accuracy : 99.50\n","Epoch : 145, training loss : 0.0151, training accuracy : 99.50, test loss : 0.3937, test accuracy : 94.13\n","\n","Epoch: 146\n","iteration :  50, loss : 0.0201, accuracy : 99.30\n","iteration : 100, loss : 0.0179, accuracy : 99.38\n","iteration : 150, loss : 0.0157, accuracy : 99.46\n","iteration : 200, loss : 0.0159, accuracy : 99.46\n","iteration : 250, loss : 0.0158, accuracy : 99.48\n","iteration : 300, loss : 0.0150, accuracy : 99.50\n","iteration : 350, loss : 0.0145, accuracy : 99.50\n","Epoch : 146, training loss : 0.0145, training accuracy : 99.50, test loss : 0.4071, test accuracy : 94.09\n","\n","Epoch: 147\n","iteration :  50, loss : 0.0175, accuracy : 99.39\n","iteration : 100, loss : 0.0171, accuracy : 99.41\n","iteration : 150, loss : 0.0179, accuracy : 99.42\n","iteration : 200, loss : 0.0167, accuracy : 99.44\n","iteration : 250, loss : 0.0153, accuracy : 99.50\n","iteration : 300, loss : 0.0147, accuracy : 99.53\n","iteration : 350, loss : 0.0145, accuracy : 99.53\n","Epoch : 147, training loss : 0.0144, training accuracy : 99.53, test loss : 0.3832, test accuracy : 94.53\n","\n","Epoch: 148\n","iteration :  50, loss : 0.0090, accuracy : 99.64\n","iteration : 100, loss : 0.0104, accuracy : 99.65\n","iteration : 150, loss : 0.0104, accuracy : 99.66\n","iteration : 200, loss : 0.0112, accuracy : 99.65\n","iteration : 250, loss : 0.0113, accuracy : 99.64\n","iteration : 300, loss : 0.0112, accuracy : 99.63\n","iteration : 350, loss : 0.0116, accuracy : 99.62\n","Epoch : 148, training loss : 0.0117, training accuracy : 99.62, test loss : 0.3994, test accuracy : 94.09\n","\n","Epoch: 149\n","iteration :  50, loss : 0.0154, accuracy : 99.50\n","iteration : 100, loss : 0.0191, accuracy : 99.38\n","iteration : 150, loss : 0.0169, accuracy : 99.45\n","iteration : 200, loss : 0.0168, accuracy : 99.45\n","iteration : 250, loss : 0.0156, accuracy : 99.46\n","iteration : 300, loss : 0.0153, accuracy : 99.47\n","iteration : 350, loss : 0.0156, accuracy : 99.47\n","Epoch : 149, training loss : 0.0161, training accuracy : 99.46, test loss : 0.4123, test accuracy : 94.03\n","\n","Epoch: 150\n","iteration :  50, loss : 0.0106, accuracy : 99.62\n","iteration : 100, loss : 0.0111, accuracy : 99.60\n","iteration : 150, loss : 0.0099, accuracy : 99.67\n","iteration : 200, loss : 0.0099, accuracy : 99.65\n","iteration : 250, loss : 0.0108, accuracy : 99.63\n","iteration : 300, loss : 0.0112, accuracy : 99.63\n","iteration : 350, loss : 0.0120, accuracy : 99.60\n","Epoch : 150, training loss : 0.0119, training accuracy : 99.60, test loss : 0.4056, test accuracy : 94.33\n","\n","Epoch: 151\n","iteration :  50, loss : 0.0088, accuracy : 99.66\n","iteration : 100, loss : 0.0109, accuracy : 99.59\n","iteration : 150, loss : 0.0112, accuracy : 99.60\n","iteration : 200, loss : 0.0113, accuracy : 99.61\n","iteration : 250, loss : 0.0117, accuracy : 99.59\n","iteration : 300, loss : 0.0125, accuracy : 99.56\n","iteration : 350, loss : 0.0123, accuracy : 99.56\n","Epoch : 151, training loss : 0.0125, training accuracy : 99.55, test loss : 0.3918, test accuracy : 94.31\n","\n","Epoch: 152\n","iteration :  50, loss : 0.0181, accuracy : 99.41\n","iteration : 100, loss : 0.0177, accuracy : 99.41\n","iteration : 150, loss : 0.0161, accuracy : 99.47\n","iteration : 200, loss : 0.0160, accuracy : 99.49\n","iteration : 250, loss : 0.0154, accuracy : 99.50\n","iteration : 300, loss : 0.0145, accuracy : 99.53\n","iteration : 350, loss : 0.0140, accuracy : 99.54\n","Epoch : 152, training loss : 0.0136, training accuracy : 99.56, test loss : 0.3998, test accuracy : 94.43\n","\n","Epoch: 153\n","iteration :  50, loss : 0.0122, accuracy : 99.58\n","iteration : 100, loss : 0.0103, accuracy : 99.68\n","iteration : 150, loss : 0.0124, accuracy : 99.59\n","iteration : 200, loss : 0.0137, accuracy : 99.54\n","iteration : 250, loss : 0.0146, accuracy : 99.52\n","iteration : 300, loss : 0.0159, accuracy : 99.48\n","iteration : 350, loss : 0.0156, accuracy : 99.49\n","Epoch : 153, training loss : 0.0159, training accuracy : 99.47, test loss : 0.3857, test accuracy : 94.40\n","\n","Epoch: 154\n","iteration :  50, loss : 0.0158, accuracy : 99.56\n","iteration : 100, loss : 0.0149, accuracy : 99.55\n","iteration : 150, loss : 0.0139, accuracy : 99.57\n","iteration : 200, loss : 0.0137, accuracy : 99.56\n","iteration : 250, loss : 0.0132, accuracy : 99.59\n","iteration : 300, loss : 0.0127, accuracy : 99.59\n","iteration : 350, loss : 0.0117, accuracy : 99.62\n","Epoch : 154, training loss : 0.0116, training accuracy : 99.63, test loss : 0.3893, test accuracy : 94.42\n","\n","Epoch: 155\n","iteration :  50, loss : 0.0079, accuracy : 99.77\n","iteration : 100, loss : 0.0116, accuracy : 99.67\n","iteration : 150, loss : 0.0106, accuracy : 99.70\n","iteration : 200, loss : 0.0103, accuracy : 99.69\n","iteration : 250, loss : 0.0099, accuracy : 99.68\n","iteration : 300, loss : 0.0094, accuracy : 99.69\n","iteration : 350, loss : 0.0095, accuracy : 99.69\n","Epoch : 155, training loss : 0.0098, training accuracy : 99.68, test loss : 0.4581, test accuracy : 94.00\n","\n","Epoch: 156\n","iteration :  50, loss : 0.0132, accuracy : 99.59\n","iteration : 100, loss : 0.0127, accuracy : 99.59\n","iteration : 150, loss : 0.0126, accuracy : 99.64\n","iteration : 200, loss : 0.0126, accuracy : 99.62\n","iteration : 250, loss : 0.0127, accuracy : 99.61\n","iteration : 300, loss : 0.0125, accuracy : 99.60\n","iteration : 350, loss : 0.0132, accuracy : 99.57\n","Epoch : 156, training loss : 0.0134, training accuracy : 99.57, test loss : 0.4118, test accuracy : 94.17\n","\n","Epoch: 157\n","iteration :  50, loss : 0.0124, accuracy : 99.55\n","iteration : 100, loss : 0.0135, accuracy : 99.51\n","iteration : 150, loss : 0.0142, accuracy : 99.47\n","iteration : 200, loss : 0.0142, accuracy : 99.49\n","iteration : 250, loss : 0.0162, accuracy : 99.44\n","iteration : 300, loss : 0.0173, accuracy : 99.41\n","iteration : 350, loss : 0.0161, accuracy : 99.45\n","Epoch : 157, training loss : 0.0158, training accuracy : 99.46, test loss : 0.3847, test accuracy : 94.35\n","\n","Epoch: 158\n","iteration :  50, loss : 0.0149, accuracy : 99.42\n","iteration : 100, loss : 0.0135, accuracy : 99.52\n","iteration : 150, loss : 0.0142, accuracy : 99.51\n","iteration : 200, loss : 0.0156, accuracy : 99.49\n","iteration : 250, loss : 0.0157, accuracy : 99.50\n","iteration : 300, loss : 0.0150, accuracy : 99.52\n","iteration : 350, loss : 0.0144, accuracy : 99.54\n","Epoch : 158, training loss : 0.0144, training accuracy : 99.53, test loss : 0.3895, test accuracy : 94.23\n","\n","Epoch: 159\n","iteration :  50, loss : 0.0149, accuracy : 99.50\n","iteration : 100, loss : 0.0141, accuracy : 99.51\n","iteration : 150, loss : 0.0142, accuracy : 99.49\n","iteration : 200, loss : 0.0150, accuracy : 99.46\n","iteration : 250, loss : 0.0152, accuracy : 99.47\n","iteration : 300, loss : 0.0149, accuracy : 99.48\n","iteration : 350, loss : 0.0141, accuracy : 99.50\n","Epoch : 159, training loss : 0.0140, training accuracy : 99.51, test loss : 0.3886, test accuracy : 94.26\n","\n","Epoch: 160\n","iteration :  50, loss : 0.0116, accuracy : 99.59\n","iteration : 100, loss : 0.0101, accuracy : 99.66\n","iteration : 150, loss : 0.0105, accuracy : 99.67\n","iteration : 200, loss : 0.0103, accuracy : 99.67\n","iteration : 250, loss : 0.0110, accuracy : 99.64\n","iteration : 300, loss : 0.0119, accuracy : 99.62\n","iteration : 350, loss : 0.0120, accuracy : 99.62\n","Epoch : 160, training loss : 0.0120, training accuracy : 99.62, test loss : 0.4141, test accuracy : 94.40\n","\n","Epoch: 161\n","iteration :  50, loss : 0.0141, accuracy : 99.55\n","iteration : 100, loss : 0.0137, accuracy : 99.54\n","iteration : 150, loss : 0.0155, accuracy : 99.48\n","iteration : 200, loss : 0.0154, accuracy : 99.48\n","iteration : 250, loss : 0.0154, accuracy : 99.49\n","iteration : 300, loss : 0.0161, accuracy : 99.47\n","iteration : 350, loss : 0.0164, accuracy : 99.45\n","Epoch : 161, training loss : 0.0161, training accuracy : 99.46, test loss : 0.3931, test accuracy : 94.49\n","\n","Epoch: 162\n","iteration :  50, loss : 0.0138, accuracy : 99.53\n","iteration : 100, loss : 0.0150, accuracy : 99.53\n","iteration : 150, loss : 0.0142, accuracy : 99.56\n","iteration : 200, loss : 0.0129, accuracy : 99.59\n","iteration : 250, loss : 0.0126, accuracy : 99.59\n","iteration : 300, loss : 0.0128, accuracy : 99.59\n","iteration : 350, loss : 0.0130, accuracy : 99.59\n","Epoch : 162, training loss : 0.0128, training accuracy : 99.60, test loss : 0.4089, test accuracy : 94.26\n","\n","Epoch: 163\n","iteration :  50, loss : 0.0105, accuracy : 99.66\n","iteration : 100, loss : 0.0113, accuracy : 99.63\n","iteration : 150, loss : 0.0141, accuracy : 99.54\n","iteration : 200, loss : 0.0154, accuracy : 99.49\n","iteration : 250, loss : 0.0154, accuracy : 99.50\n","iteration : 300, loss : 0.0146, accuracy : 99.54\n","iteration : 350, loss : 0.0140, accuracy : 99.56\n","Epoch : 163, training loss : 0.0136, training accuracy : 99.57, test loss : 0.3917, test accuracy : 94.51\n","\n","Epoch: 164\n","iteration :  50, loss : 0.0088, accuracy : 99.70\n","iteration : 100, loss : 0.0078, accuracy : 99.75\n","iteration : 150, loss : 0.0079, accuracy : 99.74\n","iteration : 200, loss : 0.0081, accuracy : 99.73\n","iteration : 250, loss : 0.0097, accuracy : 99.68\n","iteration : 300, loss : 0.0109, accuracy : 99.65\n","iteration : 350, loss : 0.0117, accuracy : 99.62\n","Epoch : 164, training loss : 0.0117, training accuracy : 99.62, test loss : 0.4033, test accuracy : 94.40\n","\n","Epoch: 165\n","iteration :  50, loss : 0.0099, accuracy : 99.66\n","iteration : 100, loss : 0.0109, accuracy : 99.62\n","iteration : 150, loss : 0.0133, accuracy : 99.53\n","iteration : 200, loss : 0.0145, accuracy : 99.52\n","iteration : 250, loss : 0.0141, accuracy : 99.53\n","iteration : 300, loss : 0.0141, accuracy : 99.53\n","iteration : 350, loss : 0.0142, accuracy : 99.53\n","Epoch : 165, training loss : 0.0141, training accuracy : 99.53, test loss : 0.4069, test accuracy : 94.16\n","\n","Epoch: 166\n","iteration :  50, loss : 0.0150, accuracy : 99.47\n","iteration : 100, loss : 0.0132, accuracy : 99.57\n","iteration : 150, loss : 0.0121, accuracy : 99.60\n","iteration : 200, loss : 0.0108, accuracy : 99.63\n","iteration : 250, loss : 0.0101, accuracy : 99.65\n","iteration : 300, loss : 0.0115, accuracy : 99.62\n","iteration : 350, loss : 0.0121, accuracy : 99.60\n","Epoch : 166, training loss : 0.0129, training accuracy : 99.59, test loss : 0.4021, test accuracy : 94.16\n","\n","Epoch: 167\n","iteration :  50, loss : 0.0183, accuracy : 99.44\n","iteration : 100, loss : 0.0161, accuracy : 99.48\n","iteration : 150, loss : 0.0159, accuracy : 99.51\n","iteration : 200, loss : 0.0160, accuracy : 99.50\n","iteration : 250, loss : 0.0163, accuracy : 99.48\n","iteration : 300, loss : 0.0161, accuracy : 99.46\n","iteration : 350, loss : 0.0154, accuracy : 99.49\n","Epoch : 167, training loss : 0.0150, training accuracy : 99.50, test loss : 0.3761, test accuracy : 94.42\n","\n","Epoch: 168\n","iteration :  50, loss : 0.0098, accuracy : 99.73\n","iteration : 100, loss : 0.0094, accuracy : 99.68\n","iteration : 150, loss : 0.0108, accuracy : 99.59\n","iteration : 200, loss : 0.0106, accuracy : 99.60\n","iteration : 250, loss : 0.0111, accuracy : 99.58\n","iteration : 300, loss : 0.0114, accuracy : 99.59\n","iteration : 350, loss : 0.0117, accuracy : 99.59\n","Epoch : 168, training loss : 0.0122, training accuracy : 99.57, test loss : 0.4119, test accuracy : 94.18\n","\n","Epoch: 169\n","iteration :  50, loss : 0.0142, accuracy : 99.56\n","iteration : 100, loss : 0.0134, accuracy : 99.56\n","iteration : 150, loss : 0.0148, accuracy : 99.52\n","iteration : 200, loss : 0.0132, accuracy : 99.58\n","iteration : 250, loss : 0.0137, accuracy : 99.55\n","iteration : 300, loss : 0.0145, accuracy : 99.53\n","iteration : 350, loss : 0.0143, accuracy : 99.53\n","Epoch : 169, training loss : 0.0144, training accuracy : 99.54, test loss : 0.3946, test accuracy : 94.32\n","\n","Epoch: 170\n","iteration :  50, loss : 0.0104, accuracy : 99.53\n","iteration : 100, loss : 0.0119, accuracy : 99.52\n","iteration : 150, loss : 0.0119, accuracy : 99.54\n","iteration : 200, loss : 0.0116, accuracy : 99.55\n","iteration : 250, loss : 0.0116, accuracy : 99.55\n","iteration : 300, loss : 0.0114, accuracy : 99.57\n","iteration : 350, loss : 0.0112, accuracy : 99.58\n","Epoch : 170, training loss : 0.0111, training accuracy : 99.58, test loss : 0.4065, test accuracy : 94.32\n","\n","Epoch: 171\n","iteration :  50, loss : 0.0093, accuracy : 99.73\n","iteration : 100, loss : 0.0087, accuracy : 99.73\n","iteration : 150, loss : 0.0089, accuracy : 99.70\n","iteration : 200, loss : 0.0098, accuracy : 99.66\n","iteration : 250, loss : 0.0097, accuracy : 99.67\n","iteration : 300, loss : 0.0104, accuracy : 99.65\n","iteration : 350, loss : 0.0110, accuracy : 99.63\n","Epoch : 171, training loss : 0.0112, training accuracy : 99.62, test loss : 0.4281, test accuracy : 94.01\n","\n","Epoch: 172\n","iteration :  50, loss : 0.0162, accuracy : 99.42\n","iteration : 100, loss : 0.0165, accuracy : 99.45\n","iteration : 150, loss : 0.0167, accuracy : 99.42\n","iteration : 200, loss : 0.0158, accuracy : 99.46\n","iteration : 250, loss : 0.0167, accuracy : 99.45\n","iteration : 300, loss : 0.0167, accuracy : 99.45\n","iteration : 350, loss : 0.0167, accuracy : 99.46\n","Epoch : 172, training loss : 0.0164, training accuracy : 99.47, test loss : 0.3944, test accuracy : 94.33\n","\n","Epoch: 173\n","iteration :  50, loss : 0.0107, accuracy : 99.56\n","iteration : 100, loss : 0.0100, accuracy : 99.64\n","iteration : 150, loss : 0.0099, accuracy : 99.65\n","iteration : 200, loss : 0.0088, accuracy : 99.69\n","iteration : 250, loss : 0.0086, accuracy : 99.71\n","iteration : 300, loss : 0.0082, accuracy : 99.71\n","iteration : 350, loss : 0.0078, accuracy : 99.73\n","Epoch : 173, training loss : 0.0079, training accuracy : 99.72, test loss : 0.4146, test accuracy : 94.35\n","\n","Epoch: 174\n","iteration :  50, loss : 0.0087, accuracy : 99.70\n","iteration : 100, loss : 0.0077, accuracy : 99.70\n","iteration : 150, loss : 0.0090, accuracy : 99.64\n","iteration : 200, loss : 0.0106, accuracy : 99.61\n","iteration : 250, loss : 0.0119, accuracy : 99.59\n","iteration : 300, loss : 0.0127, accuracy : 99.56\n","iteration : 350, loss : 0.0123, accuracy : 99.58\n","Epoch : 174, training loss : 0.0119, training accuracy : 99.59, test loss : 0.3962, test accuracy : 94.33\n","\n","Epoch: 175\n","iteration :  50, loss : 0.0073, accuracy : 99.77\n","iteration : 100, loss : 0.0105, accuracy : 99.62\n","iteration : 150, loss : 0.0101, accuracy : 99.63\n","iteration : 200, loss : 0.0108, accuracy : 99.60\n","iteration : 250, loss : 0.0104, accuracy : 99.62\n","iteration : 300, loss : 0.0120, accuracy : 99.58\n","iteration : 350, loss : 0.0123, accuracy : 99.57\n","Epoch : 175, training loss : 0.0125, training accuracy : 99.56, test loss : 0.4008, test accuracy : 94.25\n","\n","Epoch: 176\n","iteration :  50, loss : 0.0113, accuracy : 99.62\n","iteration : 100, loss : 0.0130, accuracy : 99.59\n","iteration : 150, loss : 0.0139, accuracy : 99.53\n","iteration : 200, loss : 0.0134, accuracy : 99.54\n","iteration : 250, loss : 0.0134, accuracy : 99.54\n","iteration : 300, loss : 0.0132, accuracy : 99.56\n","iteration : 350, loss : 0.0131, accuracy : 99.56\n","Epoch : 176, training loss : 0.0130, training accuracy : 99.56, test loss : 0.4100, test accuracy : 94.51\n","\n","Epoch: 177\n","iteration :  50, loss : 0.0107, accuracy : 99.75\n","iteration : 100, loss : 0.0097, accuracy : 99.75\n","iteration : 150, loss : 0.0098, accuracy : 99.72\n","iteration : 200, loss : 0.0105, accuracy : 99.69\n","iteration : 250, loss : 0.0115, accuracy : 99.65\n","iteration : 300, loss : 0.0127, accuracy : 99.60\n","iteration : 350, loss : 0.0124, accuracy : 99.61\n","Epoch : 177, training loss : 0.0123, training accuracy : 99.61, test loss : 0.3959, test accuracy : 94.39\n","\n","Epoch: 178\n","iteration :  50, loss : 0.0099, accuracy : 99.70\n","iteration : 100, loss : 0.0103, accuracy : 99.69\n","iteration : 150, loss : 0.0113, accuracy : 99.67\n","iteration : 200, loss : 0.0107, accuracy : 99.67\n","iteration : 250, loss : 0.0117, accuracy : 99.63\n","iteration : 300, loss : 0.0111, accuracy : 99.65\n","iteration : 350, loss : 0.0111, accuracy : 99.65\n","Epoch : 178, training loss : 0.0111, training accuracy : 99.65, test loss : 0.4048, test accuracy : 94.27\n","\n","Epoch: 179\n","iteration :  50, loss : 0.0097, accuracy : 99.66\n","iteration : 100, loss : 0.0093, accuracy : 99.70\n","iteration : 150, loss : 0.0118, accuracy : 99.64\n","iteration : 200, loss : 0.0119, accuracy : 99.62\n","iteration : 250, loss : 0.0114, accuracy : 99.65\n","iteration : 300, loss : 0.0116, accuracy : 99.62\n","iteration : 350, loss : 0.0117, accuracy : 99.61\n","Epoch : 179, training loss : 0.0119, training accuracy : 99.60, test loss : 0.3898, test accuracy : 94.43\n","\n","Epoch: 180\n","iteration :  50, loss : 0.0121, accuracy : 99.58\n","iteration : 100, loss : 0.0107, accuracy : 99.62\n","iteration : 150, loss : 0.0129, accuracy : 99.55\n","iteration : 200, loss : 0.0125, accuracy : 99.56\n","iteration : 250, loss : 0.0124, accuracy : 99.58\n","iteration : 300, loss : 0.0128, accuracy : 99.56\n","iteration : 350, loss : 0.0127, accuracy : 99.56\n","Epoch : 180, training loss : 0.0128, training accuracy : 99.56, test loss : 0.3940, test accuracy : 94.33\n","\n","Epoch: 181\n","iteration :  50, loss : 0.0095, accuracy : 99.62\n","iteration : 100, loss : 0.0100, accuracy : 99.62\n","iteration : 150, loss : 0.0109, accuracy : 99.63\n","iteration : 200, loss : 0.0106, accuracy : 99.65\n","iteration : 250, loss : 0.0111, accuracy : 99.66\n","iteration : 300, loss : 0.0112, accuracy : 99.65\n","iteration : 350, loss : 0.0119, accuracy : 99.63\n","Epoch : 181, training loss : 0.0122, training accuracy : 99.61, test loss : 0.4186, test accuracy : 94.23\n","\n","Epoch: 182\n","iteration :  50, loss : 0.0079, accuracy : 99.72\n","iteration : 100, loss : 0.0104, accuracy : 99.62\n","iteration : 150, loss : 0.0111, accuracy : 99.60\n","iteration : 200, loss : 0.0135, accuracy : 99.58\n","iteration : 250, loss : 0.0126, accuracy : 99.60\n","iteration : 300, loss : 0.0118, accuracy : 99.62\n","iteration : 350, loss : 0.0117, accuracy : 99.62\n","Epoch : 182, training loss : 0.0116, training accuracy : 99.62, test loss : 0.4002, test accuracy : 94.24\n","\n","Epoch: 183\n","iteration :  50, loss : 0.0091, accuracy : 99.67\n","iteration : 100, loss : 0.0080, accuracy : 99.73\n","iteration : 150, loss : 0.0096, accuracy : 99.70\n","iteration : 200, loss : 0.0090, accuracy : 99.70\n","iteration : 250, loss : 0.0094, accuracy : 99.67\n","iteration : 300, loss : 0.0094, accuracy : 99.67\n","iteration : 350, loss : 0.0104, accuracy : 99.64\n","Epoch : 183, training loss : 0.0107, training accuracy : 99.64, test loss : 0.4257, test accuracy : 93.87\n","\n","Epoch: 184\n","iteration :  50, loss : 0.0137, accuracy : 99.61\n","iteration : 100, loss : 0.0112, accuracy : 99.65\n","iteration : 150, loss : 0.0105, accuracy : 99.66\n","iteration : 200, loss : 0.0112, accuracy : 99.65\n","iteration : 250, loss : 0.0116, accuracy : 99.63\n","iteration : 300, loss : 0.0117, accuracy : 99.61\n","iteration : 350, loss : 0.0127, accuracy : 99.59\n","Epoch : 184, training loss : 0.0136, training accuracy : 99.57, test loss : 0.4077, test accuracy : 94.13\n","\n","Epoch: 185\n","iteration :  50, loss : 0.0124, accuracy : 99.62\n","iteration : 100, loss : 0.0121, accuracy : 99.59\n","iteration : 150, loss : 0.0120, accuracy : 99.59\n","iteration : 200, loss : 0.0132, accuracy : 99.57\n","iteration : 250, loss : 0.0132, accuracy : 99.58\n","iteration : 300, loss : 0.0128, accuracy : 99.57\n","iteration : 350, loss : 0.0127, accuracy : 99.58\n","Epoch : 185, training loss : 0.0126, training accuracy : 99.58, test loss : 0.4035, test accuracy : 94.29\n","\n","Epoch: 186\n","iteration :  50, loss : 0.0094, accuracy : 99.70\n","iteration : 100, loss : 0.0078, accuracy : 99.77\n","iteration : 150, loss : 0.0076, accuracy : 99.77\n","iteration : 200, loss : 0.0089, accuracy : 99.73\n","iteration : 250, loss : 0.0095, accuracy : 99.69\n","iteration : 300, loss : 0.0100, accuracy : 99.68\n","iteration : 350, loss : 0.0100, accuracy : 99.67\n","Epoch : 186, training loss : 0.0100, training accuracy : 99.67, test loss : 0.4168, test accuracy : 94.36\n","\n","Epoch: 187\n","iteration :  50, loss : 0.0068, accuracy : 99.75\n","iteration : 100, loss : 0.0096, accuracy : 99.71\n","iteration : 150, loss : 0.0115, accuracy : 99.64\n","iteration : 200, loss : 0.0109, accuracy : 99.64\n","iteration : 250, loss : 0.0116, accuracy : 99.61\n","iteration : 300, loss : 0.0115, accuracy : 99.62\n","iteration : 350, loss : 0.0120, accuracy : 99.59\n","Epoch : 187, training loss : 0.0120, training accuracy : 99.59, test loss : 0.4404, test accuracy : 94.20\n","\n","Epoch: 188\n","iteration :  50, loss : 0.0131, accuracy : 99.50\n","iteration : 100, loss : 0.0125, accuracy : 99.55\n","iteration : 150, loss : 0.0120, accuracy : 99.58\n","iteration : 200, loss : 0.0116, accuracy : 99.61\n","iteration : 250, loss : 0.0119, accuracy : 99.60\n","iteration : 300, loss : 0.0121, accuracy : 99.61\n","iteration : 350, loss : 0.0117, accuracy : 99.62\n","Epoch : 188, training loss : 0.0116, training accuracy : 99.63, test loss : 0.4126, test accuracy : 94.38\n","\n","Epoch: 189\n","iteration :  50, loss : 0.0071, accuracy : 99.72\n","iteration : 100, loss : 0.0090, accuracy : 99.67\n","iteration : 150, loss : 0.0111, accuracy : 99.62\n","iteration : 200, loss : 0.0115, accuracy : 99.62\n","iteration : 250, loss : 0.0126, accuracy : 99.58\n","iteration : 300, loss : 0.0125, accuracy : 99.58\n","iteration : 350, loss : 0.0127, accuracy : 99.58\n","Epoch : 189, training loss : 0.0126, training accuracy : 99.57, test loss : 0.4149, test accuracy : 94.33\n","\n","Epoch: 190\n","iteration :  50, loss : 0.0118, accuracy : 99.58\n","iteration : 100, loss : 0.0117, accuracy : 99.62\n","iteration : 150, loss : 0.0113, accuracy : 99.65\n","iteration : 200, loss : 0.0107, accuracy : 99.66\n","iteration : 250, loss : 0.0114, accuracy : 99.65\n","iteration : 300, loss : 0.0125, accuracy : 99.61\n","iteration : 350, loss : 0.0135, accuracy : 99.59\n","Epoch : 190, training loss : 0.0133, training accuracy : 99.60, test loss : 0.3932, test accuracy : 94.25\n","\n","Epoch: 191\n","iteration :  50, loss : 0.0112, accuracy : 99.61\n","iteration : 100, loss : 0.0096, accuracy : 99.66\n","iteration : 150, loss : 0.0085, accuracy : 99.71\n","iteration : 200, loss : 0.0081, accuracy : 99.73\n","iteration : 250, loss : 0.0085, accuracy : 99.72\n","iteration : 300, loss : 0.0094, accuracy : 99.69\n","iteration : 350, loss : 0.0106, accuracy : 99.65\n","Epoch : 191, training loss : 0.0107, training accuracy : 99.64, test loss : 0.4000, test accuracy : 94.28\n","\n","Epoch: 192\n","iteration :  50, loss : 0.0078, accuracy : 99.73\n","iteration : 100, loss : 0.0095, accuracy : 99.70\n","iteration : 150, loss : 0.0094, accuracy : 99.69\n","iteration : 200, loss : 0.0101, accuracy : 99.66\n","iteration : 250, loss : 0.0105, accuracy : 99.62\n","iteration : 300, loss : 0.0107, accuracy : 99.62\n","iteration : 350, loss : 0.0115, accuracy : 99.61\n","Epoch : 192, training loss : 0.0115, training accuracy : 99.61, test loss : 0.4002, test accuracy : 94.23\n","\n","Epoch: 193\n","iteration :  50, loss : 0.0117, accuracy : 99.59\n","iteration : 100, loss : 0.0107, accuracy : 99.63\n","iteration : 150, loss : 0.0114, accuracy : 99.62\n","iteration : 200, loss : 0.0113, accuracy : 99.61\n","iteration : 250, loss : 0.0108, accuracy : 99.63\n","iteration : 300, loss : 0.0109, accuracy : 99.62\n","iteration : 350, loss : 0.0107, accuracy : 99.63\n","Epoch : 193, training loss : 0.0107, training accuracy : 99.63, test loss : 0.4017, test accuracy : 94.27\n","\n","Epoch: 194\n","iteration :  50, loss : 0.0101, accuracy : 99.64\n","iteration : 100, loss : 0.0106, accuracy : 99.65\n","iteration : 150, loss : 0.0111, accuracy : 99.64\n","iteration : 200, loss : 0.0106, accuracy : 99.63\n","iteration : 250, loss : 0.0105, accuracy : 99.65\n","iteration : 300, loss : 0.0102, accuracy : 99.65\n","iteration : 350, loss : 0.0098, accuracy : 99.66\n","Epoch : 194, training loss : 0.0097, training accuracy : 99.66, test loss : 0.4004, test accuracy : 94.69\n","\n","Epoch: 195\n","iteration :  50, loss : 0.0085, accuracy : 99.69\n","iteration : 100, loss : 0.0080, accuracy : 99.76\n","iteration : 150, loss : 0.0095, accuracy : 99.73\n","iteration : 200, loss : 0.0092, accuracy : 99.72\n","iteration : 250, loss : 0.0096, accuracy : 99.71\n","iteration : 300, loss : 0.0095, accuracy : 99.71\n","iteration : 350, loss : 0.0107, accuracy : 99.66\n","Epoch : 195, training loss : 0.0106, training accuracy : 99.66, test loss : 0.4116, test accuracy : 94.16\n","\n","Epoch: 196\n","iteration :  50, loss : 0.0099, accuracy : 99.58\n","iteration : 100, loss : 0.0089, accuracy : 99.67\n","iteration : 150, loss : 0.0107, accuracy : 99.59\n","iteration : 200, loss : 0.0115, accuracy : 99.60\n","iteration : 250, loss : 0.0112, accuracy : 99.62\n","iteration : 300, loss : 0.0114, accuracy : 99.62\n","iteration : 350, loss : 0.0122, accuracy : 99.59\n","Epoch : 196, training loss : 0.0122, training accuracy : 99.59, test loss : 0.3964, test accuracy : 94.47\n","\n","Epoch: 197\n","iteration :  50, loss : 0.0089, accuracy : 99.61\n","iteration : 100, loss : 0.0081, accuracy : 99.70\n","iteration : 150, loss : 0.0102, accuracy : 99.67\n","iteration : 200, loss : 0.0111, accuracy : 99.63\n","iteration : 250, loss : 0.0114, accuracy : 99.62\n","iteration : 300, loss : 0.0118, accuracy : 99.61\n","iteration : 350, loss : 0.0116, accuracy : 99.62\n","Epoch : 197, training loss : 0.0115, training accuracy : 99.62, test loss : 0.4053, test accuracy : 94.27\n","\n","Epoch: 198\n","iteration :  50, loss : 0.0071, accuracy : 99.78\n","iteration : 100, loss : 0.0109, accuracy : 99.65\n","iteration : 150, loss : 0.0127, accuracy : 99.62\n","iteration : 200, loss : 0.0120, accuracy : 99.64\n","iteration : 250, loss : 0.0111, accuracy : 99.67\n","iteration : 300, loss : 0.0105, accuracy : 99.69\n","iteration : 350, loss : 0.0106, accuracy : 99.68\n","Epoch : 198, training loss : 0.0105, training accuracy : 99.68, test loss : 0.4004, test accuracy : 94.37\n","\n","Epoch: 199\n","iteration :  50, loss : 0.0066, accuracy : 99.73\n","iteration : 100, loss : 0.0080, accuracy : 99.72\n","iteration : 150, loss : 0.0083, accuracy : 99.69\n","iteration : 200, loss : 0.0089, accuracy : 99.67\n","iteration : 250, loss : 0.0092, accuracy : 99.67\n","iteration : 300, loss : 0.0091, accuracy : 99.67\n","iteration : 350, loss : 0.0093, accuracy : 99.67\n","Epoch : 199, training loss : 0.0097, training accuracy : 99.66, test loss : 0.4361, test accuracy : 94.11\n","\n","Epoch: 200\n","iteration :  50, loss : 0.0145, accuracy : 99.47\n","iteration : 100, loss : 0.0132, accuracy : 99.52\n","iteration : 150, loss : 0.0133, accuracy : 99.55\n","iteration : 200, loss : 0.0123, accuracy : 99.58\n","iteration : 250, loss : 0.0118, accuracy : 99.60\n","iteration : 300, loss : 0.0109, accuracy : 99.63\n","iteration : 350, loss : 0.0110, accuracy : 99.63\n","Epoch : 200, training loss : 0.0111, training accuracy : 99.63, test loss : 0.4210, test accuracy : 94.43\n","\n","Epoch: 201\n","iteration :  50, loss : 0.0106, accuracy : 99.67\n","iteration : 100, loss : 0.0094, accuracy : 99.70\n","iteration : 150, loss : 0.0088, accuracy : 99.73\n","iteration : 200, loss : 0.0088, accuracy : 99.74\n","iteration : 250, loss : 0.0089, accuracy : 99.74\n","iteration : 300, loss : 0.0092, accuracy : 99.72\n","iteration : 350, loss : 0.0097, accuracy : 99.70\n","Epoch : 201, training loss : 0.0101, training accuracy : 99.68, test loss : 0.4292, test accuracy : 94.24\n","\n","Epoch: 202\n","iteration :  50, loss : 0.0140, accuracy : 99.59\n","iteration : 100, loss : 0.0136, accuracy : 99.59\n","iteration : 150, loss : 0.0137, accuracy : 99.55\n","iteration : 200, loss : 0.0140, accuracy : 99.56\n","iteration : 250, loss : 0.0150, accuracy : 99.56\n","iteration : 300, loss : 0.0149, accuracy : 99.56\n","iteration : 350, loss : 0.0145, accuracy : 99.57\n","Epoch : 202, training loss : 0.0144, training accuracy : 99.57, test loss : 0.4017, test accuracy : 94.46\n","\n","Epoch: 203\n","iteration :  50, loss : 0.0091, accuracy : 99.69\n","iteration : 100, loss : 0.0090, accuracy : 99.66\n","iteration : 150, loss : 0.0095, accuracy : 99.65\n","iteration : 200, loss : 0.0094, accuracy : 99.66\n","iteration : 250, loss : 0.0085, accuracy : 99.69\n","iteration : 300, loss : 0.0088, accuracy : 99.69\n","iteration : 350, loss : 0.0094, accuracy : 99.66\n","Epoch : 203, training loss : 0.0093, training accuracy : 99.67, test loss : 0.4237, test accuracy : 94.32\n","\n","Epoch: 204\n","iteration :  50, loss : 0.0087, accuracy : 99.78\n","iteration : 100, loss : 0.0063, accuracy : 99.85\n","iteration : 150, loss : 0.0061, accuracy : 99.86\n","iteration : 200, loss : 0.0061, accuracy : 99.86\n","iteration : 250, loss : 0.0066, accuracy : 99.83\n","iteration : 300, loss : 0.0069, accuracy : 99.82\n","iteration : 350, loss : 0.0069, accuracy : 99.81\n","Epoch : 204, training loss : 0.0071, training accuracy : 99.80, test loss : 0.4398, test accuracy : 94.29\n","\n","Epoch: 205\n","iteration :  50, loss : 0.0099, accuracy : 99.64\n","iteration : 100, loss : 0.0124, accuracy : 99.55\n","iteration : 150, loss : 0.0132, accuracy : 99.52\n","iteration : 200, loss : 0.0133, accuracy : 99.52\n","iteration : 250, loss : 0.0137, accuracy : 99.54\n","iteration : 300, loss : 0.0140, accuracy : 99.53\n","iteration : 350, loss : 0.0139, accuracy : 99.55\n","Epoch : 205, training loss : 0.0138, training accuracy : 99.56, test loss : 0.4031, test accuracy : 94.11\n","\n","Epoch: 206\n","iteration :  50, loss : 0.0128, accuracy : 99.55\n","iteration : 100, loss : 0.0098, accuracy : 99.69\n","iteration : 150, loss : 0.0097, accuracy : 99.69\n","iteration : 200, loss : 0.0119, accuracy : 99.62\n","iteration : 250, loss : 0.0117, accuracy : 99.59\n","iteration : 300, loss : 0.0126, accuracy : 99.57\n","iteration : 350, loss : 0.0128, accuracy : 99.56\n","Epoch : 206, training loss : 0.0126, training accuracy : 99.57, test loss : 0.4022, test accuracy : 94.17\n","\n","Epoch: 207\n","iteration :  50, loss : 0.0132, accuracy : 99.50\n","iteration : 100, loss : 0.0111, accuracy : 99.62\n","iteration : 150, loss : 0.0106, accuracy : 99.64\n","iteration : 200, loss : 0.0115, accuracy : 99.62\n","iteration : 250, loss : 0.0123, accuracy : 99.59\n","iteration : 300, loss : 0.0122, accuracy : 99.60\n","iteration : 350, loss : 0.0117, accuracy : 99.63\n","Epoch : 207, training loss : 0.0116, training accuracy : 99.63, test loss : 0.4053, test accuracy : 94.43\n","\n","Epoch: 208\n","iteration :  50, loss : 0.0083, accuracy : 99.70\n","iteration : 100, loss : 0.0077, accuracy : 99.73\n","iteration : 150, loss : 0.0072, accuracy : 99.78\n","iteration : 200, loss : 0.0081, accuracy : 99.73\n","iteration : 250, loss : 0.0087, accuracy : 99.72\n","iteration : 300, loss : 0.0084, accuracy : 99.73\n","iteration : 350, loss : 0.0090, accuracy : 99.70\n","Epoch : 208, training loss : 0.0089, training accuracy : 99.70, test loss : 0.4139, test accuracy : 94.31\n","\n","Epoch: 209\n","iteration :  50, loss : 0.0125, accuracy : 99.59\n","iteration : 100, loss : 0.0103, accuracy : 99.70\n","iteration : 150, loss : 0.0095, accuracy : 99.73\n","iteration : 200, loss : 0.0095, accuracy : 99.74\n","iteration : 250, loss : 0.0092, accuracy : 99.72\n","iteration : 300, loss : 0.0097, accuracy : 99.69\n","iteration : 350, loss : 0.0100, accuracy : 99.68\n","Epoch : 209, training loss : 0.0100, training accuracy : 99.67, test loss : 0.4238, test accuracy : 94.20\n","\n","Epoch: 210\n","iteration :  50, loss : 0.0109, accuracy : 99.59\n","iteration : 100, loss : 0.0102, accuracy : 99.66\n","iteration : 150, loss : 0.0108, accuracy : 99.65\n","iteration : 200, loss : 0.0096, accuracy : 99.68\n","iteration : 250, loss : 0.0096, accuracy : 99.69\n","iteration : 300, loss : 0.0099, accuracy : 99.67\n","iteration : 350, loss : 0.0098, accuracy : 99.67\n","Epoch : 210, training loss : 0.0099, training accuracy : 99.67, test loss : 0.4160, test accuracy : 94.46\n","\n","Epoch: 211\n","iteration :  50, loss : 0.0086, accuracy : 99.75\n","iteration : 100, loss : 0.0095, accuracy : 99.72\n","iteration : 150, loss : 0.0109, accuracy : 99.64\n","iteration : 200, loss : 0.0114, accuracy : 99.61\n","iteration : 250, loss : 0.0111, accuracy : 99.61\n","iteration : 300, loss : 0.0110, accuracy : 99.62\n","iteration : 350, loss : 0.0107, accuracy : 99.63\n","Epoch : 211, training loss : 0.0108, training accuracy : 99.64, test loss : 0.4309, test accuracy : 94.18\n","\n","Epoch: 212\n","iteration :  50, loss : 0.0160, accuracy : 99.47\n","iteration : 100, loss : 0.0135, accuracy : 99.55\n","iteration : 150, loss : 0.0126, accuracy : 99.56\n","iteration : 200, loss : 0.0134, accuracy : 99.55\n","iteration : 250, loss : 0.0131, accuracy : 99.56\n","iteration : 300, loss : 0.0126, accuracy : 99.57\n","iteration : 350, loss : 0.0123, accuracy : 99.58\n","Epoch : 212, training loss : 0.0119, training accuracy : 99.60, test loss : 0.4159, test accuracy : 94.53\n","\n","Epoch: 213\n","iteration :  50, loss : 0.0089, accuracy : 99.69\n","iteration : 100, loss : 0.0097, accuracy : 99.67\n","iteration : 150, loss : 0.0094, accuracy : 99.69\n","iteration : 200, loss : 0.0101, accuracy : 99.66\n","iteration : 250, loss : 0.0102, accuracy : 99.67\n","iteration : 300, loss : 0.0101, accuracy : 99.67\n","iteration : 350, loss : 0.0109, accuracy : 99.64\n","Epoch : 213, training loss : 0.0109, training accuracy : 99.64, test loss : 0.4251, test accuracy : 94.17\n","\n","Epoch: 214\n","iteration :  50, loss : 0.0138, accuracy : 99.59\n","iteration : 100, loss : 0.0113, accuracy : 99.65\n","iteration : 150, loss : 0.0108, accuracy : 99.65\n","iteration : 200, loss : 0.0109, accuracy : 99.64\n","iteration : 250, loss : 0.0111, accuracy : 99.66\n","iteration : 300, loss : 0.0114, accuracy : 99.65\n","iteration : 350, loss : 0.0113, accuracy : 99.65\n","Epoch : 214, training loss : 0.0112, training accuracy : 99.66, test loss : 0.4288, test accuracy : 94.29\n","\n","Epoch: 215\n","iteration :  50, loss : 0.0089, accuracy : 99.73\n","iteration : 100, loss : 0.0078, accuracy : 99.74\n","iteration : 150, loss : 0.0077, accuracy : 99.73\n","iteration : 200, loss : 0.0083, accuracy : 99.71\n","iteration : 250, loss : 0.0094, accuracy : 99.67\n","iteration : 300, loss : 0.0104, accuracy : 99.65\n","iteration : 350, loss : 0.0105, accuracy : 99.65\n","Epoch : 215, training loss : 0.0104, training accuracy : 99.64, test loss : 0.4061, test accuracy : 94.30\n","\n","Epoch: 216\n","iteration :  50, loss : 0.0068, accuracy : 99.83\n","iteration : 100, loss : 0.0060, accuracy : 99.81\n","iteration : 150, loss : 0.0070, accuracy : 99.78\n","iteration : 200, loss : 0.0074, accuracy : 99.77\n","iteration : 250, loss : 0.0083, accuracy : 99.73\n","iteration : 300, loss : 0.0088, accuracy : 99.71\n","iteration : 350, loss : 0.0088, accuracy : 99.72\n","Epoch : 216, training loss : 0.0085, training accuracy : 99.73, test loss : 0.4108, test accuracy : 94.50\n","\n","Epoch: 217\n","iteration :  50, loss : 0.0053, accuracy : 99.81\n","iteration : 100, loss : 0.0070, accuracy : 99.73\n","iteration : 150, loss : 0.0078, accuracy : 99.73\n","iteration : 200, loss : 0.0080, accuracy : 99.73\n","iteration : 250, loss : 0.0084, accuracy : 99.71\n","iteration : 300, loss : 0.0088, accuracy : 99.70\n","iteration : 350, loss : 0.0087, accuracy : 99.70\n","Epoch : 217, training loss : 0.0093, training accuracy : 99.69, test loss : 0.4237, test accuracy : 94.26\n","\n","Epoch: 218\n","iteration :  50, loss : 0.0108, accuracy : 99.64\n","iteration : 100, loss : 0.0132, accuracy : 99.58\n","iteration : 150, loss : 0.0129, accuracy : 99.61\n","iteration : 200, loss : 0.0120, accuracy : 99.63\n","iteration : 250, loss : 0.0120, accuracy : 99.63\n","iteration : 300, loss : 0.0121, accuracy : 99.61\n","iteration : 350, loss : 0.0122, accuracy : 99.61\n","Epoch : 218, training loss : 0.0124, training accuracy : 99.61, test loss : 0.4147, test accuracy : 94.10\n","\n","Epoch: 219\n","iteration :  50, loss : 0.0100, accuracy : 99.69\n","iteration : 100, loss : 0.0081, accuracy : 99.74\n","iteration : 150, loss : 0.0074, accuracy : 99.77\n","iteration : 200, loss : 0.0074, accuracy : 99.77\n","iteration : 250, loss : 0.0067, accuracy : 99.78\n","iteration : 300, loss : 0.0069, accuracy : 99.79\n","iteration : 350, loss : 0.0073, accuracy : 99.78\n","Epoch : 219, training loss : 0.0073, training accuracy : 99.77, test loss : 0.4100, test accuracy : 94.65\n","\n","Epoch: 220\n","iteration :  50, loss : 0.0062, accuracy : 99.81\n","iteration : 100, loss : 0.0064, accuracy : 99.80\n","iteration : 150, loss : 0.0069, accuracy : 99.80\n","iteration : 200, loss : 0.0071, accuracy : 99.78\n","iteration : 250, loss : 0.0072, accuracy : 99.78\n","iteration : 300, loss : 0.0071, accuracy : 99.77\n","iteration : 350, loss : 0.0075, accuracy : 99.76\n","Epoch : 220, training loss : 0.0079, training accuracy : 99.75, test loss : 0.4473, test accuracy : 94.30\n","\n","Epoch: 221\n","iteration :  50, loss : 0.0100, accuracy : 99.58\n","iteration : 100, loss : 0.0127, accuracy : 99.53\n","iteration : 150, loss : 0.0139, accuracy : 99.56\n","iteration : 200, loss : 0.0134, accuracy : 99.58\n","iteration : 250, loss : 0.0133, accuracy : 99.58\n","iteration : 300, loss : 0.0131, accuracy : 99.57\n","iteration : 350, loss : 0.0131, accuracy : 99.57\n","Epoch : 221, training loss : 0.0131, training accuracy : 99.56, test loss : 0.4076, test accuracy : 94.43\n","\n","Epoch: 222\n","iteration :  50, loss : 0.0059, accuracy : 99.84\n","iteration : 100, loss : 0.0070, accuracy : 99.79\n","iteration : 150, loss : 0.0076, accuracy : 99.77\n","iteration : 200, loss : 0.0079, accuracy : 99.74\n","iteration : 250, loss : 0.0079, accuracy : 99.75\n","iteration : 300, loss : 0.0077, accuracy : 99.76\n","iteration : 350, loss : 0.0080, accuracy : 99.75\n","Epoch : 222, training loss : 0.0080, training accuracy : 99.75, test loss : 0.4096, test accuracy : 94.45\n","\n","Epoch: 223\n","iteration :  50, loss : 0.0066, accuracy : 99.77\n","iteration : 100, loss : 0.0061, accuracy : 99.76\n","iteration : 150, loss : 0.0070, accuracy : 99.73\n","iteration : 200, loss : 0.0074, accuracy : 99.73\n","iteration : 250, loss : 0.0078, accuracy : 99.72\n","iteration : 300, loss : 0.0087, accuracy : 99.70\n","iteration : 350, loss : 0.0090, accuracy : 99.68\n","Epoch : 223, training loss : 0.0092, training accuracy : 99.68, test loss : 0.4399, test accuracy : 94.20\n","\n","Epoch: 224\n","iteration :  50, loss : 0.0099, accuracy : 99.64\n","iteration : 100, loss : 0.0107, accuracy : 99.62\n","iteration : 150, loss : 0.0114, accuracy : 99.60\n","iteration : 200, loss : 0.0120, accuracy : 99.61\n","iteration : 250, loss : 0.0112, accuracy : 99.63\n","iteration : 300, loss : 0.0115, accuracy : 99.64\n","iteration : 350, loss : 0.0116, accuracy : 99.64\n","Epoch : 224, training loss : 0.0118, training accuracy : 99.63, test loss : 0.4397, test accuracy : 94.19\n","\n","Epoch: 225\n","iteration :  50, loss : 0.0104, accuracy : 99.67\n","iteration : 100, loss : 0.0082, accuracy : 99.73\n","iteration : 150, loss : 0.0090, accuracy : 99.69\n","iteration : 200, loss : 0.0089, accuracy : 99.70\n","iteration : 250, loss : 0.0094, accuracy : 99.69\n","iteration : 300, loss : 0.0087, accuracy : 99.72\n","iteration : 350, loss : 0.0094, accuracy : 99.71\n","Epoch : 225, training loss : 0.0095, training accuracy : 99.70, test loss : 0.4217, test accuracy : 94.45\n","\n","Epoch: 226\n","iteration :  50, loss : 0.0130, accuracy : 99.62\n","iteration : 100, loss : 0.0124, accuracy : 99.62\n","iteration : 150, loss : 0.0122, accuracy : 99.63\n","iteration : 200, loss : 0.0111, accuracy : 99.64\n","iteration : 250, loss : 0.0109, accuracy : 99.64\n","iteration : 300, loss : 0.0102, accuracy : 99.66\n","iteration : 350, loss : 0.0101, accuracy : 99.66\n","Epoch : 226, training loss : 0.0103, training accuracy : 99.65, test loss : 0.4525, test accuracy : 94.16\n","\n","Epoch: 227\n","iteration :  50, loss : 0.0081, accuracy : 99.72\n","iteration : 100, loss : 0.0100, accuracy : 99.70\n","iteration : 150, loss : 0.0088, accuracy : 99.73\n","iteration : 200, loss : 0.0111, accuracy : 99.66\n","iteration : 250, loss : 0.0119, accuracy : 99.62\n","iteration : 300, loss : 0.0124, accuracy : 99.60\n","iteration : 350, loss : 0.0127, accuracy : 99.59\n","Epoch : 227, training loss : 0.0126, training accuracy : 99.60, test loss : 0.4040, test accuracy : 94.33\n","\n","Epoch: 228\n","iteration :  50, loss : 0.0114, accuracy : 99.64\n","iteration : 100, loss : 0.0107, accuracy : 99.69\n","iteration : 150, loss : 0.0098, accuracy : 99.72\n","iteration : 200, loss : 0.0087, accuracy : 99.75\n","iteration : 250, loss : 0.0080, accuracy : 99.77\n","iteration : 300, loss : 0.0081, accuracy : 99.77\n","iteration : 350, loss : 0.0079, accuracy : 99.77\n","Epoch : 228, training loss : 0.0080, training accuracy : 99.76, test loss : 0.4275, test accuracy : 94.55\n","\n","Epoch: 229\n","iteration :  50, loss : 0.0061, accuracy : 99.81\n","iteration : 100, loss : 0.0076, accuracy : 99.76\n","iteration : 150, loss : 0.0065, accuracy : 99.77\n","iteration : 200, loss : 0.0071, accuracy : 99.75\n","iteration : 250, loss : 0.0068, accuracy : 99.76\n","iteration : 300, loss : 0.0077, accuracy : 99.72\n","iteration : 350, loss : 0.0076, accuracy : 99.73\n","Epoch : 229, training loss : 0.0075, training accuracy : 99.73, test loss : 0.4156, test accuracy : 94.47\n","\n","Epoch: 230\n","iteration :  50, loss : 0.0094, accuracy : 99.67\n","iteration : 100, loss : 0.0108, accuracy : 99.61\n","iteration : 150, loss : 0.0127, accuracy : 99.56\n","iteration : 200, loss : 0.0120, accuracy : 99.59\n","iteration : 250, loss : 0.0118, accuracy : 99.59\n","iteration : 300, loss : 0.0119, accuracy : 99.58\n","iteration : 350, loss : 0.0117, accuracy : 99.60\n","Epoch : 230, training loss : 0.0118, training accuracy : 99.61, test loss : 0.4244, test accuracy : 94.31\n","\n","Epoch: 231\n","iteration :  50, loss : 0.0096, accuracy : 99.67\n","iteration : 100, loss : 0.0113, accuracy : 99.63\n","iteration : 150, loss : 0.0108, accuracy : 99.65\n","iteration : 200, loss : 0.0103, accuracy : 99.66\n","iteration : 250, loss : 0.0107, accuracy : 99.65\n","iteration : 300, loss : 0.0106, accuracy : 99.66\n","iteration : 350, loss : 0.0106, accuracy : 99.65\n","Epoch : 231, training loss : 0.0106, training accuracy : 99.65, test loss : 0.4347, test accuracy : 94.40\n","\n","Epoch: 232\n","iteration :  50, loss : 0.0126, accuracy : 99.58\n","iteration : 100, loss : 0.0119, accuracy : 99.57\n","iteration : 150, loss : 0.0117, accuracy : 99.59\n","iteration : 200, loss : 0.0111, accuracy : 99.61\n","iteration : 250, loss : 0.0120, accuracy : 99.61\n","iteration : 300, loss : 0.0119, accuracy : 99.62\n","iteration : 350, loss : 0.0115, accuracy : 99.63\n","Epoch : 232, training loss : 0.0116, training accuracy : 99.63, test loss : 0.4042, test accuracy : 94.49\n","\n","Epoch: 233\n","iteration :  50, loss : 0.0091, accuracy : 99.64\n","iteration : 100, loss : 0.0078, accuracy : 99.73\n","iteration : 150, loss : 0.0068, accuracy : 99.77\n","iteration : 200, loss : 0.0069, accuracy : 99.74\n","iteration : 250, loss : 0.0069, accuracy : 99.76\n","iteration : 300, loss : 0.0082, accuracy : 99.72\n","iteration : 350, loss : 0.0084, accuracy : 99.72\n","Epoch : 233, training loss : 0.0085, training accuracy : 99.72, test loss : 0.4213, test accuracy : 94.38\n","\n","Epoch: 234\n","iteration :  50, loss : 0.0076, accuracy : 99.80\n","iteration : 100, loss : 0.0075, accuracy : 99.77\n","iteration : 150, loss : 0.0085, accuracy : 99.71\n","iteration : 200, loss : 0.0082, accuracy : 99.72\n","iteration : 250, loss : 0.0079, accuracy : 99.73\n","iteration : 300, loss : 0.0080, accuracy : 99.73\n","iteration : 350, loss : 0.0081, accuracy : 99.74\n","Epoch : 234, training loss : 0.0083, training accuracy : 99.73, test loss : 0.4277, test accuracy : 94.45\n","\n","Epoch: 235\n","iteration :  50, loss : 0.0086, accuracy : 99.75\n","iteration : 100, loss : 0.0111, accuracy : 99.68\n","iteration : 150, loss : 0.0096, accuracy : 99.73\n","iteration : 200, loss : 0.0094, accuracy : 99.72\n","iteration : 250, loss : 0.0103, accuracy : 99.68\n","iteration : 300, loss : 0.0107, accuracy : 99.67\n","iteration : 350, loss : 0.0107, accuracy : 99.66\n","Epoch : 235, training loss : 0.0105, training accuracy : 99.67, test loss : 0.4169, test accuracy : 94.31\n","\n","Epoch: 236\n","iteration :  50, loss : 0.0071, accuracy : 99.77\n","iteration : 100, loss : 0.0074, accuracy : 99.75\n","iteration : 150, loss : 0.0077, accuracy : 99.73\n","iteration : 200, loss : 0.0077, accuracy : 99.75\n","iteration : 250, loss : 0.0072, accuracy : 99.76\n","iteration : 300, loss : 0.0073, accuracy : 99.76\n","iteration : 350, loss : 0.0071, accuracy : 99.76\n","Epoch : 236, training loss : 0.0072, training accuracy : 99.76, test loss : 0.4240, test accuracy : 94.46\n","\n","Epoch: 237\n","iteration :  50, loss : 0.0102, accuracy : 99.75\n","iteration : 100, loss : 0.0103, accuracy : 99.73\n","iteration : 150, loss : 0.0100, accuracy : 99.73\n","iteration : 200, loss : 0.0102, accuracy : 99.72\n","iteration : 250, loss : 0.0094, accuracy : 99.74\n","iteration : 300, loss : 0.0093, accuracy : 99.73\n","iteration : 350, loss : 0.0094, accuracy : 99.71\n","Epoch : 237, training loss : 0.0093, training accuracy : 99.71, test loss : 0.4350, test accuracy : 94.30\n","\n","Epoch: 238\n","iteration :  50, loss : 0.0087, accuracy : 99.73\n","iteration : 100, loss : 0.0087, accuracy : 99.74\n","iteration : 150, loss : 0.0095, accuracy : 99.68\n","iteration : 200, loss : 0.0104, accuracy : 99.65\n","iteration : 250, loss : 0.0108, accuracy : 99.63\n","iteration : 300, loss : 0.0111, accuracy : 99.62\n","iteration : 350, loss : 0.0109, accuracy : 99.64\n","Epoch : 238, training loss : 0.0112, training accuracy : 99.63, test loss : 0.4087, test accuracy : 94.55\n","\n","Epoch: 239\n","iteration :  50, loss : 0.0058, accuracy : 99.84\n","iteration : 100, loss : 0.0065, accuracy : 99.84\n","iteration : 150, loss : 0.0060, accuracy : 99.84\n","iteration : 200, loss : 0.0063, accuracy : 99.82\n","iteration : 250, loss : 0.0069, accuracy : 99.79\n","iteration : 300, loss : 0.0082, accuracy : 99.76\n","iteration : 350, loss : 0.0088, accuracy : 99.74\n","Epoch : 239, training loss : 0.0087, training accuracy : 99.74, test loss : 0.3963, test accuracy : 94.43\n","\n","Epoch: 240\n","iteration :  50, loss : 0.0067, accuracy : 99.81\n","iteration : 100, loss : 0.0073, accuracy : 99.77\n","iteration : 150, loss : 0.0078, accuracy : 99.74\n","iteration : 200, loss : 0.0072, accuracy : 99.75\n","iteration : 250, loss : 0.0072, accuracy : 99.76\n","iteration : 300, loss : 0.0077, accuracy : 99.73\n","iteration : 350, loss : 0.0084, accuracy : 99.71\n","Epoch : 240, training loss : 0.0084, training accuracy : 99.71, test loss : 0.4179, test accuracy : 94.41\n","\n","Epoch: 241\n","iteration :  50, loss : 0.0091, accuracy : 99.69\n","iteration : 100, loss : 0.0102, accuracy : 99.70\n","iteration : 150, loss : 0.0098, accuracy : 99.70\n","iteration : 200, loss : 0.0102, accuracy : 99.68\n","iteration : 250, loss : 0.0101, accuracy : 99.67\n","iteration : 300, loss : 0.0099, accuracy : 99.66\n","iteration : 350, loss : 0.0098, accuracy : 99.68\n","Epoch : 241, training loss : 0.0099, training accuracy : 99.67, test loss : 0.4271, test accuracy : 94.35\n","\n","Epoch: 242\n","iteration :  50, loss : 0.0107, accuracy : 99.62\n","iteration : 100, loss : 0.0114, accuracy : 99.64\n","iteration : 150, loss : 0.0112, accuracy : 99.62\n","iteration : 200, loss : 0.0117, accuracy : 99.57\n","iteration : 250, loss : 0.0118, accuracy : 99.57\n","iteration : 300, loss : 0.0116, accuracy : 99.58\n","iteration : 350, loss : 0.0119, accuracy : 99.58\n","Epoch : 242, training loss : 0.0116, training accuracy : 99.59, test loss : 0.3986, test accuracy : 94.43\n","\n","Epoch: 243\n","iteration :  50, loss : 0.0091, accuracy : 99.70\n","iteration : 100, loss : 0.0086, accuracy : 99.72\n","iteration : 150, loss : 0.0094, accuracy : 99.67\n","iteration : 200, loss : 0.0095, accuracy : 99.68\n","iteration : 250, loss : 0.0095, accuracy : 99.68\n","iteration : 300, loss : 0.0096, accuracy : 99.69\n","iteration : 350, loss : 0.0095, accuracy : 99.69\n","Epoch : 243, training loss : 0.0092, training accuracy : 99.70, test loss : 0.4018, test accuracy : 94.49\n","\n","Epoch: 244\n","iteration :  50, loss : 0.0061, accuracy : 99.83\n","iteration : 100, loss : 0.0063, accuracy : 99.79\n","iteration : 150, loss : 0.0064, accuracy : 99.76\n","iteration : 200, loss : 0.0064, accuracy : 99.75\n","iteration : 250, loss : 0.0064, accuracy : 99.76\n","iteration : 300, loss : 0.0065, accuracy : 99.76\n","iteration : 350, loss : 0.0067, accuracy : 99.75\n","Epoch : 244, training loss : 0.0070, training accuracy : 99.74, test loss : 0.4377, test accuracy : 94.27\n","\n","Epoch: 245\n","iteration :  50, loss : 0.0069, accuracy : 99.78\n","iteration : 100, loss : 0.0078, accuracy : 99.74\n","iteration : 150, loss : 0.0092, accuracy : 99.72\n","iteration : 200, loss : 0.0096, accuracy : 99.70\n","iteration : 250, loss : 0.0096, accuracy : 99.70\n","iteration : 300, loss : 0.0097, accuracy : 99.70\n","iteration : 350, loss : 0.0099, accuracy : 99.69\n","Epoch : 245, training loss : 0.0102, training accuracy : 99.68, test loss : 0.4086, test accuracy : 94.48\n","\n","Epoch: 246\n","iteration :  50, loss : 0.0064, accuracy : 99.81\n","iteration : 100, loss : 0.0064, accuracy : 99.80\n","iteration : 150, loss : 0.0065, accuracy : 99.80\n","iteration : 200, loss : 0.0074, accuracy : 99.79\n","iteration : 250, loss : 0.0078, accuracy : 99.77\n","iteration : 300, loss : 0.0078, accuracy : 99.76\n","iteration : 350, loss : 0.0085, accuracy : 99.72\n","Epoch : 246, training loss : 0.0087, training accuracy : 99.72, test loss : 0.4204, test accuracy : 94.26\n","\n","Epoch: 247\n","iteration :  50, loss : 0.0137, accuracy : 99.69\n","iteration : 100, loss : 0.0099, accuracy : 99.73\n","iteration : 150, loss : 0.0092, accuracy : 99.73\n","iteration : 200, loss : 0.0088, accuracy : 99.74\n","iteration : 250, loss : 0.0090, accuracy : 99.74\n","iteration : 300, loss : 0.0085, accuracy : 99.74\n","iteration : 350, loss : 0.0085, accuracy : 99.72\n","Epoch : 247, training loss : 0.0091, training accuracy : 99.71, test loss : 0.4250, test accuracy : 94.25\n","\n","Epoch: 248\n","iteration :  50, loss : 0.0072, accuracy : 99.75\n","iteration : 100, loss : 0.0072, accuracy : 99.76\n","iteration : 150, loss : 0.0068, accuracy : 99.77\n","iteration : 200, loss : 0.0063, accuracy : 99.79\n","iteration : 250, loss : 0.0069, accuracy : 99.78\n","iteration : 300, loss : 0.0076, accuracy : 99.73\n","iteration : 350, loss : 0.0080, accuracy : 99.73\n","Epoch : 248, training loss : 0.0081, training accuracy : 99.73, test loss : 0.4273, test accuracy : 94.55\n","\n","Epoch: 249\n","iteration :  50, loss : 0.0108, accuracy : 99.64\n","iteration : 100, loss : 0.0099, accuracy : 99.65\n","iteration : 150, loss : 0.0098, accuracy : 99.65\n","iteration : 200, loss : 0.0092, accuracy : 99.68\n","iteration : 250, loss : 0.0094, accuracy : 99.68\n","iteration : 300, loss : 0.0094, accuracy : 99.67\n","iteration : 350, loss : 0.0100, accuracy : 99.66\n","Epoch : 249, training loss : 0.0102, training accuracy : 99.65, test loss : 0.4183, test accuracy : 94.33\n","\n","Epoch: 250\n","iteration :  50, loss : 0.0107, accuracy : 99.61\n","iteration : 100, loss : 0.0102, accuracy : 99.62\n","iteration : 150, loss : 0.0113, accuracy : 99.59\n","iteration : 200, loss : 0.0120, accuracy : 99.60\n","iteration : 250, loss : 0.0123, accuracy : 99.59\n","iteration : 300, loss : 0.0116, accuracy : 99.61\n","iteration : 350, loss : 0.0115, accuracy : 99.60\n","Epoch : 250, training loss : 0.0114, training accuracy : 99.61, test loss : 0.4211, test accuracy : 94.30\n","\n","Epoch: 251\n","iteration :  50, loss : 0.0071, accuracy : 99.75\n","iteration : 100, loss : 0.0058, accuracy : 99.79\n","iteration : 150, loss : 0.0079, accuracy : 99.79\n","iteration : 200, loss : 0.0077, accuracy : 99.79\n","iteration : 250, loss : 0.0072, accuracy : 99.79\n","iteration : 300, loss : 0.0070, accuracy : 99.79\n","iteration : 350, loss : 0.0070, accuracy : 99.80\n","Epoch : 251, training loss : 0.0071, training accuracy : 99.79, test loss : 0.3999, test accuracy : 94.61\n","\n","Epoch: 252\n","iteration :  50, loss : 0.0083, accuracy : 99.72\n","iteration : 100, loss : 0.0086, accuracy : 99.68\n","iteration : 150, loss : 0.0088, accuracy : 99.67\n","iteration : 200, loss : 0.0081, accuracy : 99.70\n","iteration : 250, loss : 0.0078, accuracy : 99.72\n","iteration : 300, loss : 0.0079, accuracy : 99.73\n","iteration : 350, loss : 0.0088, accuracy : 99.71\n","Epoch : 252, training loss : 0.0088, training accuracy : 99.71, test loss : 0.4379, test accuracy : 94.12\n","\n","Epoch: 253\n","iteration :  50, loss : 0.0066, accuracy : 99.80\n","iteration : 100, loss : 0.0064, accuracy : 99.78\n","iteration : 150, loss : 0.0066, accuracy : 99.77\n","iteration : 200, loss : 0.0070, accuracy : 99.76\n","iteration : 250, loss : 0.0074, accuracy : 99.73\n","iteration : 300, loss : 0.0088, accuracy : 99.69\n","iteration : 350, loss : 0.0089, accuracy : 99.70\n","Epoch : 253, training loss : 0.0092, training accuracy : 99.69, test loss : 0.4252, test accuracy : 94.40\n","\n","Epoch: 254\n","iteration :  50, loss : 0.0083, accuracy : 99.75\n","iteration : 100, loss : 0.0093, accuracy : 99.71\n","iteration : 150, loss : 0.0093, accuracy : 99.71\n","iteration : 200, loss : 0.0093, accuracy : 99.71\n","iteration : 250, loss : 0.0097, accuracy : 99.70\n","iteration : 300, loss : 0.0099, accuracy : 99.71\n","iteration : 350, loss : 0.0098, accuracy : 99.70\n","Epoch : 254, training loss : 0.0096, training accuracy : 99.71, test loss : 0.4179, test accuracy : 94.27\n","\n","Epoch: 255\n","iteration :  50, loss : 0.0118, accuracy : 99.62\n","iteration : 100, loss : 0.0130, accuracy : 99.55\n","iteration : 150, loss : 0.0122, accuracy : 99.61\n","iteration : 200, loss : 0.0103, accuracy : 99.68\n","iteration : 250, loss : 0.0097, accuracy : 99.72\n","iteration : 300, loss : 0.0092, accuracy : 99.73\n","iteration : 350, loss : 0.0084, accuracy : 99.76\n","Epoch : 255, training loss : 0.0084, training accuracy : 99.76, test loss : 0.4189, test accuracy : 94.60\n","\n","Epoch: 256\n","iteration :  50, loss : 0.0051, accuracy : 99.80\n","iteration : 100, loss : 0.0049, accuracy : 99.85\n","iteration : 150, loss : 0.0056, accuracy : 99.85\n","iteration : 200, loss : 0.0056, accuracy : 99.85\n","iteration : 250, loss : 0.0059, accuracy : 99.83\n","iteration : 300, loss : 0.0062, accuracy : 99.80\n","iteration : 350, loss : 0.0074, accuracy : 99.76\n","Epoch : 256, training loss : 0.0077, training accuracy : 99.76, test loss : 0.4217, test accuracy : 94.28\n","\n","Epoch: 257\n","iteration :  50, loss : 0.0090, accuracy : 99.72\n","iteration : 100, loss : 0.0093, accuracy : 99.68\n","iteration : 150, loss : 0.0099, accuracy : 99.65\n","iteration : 200, loss : 0.0105, accuracy : 99.63\n","iteration : 250, loss : 0.0102, accuracy : 99.65\n","iteration : 300, loss : 0.0101, accuracy : 99.66\n","iteration : 350, loss : 0.0101, accuracy : 99.67\n","Epoch : 257, training loss : 0.0101, training accuracy : 99.67, test loss : 0.4152, test accuracy : 94.39\n","\n","Epoch: 258\n","iteration :  50, loss : 0.0072, accuracy : 99.78\n","iteration : 100, loss : 0.0079, accuracy : 99.72\n","iteration : 150, loss : 0.0066, accuracy : 99.78\n","iteration : 200, loss : 0.0062, accuracy : 99.80\n","iteration : 250, loss : 0.0063, accuracy : 99.81\n","iteration : 300, loss : 0.0064, accuracy : 99.81\n","iteration : 350, loss : 0.0069, accuracy : 99.78\n","Epoch : 258, training loss : 0.0072, training accuracy : 99.77, test loss : 0.4278, test accuracy : 94.40\n","\n","Epoch: 259\n","iteration :  50, loss : 0.0068, accuracy : 99.80\n","iteration : 100, loss : 0.0071, accuracy : 99.77\n","iteration : 150, loss : 0.0087, accuracy : 99.72\n","iteration : 200, loss : 0.0105, accuracy : 99.65\n","iteration : 250, loss : 0.0104, accuracy : 99.65\n","iteration : 300, loss : 0.0102, accuracy : 99.66\n","iteration : 350, loss : 0.0104, accuracy : 99.65\n","Epoch : 259, training loss : 0.0105, training accuracy : 99.64, test loss : 0.4215, test accuracy : 94.22\n","\n","Epoch: 260\n","iteration :  50, loss : 0.0102, accuracy : 99.61\n","iteration : 100, loss : 0.0102, accuracy : 99.65\n","iteration : 150, loss : 0.0092, accuracy : 99.70\n","iteration : 200, loss : 0.0086, accuracy : 99.71\n","iteration : 250, loss : 0.0096, accuracy : 99.68\n","iteration : 300, loss : 0.0099, accuracy : 99.68\n","iteration : 350, loss : 0.0105, accuracy : 99.67\n","Epoch : 260, training loss : 0.0104, training accuracy : 99.67, test loss : 0.3970, test accuracy : 94.50\n","\n","Epoch: 261\n","iteration :  50, loss : 0.0081, accuracy : 99.77\n","iteration : 100, loss : 0.0083, accuracy : 99.75\n","iteration : 150, loss : 0.0085, accuracy : 99.73\n","iteration : 200, loss : 0.0082, accuracy : 99.74\n","iteration : 250, loss : 0.0077, accuracy : 99.76\n","iteration : 300, loss : 0.0082, accuracy : 99.74\n","iteration : 350, loss : 0.0087, accuracy : 99.72\n","Epoch : 261, training loss : 0.0089, training accuracy : 99.72, test loss : 0.4247, test accuracy : 94.25\n","\n","Epoch: 262\n","iteration :  50, loss : 0.0086, accuracy : 99.77\n","iteration : 100, loss : 0.0081, accuracy : 99.74\n","iteration : 150, loss : 0.0090, accuracy : 99.70\n","iteration : 200, loss : 0.0090, accuracy : 99.70\n","iteration : 250, loss : 0.0083, accuracy : 99.72\n","iteration : 300, loss : 0.0075, accuracy : 99.75\n","iteration : 350, loss : 0.0072, accuracy : 99.76\n","Epoch : 262, training loss : 0.0071, training accuracy : 99.76, test loss : 0.4301, test accuracy : 94.51\n","\n","Epoch: 263\n","iteration :  50, loss : 0.0053, accuracy : 99.84\n","iteration : 100, loss : 0.0054, accuracy : 99.80\n","iteration : 150, loss : 0.0067, accuracy : 99.77\n","iteration : 200, loss : 0.0083, accuracy : 99.71\n","iteration : 250, loss : 0.0087, accuracy : 99.72\n","iteration : 300, loss : 0.0085, accuracy : 99.72\n","iteration : 350, loss : 0.0083, accuracy : 99.73\n","Epoch : 263, training loss : 0.0084, training accuracy : 99.73, test loss : 0.4101, test accuracy : 94.59\n","\n","Epoch: 264\n","iteration :  50, loss : 0.0049, accuracy : 99.84\n","iteration : 100, loss : 0.0044, accuracy : 99.85\n","iteration : 150, loss : 0.0057, accuracy : 99.82\n","iteration : 200, loss : 0.0064, accuracy : 99.80\n","iteration : 250, loss : 0.0074, accuracy : 99.76\n","iteration : 300, loss : 0.0073, accuracy : 99.77\n","iteration : 350, loss : 0.0078, accuracy : 99.76\n","Epoch : 264, training loss : 0.0081, training accuracy : 99.75, test loss : 0.4379, test accuracy : 94.43\n","\n","Epoch: 265\n","iteration :  50, loss : 0.0085, accuracy : 99.67\n","iteration : 100, loss : 0.0066, accuracy : 99.73\n","iteration : 150, loss : 0.0062, accuracy : 99.74\n","iteration : 200, loss : 0.0072, accuracy : 99.72\n","iteration : 250, loss : 0.0081, accuracy : 99.71\n","iteration : 300, loss : 0.0083, accuracy : 99.71\n","iteration : 350, loss : 0.0089, accuracy : 99.70\n","Epoch : 265, training loss : 0.0093, training accuracy : 99.69, test loss : 0.4121, test accuracy : 94.32\n","\n","Epoch: 266\n","iteration :  50, loss : 0.0097, accuracy : 99.64\n","iteration : 100, loss : 0.0086, accuracy : 99.72\n","iteration : 150, loss : 0.0077, accuracy : 99.74\n","iteration : 200, loss : 0.0075, accuracy : 99.73\n","iteration : 250, loss : 0.0080, accuracy : 99.71\n","iteration : 300, loss : 0.0086, accuracy : 99.70\n","iteration : 350, loss : 0.0088, accuracy : 99.69\n","Epoch : 266, training loss : 0.0090, training accuracy : 99.68, test loss : 0.4338, test accuracy : 94.47\n","\n","Epoch: 267\n","iteration :  50, loss : 0.0091, accuracy : 99.72\n","iteration : 100, loss : 0.0098, accuracy : 99.67\n","iteration : 150, loss : 0.0118, accuracy : 99.62\n","iteration : 200, loss : 0.0122, accuracy : 99.60\n","iteration : 250, loss : 0.0115, accuracy : 99.62\n","iteration : 300, loss : 0.0109, accuracy : 99.64\n","iteration : 350, loss : 0.0104, accuracy : 99.66\n","Epoch : 267, training loss : 0.0104, training accuracy : 99.66, test loss : 0.4062, test accuracy : 94.44\n","\n","Epoch: 268\n","iteration :  50, loss : 0.0050, accuracy : 99.77\n","iteration : 100, loss : 0.0062, accuracy : 99.74\n","iteration : 150, loss : 0.0061, accuracy : 99.78\n","iteration : 200, loss : 0.0060, accuracy : 99.77\n","iteration : 250, loss : 0.0068, accuracy : 99.75\n","iteration : 300, loss : 0.0071, accuracy : 99.74\n","iteration : 350, loss : 0.0073, accuracy : 99.73\n","Epoch : 268, training loss : 0.0075, training accuracy : 99.72, test loss : 0.4237, test accuracy : 94.44\n","\n","Epoch: 269\n","iteration :  50, loss : 0.0073, accuracy : 99.70\n","iteration : 100, loss : 0.0082, accuracy : 99.72\n","iteration : 150, loss : 0.0082, accuracy : 99.71\n","iteration : 200, loss : 0.0090, accuracy : 99.67\n","iteration : 250, loss : 0.0088, accuracy : 99.69\n","iteration : 300, loss : 0.0085, accuracy : 99.70\n","iteration : 350, loss : 0.0087, accuracy : 99.69\n","Epoch : 269, training loss : 0.0087, training accuracy : 99.69, test loss : 0.4324, test accuracy : 94.37\n","\n","Epoch: 270\n","iteration :  50, loss : 0.0107, accuracy : 99.62\n","iteration : 100, loss : 0.0106, accuracy : 99.64\n","iteration : 150, loss : 0.0105, accuracy : 99.66\n","iteration : 200, loss : 0.0099, accuracy : 99.69\n","iteration : 250, loss : 0.0094, accuracy : 99.69\n","iteration : 300, loss : 0.0096, accuracy : 99.70\n","iteration : 350, loss : 0.0090, accuracy : 99.70\n","Epoch : 270, training loss : 0.0087, training accuracy : 99.71, test loss : 0.4284, test accuracy : 94.34\n","\n","Epoch: 271\n","iteration :  50, loss : 0.0050, accuracy : 99.88\n","iteration : 100, loss : 0.0054, accuracy : 99.84\n","iteration : 150, loss : 0.0054, accuracy : 99.83\n","iteration : 200, loss : 0.0055, accuracy : 99.82\n","iteration : 250, loss : 0.0062, accuracy : 99.80\n","iteration : 300, loss : 0.0072, accuracy : 99.77\n","iteration : 350, loss : 0.0081, accuracy : 99.73\n","Epoch : 271, training loss : 0.0082, training accuracy : 99.72, test loss : 0.4480, test accuracy : 94.00\n","\n","Epoch: 272\n","iteration :  50, loss : 0.0098, accuracy : 99.73\n","iteration : 100, loss : 0.0094, accuracy : 99.70\n","iteration : 150, loss : 0.0087, accuracy : 99.72\n","iteration : 200, loss : 0.0090, accuracy : 99.73\n","iteration : 250, loss : 0.0085, accuracy : 99.74\n","iteration : 300, loss : 0.0084, accuracy : 99.75\n","iteration : 350, loss : 0.0078, accuracy : 99.77\n","Epoch : 272, training loss : 0.0079, training accuracy : 99.76, test loss : 0.4221, test accuracy : 94.38\n","\n","Epoch: 273\n","iteration :  50, loss : 0.0083, accuracy : 99.78\n","iteration : 100, loss : 0.0097, accuracy : 99.77\n","iteration : 150, loss : 0.0094, accuracy : 99.77\n","iteration : 200, loss : 0.0089, accuracy : 99.78\n","iteration : 250, loss : 0.0083, accuracy : 99.79\n","iteration : 300, loss : 0.0080, accuracy : 99.79\n","iteration : 350, loss : 0.0076, accuracy : 99.79\n","Epoch : 273, training loss : 0.0075, training accuracy : 99.79, test loss : 0.4178, test accuracy : 94.58\n","\n","Epoch: 274\n","iteration :  50, loss : 0.0051, accuracy : 99.86\n","iteration : 100, loss : 0.0060, accuracy : 99.80\n","iteration : 150, loss : 0.0073, accuracy : 99.74\n","iteration : 200, loss : 0.0085, accuracy : 99.70\n","iteration : 250, loss : 0.0089, accuracy : 99.69\n","iteration : 300, loss : 0.0089, accuracy : 99.69\n","iteration : 350, loss : 0.0086, accuracy : 99.70\n","Epoch : 274, training loss : 0.0087, training accuracy : 99.70, test loss : 0.4266, test accuracy : 94.58\n","\n","Epoch: 275\n","iteration :  50, loss : 0.0092, accuracy : 99.66\n","iteration : 100, loss : 0.0096, accuracy : 99.66\n","iteration : 150, loss : 0.0106, accuracy : 99.62\n","iteration : 200, loss : 0.0102, accuracy : 99.65\n","iteration : 250, loss : 0.0099, accuracy : 99.65\n","iteration : 300, loss : 0.0094, accuracy : 99.68\n","iteration : 350, loss : 0.0090, accuracy : 99.69\n","Epoch : 275, training loss : 0.0090, training accuracy : 99.68, test loss : 0.4232, test accuracy : 94.42\n","\n","Epoch: 276\n","iteration :  50, loss : 0.0065, accuracy : 99.77\n","iteration : 100, loss : 0.0068, accuracy : 99.77\n","iteration : 150, loss : 0.0073, accuracy : 99.74\n","iteration : 200, loss : 0.0074, accuracy : 99.75\n","iteration : 250, loss : 0.0073, accuracy : 99.75\n","iteration : 300, loss : 0.0074, accuracy : 99.75\n","iteration : 350, loss : 0.0075, accuracy : 99.76\n","Epoch : 276, training loss : 0.0082, training accuracy : 99.73, test loss : 0.4484, test accuracy : 94.08\n","\n","Epoch: 277\n","iteration :  50, loss : 0.0112, accuracy : 99.67\n","iteration : 100, loss : 0.0088, accuracy : 99.73\n","iteration : 150, loss : 0.0081, accuracy : 99.75\n","iteration : 200, loss : 0.0072, accuracy : 99.78\n","iteration : 250, loss : 0.0073, accuracy : 99.78\n","iteration : 300, loss : 0.0081, accuracy : 99.76\n","iteration : 350, loss : 0.0086, accuracy : 99.74\n","Epoch : 277, training loss : 0.0088, training accuracy : 99.74, test loss : 0.4473, test accuracy : 94.10\n","\n","Epoch: 278\n","iteration :  50, loss : 0.0056, accuracy : 99.78\n","iteration : 100, loss : 0.0058, accuracy : 99.80\n","iteration : 150, loss : 0.0067, accuracy : 99.77\n","iteration : 200, loss : 0.0066, accuracy : 99.76\n","iteration : 250, loss : 0.0071, accuracy : 99.75\n","iteration : 300, loss : 0.0067, accuracy : 99.75\n","iteration : 350, loss : 0.0070, accuracy : 99.75\n","Epoch : 278, training loss : 0.0068, training accuracy : 99.76, test loss : 0.4283, test accuracy : 94.38\n","\n","Epoch: 279\n","iteration :  50, loss : 0.0055, accuracy : 99.81\n","iteration : 100, loss : 0.0075, accuracy : 99.77\n","iteration : 150, loss : 0.0066, accuracy : 99.79\n","iteration : 200, loss : 0.0085, accuracy : 99.73\n","iteration : 250, loss : 0.0081, accuracy : 99.74\n","iteration : 300, loss : 0.0078, accuracy : 99.76\n","iteration : 350, loss : 0.0078, accuracy : 99.75\n","Epoch : 279, training loss : 0.0079, training accuracy : 99.75, test loss : 0.4324, test accuracy : 94.31\n","\n","Epoch: 280\n","iteration :  50, loss : 0.0059, accuracy : 99.77\n","iteration : 100, loss : 0.0075, accuracy : 99.76\n","iteration : 150, loss : 0.0077, accuracy : 99.74\n","iteration : 200, loss : 0.0085, accuracy : 99.73\n","iteration : 250, loss : 0.0094, accuracy : 99.71\n","iteration : 300, loss : 0.0097, accuracy : 99.68\n","iteration : 350, loss : 0.0106, accuracy : 99.67\n","Epoch : 280, training loss : 0.0106, training accuracy : 99.67, test loss : 0.4345, test accuracy : 94.30\n","\n","Epoch: 281\n","iteration :  50, loss : 0.0092, accuracy : 99.72\n","iteration : 100, loss : 0.0080, accuracy : 99.73\n","iteration : 150, loss : 0.0080, accuracy : 99.74\n","iteration : 200, loss : 0.0072, accuracy : 99.76\n","iteration : 250, loss : 0.0079, accuracy : 99.73\n","iteration : 300, loss : 0.0081, accuracy : 99.72\n","iteration : 350, loss : 0.0086, accuracy : 99.71\n","Epoch : 281, training loss : 0.0089, training accuracy : 99.70, test loss : 0.4196, test accuracy : 94.38\n","\n","Epoch: 282\n","iteration :  50, loss : 0.0045, accuracy : 99.86\n","iteration : 100, loss : 0.0050, accuracy : 99.84\n","iteration : 150, loss : 0.0063, accuracy : 99.81\n","iteration : 200, loss : 0.0065, accuracy : 99.81\n","iteration : 250, loss : 0.0067, accuracy : 99.79\n","iteration : 300, loss : 0.0068, accuracy : 99.78\n","iteration : 350, loss : 0.0078, accuracy : 99.76\n","Epoch : 282, training loss : 0.0077, training accuracy : 99.76, test loss : 0.4024, test accuracy : 94.53\n","\n","Epoch: 283\n","iteration :  50, loss : 0.0058, accuracy : 99.81\n","iteration : 100, loss : 0.0080, accuracy : 99.75\n","iteration : 150, loss : 0.0091, accuracy : 99.71\n","iteration : 200, loss : 0.0086, accuracy : 99.73\n","iteration : 250, loss : 0.0078, accuracy : 99.75\n","iteration : 300, loss : 0.0074, accuracy : 99.77\n","iteration : 350, loss : 0.0073, accuracy : 99.76\n","Epoch : 283, training loss : 0.0075, training accuracy : 99.76, test loss : 0.4264, test accuracy : 94.27\n","\n","Epoch: 284\n","iteration :  50, loss : 0.0073, accuracy : 99.80\n","iteration : 100, loss : 0.0062, accuracy : 99.81\n","iteration : 150, loss : 0.0062, accuracy : 99.82\n","iteration : 200, loss : 0.0065, accuracy : 99.79\n","iteration : 250, loss : 0.0063, accuracy : 99.77\n","iteration : 300, loss : 0.0060, accuracy : 99.78\n","iteration : 350, loss : 0.0057, accuracy : 99.79\n","Epoch : 284, training loss : 0.0058, training accuracy : 99.79, test loss : 0.4510, test accuracy : 94.35\n","\n","Epoch: 285\n","iteration :  50, loss : 0.0138, accuracy : 99.56\n","iteration : 100, loss : 0.0097, accuracy : 99.69\n","iteration : 150, loss : 0.0085, accuracy : 99.73\n","iteration : 200, loss : 0.0077, accuracy : 99.76\n","iteration : 300, loss : 0.0081, accuracy : 99.74\n","iteration : 350, loss : 0.0083, accuracy : 99.72\n","Epoch : 285, training loss : 0.0081, training accuracy : 99.72, test loss : 0.4451, test accuracy : 94.36\n","\n","Epoch: 286\n","iteration :  50, loss : 0.0139, accuracy : 99.59\n","iteration : 100, loss : 0.0137, accuracy : 99.59\n","iteration : 150, loss : 0.0135, accuracy : 99.57\n","iteration : 200, loss : 0.0124, accuracy : 99.62\n","iteration : 250, loss : 0.0121, accuracy : 99.62\n","iteration : 300, loss : 0.0116, accuracy : 99.63\n","iteration : 350, loss : 0.0118, accuracy : 99.63\n","Epoch : 286, training loss : 0.0114, training accuracy : 99.64, test loss : 0.4251, test accuracy : 94.37\n","\n","Epoch: 287\n","iteration :  50, loss : 0.0045, accuracy : 99.86\n","iteration : 100, loss : 0.0053, accuracy : 99.83\n","iteration : 150, loss : 0.0056, accuracy : 99.81\n","iteration : 200, loss : 0.0063, accuracy : 99.80\n","iteration : 250, loss : 0.0060, accuracy : 99.80\n","iteration : 300, loss : 0.0059, accuracy : 99.79\n","iteration : 350, loss : 0.0058, accuracy : 99.79\n","Epoch : 287, training loss : 0.0058, training accuracy : 99.79, test loss : 0.4429, test accuracy : 94.39\n","\n","Epoch: 288\n","iteration :  50, loss : 0.0041, accuracy : 99.89\n","iteration : 100, loss : 0.0050, accuracy : 99.83\n","iteration : 150, loss : 0.0065, accuracy : 99.78\n","iteration : 200, loss : 0.0080, accuracy : 99.75\n","iteration : 250, loss : 0.0090, accuracy : 99.71\n","iteration : 300, loss : 0.0092, accuracy : 99.70\n","iteration : 350, loss : 0.0092, accuracy : 99.70\n","Epoch : 288, training loss : 0.0094, training accuracy : 99.69, test loss : 0.4293, test accuracy : 94.36\n","\n","Epoch: 289\n","iteration :  50, loss : 0.0053, accuracy : 99.77\n","iteration : 100, loss : 0.0055, accuracy : 99.77\n","iteration : 150, loss : 0.0060, accuracy : 99.76\n","iteration : 200, loss : 0.0062, accuracy : 99.77\n","iteration : 250, loss : 0.0063, accuracy : 99.78\n","iteration : 300, loss : 0.0061, accuracy : 99.79\n","iteration : 350, loss : 0.0058, accuracy : 99.80\n","Epoch : 289, training loss : 0.0060, training accuracy : 99.80, test loss : 0.4464, test accuracy : 94.37\n","\n","Epoch: 290\n","iteration :  50, loss : 0.0051, accuracy : 99.91\n","iteration : 100, loss : 0.0048, accuracy : 99.89\n","iteration : 150, loss : 0.0054, accuracy : 99.84\n","iteration : 200, loss : 0.0055, accuracy : 99.83\n","iteration : 250, loss : 0.0066, accuracy : 99.80\n","iteration : 300, loss : 0.0071, accuracy : 99.78\n","iteration : 350, loss : 0.0079, accuracy : 99.76\n","Epoch : 290, training loss : 0.0079, training accuracy : 99.76, test loss : 0.4292, test accuracy : 94.35\n","\n","Epoch: 291\n","iteration :  50, loss : 0.0125, accuracy : 99.69\n","iteration : 100, loss : 0.0103, accuracy : 99.72\n","iteration : 150, loss : 0.0088, accuracy : 99.73\n","iteration : 200, loss : 0.0080, accuracy : 99.76\n","iteration : 250, loss : 0.0088, accuracy : 99.73\n","iteration : 300, loss : 0.0089, accuracy : 99.73\n","iteration : 350, loss : 0.0088, accuracy : 99.75\n","Epoch : 291, training loss : 0.0092, training accuracy : 99.73, test loss : 0.4365, test accuracy : 94.40\n","\n","Epoch: 292\n","iteration :  50, loss : 0.0078, accuracy : 99.73\n","iteration : 100, loss : 0.0082, accuracy : 99.72\n","iteration : 150, loss : 0.0079, accuracy : 99.73\n","iteration : 200, loss : 0.0089, accuracy : 99.70\n","iteration : 250, loss : 0.0094, accuracy : 99.69\n","iteration : 300, loss : 0.0097, accuracy : 99.68\n","iteration : 350, loss : 0.0099, accuracy : 99.67\n","Epoch : 292, training loss : 0.0100, training accuracy : 99.66, test loss : 0.4075, test accuracy : 94.29\n","\n","Epoch: 293\n","iteration :  50, loss : 0.0085, accuracy : 99.73\n","iteration : 100, loss : 0.0083, accuracy : 99.73\n","iteration : 150, loss : 0.0078, accuracy : 99.76\n","iteration : 200, loss : 0.0076, accuracy : 99.76\n","iteration : 250, loss : 0.0079, accuracy : 99.76\n","iteration : 300, loss : 0.0078, accuracy : 99.77\n","iteration : 350, loss : 0.0081, accuracy : 99.75\n","Epoch : 293, training loss : 0.0080, training accuracy : 99.75, test loss : 0.4073, test accuracy : 94.47\n","\n","Epoch: 294\n","iteration :  50, loss : 0.0098, accuracy : 99.69\n","iteration : 100, loss : 0.0071, accuracy : 99.78\n","iteration : 150, loss : 0.0064, accuracy : 99.81\n","iteration : 200, loss : 0.0065, accuracy : 99.80\n","iteration : 250, loss : 0.0068, accuracy : 99.79\n","iteration : 300, loss : 0.0073, accuracy : 99.77\n","iteration : 350, loss : 0.0071, accuracy : 99.78\n","Epoch : 294, training loss : 0.0070, training accuracy : 99.78, test loss : 0.4307, test accuracy : 94.56\n","\n","Epoch: 295\n","iteration :  50, loss : 0.0043, accuracy : 99.86\n","iteration : 100, loss : 0.0049, accuracy : 99.83\n","iteration : 150, loss : 0.0064, accuracy : 99.80\n","iteration : 200, loss : 0.0059, accuracy : 99.81\n","iteration : 250, loss : 0.0067, accuracy : 99.80\n","iteration : 300, loss : 0.0066, accuracy : 99.80\n","iteration : 350, loss : 0.0065, accuracy : 99.80\n","Epoch : 295, training loss : 0.0065, training accuracy : 99.80, test loss : 0.4238, test accuracy : 94.63\n","\n","Epoch: 296\n","iteration :  50, loss : 0.0057, accuracy : 99.81\n","iteration : 100, loss : 0.0063, accuracy : 99.80\n","iteration : 150, loss : 0.0062, accuracy : 99.78\n","iteration : 200, loss : 0.0081, accuracy : 99.73\n","iteration : 250, loss : 0.0084, accuracy : 99.71\n","iteration : 300, loss : 0.0084, accuracy : 99.71\n","iteration : 350, loss : 0.0089, accuracy : 99.69\n","Epoch : 296, training loss : 0.0088, training accuracy : 99.70, test loss : 0.4178, test accuracy : 94.35\n","\n","Epoch: 297\n","iteration :  50, loss : 0.0080, accuracy : 99.72\n","iteration : 100, loss : 0.0075, accuracy : 99.70\n","iteration : 150, loss : 0.0079, accuracy : 99.69\n","iteration : 200, loss : 0.0085, accuracy : 99.66\n","iteration : 250, loss : 0.0085, accuracy : 99.67\n","iteration : 300, loss : 0.0084, accuracy : 99.67\n","iteration : 350, loss : 0.0079, accuracy : 99.69\n","Epoch : 297, training loss : 0.0078, training accuracy : 99.70, test loss : 0.4168, test accuracy : 94.44\n","\n","Epoch: 298\n","iteration :  50, loss : 0.0066, accuracy : 99.73\n","iteration : 100, loss : 0.0064, accuracy : 99.77\n","iteration : 150, loss : 0.0069, accuracy : 99.74\n","iteration : 200, loss : 0.0069, accuracy : 99.75\n","iteration : 250, loss : 0.0067, accuracy : 99.76\n","iteration : 300, loss : 0.0063, accuracy : 99.78\n","iteration : 350, loss : 0.0064, accuracy : 99.77\n","Epoch : 298, training loss : 0.0064, training accuracy : 99.77, test loss : 0.4319, test accuracy : 94.40\n","\n","Epoch: 299\n","iteration :  50, loss : 0.0090, accuracy : 99.72\n","iteration : 100, loss : 0.0093, accuracy : 99.68\n","iteration : 150, loss : 0.0107, accuracy : 99.66\n","iteration : 200, loss : 0.0105, accuracy : 99.67\n","iteration : 250, loss : 0.0095, accuracy : 99.70\n","iteration : 300, loss : 0.0096, accuracy : 99.69\n","iteration : 350, loss : 0.0089, accuracy : 99.71\n","Epoch : 299, training loss : 0.0093, training accuracy : 99.71, test loss : 0.4225, test accuracy : 94.26\n","\n","Epoch: 300\n","iteration :  50, loss : 0.0063, accuracy : 99.83\n","iteration : 100, loss : 0.0076, accuracy : 99.77\n","iteration : 150, loss : 0.0072, accuracy : 99.78\n","iteration : 200, loss : 0.0070, accuracy : 99.78\n","iteration : 250, loss : 0.0073, accuracy : 99.76\n","iteration : 300, loss : 0.0071, accuracy : 99.77\n","iteration : 350, loss : 0.0072, accuracy : 99.76\n","Epoch : 300, training loss : 0.0074, training accuracy : 99.75, test loss : 0.4653, test accuracy : 93.80\n"]}]},{"cell_type":"code","source":["# the hold-out test set\n","testloader = torch.utils.data.DataLoader(\n","    testset, batch_size=256, shuffle=False, num_workers=2)\n","test_loss, test_acc = test(0, net, criterion, testloader)\n","test_loss, test_acc"],"metadata":{"id":"iUQVIKR-X3v6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668313162607,"user_tz":-480,"elapsed":2903,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}},"outputId":"71eb65d3-37f5-433f-dab5-f92df8df1db1"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.4382414690711919, 94.27243392747388)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["plt.plot(range(len(train_acc_list)), train_acc_list, 'b')\n","plt.plot(range(len(test_acc_list)), test_acc_list, 'r')\n","plt.xlabel(\"Number of epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Accuracy curve : Linear\")\n","plt.legend(['train', 'test'])\n","plt.show()"],"metadata":{"id":"7CNz1iabSB21","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1668313162608,"user_tz":-480,"elapsed":10,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}},"outputId":"ecd6bb1d-27fd-47a1-a354-abf4b691edbd"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["plt.plot(range(len(train_loss_list)), train_loss_list, 'b')\n","plt.plot(range(len(test_loss_list)), test_loss_list, 'r')\n","plt.xlabel(\"Number of epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Loss curve : Linear\")\n","plt.legend(['train', 'test'])\n","plt.show()"],"metadata":{"id":"E9qb9ItHSC5U","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1668313162608,"user_tz":-480,"elapsed":8,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}},"outputId":"ff1902ca-4365-4254-f5b2-0f5fddbc92dc"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["print(f\"train_loss_list_linear = {train_loss_list}\") \n","print(f\"train_acc_list_linear = {train_acc_list}\")\n","print(f\"test_loss_list_linear = {test_loss_list}\")\n","print(f\"test_acc_list_linear = {test_acc_list}\")"],"metadata":{"id":"3eiY3bTlWipW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668313162609,"user_tz":-480,"elapsed":9,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}},"outputId":"897d4be2-0e9a-4bc5-e1f0-dc020a719aea"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["train_loss_list_linear = [1.0505396097010067, 0.41031305952285363, 0.34015994405924144, 0.3038505317194029, 0.27671615290771007, 0.2539030461090044, 0.24293845730422312, 0.2313264879753919, 0.22205986383403867, 0.21279181394635177, 0.20017173882260877, 0.19267895106014196, 0.18516845405505603, 0.18218227440546844, 0.17281363284604012, 0.16757936995264475, 0.1608044776490064, 0.1526946394343363, 0.1503949542921087, 0.14460325269861435, 0.1379334318267338, 0.13074936200347212, 0.12652073063834654, 0.12361395870888137, 0.11955785878043027, 0.11495751238915171, 0.10918548092407586, 0.10549298947964741, 0.10151599690843081, 0.09746526491886312, 0.09452159306524084, 0.09095732697353857, 0.08772212413056352, 0.08348307219462667, 0.08420775942554884, 0.07539896097104885, 0.07707164484154443, 0.07315899130855473, 0.07151561531902047, 0.06873627238071506, 0.06587666986752452, 0.060232834865876696, 0.059981180607343754, 0.06175297403930204, 0.05708458852451951, 0.05296678836066225, 0.057111382709063976, 0.053133565748266894, 0.05266129370491073, 0.050845057070684346, 0.04849550221115351, 0.0469664877891379, 0.04695639163596419, 0.04652371517443136, 0.04273645039004221, 0.042981587787635805, 0.040151388551610795, 0.03779632822411049, 0.04038962408859879, 0.04276739005321198, 0.035970243897294085, 0.0389290425395164, 0.034595519276827996, 0.034754975707721986, 0.03550548981976138, 0.034968214722219, 0.033513369056052934, 0.033747713374943145, 0.03146642715614011, 0.03088276023026253, 0.03096695340504784, 0.030255960882325888, 0.029922214430077934, 0.026458163596317426, 0.030674233368527256, 0.026803990912770092, 0.028383832357679988, 0.029045142340322395, 0.026921882543196714, 0.025758919344589033, 0.027054627095336514, 0.026907914471629563, 0.02701804478293749, 0.026367548554233428, 0.0261913293705708, 0.02126370853306549, 0.023870387598386333, 0.02343241305678558, 0.026290576351723865, 0.024439686884867598, 0.02106365902915024, 0.022621461096346544, 0.022915108798849105, 0.026723837544939667, 0.021479926218290063, 0.022599881692684752, 0.02025709556021947, 0.019150306689010323, 0.0245601841217654, 0.02191897199554167, 0.01751039288937257, 0.019330726730524307, 0.019164910448808477, 0.024538845911642237, 0.015059424295682626, 0.020382445553086728, 0.022040061389306198, 0.018767614002140155, 0.019355695793985044, 0.019107737408797596, 0.017818392037986942, 0.017417942697963446, 0.021768966118750215, 0.017869346996114355, 0.017951215525590914, 0.01640004834187341, 0.01777675135988997, 0.019044938084980482, 0.015788522874557873, 0.022552578193564623, 0.019296770346089745, 0.014811130384146363, 0.015027894850487148, 0.018469126043487265, 0.018098258266041212, 0.014053442152699729, 0.015989337644331865, 0.018125206405116463, 0.016060621967932922, 0.014774189744400855, 0.01385672290374157, 0.018077892058706895, 0.01727216446030504, 0.014268980369684513, 0.015724211079724697, 0.016640492273927766, 0.014277730624145401, 0.016971004403142326, 0.014619164786088283, 0.016830329990812937, 0.01374343925469295, 0.012524507506886185, 0.01549116191725552, 0.013598875393053052, 0.0151209402418879, 0.014543565561276227, 0.01439005304061679, 0.01173475706005888, 0.016134371224896974, 0.011917180406560032, 0.012485065904832735, 0.0135999512963786, 0.01591276152397482, 0.011587380154317354, 0.009772636422980987, 0.01344329923276031, 0.015756404174912624, 0.014378462400149205, 0.014014234783006126, 0.012014912663851542, 0.01611480384725613, 0.012844832076313767, 0.013578993814619104, 0.011672752483787808, 0.014098815763512592, 0.012935566670426325, 0.015032568787632202, 0.012224024389351091, 0.014372231721552152, 0.011108738588597336, 0.011174887407980897, 0.016397042357398143, 0.007919598232576864, 0.011932518933157513, 0.012465056306042874, 0.012968409797498517, 0.012325529049170838, 0.011099239793170491, 0.011867815633636468, 0.012848886264346762, 0.012182228031996032, 0.011562556203482023, 0.010714672763688681, 0.013554639555182596, 0.012572727286869529, 0.01000095399527329, 0.011995266647266443, 0.011573533052920085, 0.012627172824654724, 0.013339461832399402, 0.010677528724291735, 0.011543188395016422, 0.010650319310586942, 0.009674460366150607, 0.010641892690030602, 0.012230279986791725, 0.01145689182891605, 0.01050705676828164, 0.00970218700554869, 0.011088927940358716, 0.010147759896973753, 0.0144252521625949, 0.009280225094541092, 0.0071248399373703905, 0.013807516299508516, 0.01255990872180107, 0.011576532107942895, 0.008876261175843192, 0.009988300831966212, 0.00985363164915767, 0.01084158176923064, 0.011923880645647825, 0.010890684340816107, 0.011154608579179295, 0.010417346872992216, 0.00848533340091224, 0.009280508183635208, 0.012399288785308195, 0.0072954312946646145, 0.007857306191068237, 0.013135696996073112, 0.007985612870672613, 0.009203406998578557, 0.011825267453099425, 0.009498726522558978, 0.010254976841146922, 0.012558721663513307, 0.007996204799592626, 0.007471766532690587, 0.01177365344033834, 0.010632048703338191, 0.01163114502161057, 0.008471069070895856, 0.008329393120841747, 0.010546008776983772, 0.007213423388353836, 0.009344507342992069, 0.01120725078885267, 0.008723668579122892, 0.008438797396795254, 0.009862698597215867, 0.011641287900165775, 0.009182740705942006, 0.00702334287046593, 0.010164535000019891, 0.008744396335386742, 0.009129313499368456, 0.008084669785307412, 0.010208096987843342, 0.011367271971373962, 0.007117051272343865, 0.008831601460626934, 0.00922884266564445, 0.009587360389017516, 0.008383878850809764, 0.007664171105706518, 0.010088089144474219, 0.007183663350923383, 0.010528553138330638, 0.010388069153280813, 0.008873608166863086, 0.007134666277026189, 0.00842848956719368, 0.008079520347828268, 0.009280271344362845, 0.008955260842407897, 0.010437573963957794, 0.007464409461843186, 0.00868264229136562, 0.008687793158964795, 0.008216140737795655, 0.007891892086514802, 0.007512410591053153, 0.008665417990315836, 0.008976994133145053, 0.008162402152780846, 0.008810677293791461, 0.006835815719566462, 0.007850608918254282, 0.010575828147088042, 0.008934358710317107, 0.0076927311314263745, 0.007455576667292384, 0.005771527193367357, 0.008088972039366073, 0.011438270648105747, 0.005829402718917685, 0.009437662637821316, 0.006043440636937449, 0.007854135620251515, 0.009180552848274084, 0.010004485826416422, 0.007954190094466415, 0.0069836680795018575, 0.006469878575636705, 0.008808609063802835, 0.007791922163181544, 0.006387679697369947, 0.009282423594551585, 0.007415674569260415]\n","train_acc_list_linear = [64.05293806246691, 87.14875595553202, 89.55002646903124, 90.75913181577555, 91.62308099523557, 92.33456855479089, 92.87030174695606, 93.13922710428798, 93.25780836421387, 93.82106934886183, 94.23822128110112, 94.36315510852303, 94.60667019587083, 94.74007411328745, 95.01111699311805, 95.09158284806776, 95.25674960296453, 95.67178401270513, 95.61461090524087, 95.74377977766014, 95.9915299100053, 96.22869242985706, 96.29645314981472, 96.45526733721546, 96.42985706723134, 96.65431445209106, 96.86818422445738, 96.87241926945474, 97.08628904182108, 97.16040232927475, 97.2641609317099, 97.3361566966649, 97.35309687665432, 97.51191106405506, 97.51191106405506, 97.76601376389624, 97.7342509264161, 97.88035997882477, 97.82953943885654, 97.96717840127052, 98.00317628374802, 98.16622551614611, 98.13658020116463, 98.11540497617787, 98.1937533086289, 98.37374272101641, 98.19798835362626, 98.44150344097406, 98.33562731604023, 98.41821069348862, 98.43303335097936, 98.4923239809423, 98.5643197458973, 98.4923239809423, 98.66807834833246, 98.64902064584436, 98.69348861831656, 98.76971942826893, 98.68925357331922, 98.64690312334568, 98.82053996823716, 98.74219163578613, 98.81842244573849, 98.86500794070938, 98.88194812069878, 98.78877713075701, 98.90100582318688, 98.90312334568554, 98.96664902064585, 98.97723663313923, 98.98358920063525, 99.0428798305982, 99.01111699311805, 99.12122816304924, 98.98570672313393, 99.10852302805718, 99.09158284806776, 99.05134992059291, 99.1233456855479, 99.1868713605082, 99.0873478030704, 99.10217046056114, 99.08523028057174, 99.13181577554262, 99.11064055055584, 99.33721545791424, 99.22710428798305, 99.17628374801482, 99.0979354155638, 99.20169401799895, 99.2694547379566, 99.2419269454738, 99.25463208046585, 99.08099523557438, 99.26733721545791, 99.2419269454738, 99.30968766543144, 99.3223928004235, 99.1868713605082, 99.25463208046585, 99.40921122286925, 99.36262572789836, 99.3499205929063, 99.16357861302276, 99.52355743779778, 99.31815775542616, 99.2779248279513, 99.37109581789306, 99.3499205929063, 99.37321334039174, 99.36050820539968, 99.42826892535733, 99.22075172048703, 99.41979883536263, 99.3943885653785, 99.46426680783483, 99.39015352038115, 99.33509793541556, 99.47697194282689, 99.28427739544733, 99.36050820539968, 99.5574377977766, 99.5044997353097, 99.41556379036527, 99.38803599788248, 99.5489677077819, 99.49179460031763, 99.37956590788777, 99.47697194282689, 99.5214399152991, 99.55108523028058, 99.42403388035999, 99.45156167284277, 99.51720487030175, 99.47273689782953, 99.42403388035999, 99.5299100052938, 99.41132874536792, 99.48755955532027, 99.46638433033351, 99.53202752779248, 99.57014293276866, 99.49179460031763, 99.53626257278984, 99.50026469031233, 99.50026469031233, 99.5299100052938, 99.61884595023822, 99.45579671784013, 99.59978824775013, 99.55108523028058, 99.55532027527792, 99.47273689782953, 99.62519851773425, 99.67813658020117, 99.57437797776602, 99.45579671784013, 99.5299100052938, 99.50873478030704, 99.61672842773955, 99.46214928533615, 99.59555320275278, 99.57014293276866, 99.6209634727369, 99.53414505029116, 99.58920063525674, 99.5044997353097, 99.57014293276866, 99.53626257278984, 99.58073054526204, 99.6209634727369, 99.46850185283219, 99.72260455267337, 99.58920063525674, 99.55955532027528, 99.56379036527264, 99.60825833774484, 99.64849126521969, 99.60402329274748, 99.5574377977766, 99.60825833774484, 99.61884595023822, 99.63790365272631, 99.56802541026998, 99.58284806776072, 99.66754896770779, 99.58708311275808, 99.62519851773425, 99.57226045526734, 99.59767072525146, 99.64213869772367, 99.60614081524616, 99.63366860772896, 99.66331392271043, 99.65907887771307, 99.58920063525674, 99.61884595023822, 99.67813658020117, 99.66119640021175, 99.62731604023293, 99.68237162519851, 99.57437797776602, 99.66543144520911, 99.80307040762308, 99.5574377977766, 99.5659078877713, 99.63366860772896, 99.69931180518793, 99.66966649020645, 99.67178401270513, 99.63578613022763, 99.59767072525146, 99.63790365272631, 99.66119640021175, 99.64425622022235, 99.72683959767072, 99.68660667019587, 99.61249338274219, 99.7734250926416, 99.7480148226575, 99.56379036527264, 99.74589730015882, 99.67813658020117, 99.62731604023293, 99.69931180518793, 99.65484383271573, 99.59767072525146, 99.7649550026469, 99.73319216516676, 99.61037586024352, 99.65060878771837, 99.62731604023293, 99.72260455267337, 99.73107464266808, 99.66543144520911, 99.76071995764956, 99.71413446267867, 99.62731604023293, 99.74166225516146, 99.71201694017999, 99.67178401270513, 99.58708311275808, 99.69507676019057, 99.73954473266278, 99.68025410269983, 99.71836950767602, 99.70566437268396, 99.73107464266808, 99.65272631021705, 99.61037586024352, 99.79460031762838, 99.71201694017999, 99.68872419269455, 99.70778189518263, 99.7564849126522, 99.7564849126522, 99.66543144520911, 99.76919004764426, 99.64213869772367, 99.66966649020645, 99.71836950767602, 99.76071995764956, 99.73319216516676, 99.75224986765484, 99.6929592376919, 99.67813658020117, 99.65907887771307, 99.72472207517205, 99.68872419269455, 99.71413446267867, 99.72472207517205, 99.76071995764956, 99.7924827951297, 99.69719428268925, 99.68448914769719, 99.73107464266808, 99.73742721016411, 99.76283748014822, 99.75224986765484, 99.66543144520911, 99.70354685018528, 99.7564849126522, 99.76283748014822, 99.79460031762838, 99.72260455267337, 99.64002117522499, 99.79036527263102, 99.69084171519323, 99.8009528851244, 99.75860243515088, 99.73107464266808, 99.6569613552144, 99.75013234515616, 99.77977766013764, 99.79883536262572, 99.70142932768661, 99.69507676019057, 99.7734250926416, 99.70989941768131, 99.7480148226575]\n","test_loss_list_linear = [0.6001535044873462, 0.4386981564993952, 0.32313791202271686, 0.3436826935001448, 0.3047397654576629, 0.28500792238057826, 0.26378655251042515, 0.2683426228297107, 0.27285771396960695, 0.2532431707516605, 0.25363739693135606, 0.25782927618745494, 0.2381599084200228, 0.24098271157081222, 0.23853215436432876, 0.22876223501767598, 0.2459365823762674, 0.24074384005849853, 0.23645990466078123, 0.23522190126937395, 0.23930488064812094, 0.23977934446770185, 0.22856533881642072, 0.2503986795633739, 0.2523015177096514, 0.2286284007497278, 0.2522817155821066, 0.23435633048853455, 0.25106761294106644, 0.23668714861075082, 0.25767872133748787, 0.2464016547937896, 0.24990028208669493, 0.25964026233437015, 0.2509775684014255, 0.25643125852095144, 0.25149472640352505, 0.2636343431750349, 0.2690670864802657, 0.2728121512952973, 0.2877597091719508, 0.2628066184400928, 0.289077399882908, 0.2637001336643509, 0.2718517802947876, 0.30822780637034014, 0.2853905560412243, 0.3029168626914422, 0.2886001042948634, 0.30125397385335434, 0.2918206257928236, 0.31290997323744435, 0.3016124471894228, 0.3364011060409978, 0.30226883032888757, 0.30097986143264993, 0.3160975992350894, 0.324009220079318, 0.2896068644545534, 0.28848243194321793, 0.30809056048518885, 0.31027250127026845, 0.31317287329219134, 0.3204711799728958, 0.323861251740406, 0.30745547297684583, 0.313345615642474, 0.31225476020435783, 0.32664194748755176, 0.3649349614393477, 0.3289772248781268, 0.34484266127715363, 0.34519970382326376, 0.3562348909566508, 0.34551431653181125, 0.3507686852495752, 0.3557186407749267, 0.34874562685396154, 0.3626312471414898, 0.32565479080977977, 0.3328241787111277, 0.3502718099739914, 0.35965223179436195, 0.33991847547026827, 0.32748869253212914, 0.3568636128751963, 0.366436490642966, 0.36107295554350405, 0.34370773008056715, 0.343383331070928, 0.3387923375794701, 0.33830804925631075, 0.3589262347485797, 0.3675877243079537, 0.3818419510498643, 0.35536084654649686, 0.35281344309595286, 0.3716038850629154, 0.35846942082485733, 0.34315043032242387, 0.36869288876871853, 0.3778895241226636, 0.38406652862242624, 0.352233542257226, 0.3620971898712656, 0.37449508531055614, 0.37493528568131085, 0.36601132105159406, 0.36861560567665624, 0.3717369966793294, 0.369726698087784, 0.3781300349087984, 0.35664984070714195, 0.3536169459751132, 0.406203392372631, 0.3737115380445532, 0.36973171939562055, 0.37459768973948326, 0.40706704461983606, 0.3881958369896108, 0.37344259142364356, 0.3670044747710812, 0.3696818688847855, 0.37015472998952165, 0.38189552233134416, 0.3749138325744984, 0.3891030573742647, 0.3678013856029686, 0.36681280497863306, 0.3926687809620418, 0.4037954283184281, 0.4014408321065061, 0.3803745116673264, 0.38791271775741787, 0.37617705127808687, 0.3729255223537193, 0.36608954668775495, 0.3800407153572522, 0.37864029130843635, 0.3903196998415332, 0.39593674976597815, 0.4233312764953749, 0.41837985076092404, 0.4037898524353902, 0.39368393412772934, 0.40711697678574743, 0.3831657852119237, 0.39936033349630295, 0.4122653530234946, 0.4055917443908459, 0.391819414573119, 0.3998463283493823, 0.3856644867325896, 0.38932094629853964, 0.45811930652159977, 0.4117749379582557, 0.3846923142269838, 0.38948512334814844, 0.3886060610632686, 0.4141315968488069, 0.39312611405244646, 0.40893315564037536, 0.3917342342217179, 0.4033093715232669, 0.40686407040658534, 0.402124198153615, 0.3760559221218322, 0.41189432279298116, 0.3945868524777539, 0.4064665962668026, 0.4281328501380688, 0.3944055610610282, 0.4145982712644207, 0.39619766517231864, 0.4008463170269833, 0.4100334781368135, 0.3959438812681565, 0.4048078361277779, 0.3898382809506181, 0.3940078625638111, 0.41857934771699135, 0.40016016322553305, 0.42573420590191496, 0.4076968614815497, 0.40349324788971275, 0.41680151768320917, 0.4404344489323158, 0.4126104597257925, 0.41489401694464806, 0.39322311091510687, 0.39995222047482637, 0.4001541677862406, 0.40168759471955984, 0.4003755842317261, 0.4116448443930815, 0.3964004161512004, 0.40526396525092423, 0.40040231844885094, 0.436148803023731, 0.42100324081804824, 0.42921065237811384, 0.4016612854548821, 0.4237121128860642, 0.439825722326835, 0.40309608828586835, 0.4022408921143734, 0.40526854241376414, 0.4139130270638156, 0.42377193091327653, 0.4159748113506437, 0.43089511207140546, 0.41587188575124623, 0.42511460325662415, 0.42877695572507735, 0.4061464395730154, 0.4108063448129185, 0.4237177971266575, 0.4147245909142144, 0.4100258317867331, 0.44727529514599224, 0.40763759292552576, 0.4096112189969669, 0.4398777195818576, 0.4397024883450392, 0.42169872507014694, 0.4525160300362782, 0.4039532243748944, 0.42747145336048276, 0.41558541071500776, 0.4243580105614063, 0.4347197997529863, 0.40417124533697085, 0.4213481634563091, 0.42768024219492196, 0.41689553120922224, 0.42403014976640835, 0.43499788091353636, 0.40865986559576556, 0.39625785907949596, 0.41788156942793114, 0.42710175029203, 0.39860118992453186, 0.40182735008534554, 0.43774937425612237, 0.4086107819651564, 0.42035614554861594, 0.42495340735231546, 0.42730405055943477, 0.41829457241749646, 0.4210991954211803, 0.39986408456210415, 0.43789072635163573, 0.4252349973893633, 0.4179426681058591, 0.4189265777229094, 0.42167082347327334, 0.4152061831133038, 0.4278368429582128, 0.42154261065354826, 0.39703031598279875, 0.42471260858663157, 0.4301079974747172, 0.4101321147526523, 0.4378960633869557, 0.412081252308745, 0.4338206772089881, 0.4061669551530013, 0.4237026169088067, 0.4324107744557527, 0.4283796655671561, 0.4480068746077664, 0.42207027151815446, 0.4178310304186216, 0.42660820346289113, 0.423226847276822, 0.44835605301127274, 0.4472741484733335, 0.4282900923771747, 0.4323618656535651, 0.4345184702519784, 0.4196194001455225, 0.4023636024691822, 0.4263699218977754, 0.45100487594940136, 0.4451090616046214, 0.4251364004779972, 0.4428678105822673, 0.42934233425459, 0.4463761615374025, 0.42917647955519167, 0.43650849757935195, 0.40754444616865, 0.4072841090405835, 0.43068673907249583, 0.42376545924857695, 0.4177722467438263, 0.41679786920105794, 0.4319006550381435, 0.42252690807057947, 0.4652784176572573]\n","test_acc_list_linear = [81.16548862937923, 86.56653349723418, 90.2581438229871, 89.47065150583897, 90.86893054701905, 91.77934849416103, 92.38629379225569, 92.26336816226183, 92.23263675476336, 92.60525507068223, 92.71665642286416, 92.73586355255071, 93.29287031346036, 93.27366318377382, 93.4081130915796, 93.58481868469576, 93.13921327596803, 93.3620159803319, 93.6078672403196, 93.46957590657652, 93.5540872771973, 93.73847572218807, 93.77688998156115, 93.21220036877689, 93.30055316533497, 94.06883835279656, 93.46957590657652, 94.04963122311001, 93.73847572218807, 93.8959741856177, 93.44652735095268, 93.91518131530424, 93.73847572218807, 93.6578057775046, 93.9881684081131, 93.98432698217579, 93.95743700061463, 93.98432698217579, 93.8921327596804, 93.92670559311617, 93.68469575906576, 94.3338967424708, 93.6040258143823, 94.10341118623234, 94.14950829748003, 93.79609711124769, 94.17255685310387, 93.64244007375538, 93.9958512599877, 93.56945298094652, 94.00353411186232, 93.67317148125385, 93.96127842655194, 93.50799016594961, 93.99969268592501, 94.3300553165335, 93.97664413030117, 93.78457283343577, 94.16871542716656, 94.10341118623234, 94.16103257529196, 94.16487400122925, 94.05731407498463, 94.11877688998156, 94.12645974185618, 94.16487400122925, 94.17639827904118, 94.17639827904118, 94.18792255685311, 94.02658266748617, 94.1379840196681, 93.90365703749232, 93.80762138905962, 93.93054701905348, 94.00353411186232, 93.98432698217579, 93.97280270436386, 94.06499692685925, 93.99969268592501, 94.25706822372464, 94.41840811309157, 94.01505838967425, 93.78457283343577, 94.14566687154272, 94.25706822372464, 94.04963122311001, 93.8959741856177, 93.97280270436386, 94.13030116779349, 94.41072526121697, 94.20712968653964, 94.31084818684695, 93.77304855562384, 93.85755992624462, 93.78073140749846, 94.21865396435157, 94.3262138905962, 93.96896127842655, 94.20328826060233, 94.43377381684081, 94.19944683466503, 94.17639827904118, 93.82298709280884, 94.3761524277812, 94.31084818684695, 94.13030116779349, 94.18023970497849, 94.27627535341118, 94.14950829748003, 94.30700676090964, 94.41456668715428, 94.35310387215735, 94.10341118623234, 94.3262138905962, 93.75, 94.23786109403811, 94.28779963122311, 93.94975414874001, 93.8921327596804, 93.83066994468346, 94.08420405654579, 94.37231100184388, 94.17255685310387, 94.44913952059004, 94.14950829748003, 94.3761524277812, 94.22249539028887, 94.21865396435157, 94.53365089121081, 94.14566687154272, 94.16487400122925, 93.91133988936693, 93.98432698217579, 94.2839582052858, 94.19944683466503, 94.21481253841426, 94.3338967424708, 93.98432698217579, 94.18792255685311, 94.03042409342348, 94.27627535341118, 93.83066994468346, 94.12261831591887, 94.02274124154886, 94.13030116779349, 94.0880454824831, 94.52980946527352, 94.0880454824831, 94.02658266748617, 94.3262138905962, 94.31084818684695, 94.42609096496619, 94.39535955746773, 94.42224953902888, 93.99969268592501, 94.16871542716656, 94.35310387215735, 94.23017824216349, 94.26475107559926, 94.39535955746773, 94.49139520590043, 94.26090964966195, 94.51444376152428, 94.40304240934235, 94.15719114935465, 94.16103257529196, 94.41840811309157, 94.17639827904118, 94.31853103872157, 94.31853103872157, 94.00737553779963, 94.3338967424708, 94.34926244622004, 94.3338967424708, 94.24554394591273, 94.51060233558697, 94.39151813153042, 94.27243392747388, 94.43377381684081, 94.3262138905962, 94.23017824216349, 94.24170251997542, 93.86908420405655, 94.13030116779349, 94.29164105716042, 94.35694529809466, 94.19560540872772, 94.3799938537185, 94.3338967424708, 94.25322679778733, 94.2839582052858, 94.2340196681008, 94.26859250153657, 94.69114935464044, 94.16487400122925, 94.46834665027659, 94.27243392747388, 94.36846957590657, 94.10725261216963, 94.43377381684081, 94.23786109403811, 94.46450522433928, 94.32237246465888, 94.28779963122311, 94.11493546404425, 94.16871542716656, 94.4299323909035, 94.30700676090964, 94.19560540872772, 94.46066379840197, 94.17639827904118, 94.53365089121081, 94.16871542716656, 94.29164105716042, 94.29548248309773, 94.49523663183774, 94.25706822372464, 94.10341118623234, 94.64889366933005, 94.30316533497235, 94.42609096496619, 94.44529809465274, 94.19944683466503, 94.1917639827904, 94.44529809465274, 94.16103257529196, 94.3338967424708, 94.54901659496005, 94.4721880762139, 94.31084818684695, 94.39920098340504, 94.49139520590043, 94.3761524277812, 94.45298094652735, 94.31468961278426, 94.45682237246466, 94.30316533497235, 94.55285802089736, 94.4299323909035, 94.40688383527966, 94.34542102028273, 94.4299323909035, 94.49139520590043, 94.27243392747388, 94.47602950215119, 94.26090964966195, 94.24554394591273, 94.54517516902274, 94.3300553165335, 94.29548248309773, 94.61432083589429, 94.11877688998156, 94.40304240934235, 94.27243392747388, 94.59511370620774, 94.2839582052858, 94.39151813153042, 94.39535955746773, 94.21865396435157, 94.49523663183774, 94.24554394591273, 94.51060233558697, 94.59127228027043, 94.43377381684081, 94.31853103872157, 94.46834665027659, 94.43761524277812, 94.43761524277812, 94.37231100184388, 94.34157959434542, 94.00353411186232, 94.38383527965581, 94.58358942839583, 94.5759065765212, 94.41840811309157, 94.07652120467118, 94.09956976029503, 94.3799938537185, 94.30700676090964, 94.29932390903504, 94.38383527965581, 94.5259680393362, 94.26859250153657, 94.35310387215735, 94.36462814996926, 94.37231100184388, 94.38767670559312, 94.35694529809466, 94.36846957590657, 94.34542102028273, 94.40304240934235, 94.28779963122311, 94.46834665027659, 94.56054087277197, 94.62968653964352, 94.35310387215735, 94.43761524277812, 94.39535955746773, 94.26475107559926, 93.79609711124769]\n"]}]},{"cell_type":"code","source":["train_loss_list_01 = [2.3849518770770977, 2.2417600981911345, 2.2415069635644516, 2.2409557133186153, 2.2419579268147953, 2.240125378942102, 2.240931454066662, 2.2417839348800785, 2.242252948807507, 2.241471426273749, 2.241231945472035, 2.2413479971691843, 2.241036834432504, 2.2407813569717616, 2.2415969093963706]\n","train_acc_list_01 = [18.56855479089465, 18.617257808364215, 18.746426680783483, 18.60243515087348, 18.61937533086289, 18.886183165696135, 18.60243515087348, 18.598200105876124, 18.604552673372154, 18.740074113287452, 18.731604023292746, 18.814187400741133, 18.848067760719957, 18.82901005823187, 18.752779248279513]\n","test_loss_list_01 = [2.2387831538331273, 2.241503697984359, 2.241926829020182, 2.240557459055209, 2.2406100852816713, 2.252836311564726, 2.2468298743752873, 2.2446437150824305, 2.2425780202828203, 2.240177970306546, 2.243702617346072, 2.2441832843948815, 2.253918958645241, 2.245230858232461, 2.2435202879064224]\n","test_acc_list_01 = [18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 14.27858020897357, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463]\n","train_loss_list_001 = [2.2888378896687414, 2.232192633274771, 1.4893088792236193, 0.5001831288098643, 0.3830500937251218, 0.32867970416539405, 0.29770232389774426, 0.27895135900919354, 0.2627035691970732, 0.24814978033950336, 0.23438045485475198, 0.2243682525668364, 0.21301924496848731, 0.20818865677811266, 0.1958482328166322]\n","train_acc_list_001 = [18.50926416093171, 18.968766543144522, 47.80307040762308, 84.23292747485442, 88.15881418740074, 89.9142403388036, 91.04923239809423, 91.63790365272631, 92.08893594494441, 92.58020116463737, 93.03758602435151, 93.36791953414505, 93.715193223928, 93.84012705134992, 94.35044997353097]\n","test_loss_list_001 = [2.2451091665847627, 2.2302937355695986, 0.684039752711268, 0.4374444575286379, 0.39873581839834943, 0.36398082489476485, 0.3313831433507742, 0.3210300371854329, 0.2847569804346445, 0.29315854806233854, 0.27853756525791157, 0.26896954926789973, 0.2596830692069203, 0.26028463620619446, 0.2491153629460171]\n","test_acc_list_001 = [18.88060848186847, 19.053472649047325, 78.20759065765212, 86.33988936693301, 87.90334972341734, 88.90596189305471, 90.08143822987093, 90.81515058389674, 91.70636140135218, 91.54118008604794, 91.8638598647818, 92.2480024585126, 92.43239090350338, 92.50537799631223, 92.82037492317149]\n","train_loss_list_0001 = [1.8565612323885041, 0.5532636212785715, 0.4003713336094285, 0.3402645644860539, 0.309145948165639, 0.2848975209968523, 0.262982070708501, 0.24855145600026216, 0.2386487888167221, 0.2278864942390098, 0.21327269485164788, 0.20556094100683686, 0.19517452138549268, 0.18913837452608395, 0.18232752032436653]\n","train_acc_list_0001 = [34.7993647432504, 82.35468501852831, 87.65272631021705, 89.51614610905241, 90.6723133933298, 91.51932239280042, 92.26892535733192, 92.59925886712546, 92.97617787188989, 93.34674430915828, 93.69401799894123, 93.97353096876654, 94.31868713605083, 94.53255690841715, 94.71254632080466]\n","test_loss_list_0001 = [1.0861167063315709, 0.46979708385233787, 0.41340532643245714, 0.3364271931350231, 0.3262409484561752, 0.34040282589986043, 0.28803076817854945, 0.2942232322678262, 0.2779932311169949, 0.27514038454083833, 0.2478603608906269, 0.2512748020463714, 0.26197264781769586, 0.2462065773194327, 0.24985540344142446]\n","test_acc_list_0001 = [64.00583896742471, 85.58312845728334, 87.41933005531654, 89.81637984019667, 89.970036877689, 89.99308543331284, 91.59111862323294, 91.35295021511985, 91.82928703134604, 92.03672403196066, 92.76275353411187, 92.83574062692071, 92.90488629379226, 92.98555623847572, 92.87031346035648]\n","train_loss_list_00001 = [1.2440541174192092, 0.4583125376927497, 0.36052036624613815, 0.3151768069603256, 0.2875107263081119, 0.26835051384883196, 0.25187577066948097, 0.23390740957767336, 0.22118305101950317, 0.21190600004299545, 0.20555683115350845, 0.1952596850249018, 0.18612936185546683, 0.18178928815090883, 0.17480877608181986]\n","train_acc_list_00001 = [57.18581259925887, 85.53943885653786, 88.79618845950239, 90.25304393859184, 91.214399152991, 92.01058761249338, 92.36421386977237, 93.09899417681312, 93.43991529910005, 93.80412916887242, 93.86765484383271, 94.25092641609317, 94.500794070937, 94.64478560084702, 94.82477501323451]\n","test_loss_list_00001 = [0.5935118007017117, 0.43328142947718207, 0.3668157114994292, 0.34575528556517526, 0.3590214093964474, 0.3134572241893586, 0.2903973020467104, 0.28062032824199573, 0.26905518266208034, 0.26447016406146917, 0.27132851287138227, 0.26421160440818936, 0.25491809147391836, 0.24584030433028353, 0.2630316608895858]\n","test_acc_list_00001 = [80.93500307314075, 86.63567916410571, 88.97510755992624, 89.3438844499078, 88.99431468961278, 90.58466502765826, 91.54502151198525, 91.56422864167179, 92.02135832821143, 92.25184388444991, 91.97910264290104, 92.37861094038107, 92.72433927473878, 92.96250768285188, 92.59757221880763]\n","\n","\n","\n","\n","\n","# train_loss_list_001 = [1.5218167792493924, 1.0340943300305083, 0.7934107637633911, 0.6561045421959874, 0.5800367868936862, 0.5100019117132925, 0.4574989944982072, 0.4208847186245476, 0.3881891872079228, 0.35861467820006054, 0.3339165490084944, 0.3111862796849717, 0.2948872684575498, 0.27018505394363557, 0.25883166084940823]\n","# train_acc_list_001 = [44.0975, 63.055, 72.2075, 77.0575, 79.93, 82.43, 84.0575, 85.47, 86.5625, 87.675, 88.48, 89.16, 89.645, 90.5075, 90.9225]\n","# test_loss_list_001 = [1.3665137306044373, 1.0809951907471766, 0.8369579171832604, 0.7580914105041118, 0.6663558483123779, 0.7236429437806334, 0.5709026199352892, 0.5137608224832559, 0.5140901245648348, 0.48385591937016836, 0.47491426897954336, 0.5022718974306614, 0.5243912806993798, 0.42129093069064466, 0.4074777747634091]\n","# test_acc_list_001 = [52.13, 63.83, 71.47, 73.82, 77.34, 76.49, 80.87, 82.32, 82.77, 83.6, 84.17, 83.3, 83.55, 86.28, 86.86]\n","# train_loss_list_01 = [1.8962965864723864, 1.472022865146113, 1.2269341696184664, 1.0348994015885618, 0.9050399440165144, 0.7892040218027255, 0.6947498847120486, 0.6181783355272616, 0.5774767158892208, 0.5502305545936377, 0.5206893583456167, 0.5026034010104097, 0.4774538204311944, 0.4683271567471111, 0.4492297477710742]\n","# train_acc_list_01 = [31.045, 45.415, 55.22, 62.9525, 67.66, 72.095, 75.7825, 78.6325, 80.1775, 80.8325, 82.04, 82.7775, 83.69, 83.865, 84.6225]\n","# test_loss_list_01 = [1.6557437422909314, 1.5662637073782426, 1.1888765285286722, 1.1435910184172136, 0.9932384845576708, 0.7845515208908275, 0.7405012536652481, 0.7023888849004915, 0.6914112718799447, 0.8937227891970284, 0.6744754122027868, 0.7125071339969393, 0.595223272148567, 0.6645651912387414, 0.5624623864511901]\n","# test_acc_list_01 = [38.54, 45.39, 57.61, 59.19, 65.26, 72.6, 74.56, 76.24, 76.7, 71.16, 77.34, 75.59, 80.06, 77.85, 81.28]\n","# train_loss_list_0001 = [1.6901012103016766, 1.282657652045972, 1.0717586383652002, 0.940055356619838, 0.8364242675205389, 0.7547609810821545, 0.6785155514749094, 0.6320573160061821, 0.5852954303875518, 0.5420240767466755, 0.506621429809747, 0.47925190327647393, 0.4483506758563435, 0.4286465794800189, 0.40272510780122717]\n","# train_acc_list_0001 = [37.2, 53.36, 61.4225, 66.4725, 70.2, 73.2275, 76.08, 77.8025, 79.53, 80.905, 82.42, 83.1425, 84.5575, 85.195, 86.005]\n","# test_loss_list_0001 = [1.4665760239468346, 1.2375031430510026, 1.0847761902628066, 1.0535234567485279, 0.8635394460038294, 0.757294207434111, 0.7295623666877988, 0.7312412850464447, 0.7336276015148887, 0.6307676260984396, 0.6266382736495778, 0.6370392079594769, 0.5392829055273081, 0.5410988666588747, 0.5530912065053288]\n","# test_acc_list_0001 = [46.98, 55.76, 61.4, 63.25, 69.13, 73.23, 74.32, 74.64, 73.96, 78.38, 78.25, 78.58, 81.0, 81.49, 81.32]\n","\n","train_loss_list_cut = [1.613359474907287, 1.186605121571416, 0.9613291156558564, 0.8175660327981455, 0.7329503829105974, 0.6675834229198127, 0.6155491586500844, 0.5636878716298186, 0.5260912411319562, 0.5027581219094249, 0.4726218120834698, 0.44723697268543916, 0.43208082353535554, 0.41164722000828946, 0.3974420052652542, 0.3826391176103403, 0.35894755928661115, 0.3507439031863746, 0.34107909901454425, 0.32801356564124173, 0.3124787288542373, 0.31465199137457645, 0.298767308029123, 0.28487236778766584, 0.27646335530966615, 0.27320462827103587, 0.26612033452184053, 0.26308306258993025, 0.2525483318411123, 0.24124891794146822, 0.24217433363389665, 0.23168825182004477, 0.23012469901730076, 0.21693348256162942, 0.21930161923074876, 0.21653421889669217, 0.21434410071125426, 0.20718723166579256, 0.2052558541250305, 0.19716152494041303, 0.1941497164983719, 0.19097941378339792, 0.18447992457939794, 0.18228636479701477, 0.17657887242948667, 0.17477260330043282, 0.1733962548212312, 0.17061091698825168, 0.16732201631219623, 0.1637549052556483, 0.1613706673700779, 0.16051728827075457, 0.15993363755389142, 0.15627589414770993, 0.15532852677158274, 0.15280420149858007, 0.15101519260353174, 0.14880275238341037, 0.13978494027742563, 0.14830744789002803, 0.14331960949463585, 0.13924681502409256, 0.13707038418601114, 0.1308897960062225, 0.13411890785581768, 0.13409768981627002, 0.13344513029217148, 0.1273199183205827, 0.1283481349103367, 0.12471981016924968, 0.1280518789260913, 0.12418704933394639, 0.12167530884139073, 0.12545658500430684, 0.11795977773234105, 0.11789289145423962, 0.12059933257202943, 0.11666790398355491, 0.11807365684558789, 0.11512304616931338, 0.11561917723082125, 0.11491954412323217, 0.11419005636661388, 0.10912806965624944, 0.11002509410198504, 0.11631911551466766, 0.10705401468129394, 0.1092875181331326, 0.10784903160942058, 0.10965043486069186, 0.10153051761511606, 0.1083350477579493, 0.10791226423467501, 0.10326221440665828, 0.10488084647149895, 0.100699621469925, 0.1017464189983595, 0.1026811115919782, 0.10191941613587327, 0.10146693645503384, 0.0997033108370944, 0.09700418662386961, 0.09839744385653221, 0.09619725261109706, 0.0990427272757307, 0.0953601595407096, 0.09479633424157342, 0.09373613773062588, 0.09360281742228486, 0.09450248972224161, 0.0905749333885531, 0.09483718122251499, 0.094004499824188, 0.09207623065731967, 0.0874123571696468, 0.08727556101073282, 0.09273509363444468, 0.08398670141106121, 0.08792692410964935, 0.08606394986732128, 0.08853992108648387, 0.08270674364302105, 0.08553103019539922, 0.08325290489799013, 0.08070171735109613, 0.08357380274028633, 0.0855067997409132, 0.07974059663760585, 0.07902837820208301, 0.07707989068862539, 0.08178071627101768, 0.07777025827025168, 0.0837722305065622, 0.07823536036232599, 0.07849429675731986, 0.08163950307229266, 0.0772132684176151, 0.0742708618630664, 0.07653025378839086, 0.07370652056361635, 0.07428970992767488, 0.066969591103637, 0.07278624822656377, 0.0711755252714022, 0.07434361697005007, 0.0714579665521606, 0.06873778960468194, 0.06797652607099317, 0.06636746319385763, 0.06754642966004035, 0.07100995908232448, 0.07219889727584757, 0.06691185421884631, 0.06648011294047768, 0.06790807842018125, 0.06884961091755583, 0.06649817791454994, 0.06520170254853015, 0.06067689375196116, 0.06284649541583685, 0.058577289441808726, 0.06126952098277859, 0.05914597977369357, 0.06332467258952487, 0.057384233588513474, 0.055878468872473455, 0.0626550735429691, 0.05836306477245241, 0.058223563505294985, 0.05526084442453358, 0.05660795328168633, 0.0533848489447238, 0.05570016410677863, 0.052253410154685806, 0.053411352781418224, 0.05460695667971913, 0.051183629400147417, 0.053861447934287425, 0.05485730031029152, 0.05130477134769146, 0.04791999825934014, 0.0483061204941128, 0.04967576256259895, 0.045770330684848676, 0.04519799896501028, 0.04884168341720161, 0.04494558678963742, 0.04718005882141689, 0.044031581079688506, 0.04476618649699865, 0.043659136812098494, 0.04084714540554145, 0.04083325983599399, 0.04264434854375026, 0.04191593292166297, 0.03981593097694004, 0.043085993813594785, 0.040142026240416705, 0.03974097740119353, 0.037398707843162474, 0.03773854231051268, 0.035977833013172256, 0.037191637455464936, 0.03843252851401631, 0.03596398131787991, 0.03615279636307123, 0.03480513299854038, 0.034845688106557623, 0.03309281391743273, 0.03143419835645075, 0.030938323252438643, 0.031188237175833397, 0.032819104747632485, 0.03191146987844437, 0.03148931583624702, 0.030030576116479815, 0.03224378252050843, 0.03121553240239787, 0.02776832960601063, 0.02880164314531528, 0.029192425741311222, 0.030026258470062107, 0.029695636324269085, 0.027793155418494687, 0.026486221334551828, 0.026275856554293976, 0.025177531725408646, 0.025483246410664278, 0.023590462400574986, 0.025644099438033356, 0.027068594341187146, 0.02301408553766771, 0.02522345676426047, 0.023035302803220865, 0.021253975071444418, 0.02299421675913869, 0.022151207279476424, 0.02280317421388119, 0.022020146825734655, 0.019744288622618865, 0.021754962591507946, 0.02058648679832431, 0.019481258098625193, 0.018746506298904102, 0.02082187346794223, 0.019484504032284973, 0.018540539403487676, 0.018026220258518744, 0.018277281947350635, 0.019090669363150937, 0.018498932709917426, 0.016855266360646357, 0.017087985687076854, 0.01755107378292555, 0.0162497674808287, 0.016687223960023624, 0.01735119057555918, 0.016141063884457057, 0.015963702109648276, 0.01607858874766638, 0.015593683267140184, 0.017362511261907843, 0.015086121411217502, 0.014080422949388076, 0.01572396905130198, 0.01647015061964409, 0.015150130807850569, 0.014522404045821688, 0.015314155997271045, 0.014406249093742798, 0.014474769565128028, 0.014898723138633151, 0.014346211947822056, 0.013767596740370836, 0.012941224452929376, 0.01388948843457376, 0.013728754877591856, 0.012941669198511817, 0.013923830428598122, 0.01301820403204475, 0.013493596776626622, 0.014167216677105608, 0.012224345361983505, 0.013615870727791479, 0.014401413207968916, 0.013055011124228137, 0.013154573026321495, 0.013493608308438295, 0.012507462098944587, 0.012766335765792492, 0.013181844661488367, 0.013105310207699982, 0.014206890060682409, 0.01374277858861005, 0.012588148265660475, 0.013434472534368141, 0.013608296886800576, 0.012433568900153517, 0.012731193249246266, 0.012850580789437429]\n","train_acc_list_cut = [40.9, 57.2025, 65.81, 71.35, 74.33, 76.565, 78.5275, 80.4, 81.7075, 82.5125, 83.585, 84.51, 85.1225, 85.4725, 85.9375, 86.5425, 87.3725, 87.685, 88.0775, 88.5075, 89.195, 88.7475, 89.465, 89.89, 90.23, 90.4575, 90.6025, 90.64, 91.0475, 91.385, 91.485, 91.8375, 91.855, 92.455, 92.2575, 92.455, 92.4025, 92.6625, 92.92, 93.085, 93.19, 93.35, 93.635, 93.515, 93.77, 93.805, 93.8825, 93.9425, 94.15, 94.27, 94.3925, 94.3325, 94.4625, 94.545, 94.6175, 94.6675, 94.66, 94.7825, 95.1875, 94.845, 94.9125, 95.1, 95.2425, 95.45, 95.28, 95.2525, 95.3375, 95.6875, 95.58, 95.74, 95.56, 95.7275, 95.7375, 95.7325, 95.96, 96.0225, 95.8975, 95.9725, 95.9975, 96.035, 95.935, 96.0, 96.1025, 96.3225, 96.3075, 96.0575, 96.32, 96.3125, 96.3075, 96.26, 96.575, 96.3125, 96.3875, 96.495, 96.4125, 96.585, 96.49, 96.455, 96.4925, 96.4725, 96.6375, 96.6125, 96.715, 96.775, 96.675, 96.7725, 96.7825, 96.7825, 96.775, 96.835, 96.9425, 96.72, 96.7375, 96.8475, 97.035, 97.0625, 96.845, 97.2175, 97.06, 97.1575, 97.055, 97.2325, 97.125, 97.2375, 97.315, 97.2125, 97.1925, 97.2775, 97.3325, 97.45, 97.25, 97.395, 97.23, 97.3725, 97.355, 97.2325, 97.4625, 97.4875, 97.4075, 97.545, 97.5525, 97.7425, 97.545, 97.6125, 97.505, 97.635, 97.7125, 97.72, 97.8225, 97.78, 97.6175, 97.5975, 97.86, 97.7825, 97.7725, 97.7525, 97.8075, 97.7875, 97.9775, 97.96, 98.1425, 97.9675, 98.0225, 97.88, 98.1, 98.2375, 97.9275, 97.995, 98.0375, 98.2175, 98.12, 98.26, 98.185, 98.2625, 98.275, 98.23, 98.285, 98.2475, 98.195, 98.36, 98.48, 98.4025, 98.315, 98.4725, 98.5175, 98.4075, 98.5175, 98.46, 98.535, 98.48, 98.6225, 98.6675, 98.72, 98.5975, 98.6575, 98.68, 98.525, 98.7025, 98.715, 98.78, 98.8, 98.845, 98.7975, 98.75, 98.835, 98.8225, 98.8975, 98.9, 98.925, 99.045, 98.995, 99.0175, 99.0025, 98.97, 98.9425, 99.075, 98.945, 98.9975, 99.07, 99.0825, 99.0525, 99.0625, 99.0075, 99.085, 99.2075, 99.19, 99.2475, 99.1775, 99.265, 99.1775, 99.1425, 99.255, 99.21, 99.215, 99.34, 99.245, 99.29, 99.28, 99.3, 99.3725, 99.3175, 99.3475, 99.4, 99.41, 99.2975, 99.4, 99.44, 99.45, 99.4325, 99.425, 99.4025, 99.4775, 99.44, 99.4275, 99.495, 99.4925, 99.4575, 99.485, 99.5075, 99.5, 99.5075, 99.425, 99.535, 99.5825, 99.4725, 99.5025, 99.5375, 99.545, 99.53, 99.58, 99.5525, 99.5425, 99.5775, 99.58, 99.635, 99.605, 99.59, 99.605, 99.6075, 99.65, 99.59, 99.58, 99.6125, 99.575, 99.5775, 99.59, 99.59, 99.585, 99.6075, 99.5975, 99.61, 99.635, 99.5625, 99.6, 99.6175, 99.5925, 99.6075, 99.6225, 99.5925, 99.615]\n","test_loss_list_cut = [1.4791154242769073, 1.1658613644068754, 0.9872214477273482, 0.8314349047745331, 0.9944802085055581, 0.7577941908112055, 0.7259182379215579, 0.6789853301229356, 0.7040932129455518, 0.6710618870167793, 0.5932643009891992, 0.7190747709968422, 0.5915243693544895, 0.5677886009216309, 0.5548223072214972, 0.48938161738311187, 0.5485320487354375, 0.5049594323846358, 0.5024378439293632, 0.5253199633163742, 0.545006987037538, 0.49844539429568036, 0.4618456284456615, 0.47183522431156305, 0.45087659849396233, 0.5046738835075234, 0.4737275925618184, 0.517040255326259, 0.47144785334792316, 0.43287935023066365, 0.4623851370585116, 0.4191177538301371, 0.40598977762687055, 0.39758752437332007, 0.429098657414883, 0.49839673049842254, 0.4335803312214115, 0.4391304107406471, 0.4258851580604722, 0.4272765200349349, 0.41979367031326775, 0.3996517728023891, 0.39644326382799994, 0.4050762924966933, 0.37220431883123856, 0.41266086810751806, 0.4058349334363696, 0.40598829731911046, 0.4262330528301529, 0.4142030260608166, 0.35964680000951016, 0.3874821408262736, 0.3994222947313816, 0.4099999762411359, 0.48654232843767237, 0.40172827545600603, 0.3953292958344085, 0.4276507317642622, 0.37284702835958217, 0.3759660202113888, 0.39387373701681067, 0.3743562951118131, 0.3970871818593786, 0.41597020795828177, 0.3505105532800095, 0.3577760239190693, 0.3745738009486017, 0.36575221789034107, 0.3922628566056867, 0.3804579684628716, 0.3428110468991195, 0.38194986197012887, 0.35429555196550827, 0.361780740603616, 0.3707258914467655, 0.3518540302786646, 0.3650943885875654, 0.3918004062356828, 0.3596177604756778, 0.37847324338140365, 0.40541056722779817, 0.39005918272688417, 0.3564605245107337, 0.36085661019705517, 0.41434526443481445, 0.3446986880860751, 0.3807661754043796, 0.3560769367444364, 0.3401542149389846, 0.33212360739707947, 0.34799107928064804, 0.40249927549422543, 0.3623131317428396, 0.38307136523572705, 0.3425910604905479, 0.3611237068153635, 0.37625472587120684, 0.3761880048845388, 0.3633357567500465, 0.32559320141997516, 0.3548705181743525, 0.37774981407425073, 0.33313915548445305, 0.3662335353938839, 0.34161262233046036, 0.33970868606356125, 0.33961755310810066, 0.35591573598264137, 0.36459438993206505, 0.34952369747282586, 0.3646538981908484, 0.3669853182155875, 0.346222849586342, 0.3648104143293598, 0.35329970227012153, 0.3857896882521955, 0.3397268560491031, 0.3996561256390584, 0.344681443670128, 0.35413239726537393, 0.3316430355174632, 0.38716104249410993, 0.32942197028594683, 0.35217226400405544, 0.37594665285152723, 0.34076649818239335, 0.3449836048898818, 0.3587528810470919, 0.3401296163284326, 0.3270592946983591, 0.32152744599535493, 0.3485121142260636, 0.33158980649483355, 0.35384547361467455, 0.3337541961971718, 0.31837486522861674, 0.32609030859002586, 0.35300223284129856, 0.31153832630643363, 0.331745189390605, 0.31228505301324627, 0.32915962798685966, 0.307383563322357, 0.3250211654584619, 0.32271280979053885, 0.3312963891444327, 0.3233849070494688, 0.3239633294789097, 0.3277184535996823, 0.3104742332538472, 0.32017407990709135, 0.32736679232573207, 0.31899695456782473, 0.29834681513566, 0.3152913172033769, 0.3275818183452268, 0.33088456924203075, 0.3209677238630343, 0.32485942636864096, 0.3357626995708369, 0.3363142457755306, 0.3152533290506918, 0.3161260941171948, 0.3332944193595572, 0.3038376487697227, 0.34032498092591007, 0.31091189195838154, 0.31926076189626623, 0.31000442501110365, 0.3010354260855083, 0.30018055627617657, 0.3127445231510114, 0.30238260064698474, 0.3182603884724122, 0.31473101213385785, 0.29884613908921615, 0.31703367735011667, 0.2913209448886823, 0.2881702622280845, 0.31681924888604807, 0.29637292385855807, 0.2983416555614411, 0.29558402111258686, 0.29196765764227395, 0.3100640736048735, 0.31831720773177813, 0.29677640637264974, 0.30746520772764957, 0.2865563590503946, 0.30253688547807406, 0.28961686959749533, 0.29738174973032144, 0.29680030708071553, 0.29409151684634294, 0.2892140953601161, 0.3005977722851536, 0.2880074861872045, 0.27800113717211955, 0.2859659475993507, 0.2899065754270252, 0.28989569729642023, 0.29461942848902717, 0.27184448862754845, 0.2677759771482854, 0.2699777761214896, 0.3000830202540265, 0.2926526506301723, 0.2815253124395503, 0.2683991437094121, 0.2708052956982504, 0.2659032362737233, 0.29111536092396023, 0.27172746575331386, 0.2721299055633666, 0.27334422420097304, 0.27823255380874945, 0.2846702391022368, 0.26914313680763485, 0.2824036598299878, 0.26155152982926066, 0.28833567049307157, 0.2757935132595557, 0.28530820940114276, 0.26061007040965406, 0.2689024790932861, 0.2690693513502049, 0.2623352914859977, 0.26749783254499676, 0.2726406627629377, 0.2707079539570627, 0.2750299688947352, 0.2752766144237941, 0.26105580568502224, 0.2643242926348614, 0.2672247627302061, 0.27170711321921287, 0.28075962617427486, 0.25020905593528026, 0.24921881190583675, 0.26484523855055436, 0.2614167183637619, 0.27086676525164255, 0.2653467998474459, 0.25267240150442605, 0.2534334840653818, 0.26007933452536786, 0.2619169997640803, 0.2546714186857018, 0.2537678420732293, 0.27184398217669015, 0.24711663049610355, 0.26054487415129624, 0.2526520066246202, 0.2480248349565494, 0.24464330218638045, 0.2543100225208681, 0.2467851509587674, 0.2543815068806274, 0.2550846805112271, 0.24686935845809646, 0.25780645163753363, 0.24647484842357756, 0.2498779943849467, 0.24236657725104802, 0.25234464791756644, 0.23720906674861908, 0.2444623167378993, 0.24947976245533063, 0.24974906840656377, 0.24106483623574052, 0.24051216914306714, 0.24444433122496062, 0.240749250955974, 0.24741494844231424, 0.24492908486082585, 0.24239608881217015, 0.24886162715810764, 0.24737394035239763, 0.24470583080679556, 0.23975468323200563, 0.25973454749659647, 0.24880992423129988, 0.25671024592239644, 0.2394170629072793, 0.2508298989526833, 0.25579182813061946, 0.23148325047915494, 0.2473917234736153, 0.23667787901962858, 0.24764571838741062, 0.23395111053427564, 0.23682133947746664, 0.2453216223777095, 0.2395489558200293, 0.24663213140602352, 0.2379017510934721, 0.24195825148232375, 0.23623901610321638, 0.24765730121090443, 0.24364126761314236]\n","test_acc_list_cut = [47.45, 60.0, 65.86, 71.15, 68.02, 74.04, 74.75, 76.5, 76.38, 77.35, 79.87, 75.79, 80.02, 80.57, 81.27, 83.4, 81.97, 82.87, 83.07, 82.72, 81.44, 83.43, 84.51, 84.41, 84.85, 83.96, 84.21, 82.61, 85.09, 85.42, 85.35, 86.23, 86.96, 86.92, 85.98, 84.21, 85.86, 85.85, 85.91, 86.93, 86.74, 86.97, 87.32, 87.19, 87.67, 86.55, 86.81, 87.37, 86.84, 87.3, 88.46, 87.92, 87.66, 87.19, 85.59, 87.67, 87.69, 86.81, 88.24, 88.24, 87.26, 88.01, 87.61, 87.88, 88.96, 88.76, 88.97, 88.92, 87.96, 88.36, 88.67, 87.88, 88.96, 88.67, 88.46, 88.99, 88.87, 88.21, 88.92, 88.53, 88.17, 88.26, 89.01, 88.57, 87.5, 89.68, 88.57, 88.93, 89.45, 89.58, 89.15, 88.23, 88.64, 88.35, 89.49, 89.34, 89.23, 88.47, 88.78, 89.82, 89.47, 89.04, 89.77, 88.77, 89.85, 89.69, 89.79, 89.18, 89.03, 89.57, 89.04, 89.3, 89.43, 89.17, 89.25, 88.69, 89.73, 88.08, 89.49, 89.59, 90.02, 88.41, 89.94, 89.77, 88.87, 89.91, 89.6, 89.29, 90.01, 90.18, 90.39, 89.52, 90.2, 89.82, 89.98, 90.55, 90.27, 89.84, 90.81, 90.16, 90.58, 90.17, 91.06, 90.49, 90.02, 90.36, 90.15, 90.41, 90.29, 91.05, 90.46, 90.37, 90.3, 91.15, 90.77, 90.49, 90.34, 90.44, 90.56, 90.45, 90.12, 90.36, 91.18, 90.31, 91.04, 90.24, 90.89, 90.56, 91.21, 91.14, 90.88, 90.8, 90.98, 90.69, 90.8, 91.24, 90.76, 91.31, 91.56, 90.68, 90.91, 91.29, 91.61, 91.43, 91.23, 90.98, 91.61, 91.17, 91.7, 91.2, 92.06, 91.39, 91.26, 91.56, 91.42, 91.42, 91.78, 91.94, 91.69, 91.44, 92.0, 91.36, 91.88, 92.07, 92.17, 91.33, 91.74, 91.8, 92.13, 92.09, 92.31, 91.55, 92.01, 92.26, 92.4, 91.8, 91.83, 92.3, 92.02, 92.56, 92.16, 92.24, 91.79, 92.59, 92.35, 92.7, 92.71, 92.45, 92.55, 92.34, 92.02, 92.56, 92.65, 92.35, 92.53, 92.23, 92.47, 92.65, 92.84, 92.75, 92.85, 92.58, 92.62, 92.95, 92.94, 92.61, 92.87, 92.93, 92.82, 92.37, 92.94, 92.82, 92.81, 93.03, 93.0, 92.85, 93.13, 92.88, 92.75, 93.02, 92.82, 93.14, 92.91, 93.07, 92.55, 93.2, 93.19, 93.02, 93.01, 93.03, 93.35, 93.0, 93.14, 92.89, 93.14, 93.2, 93.12, 93.15, 93.17, 93.22, 93.14, 93.1, 93.0, 93.72, 92.96, 92.94, 93.39, 92.96, 93.36, 93.22, 93.51, 93.28, 93.27, 93.3, 93.29, 93.18, 93.24, 93.64, 93.27, 93.29]\n","train_loss_list_wd5e4 = [1.5027774480965952, 1.0276084239490497, 0.7975675012356938, 0.6686166104988549, 0.5772798815474343, 0.5116038408142309, 0.461431055594557, 0.4285996074493701, 0.3872021212459753, 0.36954540337998265, 0.33349453384122146, 0.3191225348760526, 0.29570154136362164, 0.2778870724736692, 0.26335706169041584, 0.2490621807809455, 0.23208605314786443, 0.22031858939522753, 0.20280856089279675, 0.1948807320465295, 0.18225760984058959, 0.17901248411058238, 0.16944760515000493, 0.15725475339034495, 0.15281064094255525, 0.14829571347552747, 0.1351967308396539, 0.1339439639982324, 0.12818257354747373, 0.1161808082328056, 0.11971007128612111, 0.11157218916728474, 0.11184166256969158, 0.1071621371736637, 0.09870970028396041, 0.09892762057221355, 0.0908012348063552, 0.08706318784933596, 0.08129636609492401, 0.0844175164608624, 0.07711375228608378, 0.0727171496318552, 0.07881306375439365, 0.06988748621207456, 0.06977271015187517, 0.07213704411785443, 0.06465452981178467, 0.059860886116259206, 0.06565443985164165, 0.055741984914904966, 0.05937281503273656, 0.054797398726851604, 0.04783525239057339, 0.057667528927778475, 0.0519976342906253, 0.05075258484479195, 0.0479780873997857, 0.051437813953047216, 0.044275228567897514, 0.05218542266202668, 0.047849885717677045, 0.04727344876809861, 0.04353566757275369, 0.05274154159564751, 0.03900954714669778, 0.038132579750217756, 0.0438798694252468, 0.04052391117319655, 0.0444194049285814, 0.03921739171041896, 0.04322019030456059, 0.03981477512677495, 0.04147126957232627, 0.03451747147622295, 0.03873391680645581, 0.03558630044438159, 0.03961444919863448, 0.03973888016243379, 0.03753592373844915, 0.03485113727642943, 0.036234460864811184, 0.03558692057875875, 0.03258687717030747, 0.03053688010224662, 0.03501797043614256, 0.02845712277083137, 0.03135093330991821, 0.03356501266074638, 0.03350056209170019, 0.03376623985473626, 0.0308699009333032, 0.02893257925968272, 0.027391545217150984, 0.0286959023021471, 0.030725791665781942, 0.026020749267517997, 0.03082717279829204, 0.02599965874775173, 0.03394242989184995, 0.03584211132750986, 0.032864981473753815, 0.03261832850271116, 0.03152383655345383, 0.028458409716550725, 0.0237263294655425, 0.02717581400335335, 0.028603503928362084, 0.02477863742285572, 0.026328867512603348, 0.02738554204796283, 0.024270188131818946, 0.02639033293170027, 0.028431153394275915, 0.0267944870994221, 0.022552848333112014, 0.027474652415665147, 0.022996818839450376, 0.02170721744931044, 0.024480172923168005, 0.025365150559651918, 0.02576148252154644, 0.024583259466499946, 0.026209578144188506, 0.022519710091368172, 0.022190634743682446, 0.017703767737207082, 0.019398964044396966, 0.02643031852926833, 0.02380849324953787, 0.02303797679733092, 0.015461873901173318, 0.016369462731820994, 0.023921750444984333, 0.024145581647188375, 0.024439221988923062, 0.021081448698151536, 0.019269814025595806, 0.01770727836546271, 0.015750449192457307, 0.018357921256341586, 0.016851160442084668, 0.016779405207331545, 0.01922887265860749, 0.01491048913590384, 0.017494613310685175, 0.020450935306655357, 0.019253915843045036, 0.01861391122789143, 0.017561238870908397, 0.01683490170342937, 0.012796001498417827, 0.016780197644567552, 0.014076976357370067, 0.0157260496032457, 0.016004126569547784, 0.017361198594353307, 0.01750588047760018, 0.014100992143118439, 0.012314881729229857, 0.008250951137283621, 0.013473853790245878, 0.010151084203766985, 0.009842516266005918, 0.010620841719269657, 0.009969146477769667, 0.011355855877097613, 0.007406337388096372, 0.008986727931512931, 0.009986997959159387, 0.009125781858848712, 0.007472109663621567, 0.008835015864224551, 0.004292508458737998, 0.005812553818874692, 0.00677099364538924, 0.0067322269050826946, 0.004625315853274061, 0.005215383676132158, 0.006344635733596671, 0.005187604376992669, 0.003839952308653345, 0.003965519353213271, 0.002669242659610467, 0.002117635275329502, 0.002775355486739308, 0.00265736014845546, 0.0022718249013076145, 0.0020042899910497447, 0.0016117119838441976, 0.0014573458997613063, 0.001228732236187917, 0.0012267742422409356, 0.0014500122589130586, 0.0014915024765362493, 0.0012808567260394986, 0.0011165388441382767, 0.0012906825464864531, 0.001357362313477245, 0.0012554813951131897, 0.0011106275753623928, 0.0011766462907799112, 0.0011652772541354281, 0.0014127067940387006, 0.0012243740158691145, 0.0011723753179798421, 0.0012344509843341149, 0.0012428820435963451, 0.0011997493186641259, 0.001336276902967451, 0.0011452813391029217, 0.0011089205116661378, 0.001165861148571673, 0.0012621701129313452, 0.0011624022613475902, 0.0012330106737020725, 0.0011809163343030425, 0.001101714661181235, 0.0011684441624340205, 0.0011685377142329615, 0.0012322912058129478, 0.0011872104088293787, 0.001143343054307119, 0.0011744529526597394, 0.001203257890125088, 0.00115107328663714, 0.0011390011661653273, 0.0012292457904782706, 0.0011242386569215443, 0.0011883258320072802, 0.0011454876748467097, 0.001156560716423066, 0.0011528850767014627, 0.001165562277152456, 0.0011236844305395365, 0.0011447015948914967, 0.0012182490931773268, 0.0011218772364628559, 0.001162500955319157, 0.0011594401151403047, 0.001198594366161587, 0.0011824657069370388, 0.001172395464897263, 0.0012272381267998333, 0.001153445542647173, 0.0012023703809961462, 0.0011459320135334262, 0.0012018852982485589, 0.0011949562754023809, 0.0011886567682230149, 0.0011700176551697043, 0.0011815206049539792, 0.0011973182879798947, 0.0012122210003242206, 0.0011632622707971392, 0.0011874910569734894, 0.0011854940763534828, 0.0011964635884451765, 0.0011862511147771734, 0.001194577806401617, 0.0012562638589407142, 0.0012219592303293534, 0.0011857493995159221, 0.0011942158280217204, 0.0011750017043601828, 0.001190489213080547, 0.0011951297786780082, 0.0011906062601321635, 0.0011730845402048442, 0.0012332784984939206, 0.0012139175384760664, 0.0011773592329021698, 0.0012054313082075394, 0.0011924652807851926, 0.0012579563214404942, 0.001199958441122926, 0.0012173140406632386, 0.0012009810876122083, 0.001210526931255806, 0.0011779946152689143, 0.0011719051533164427, 0.001181355180083432, 0.0011896568855580191, 0.0012324937115670345, 0.0011941396765940534, 0.0011866521274376386, 0.0011868935034494287, 0.0011929624456207093, 0.0012042453618922506, 0.001203572630105665, 0.001169494700063163, 0.0012129276695946893, 0.0012054597970452337, 0.0012071873559750402, 0.0011781047958621797, 0.0011885599540055584, 0.0011778895794518126, 0.0011938168243624079, 0.0011808463227607833, 0.0012280858834437763, 0.001201700613523027]\n","train_acc_list_wd5e4 = [44.9675, 63.1875, 71.8725, 76.5, 79.885, 82.1125, 83.93, 85.2275, 86.5525, 87.015, 88.4975, 88.8775, 89.675, 90.22, 90.8925, 91.28, 91.83, 92.26, 92.8925, 93.18, 93.5725, 93.6975, 94.0725, 94.48, 94.7275, 94.8025, 95.185, 95.255, 95.445, 96.0025, 95.7275, 96.06, 96.1225, 96.2175, 96.5175, 96.4475, 96.815, 96.9275, 97.2, 97.03, 97.3525, 97.5325, 97.2775, 97.6, 97.6325, 97.4725, 97.8175, 97.9575, 97.6775, 98.13, 97.9825, 98.115, 98.465, 98.025, 98.2125, 98.315, 98.395, 98.265, 98.535, 98.2375, 98.3425, 98.4175, 98.59, 98.165, 98.775, 98.7575, 98.4825, 98.6875, 98.425, 98.76, 98.555, 98.6875, 98.565, 98.86, 98.715, 98.8725, 98.665, 98.645, 98.765, 98.8425, 98.845, 98.8475, 98.95, 99.0225, 98.8175, 99.0825, 98.97, 98.91, 98.885, 98.87, 98.975, 99.0475, 99.1425, 99.065, 99.0175, 99.1325, 98.9975, 99.205, 98.9175, 98.85, 98.9625, 98.9, 99.02, 99.0675, 99.295, 99.1675, 99.08, 99.225, 99.1425, 99.1, 99.2525, 99.155, 99.0975, 99.165, 99.3, 99.1275, 99.3225, 99.3125, 99.245, 99.1725, 99.1575, 99.2175, 99.1825, 99.32, 99.29, 99.48, 99.44, 99.17, 99.25, 99.32, 99.5675, 99.5, 99.275, 99.2075, 99.2025, 99.3425, 99.4, 99.5125, 99.5125, 99.495, 99.4975, 99.4925, 99.4125, 99.565, 99.465, 99.365, 99.4025, 99.4375, 99.445, 99.4825, 99.645, 99.4825, 99.62, 99.5275, 99.53, 99.43, 99.485, 99.61, 99.6675, 99.785, 99.5775, 99.705, 99.725, 99.6975, 99.69, 99.705, 99.8125, 99.765, 99.725, 99.77, 99.81, 99.785, 99.92, 99.8575, 99.8125, 99.82, 99.9025, 99.885, 99.84, 99.88, 99.935, 99.93, 99.965, 99.9775, 99.9475, 99.9625, 99.955, 99.98, 99.9875, 99.9925, 100.0, 99.995, 99.985, 99.9925, 99.9975, 100.0, 99.99, 99.9925, 99.9975, 99.9975, 99.995, 99.9925, 99.9925, 99.995, 99.9975, 99.9975, 99.9975, 99.9975, 99.99, 100.0, 100.0, 100.0, 99.9925, 100.0, 99.995, 100.0, 100.0, 99.9975, 99.9975, 99.995, 100.0, 100.0, 100.0, 99.995, 100.0, 100.0, 99.9975, 100.0, 99.9975, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.9975, 100.0, 100.0, 100.0, 99.9975, 100.0, 99.9975, 99.9975, 100.0, 100.0, 100.0, 100.0, 99.9975, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.9975, 100.0, 100.0, 100.0, 100.0, 99.995, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.9975, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.9975, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.9975, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","test_loss_list_wd5e4 = [1.2136726432208773, 0.9851384208172183, 0.8816822442827346, 0.9342003608051734, 0.7205261165582681, 0.7135021192363545, 0.6295640034766137, 0.6222952057289172, 0.5453219817409033, 0.6333636732041081, 0.5167707955535454, 0.5517654562298255, 0.4426909998247895, 0.41966562520099593, 0.5765619779689403, 0.43953118633620347, 0.3954082934916774, 0.399195172552821, 0.3910487050874324, 0.38879678803908674, 0.4299736600133437, 0.38120186121403415, 0.4164479757788815, 0.3728801941947092, 0.42476696719097184, 0.395566382551495, 0.39108878091166294, 0.390310141670553, 0.4194243029703068, 0.3851487408333187, 0.43473647101015983, 0.3949222198770016, 0.43027733530424817, 0.46044455280032337, 0.4314384918801392, 0.402132544525062, 0.4030761315098292, 0.4495672079958493, 0.39670435857923725, 0.3508086872251728, 0.43815861830982983, 0.4294034951849829, 0.44646918698202204, 0.4012679084192348, 0.3856019262648836, 0.38729274404954306, 0.41598545373240603, 0.4074918993666202, 0.3850251690873617, 0.36644049479237084, 0.4081271881166893, 0.3885994453596163, 0.3874774380952497, 0.38053672147702566, 0.46447082222262515, 0.3927165820628782, 0.38685785233974457, 0.3861157114181337, 0.37443527598169785, 0.3745674545629115, 0.42922606705864774, 0.3947119893906992, 0.4066375641128685, 0.4015842970413498, 0.36048868430566183, 0.35823154091080534, 0.36034491677072983, 0.3813755610321142, 0.35023685667333726, 0.3729325658347033, 0.3793654409767706, 0.3758758772400361, 0.386005234491976, 0.3741716125720664, 0.38768857264820533, 0.4233778007800066, 0.3564016471935224, 0.37897610098500795, 0.40855275943309444, 0.37117944054211244, 0.4877219747138929, 0.32491220892230166, 0.3434305104273784, 0.3840078609653666, 0.3549162511584125, 0.3900517902419537, 0.4008802462227737, 0.37963688882845864, 0.41286554225260697, 0.3738790906116932, 0.39308812431519546, 0.40336327028425434, 0.3903807069681868, 0.3731421724527697, 0.36139429652992683, 0.36114918450011485, 0.3433755166545699, 0.33576442904864684, 0.38036759027951883, 0.389648184368882, 0.3580984584515608, 0.38816530191445653, 0.35682666716696343, 0.3467950366343124, 0.3625389872283875, 0.35996044842125496, 0.3454359777366059, 0.3356767878690852, 0.37700900737243365, 0.35454515490350846, 0.33726465683194656, 0.37725700768111625, 0.37593507747861404, 0.3295244945189621, 0.3762158106399488, 0.38346752543238144, 0.3287717970677569, 0.3532322215128548, 0.3622320907402642, 0.3615872695853439, 0.3733052865047998, 0.33632627308745927, 0.3659961585757099, 0.34503319652020176, 0.3413062731299219, 0.3364775993778736, 0.3670855132462103, 0.34390894257569615, 0.35701036585282675, 0.33068783996225914, 0.3194702649606934, 0.35311298242098166, 0.35698866938488394, 0.35237887407405466, 0.38091013099573834, 0.3747274860551086, 0.3419938689168495, 0.3380954069427297, 0.36431473842527295, 0.37605810872738876, 0.3960524099537089, 0.33081852295730685, 0.36062877370586877, 0.3480613913528527, 0.37270384611962715, 0.34597224412085137, 0.3434583605090274, 0.34766560349660586, 0.3527573428199261, 0.3291342975218085, 0.3357704000759728, 0.3537662517798098, 0.35035382720488534, 0.3609619809291031, 0.36449365525306027, 0.38716287873213806, 0.36449907418293287, 0.3543851946162272, 0.3296925408553474, 0.33976211521444444, 0.36568557687952546, 0.3350432302944268, 0.35040959508358677, 0.33734601575739775, 0.35390251950372625, 0.325316196189651, 0.3150268595995782, 0.34807058489775355, 0.34181052182294147, 0.30128647698254524, 0.3265819955098478, 0.3273799891901922, 0.3255926795964, 0.3264697471374198, 0.31853930699297145, 0.3249078211905081, 0.30419793300613573, 0.31979161029375053, 0.33804947467921653, 0.30469325590360014, 0.32201941085012653, 0.32308190551739707, 0.3179449903531165, 0.29340258193544194, 0.30763082790978347, 0.3099403906660744, 0.3032598841133751, 0.30206969182325316, 0.28878650833157044, 0.298862298172486, 0.2903934564394287, 0.2809895239298857, 0.2981501730936992, 0.2927116846925096, 0.2824138938626157, 0.28358515229406234, 0.2825708462844921, 0.29461616579490374, 0.2836763092988654, 0.28226735923863666, 0.2746177826878391, 0.27155414657502236, 0.2885775946174996, 0.27818745195488387, 0.27747765494675575, 0.28425973069064225, 0.27348717754777474, 0.27310062048933176, 0.2786915644626074, 0.2682647790429713, 0.27626944993492925, 0.28479830703780623, 0.27027927178748046, 0.2733822947344448, 0.2701373880233946, 0.2778020071549506, 0.2666197860542732, 0.26562596329405336, 0.2745143292070944, 0.27233143329997606, 0.26666624231051794, 0.2696480587407758, 0.2745003360736219, 0.27249939272863954, 0.27024260172738307, 0.2686373513144783, 0.27092717569085617, 0.2656354494392872, 0.26311222001721585, 0.26525769873133187, 0.26492436928085134, 0.2699424793731563, 0.2719281587419631, 0.27291557249389115, 0.2715623058095763, 0.26247314769255964, 0.25891310165200054, 0.27840734131728545, 0.27305792734215534, 0.2638986749645275, 0.26656815414375895, 0.2615214324544502, 0.2578285336494446, 0.27850422602665575, 0.2716222282829164, 0.2712610442238518, 0.2711411705594274, 0.26657556308598457, 0.265236472498767, 0.2611617881663238, 0.27041642509306535, 0.25506745703235456, 0.2576812288806408, 0.2628553329577929, 0.2742771508195732, 0.26676151354478883, 0.26692218276896057, 0.27390673850910574, 0.2696215535360801, 0.2623596463022353, 0.2678805201585534, 0.2617303827140905, 0.2673761573254685, 0.2679485789016832, 0.26076228487529335, 0.26153764751138564, 0.2555880120283441, 0.2642273437939113, 0.25984900718248344, 0.26822723297378687, 0.2618812537645992, 0.26794138192376005, 0.2702119716832155, 0.27756816747633717, 0.2612695039450368, 0.2614873691072947, 0.2663590583148636, 0.25799272407459306, 0.2680966036417816, 0.27000968761836425, 0.2693696271015119, 0.25710588410685337, 0.26840231454447855, 0.2647050721924516, 0.2639507615019249, 0.27469288246541085, 0.2502636852898175, 0.26998129741677757, 0.2636978205623506, 0.2510043778279914, 0.26851412955718706, 0.2697306358833102, 0.26649072681423985, 0.2556019111336032, 0.2660581706256806, 0.27122338370809074, 0.2661679719067827, 0.2716638084170939, 0.2666107994280284, 0.25817724770005746]\n","test_acc_list_wd5e4 = [57.49, 65.32, 68.85, 69.25, 75.11, 76.47, 79.04, 78.91, 81.38, 79.78, 83.31, 82.27, 85.39, 86.04, 81.19, 85.57, 86.87, 86.8, 87.39, 87.89, 86.55, 87.98, 87.07, 88.42, 87.53, 87.54, 88.73, 88.01, 87.66, 88.41, 87.62, 88.47, 87.7, 87.31, 87.93, 88.33, 88.35, 87.92, 88.93, 89.82, 88.12, 87.97, 88.15, 89.02, 89.51, 89.51, 88.97, 88.91, 89.73, 90.22, 89.19, 89.69, 89.73, 89.78, 87.74, 89.45, 89.75, 89.88, 89.95, 90.06, 88.65, 89.62, 89.26, 89.31, 90.25, 90.69, 90.2, 90.24, 90.68, 90.65, 90.07, 89.97, 90.12, 90.12, 89.86, 88.49, 90.59, 90.09, 89.83, 90.61, 87.36, 91.49, 90.93, 90.05, 90.69, 89.85, 89.84, 90.3, 89.98, 90.2, 90.1, 89.68, 89.81, 90.13, 90.46, 90.27, 91.08, 91.19, 90.42, 89.93, 90.76, 90.14, 90.89, 90.66, 90.76, 91.03, 91.41, 90.93, 90.67, 90.6, 91.03, 90.24, 90.46, 91.57, 90.73, 90.03, 91.58, 90.88, 90.92, 90.68, 90.39, 91.06, 90.78, 91.26, 91.24, 91.34, 90.73, 90.8, 90.85, 91.48, 91.91, 91.43, 90.71, 90.95, 90.31, 90.52, 91.39, 91.55, 90.75, 90.81, 90.03, 91.94, 90.96, 91.39, 90.87, 91.48, 91.35, 91.49, 91.32, 91.69, 92.11, 91.03, 91.27, 91.16, 91.05, 90.7, 91.13, 91.46, 91.82, 91.81, 91.49, 91.99, 91.79, 91.73, 91.2, 91.93, 92.24, 91.43, 91.47, 92.96, 92.19, 92.09, 92.48, 92.02, 92.34, 92.2, 92.68, 92.39, 91.92, 92.75, 92.45, 92.44, 92.63, 93.15, 92.81, 92.81, 92.69, 92.93, 93.25, 92.81, 93.06, 93.3, 93.25, 93.18, 93.24, 93.27, 93.09, 92.97, 93.34, 93.48, 93.5, 93.69, 92.96, 93.63, 93.47, 93.2, 93.34, 93.33, 93.45, 93.63, 93.43, 93.45, 93.43, 93.28, 93.34, 93.46, 93.25, 93.5, 93.43, 93.59, 93.52, 93.6, 93.48, 93.48, 93.64, 93.39, 93.43, 93.53, 93.86, 93.52, 93.62, 93.52, 93.53, 93.39, 93.49, 93.6, 93.69, 93.23, 93.55, 93.52, 93.32, 93.61, 93.58, 93.53, 93.55, 93.62, 93.58, 93.59, 93.54, 93.48, 93.56, 93.71, 93.59, 93.5, 93.49, 93.58, 93.58, 93.58, 93.57, 93.58, 93.4, 93.52, 93.66, 93.54, 93.58, 93.84, 93.78, 93.32, 93.76, 93.65, 93.72, 93.33, 93.67, 93.51, 93.87, 93.69, 93.5, 93.81, 93.66, 93.74, 93.39, 93.78, 93.7, 93.6, 93.74, 93.79, 93.85, 93.54, 93.78, 93.83, 93.51, 93.47, 93.65, 93.63, 93.65, 93.52, 93.58, 93.48, 93.61, 93.69]\n","train_loss_list_wd1e2 = [1.5167798984545868, 1.027339467034934, 0.8097865730047987, 0.719615878769384, 0.658255658305872, 0.615522557935014, 0.5982994875207115, 0.5846719085789336, 0.5773727887164289, 0.5627464520664641, 0.5591158762145728, 0.5449530482292175, 0.5340716247550976, 0.5340199959925569, 0.5181504983109788, 0.5176402507498622, 0.5080099205810803, 0.49660853408396055, 0.49530376631992695, 0.4915612660848295, 0.4967052273856946, 0.49324704406741327, 0.49331052558490646, 0.48590693801355817, 0.4841031406443721, 0.48545389605787237, 0.4772332070734554, 0.47386771064406386, 0.47569251241394506, 0.4783006565639386, 0.4702882940967243, 0.47064500009289945, 0.47294196457908555, 0.45738911800110305, 0.4716209914928046, 0.4719133836011917, 0.4696217343068351, 0.45638318650257853, 0.46723246879090136, 0.4585420537870913, 0.45578641851489154, 0.465418814565427, 0.4614397684415689, 0.45631032715590236, 0.4486660618370714, 0.4534833081804525, 0.45102608156280394, 0.4530490816782077, 0.45389505011585957, 0.45014332449093414, 0.4494515047096216, 0.450234164349949, 0.4440193151037533, 0.44662567982658413, 0.44600409516892114, 0.4423091958125178, 0.44665925180950106, 0.4360342098120302, 0.43951448350668715, 0.44023644362394804, 0.4460902175964258, 0.43867638192999475, 0.4361597361465612, 0.433228444367552, 0.43528716051921296, 0.4372344275061696, 0.4323961653838904, 0.43725441934201664, 0.43545952991555675, 0.42910580998792436, 0.43043560903674116, 0.43121091731059286, 0.42305412998024267, 0.42636741055086397, 0.4268225592831834, 0.42100020314748293, 0.41761867097391486, 0.4185335077702428, 0.42368483900452575, 0.41616832524442826, 0.41972924578494536, 0.410687822789049, 0.4157286212562372, 0.4089399065358189, 0.40666280982022085, 0.4132289454198112, 0.40205181121064454, 0.40999404700419395, 0.4086824649819932, 0.40080371218177074, 0.4015931721788626, 0.4063145552580349, 0.4066784158110999, 0.40118428522024674, 0.4009731699483463, 0.3969333416547257, 0.39313930387314133, 0.39997971186432213, 0.3931039036653293, 0.38969586989559685, 0.3916486538351534, 0.38877204070076016, 0.38579398788773595, 0.3810211131557489, 0.3882365185803118, 0.38886873219340756, 0.3846093181984874, 0.38404670505287547, 0.3830401858392234, 0.3767934866701833, 0.37473060204959907, 0.37977902538860187, 0.37377259620843223, 0.38002860750824496, 0.36324887853651383, 0.3618837351235338, 0.36737791051308566, 0.3669434030311176, 0.3633396982099302, 0.36406448107367506, 0.3577735069365547, 0.353955817536805, 0.3599519186888259, 0.35612359438270047, 0.35251178142552175, 0.35027061312343366, 0.3470285452497653, 0.3470985202934034, 0.3467607243468586, 0.33784743396047584, 0.34203178333207823, 0.3446982724312395, 0.3408664211678429, 0.3342146307420426, 0.33859410405920715, 0.3276973366737366, 0.33356578295794537, 0.33072001608415913, 0.32800227998735043, 0.32374877627855675, 0.32380120865643597, 0.323726001829385, 0.3161135405397263, 0.32177544154298193, 0.3120566315639514, 0.31642273844431, 0.308783637401395, 0.32058241168340557, 0.31076529688728505, 0.3038082039489533, 0.2967669633678354, 0.30553271728582654, 0.29508178397870294, 0.2989721709070876, 0.2943779766654816, 0.29553699583862536, 0.28911615298769344, 0.29165190915330147, 0.29362286717746966, 0.28382395979124136, 0.2868227225999101, 0.2803722090138414, 0.27424085373505236, 0.28322451868758036, 0.2771561364777172, 0.2667812052816629, 0.2687817446578044, 0.26123926229179856, 0.2610385168474703, 0.2666228299799819, 0.2595565085784315, 0.25669008474380445, 0.2462938559798006, 0.2528521096982514, 0.24889454671654837, 0.2559791601504, 0.24216721735347194, 0.2481234513056545, 0.2393635288356973, 0.23972950325891995, 0.23211169509461133, 0.23631990731905061, 0.2304189305621595, 0.22999336732366976, 0.2226063944994451, 0.22054641979475753, 0.21703065643771388, 0.21686043295140464, 0.21233341681024137, 0.21059229460577614, 0.20723726490911204, 0.20685803997345245, 0.20887376510868438, 0.1978470858531638, 0.2038871747569535, 0.19181662209974693, 0.19145933929057166, 0.1935519773167924, 0.19051632768334673, 0.18543817138614746, 0.17970925828995415, 0.18026368427105224, 0.17701446067410917, 0.17569915164773836, 0.16774458888049323, 0.17213442190862693, 0.1631373402100211, 0.16456650209407836, 0.16205769175062545, 0.1562980950569002, 0.1515140765891098, 0.15663365386545466, 0.15088544290857955, 0.14032981417382867, 0.14692522343783715, 0.14212213777981628, 0.1392525550894463, 0.13808176975947217, 0.12566476896071968, 0.13361202100642955, 0.1256047902753749, 0.1272383151462855, 0.11795103549957275, 0.11710383291966237, 0.11266100632782561, 0.11401164303191554, 0.106656764119197, 0.10556819721961173, 0.10439886295566925, 0.10726791070387386, 0.09460471522884246, 0.0962810536590628, 0.09549028507341592, 0.09219917137259112, 0.0865226152379768, 0.08575040581651008, 0.08219950793745419, 0.07716210633992387, 0.07188480715163219, 0.08065827630650692, 0.06764008765355847, 0.06986326664186324, 0.07430443038551, 0.06353453783609997, 0.06618601354523398, 0.057043209338721375, 0.051298089039782745, 0.054104091200870445, 0.04759680214352882, 0.053709484345187394, 0.046893905104396824, 0.043303748533224905, 0.04337597922228586, 0.0364828174844527, 0.035764870218956434, 0.03372384082918731, 0.03319300545718723, 0.03330101266193885, 0.03186584125978116, 0.027693336871199715, 0.026877068286648573, 0.026169767811561166, 0.0256406356053897, 0.025631253985456005, 0.024362976106401448, 0.023579948727553264, 0.02450076937556457, 0.023537636362611296, 0.02355496631786465, 0.023737981790504136, 0.022986546093330215, 0.023408689955695748, 0.023427624023332, 0.02295914088813261, 0.023163542187156768, 0.023356065636102003, 0.023212027953217584, 0.02309029637434231, 0.022946245367296586, 0.022692412935411587, 0.02339219701842378, 0.023122945366004784, 0.023124087244843522, 0.02343619195893169, 0.022982527528660365, 0.023213101919895163, 0.02317301971248735, 0.022974888207956245, 0.023228626388806503, 0.02310882277263049, 0.023166305644396014, 0.022929255026407518, 0.02320044601377778, 0.02337465347787633, 0.02341003445224069, 0.022785558921698566, 0.023203995150213423, 0.023422795285384494, 0.023028960588355414, 0.023342699217148863]\n","train_acc_list_wd1e2 = [44.33, 63.2525, 71.6725, 75.2775, 77.445, 79.1175, 80.16, 80.8725, 80.74, 81.4475, 81.53, 82.1375, 82.65, 82.6, 82.96, 83.1775, 83.415, 83.7225, 83.915, 84.0275, 83.7325, 83.8675, 83.855, 84.1725, 84.09, 84.1675, 84.56, 84.5075, 84.6425, 84.4775, 84.74, 84.7025, 84.6975, 85.115, 84.7575, 84.705, 84.82, 85.3025, 84.7525, 85.0175, 85.3575, 84.9425, 85.02, 85.27, 85.5525, 85.28, 85.3825, 85.275, 85.2875, 85.52, 85.4475, 85.18, 85.4925, 85.525, 85.6125, 85.75, 85.4725, 85.7925, 85.8875, 85.5825, 85.7075, 85.8275, 86.0, 86.11, 85.95, 85.9425, 85.93, 85.89, 85.92, 86.29, 86.0525, 86.085, 86.41, 86.3275, 86.2675, 86.5075, 86.5475, 86.4525, 86.245, 86.705, 86.37, 86.7625, 86.705, 86.8875, 86.9225, 86.7075, 87.0625, 86.7475, 87.0175, 87.1175, 87.105, 86.8725, 87.09, 87.08, 87.1425, 87.405, 87.4725, 87.09, 87.4975, 87.53, 87.6025, 87.6175, 87.61, 87.685, 87.5425, 87.6175, 87.635, 87.8375, 87.78, 87.9375, 88.0275, 87.7925, 88.2425, 87.6675, 88.5325, 88.5275, 88.3, 88.4075, 88.42, 88.435, 88.6525, 88.795, 88.54, 88.7475, 88.7525, 88.77, 88.8375, 88.9225, 88.9325, 89.41, 89.1775, 89.045, 89.1575, 89.53, 89.3225, 89.855, 89.5225, 89.5275, 89.67, 89.66, 89.7775, 89.81, 90.0825, 89.9125, 90.125, 90.0025, 90.1125, 89.94, 90.265, 90.4675, 90.795, 90.4, 90.8425, 90.7075, 90.79, 90.6825, 91.02, 91.01, 90.935, 91.225, 90.995, 91.265, 91.47, 91.1175, 91.3675, 91.805, 91.6375, 91.945, 92.08, 91.76, 91.995, 92.1175, 92.48, 92.1875, 92.3625, 92.13, 92.595, 92.445, 92.71, 92.67, 93.005, 92.7375, 92.9675, 93.0725, 93.2, 93.335, 93.5175, 93.475, 93.62, 93.7325, 93.7275, 93.7925, 93.66, 94.175, 93.9525, 94.44, 94.3725, 94.22, 94.4575, 94.51, 94.8425, 94.695, 94.77, 94.87, 95.23, 94.9475, 95.2325, 95.23, 95.28, 95.5575, 95.725, 95.595, 95.7125, 96.0975, 95.9275, 95.985, 96.155, 96.23, 96.7125, 96.4, 96.5725, 96.5825, 96.8275, 96.9275, 97.0525, 96.9475, 97.2575, 97.295, 97.4575, 97.2975, 97.66, 97.6175, 97.5925, 97.81, 98.01, 97.9825, 98.08, 98.2975, 98.5225, 98.105, 98.595, 98.47, 98.3475, 98.6925, 98.59, 99.0025, 99.1525, 99.095, 99.27, 99.0025, 99.2475, 99.4225, 99.43, 99.6275, 99.635, 99.6975, 99.715, 99.7175, 99.7575, 99.885, 99.895, 99.9175, 99.925, 99.9225, 99.9675, 99.99, 99.955, 99.9825, 99.985, 99.98, 99.9875, 99.985, 99.9875, 99.995, 99.9925, 99.995, 99.9975, 99.9975, 99.9975, 99.9975, 99.995, 99.9975, 99.9975, 99.9975, 99.9925, 99.995, 99.995, 99.9975, 99.9925, 99.9975, 99.9975, 99.9925, 99.9925, 99.9975, 100.0, 99.99, 99.9975, 99.9975, 99.9925, 99.995]\n","test_loss_list_wd1e2 = [1.3725743022146104, 1.1929742784439763, 0.9703254548809196, 0.8823626479016075, 0.7912342133401316, 0.7744240081762965, 0.9433422028263913, 0.698423402218879, 0.6534588306765013, 0.8720321919344649, 0.9694693926014478, 0.7136559109144573, 1.0214628554597687, 0.8677132740805421, 0.7085553053059156, 0.6858387778076944, 0.8705045671402654, 0.7853590740433222, 0.6123643494859526, 0.8236432565918451, 0.639409672987612, 0.7271271928956237, 0.6982333724257312, 0.8511822268932681, 0.8309068830707406, 0.8227003050755851, 0.7763343317599236, 1.2531145765811582, 0.7305624854715564, 0.7311744048625608, 0.9035976242415512, 0.6800222517568854, 0.5853997695295117, 0.7430345084093795, 0.8785871493665478, 1.108451329454591, 0.6588784128050261, 0.7044716858411137, 0.6049494954604137, 0.6143702955185613, 0.7461452868920339, 0.6528882425797137, 0.8694826870024959, 0.5893921456005, 0.6651792013192479, 0.6350515420678295, 0.6344684543488901, 0.6994746138777914, 0.5725251994555509, 0.6624086785920059, 0.9637637417527694, 0.8048486015464686, 0.6040883234030083, 0.7363305929340894, 0.6205344230313844, 0.6153643851793265, 0.7306718335875982, 0.6487590738489658, 0.7805856805813464, 0.6067438793333271, 0.6581050104732755, 0.6229219368741482, 0.5560055741026432, 0.6660232819333861, 0.7725009058095231, 0.6505244955231871, 0.5968554544297955, 0.7541794965538797, 0.6514349609990663, 0.7917481374137009, 0.6845550778545911, 0.7952898657774623, 0.6756763978849484, 0.7763081943687005, 0.8057050523878653, 0.7995553084566623, 0.6522585726991484, 0.5840945632397374, 0.6991102891632274, 0.6438415571104122, 0.5860964950126938, 0.635802041126203, 0.9848449245283876, 0.7002730075317093, 0.7162983300565164, 0.637317259100419, 1.0616072612472727, 0.5819362533997886, 0.6480541802659819, 0.7091145688974405, 0.532154082497464, 0.7218736040441296, 1.2941748115080822, 0.5242264851739135, 0.5975038005581385, 0.5866859227041655, 0.7909847196144394, 0.5758454048935371, 0.613415573971181, 0.6326792579662951, 0.6269164990775192, 0.5572914639605752, 0.5726913866362994, 0.6187993967080418, 0.6928256652023219, 0.5965810301183145, 0.6376756267457069, 0.5003311121011083, 0.5492256042323534, 0.601341659509683, 0.68496092286291, 0.5872152938118463, 0.5926056911673727, 0.5051948205579685, 0.5469717281528667, 0.7418177361729779, 0.7266407209106639, 0.7612239318557933, 0.4831244179719611, 0.6568866824801964, 0.7060362685330307, 0.693530101564866, 0.5567308860489085, 0.7726584718197207, 0.7781753985187675, 0.761501886422121, 0.6479162256928939, 0.7326241222363484, 0.5910413627383075, 0.7026853682119635, 0.7172112155564224, 0.6026144582259504, 0.5826918271523488, 0.5626278546037553, 0.49854521132722684, 0.6062672617314737, 0.5234693847125089, 0.5272691702540917, 0.6541247133967243, 0.42634944221641446, 0.638887640041641, 0.49163430740561664, 0.8650434718856329, 0.6591806264617776, 0.5614948665039449, 0.5188067898720126, 0.583303042982198, 0.5776442757135705, 0.7945110775247405, 0.4383143160162093, 0.5127309507961515, 0.48725567663772196, 0.5552749682830859, 0.5127951763098753, 0.5552909845792795, 0.6396092316017875, 0.6915487266039546, 0.5918025759202016, 0.6109406363360489, 0.49616090745865543, 0.4317665135935892, 0.5233679349663891, 0.46711384986020343, 0.5448861080634443, 0.705641579401644, 0.48266834171512457, 0.4491133007067668, 0.6736038417755803, 0.41231273925757106, 0.4804556973372834, 0.49244492793384986, 0.5156307778780973, 0.5698083575013317, 0.4579203664502011, 0.5245823471606532, 0.4540955895864511, 0.4462763463394551, 0.47661840538435346, 0.3877083959081505, 0.5359865875938271, 0.47837658622596835, 0.5976610659044, 0.4057789820281765, 0.4568231581132623, 0.5033613733852966, 0.4880643072007578, 0.421935570013674, 0.3864406771674941, 0.3924215535951566, 0.4215288765822785, 0.3856588805778117, 0.39591050393219235, 0.3960021594657174, 0.4162447214881076, 0.4317766793921024, 0.43716210089152374, 0.3752851269290417, 0.3684254226428044, 0.4046018751738947, 0.4570601512736912, 0.42681945275656785, 0.3557315610254867, 0.38338644142392314, 0.45626604632486273, 0.48571689672107937, 0.4053226277420792, 0.38042039244989806, 0.40194732573213454, 0.3663549528846258, 0.40040300088592723, 0.33492799480504626, 0.34661694832994966, 0.3733026383421089, 0.31432308200039444, 0.35983454105974755, 0.3449418092075783, 0.38464838134337076, 0.34258481332018403, 0.3416274746384802, 0.3719708046203927, 0.33954131207134153, 0.3303550594969641, 0.3256681533176688, 0.3663260734911206, 0.305223887479758, 0.3600897785229019, 0.359975767286518, 0.3134645165144643, 0.31159543180013005, 0.2859196728920635, 0.3370714645031132, 0.30697164241271685, 0.3175534585231467, 0.31721039870871776, 0.3941425471743451, 0.34323022165630435, 0.2986761056169679, 0.2926558808812612, 0.298173848963991, 0.29151669446426104, 0.3160338721509221, 0.2907146306920655, 0.29263262648748445, 0.27918298995193047, 0.2787177439166021, 0.27893129094869273, 0.27565936725350876, 0.2982580420337146, 0.32113587752550465, 0.28794968552604505, 0.2873940949764433, 0.2720843562031094, 0.255550967647305, 0.24216599573817435, 0.2502805740584301, 0.2626812101542195, 0.2440197715842271, 0.24417917901956582, 0.2448149986470802, 0.2319961440148233, 0.22655500405574147, 0.2284358123058005, 0.2258316146422036, 0.22443584173540526, 0.21244820348824126, 0.21419980961687957, 0.20566311539917054, 0.20899182690095297, 0.20759060931733891, 0.20997956381002558, 0.2037774644131902, 0.20164045950845827, 0.20583347683843178, 0.209160113353518, 0.2061407360000701, 0.1988746996827518, 0.2016011231307742, 0.20003076869098446, 0.20136920108070858, 0.20208889264849167, 0.19937377427763578, 0.20227546367464186, 0.19644954659139055, 0.2079336524386949, 0.19830586704649503, 0.2019951339763931, 0.2011260839202736, 0.1998056554341618, 0.20407455923813808, 0.20218830621695216, 0.20711066649307178, 0.20228053129549267, 0.1982952310126039, 0.1989742641018916, 0.20098775002775313, 0.19563924860727938, 0.20572516359860385, 0.19656268205446534, 0.19923276595677, 0.1936172448287282]\n","test_acc_list_wd1e2 = [52.13, 58.0, 66.47, 68.48, 71.93, 73.38, 68.66, 76.35, 78.12, 70.27, 67.31, 76.04, 66.26, 71.09, 76.74, 77.08, 70.56, 74.21, 79.8, 73.72, 78.4, 76.32, 76.58, 71.8, 72.87, 73.02, 74.38, 58.91, 74.56, 75.75, 69.39, 78.21, 80.51, 75.74, 71.26, 65.74, 77.96, 76.81, 80.1, 79.77, 74.87, 77.76, 72.43, 80.66, 78.24, 79.29, 79.0, 77.18, 81.23, 77.41, 70.82, 74.14, 79.96, 75.72, 79.75, 80.63, 76.93, 78.66, 73.71, 79.9, 78.5, 79.77, 82.0, 78.63, 74.67, 77.94, 80.15, 75.57, 78.33, 74.1, 77.43, 74.34, 78.18, 75.35, 74.2, 73.88, 78.85, 80.44, 76.92, 78.07, 80.31, 78.92, 68.42, 77.39, 76.56, 79.35, 67.33, 80.82, 78.55, 77.35, 82.3, 77.25, 61.02, 82.77, 79.87, 81.04, 73.94, 81.59, 79.69, 78.21, 79.9, 81.84, 81.13, 80.0, 77.16, 80.57, 79.35, 83.74, 81.48, 80.41, 78.15, 80.5, 80.9, 83.64, 82.31, 75.42, 76.71, 75.99, 84.67, 79.01, 76.87, 77.9, 81.65, 74.49, 73.92, 75.98, 78.22, 76.52, 80.6, 77.42, 76.86, 80.4, 80.66, 81.63, 84.08, 80.38, 83.18, 82.73, 78.42, 86.07, 78.92, 84.8, 74.23, 78.45, 82.33, 83.06, 80.78, 81.68, 75.94, 85.72, 83.08, 84.02, 81.86, 83.38, 81.98, 79.64, 79.1, 80.78, 80.36, 83.85, 86.0, 82.75, 85.08, 82.98, 77.55, 84.19, 85.7, 77.95, 86.42, 84.35, 83.96, 82.9, 81.53, 85.4, 83.22, 85.75, 85.89, 84.67, 87.57, 83.16, 85.08, 81.54, 87.43, 85.54, 83.96, 84.48, 86.54, 87.69, 87.78, 86.26, 87.73, 87.31, 87.28, 86.94, 86.55, 86.06, 88.29, 88.32, 87.19, 85.53, 86.85, 89.14, 88.15, 85.86, 84.75, 87.47, 88.24, 87.6, 88.28, 87.78, 89.53, 89.36, 88.74, 90.36, 88.87, 89.5, 87.99, 89.19, 89.71, 88.6, 89.51, 90.06, 90.36, 88.83, 90.54, 89.04, 89.2, 90.63, 90.62, 91.59, 90.18, 90.87, 90.09, 90.93, 88.63, 89.71, 91.42, 91.72, 91.15, 91.61, 90.94, 91.63, 91.49, 92.14, 92.34, 92.5, 92.22, 91.41, 90.91, 92.27, 92.05, 92.77, 93.17, 93.48, 93.25, 92.79, 93.44, 93.49, 93.54, 93.83, 93.98, 93.84, 94.0, 94.24, 94.31, 94.42, 94.67, 94.34, 94.28, 94.61, 94.58, 94.66, 94.53, 94.5, 94.65, 94.62, 94.71, 94.73, 94.69, 94.61, 94.78, 94.59, 94.83, 94.68, 94.68, 94.76, 94.76, 94.77, 94.61, 94.75, 94.64, 94.51, 94.78, 94.81, 94.72, 94.81, 94.72, 94.92, 94.66, 94.96]\n","train_loss_list_300const = [1.5072595094339536, 1.0231038059670323, 0.7837633473423723, 0.6642771163306678, 0.5742667439265754, 0.5122711343315843, 0.4693711296723673, 0.42363618176204326, 0.38468483099922207, 0.3563146945386649, 0.32989333312922775, 0.3088601354402475, 0.28732080238695723, 0.2773427833050204, 0.255741254994854, 0.2355493075502947, 0.22032112675829055, 0.20569888635660513, 0.19303267375348857, 0.18455393645710078, 0.1760997775430306, 0.1610161360388937, 0.15303532645915643, 0.14379756043132502, 0.13295495837998275, 0.12522198601414603, 0.12198948780425821, 0.10830174501949606, 0.1100872532187845, 0.1019453627054398, 0.10001775390876178, 0.0945176584318804, 0.09056858165552631, 0.08527834246905086, 0.07428395165243563, 0.073358194616894, 0.0680886913840763, 0.06761494047416094, 0.06709703737006972, 0.05811852629716023, 0.05694502567985473, 0.054410113292499285, 0.048847372924831635, 0.05006321483610061, 0.04818616545470521, 0.04477997207657074, 0.04385583504540518, 0.044935471408021524, 0.04291497548661245, 0.03747522448019955, 0.03720155920232304, 0.03781872331246603, 0.03907512170084106, 0.03808571144822426, 0.0337266662997155, 0.03255701906303652, 0.02515740589887356, 0.024542150663780255, 0.02793147737166276, 0.02593546934959928, 0.02561265908809492, 0.027039424086304994, 0.02195272859767639, 0.022481467933937037, 0.023805265842651288, 0.019805631663177174, 0.020343415882660094, 0.022202910110800743, 0.021919588551681024, 0.025648440866278835, 0.024350768256822405, 0.02123939903258099, 0.01514708600285948, 0.013058545996253482, 0.016306638918867626, 0.01685327520953289, 0.016574702121484014, 0.016640731977996603, 0.01489181877258933, 0.015860306949298176, 0.014099853219945703, 0.013995581963445438, 0.016321878165777286, 0.013422961495113753, 0.010429043487289373, 0.015911166273230783, 0.011775680992100685, 0.014917363881686935, 0.018574517294552517, 0.012787643851754746, 0.014939473080523192, 0.01176600590211186, 0.012982209259662748, 0.008858771788844534, 0.009820060386200072, 0.009505460298391053, 0.011240429890194399, 0.010675670454989353, 0.010158317344160542, 0.006973291840534449, 0.006880928409012844, 0.005811905768775168, 0.007408292713742807, 0.007451252999362914, 0.010354434164527717, 0.01092628369954178, 0.012062771040645908, 0.007832180905609038, 0.010386954512029251, 0.010358608426182522, 0.00795716502255174, 0.0063932851670936985, 0.006447436372195698, 0.004587642372207018, 0.007233876957458231, 0.007980881170325053, 0.010550779263485601, 0.012090449684582942, 0.009726078081678914, 0.00813099715300611, 0.006632155526443176, 0.00597371292983393, 0.004589174477389631, 0.003584162614903578, 0.005510094879151764, 0.007690454193111211, 0.006682628281595362, 0.005014813251454181, 0.005320725576812532, 0.007166650853292368, 0.007646939404855167, 0.0068286928395223144, 0.008263683283372191, 0.007336255545465137, 0.007655256824561777, 0.007321817508736698, 0.00431125137086996, 0.003226296991330126, 0.004760576777890367, 0.0063299430897483565, 0.004795740673675748, 0.0033784159969536777, 0.0035024787487254625, 0.005299788615376221, 0.003612780912293712, 0.0032062702902157835, 0.004884716233539565, 0.005524865538374664, 0.0067742976795348445, 0.00882896750121604, 0.005893147790118473, 0.00848282681003614, 0.007084418307778205, 0.0041311039470466075, 0.003654746470935981, 0.0033575089104424215, 0.0021545471597365076, 0.003389105463073925, 0.004264044310640164, 0.004854566317398292, 0.0023904619371291056, 0.002829549484107492, 0.002053513441469564, 0.002324710492194019, 0.0021624633618179965, 0.00212872851480438, 0.0023564651491906493, 0.003220773860256611, 0.002329243483711235, 0.0029083483295660978, 0.001973968918878853, 0.00209470545457433, 0.0020779970437868503, 0.0028365065618229167, 0.003357957487961407, 0.0030591108087931595, 0.002803605341979417, 0.0023873494445828206, 0.0023525519992746557, 0.002546498180350455, 0.0016468311933363184, 0.004213925738022168, 0.003313322557223379, 0.003231858396061877, 0.002629125782985243, 0.0029141006389791914, 0.003536610023096286, 0.004142602702752726, 0.005321672680347896, 0.005746499752380254, 0.0031256999963618884, 0.0032810929011951122, 0.0043974452997825285, 0.005239838635538117, 0.004797415686162696, 0.0032062243664227707, 0.003533768229311691, 0.0029152913773755726, 0.0041634554793835415, 0.0021060470147562338, 0.005407320675629354, 0.006459823155465985, 0.004450791821244248, 0.004911506875814143, 0.003201270101376409, 0.0062131848153570805, 0.003254528715726523, 0.003693553237162894, 0.00231178058878833, 0.002128929863538825, 0.0034310214809528308, 0.0021012531412071865, 0.0037686275719023775, 0.0026402074050687757, 0.0015023963813803039, 0.0016959904317550368, 0.0023601827229728445, 0.0016248808494453031, 0.001744074698825616, 0.0017098960009427912, 0.001745167300260726, 0.001709676564420346, 0.0014354304178802375, 0.0017766182493312826, 0.0017726632421619605, 0.005174195695061486, 0.00404562306744882, 0.0019462628384505156, 0.0021156957895648327, 0.003270384036677395, 0.004819947180601103, 0.004801801557994203, 0.003892041585816488, 0.003026418740098223, 0.0016867717583173738, 0.00243665445885507, 0.001924227454584904, 0.0032565365431517818, 0.0025015898762403913, 0.004080375838660543, 0.0034671720829839744, 0.002242059777764631, 0.00174158359747937, 0.0023047459024574768, 0.0018280270336568435, 0.003222634576515772, 0.002665815578360469, 0.002171202788719592, 0.004139460606425585, 0.005407126804135614, 0.003192231660575842, 0.0023893227233684547, 0.0017126825603354112, 0.0012934664354602478, 0.0024260497488599003, 0.0017768104415345862, 0.001707909157712362, 0.0025417737575718987, 0.0026618135311662788, 0.0013963878702470945, 0.001963627433890095, 0.0015268292372885813, 0.0010931521974983068, 0.0014422832873635296, 0.0014909466068760181, 0.0013153712134022825, 0.0010111237624123271, 0.0009827128673119666, 0.0005205708235784471, 0.0008319928409817137, 0.0007095568490024797, 0.00037128912167129697, 0.0006035467810239169, 0.0011062782132314122, 0.000675376708713361, 0.0006885260622773773, 0.00101789951790438, 0.0006217252514125575, 0.0007492425983336682, 0.0021772955004840527, 0.0016886424110349782, 0.0013806177742215066, 0.001364799225246333, 0.0013202676723717748, 0.0013149851532095538, 0.0010957021063876863, 0.0007910217270622839, 0.0011311705605573214, 0.000875898118397272, 0.0015793223269400525, 0.0013224604617411992, 0.0022564116427801696, 0.0026849516309372387, 0.0020301068258375223, 0.0006494859589330384, 0.0005210057817731313, 0.000972889763034617, 0.0010060088542230168, 0.0009481032836110347, 0.001107927744007216]\n","train_acc_list_300const = [44.7525, 63.5, 72.3975, 76.605, 79.975, 82.355, 83.73, 85.3525, 86.61, 87.5825, 88.51, 89.1375, 90.01, 90.3875, 91.105, 91.8175, 92.1325, 92.8725, 93.125, 93.5025, 93.6875, 94.285, 94.705, 94.91, 95.275, 95.5425, 95.6975, 96.1225, 96.08, 96.3625, 96.4425, 96.6725, 96.75, 96.98, 97.385, 97.405, 97.635, 97.55, 97.615, 97.935, 97.9225, 98.115, 98.2575, 98.245, 98.31, 98.4675, 98.44, 98.46, 98.4925, 98.7, 98.6225, 98.6575, 98.6, 98.63, 98.765, 98.835, 99.135, 99.13, 99.0825, 99.0975, 99.1425, 99.085, 99.25, 99.21, 99.1575, 99.3575, 99.285, 99.2325, 99.23, 99.12, 99.155, 99.3075, 99.505, 99.57, 99.4, 99.43, 99.425, 99.4425, 99.495, 99.4975, 99.4875, 99.5125, 99.4175, 99.5525, 99.6225, 99.455, 99.59, 99.475, 99.355, 99.5525, 99.4975, 99.6075, 99.545, 99.7325, 99.655, 99.6675, 99.655, 99.63, 99.65, 99.7875, 99.8125, 99.82, 99.7425, 99.7475, 99.66, 99.6325, 99.55, 99.74, 99.685, 99.6475, 99.7425, 99.7775, 99.77, 99.86, 99.7625, 99.7475, 99.6, 99.5925, 99.68, 99.7275, 99.775, 99.8, 99.8475, 99.895, 99.82, 99.7325, 99.7725, 99.8375, 99.8025, 99.7625, 99.725, 99.7525, 99.705, 99.7675, 99.735, 99.72, 99.8675, 99.8975, 99.845, 99.7875, 99.8475, 99.8725, 99.8825, 99.8425, 99.865, 99.905, 99.8525, 99.805, 99.7725, 99.695, 99.8, 99.7325, 99.76, 99.8675, 99.8725, 99.9125, 99.9425, 99.9, 99.86, 99.83, 99.935, 99.8975, 99.9425, 99.9225, 99.9325, 99.9325, 99.9275, 99.8825, 99.9275, 99.8975, 99.9425, 99.92, 99.94, 99.8975, 99.895, 99.89, 99.9075, 99.9225, 99.9175, 99.91, 99.9525, 99.855, 99.885, 99.88, 99.915, 99.9, 99.8775, 99.8475, 99.8175, 99.7875, 99.905, 99.8825, 99.8775, 99.8225, 99.8675, 99.875, 99.89, 99.9025, 99.8725, 99.9275, 99.825, 99.77, 99.86, 99.815, 99.905, 99.78, 99.8975, 99.8875, 99.925, 99.9225, 99.8875, 99.9375, 99.8775, 99.91, 99.96, 99.9425, 99.9175, 99.9525, 99.945, 99.9425, 99.945, 99.935, 99.96, 99.9375, 99.9275, 99.8525, 99.8525, 99.945, 99.935, 99.8825, 99.8275, 99.825, 99.8725, 99.8875, 99.9425, 99.9125, 99.925, 99.89, 99.9175, 99.8725, 99.8975, 99.925, 99.9475, 99.9325, 99.93, 99.8975, 99.88, 99.925, 99.8575, 99.8025, 99.895, 99.9175, 99.9475, 99.955, 99.9225, 99.94, 99.9325, 99.92, 99.8875, 99.9625, 99.925, 99.95, 99.965, 99.955, 99.9625, 99.9675, 99.9725, 99.97, 99.9925, 99.9725, 99.9825, 99.9925, 99.9825, 99.9625, 99.9875, 99.9725, 99.9625, 99.985, 99.975, 99.9375, 99.9475, 99.9525, 99.9625, 99.965, 99.97, 99.97, 99.9775, 99.9675, 99.9775, 99.9525, 99.95, 99.9225, 99.905, 99.945, 99.985, 99.985, 99.9675, 99.98, 99.9725, 99.95]\n","test_loss_list_300const = [1.3109248876571655, 0.9655934632578983, 0.8187996443313889, 0.689740173047102, 0.6772998514809186, 0.6437552631655826, 0.5553377157525171, 0.5520454826234262, 0.5120236824584913, 0.5249090968053552, 0.47987785124326054, 0.45728976138030425, 0.4652932938895648, 0.49931400976603546, 0.5139825019655349, 0.46358482577378235, 0.5389019496078733, 0.4064606526229955, 0.4374082180895383, 0.41569147004356866, 0.42417793334284914, 0.43346760355973546, 0.4166975364654879, 0.3910007622045807, 0.4190592248983021, 0.4890744652174696, 0.4130742766811878, 0.44733505535729323, 0.3960334837813921, 0.4205396575263784, 0.4506959509623202, 0.45510448968108697, 0.4337734672464902, 0.4140701989961576, 0.44726073873948446, 0.43756397483469567, 0.4081488196985631, 0.4404116733164727, 0.4069605218836024, 0.4365550541802298, 0.4524993513581119, 0.4810156839180596, 0.4475790313150309, 0.43388396841061266, 0.4388974361781833, 0.4250442619565167, 0.4161135846678215, 0.4599215022370785, 0.4951787300502198, 0.5083512184740622, 0.4711726530443264, 0.5019661293754095, 0.42351165593047685, 0.4634768115946009, 0.472742423415184, 0.4849290226267863, 0.4477674431061443, 0.48274370330043986, 0.4825481849757931, 0.4942950615777245, 0.5367305686202231, 0.4768067407834379, 0.4528346563441844, 0.49772302598892887, 0.43751826391944404, 0.4484408743019345, 0.5320610732217378, 0.47107771444547025, 0.4548007876058168, 0.48090932169292544, 0.47415826705437675, 0.44294909170911284, 0.408969871039632, 0.4602267291349701, 0.4937338570627985, 0.5272085793033431, 0.5100355125680754, 0.46345121894456165, 0.4728180213442332, 0.48767814587188674, 0.4734298460468461, 0.5140062019794802, 0.48423475234568875, 0.4522600043800813, 0.4885755015324943, 0.4898544026515152, 0.48496218667000157, 0.5125900219324269, 0.4700437818146959, 0.45802032928678055, 0.49178935455370554, 0.48068239813364005, 0.4772832633196553, 0.45595825010839897, 0.4741470496865767, 0.508940930796575, 0.47970542651188525, 0.5067461744139466, 0.47261701335635364, 0.4504903811442701, 0.4822925106634068, 0.4916953529360928, 0.4976545244078093, 0.5076064607010612, 0.512105936019481, 0.5002134619634363, 0.4895322826466983, 0.46702025679847864, 0.5068643896640102, 0.5748100429773331, 0.4924963390148139, 0.49676062770282164, 0.5234567566385752, 0.49199416045146654, 0.5275697438400003, 0.5010442611160157, 0.49138097276416004, 0.5251847050989731, 0.5231706929169123, 0.4994612190919586, 0.475140321481077, 0.4973598703553405, 0.46391360763507555, 0.4987307276718224, 0.5342934448507768, 0.490154218258737, 0.5101715593209749, 0.5079800128182278, 0.4876681245580504, 0.5047554036107245, 0.4933491258681575, 0.5017587872622888, 0.5059225696928894, 0.4965471655507631, 0.5347162768999233, 0.5293986288995682, 0.48946061645504796, 0.4993787820957884, 0.5046113696468028, 0.5203786311270315, 0.5163537305367144, 0.4821115889692608, 0.554601405617557, 0.5177212712130969, 0.5428616695011719, 0.5283017215094988, 0.5123567226566846, 0.5303934999281847, 0.5816303280335439, 0.5290483341941351, 0.5672795996069908, 0.579266353309909, 0.5199603319545335, 0.4895725855721703, 0.5205931299472157, 0.5044250222323816, 0.5172668089029155, 0.48294846157107174, 0.5366536256255983, 0.5250458570220803, 0.5189918728568886, 0.5009268411918532, 0.5045282197526738, 0.5237355313346356, 0.511520393098457, 0.525018301002587, 0.510031249515618, 0.5295086546411997, 0.4966339695302746, 0.52833208498321, 0.49447107315063477, 0.5136264913444277, 0.5089094453031504, 0.5464415133376664, 0.5187408701528476, 0.5190243262656128, 0.5516869642689258, 0.5397132114519047, 0.5154607352576678, 0.5146083532820774, 0.5073600661339639, 0.5701480022148241, 0.5735466538728038, 0.5491804146691214, 0.5422320174454134, 0.5446482123453406, 0.5426935783669918, 0.5710887145015258, 0.5220382987887044, 0.5417104106915148, 0.5754493603223487, 0.533619965744924, 0.5762778842185117, 0.5338592627380467, 0.5573781338296359, 0.5375887101775483, 0.5312822029183183, 0.5451974290647085, 0.5270344963933848, 0.5519347873669637, 0.5583887022884586, 0.5747697632524031, 0.53732075910025, 0.544713698799097, 0.54281858609447, 0.5719384611407413, 0.5202449362111997, 0.5084290615742719, 0.5141259058366848, 0.5029577503475962, 0.5330851511864723, 0.5383445264040669, 0.5445871983147874, 0.5439003353254704, 0.5215786695480347, 0.5109690418349037, 0.530744302310521, 0.49466055395859704, 0.5258592778368841, 0.5579611717522899, 0.5201689512292041, 0.5321517630091196, 0.5553653376011909, 0.5559994182254695, 0.5492764958475209, 0.5437155616811559, 0.5355881104552294, 0.5277321902634222, 0.539707180819934, 0.5771049804325346, 0.5852305162933809, 0.5669170301171798, 0.5253017652261106, 0.5338942474579509, 0.5554900363653521, 0.5405757495119602, 0.5658218766315074, 0.5613152086734772, 0.5465129902468452, 0.5272626559945601, 0.5295005417134189, 0.5047299167777919, 0.49300466383559793, 0.5492192791609825, 0.553901323977905, 0.5375248759607726, 0.5450990347168113, 0.5740641949674751, 0.6136820884067801, 0.549185292064389, 0.5533378690103942, 0.5597253417289709, 0.5323915726776365, 0.5313113266720048, 0.5539356519149828, 0.5392684795056717, 0.5539341314306742, 0.5655378125890901, 0.5571187838346143, 0.5493852450877805, 0.541150254162052, 0.5641609287903279, 0.5385742417619198, 0.5644041978860204, 0.5555187009180649, 0.5374931981669197, 0.5337770737801926, 0.5295022774157645, 0.5276252516085589, 0.526966481646405, 0.5239434323356121, 0.5202406580689587, 0.5424046025057382, 0.5546739329642887, 0.5492268700765658, 0.5330030725726599, 0.5302840090250667, 0.559327697074866, 0.5229975948982601, 0.5579739920323408, 0.5483722508519511, 0.5500919239807732, 0.5255736416276497, 0.5679198548763613, 0.5679364106323146, 0.5342161246115649, 0.5500478484208071, 0.5313761402157289, 0.5704804831479169, 0.5673190015780775, 0.5638997756604907, 0.5896313563932346, 0.5433095578528657, 0.5565140822642967, 0.5584272151883645, 0.5537656983242759, 0.548184348058097, 0.5406601837352861, 0.555926272952104, 0.5514698358653467]\n","test_acc_list_300const = [53.98, 65.75, 72.1, 76.14, 77.31, 77.93, 81.02, 81.31, 82.75, 82.79, 83.69, 84.8, 85.35, 83.73, 83.79, 85.27, 84.08, 86.95, 86.6, 86.76, 87.11, 87.3, 88.07, 88.24, 87.9, 86.96, 88.42, 88.0, 88.7, 88.74, 87.84, 87.77, 88.76, 88.95, 88.48, 88.71, 89.77, 88.58, 89.26, 89.81, 89.22, 88.58, 89.44, 89.89, 89.57, 89.96, 89.93, 89.62, 88.5, 89.02, 89.32, 89.09, 90.25, 89.9, 90.15, 89.83, 90.56, 89.5, 90.0, 89.84, 89.55, 90.01, 90.27, 89.89, 90.63, 90.74, 89.52, 90.6, 90.0, 90.07, 90.5, 91.04, 91.19, 90.84, 90.5, 89.92, 90.31, 90.59, 90.56, 90.44, 90.87, 90.43, 90.47, 91.12, 90.58, 90.7, 90.83, 90.28, 91.18, 91.08, 90.76, 90.93, 91.05, 91.44, 91.19, 90.73, 91.14, 90.84, 91.04, 91.48, 90.9, 91.52, 91.12, 91.39, 90.99, 90.96, 91.09, 91.44, 91.0, 90.32, 91.25, 91.42, 91.16, 91.08, 90.75, 91.24, 91.32, 90.74, 90.9, 91.13, 91.6, 91.41, 91.7, 91.22, 90.61, 91.46, 90.95, 91.5, 91.36, 91.43, 91.4, 90.91, 91.13, 91.28, 91.29, 91.08, 91.73, 91.34, 91.19, 91.15, 91.59, 91.75, 91.13, 91.5, 91.47, 91.33, 91.42, 91.52, 90.83, 91.11, 91.09, 90.95, 91.6, 91.74, 91.37, 91.74, 91.61, 91.83, 90.89, 91.51, 91.79, 91.72, 92.0, 91.68, 91.82, 91.75, 91.83, 91.66, 91.79, 91.57, 91.82, 91.86, 91.98, 91.55, 91.74, 91.64, 91.27, 91.43, 91.88, 91.69, 92.03, 91.23, 91.2, 91.33, 91.81, 91.53, 91.45, 91.15, 91.51, 90.91, 91.23, 91.95, 91.46, 91.29, 91.48, 91.44, 91.69, 91.54, 91.51, 91.46, 91.42, 91.05, 91.18, 91.19, 91.56, 91.29, 91.73, 91.76, 91.56, 91.49, 91.62, 91.53, 91.7, 91.61, 91.97, 91.83, 92.04, 91.91, 91.65, 91.62, 91.6, 91.81, 91.53, 91.51, 91.84, 91.74, 91.75, 91.74, 91.9, 91.56, 91.06, 91.42, 91.51, 91.83, 91.39, 91.63, 91.73, 91.66, 91.55, 91.7, 91.4, 91.93, 92.04, 91.7, 91.47, 91.45, 91.64, 91.32, 90.81, 91.54, 91.31, 91.47, 92.03, 91.83, 91.86, 91.87, 91.91, 91.64, 91.84, 91.63, 91.8, 91.87, 92.0, 91.71, 91.79, 91.94, 92.08, 91.91, 92.31, 92.23, 92.29, 92.38, 92.07, 92.0, 91.81, 92.24, 92.44, 92.16, 92.14, 91.99, 91.69, 91.77, 92.03, 91.96, 91.84, 92.05, 91.96, 91.89, 92.32, 91.83, 91.85, 91.69, 92.02, 91.96, 91.93, 92.11, 91.92, 92.17, 91.77, 92.18]\n","train_loss_list_300cosine = [1.5071465310197287, 1.0219155532864337, 0.7846573638839843, 0.6613810150958479, 0.5711964959153732, 0.5125089824770968, 0.4690145238900718, 0.4279545375142996, 0.38901165142036476, 0.3574826151799089, 0.32995736313323243, 0.3070905926033331, 0.29151374520585177, 0.27276346844415694, 0.2528251954637016, 0.2403833875164818, 0.21865639683251945, 0.21172414217798854, 0.1913816854833795, 0.18111336490692803, 0.1749152649943821, 0.16864872572663875, 0.15266839607645527, 0.1438077868649754, 0.131705386099962, 0.12894651846002086, 0.12342969215097138, 0.11197239956773888, 0.10989574266198915, 0.10079097377058988, 0.08904699315302098, 0.09436483237856684, 0.08817791208898583, 0.08477092711939313, 0.08056267116147393, 0.07277504891490404, 0.07563522219146117, 0.07128996417795222, 0.057986204402324874, 0.06231818245218013, 0.05127317121716591, 0.05075172336099628, 0.05728455614774657, 0.05022484378014414, 0.047201051832007145, 0.04299503102446326, 0.04491299623028396, 0.03698193365499711, 0.03486268078765502, 0.03927968754864539, 0.03724308135345007, 0.03970887712738551, 0.03285741158493292, 0.028173236158518744, 0.028217624198978605, 0.029066849599247234, 0.028810474211156678, 0.026399405389732587, 0.025763797607963174, 0.022101726805115827, 0.0206387186558328, 0.023366123397712605, 0.019345413963012873, 0.024243142143205797, 0.02154286678515214, 0.01816358644301042, 0.021265280448992292, 0.015330405338271595, 0.017995145478354284, 0.014342598256486924, 0.015467149512258362, 0.016130026668673175, 0.013699235769971377, 0.011888031450363573, 0.010789586022736494, 0.010900068600833514, 0.009051817458605739, 0.010178615377595523, 0.011202018590738473, 0.014404841935349116, 0.01132253416424867, 0.010159075095953521, 0.008117529459464283, 0.009489624014945505, 0.010137052083415494, 0.008486186185057242, 0.006968282311358831, 0.007533594105837527, 0.008950318053382235, 0.008889065595822946, 0.007539918537286241, 0.0057594785649967666, 0.006437454009137117, 0.005282934063498991, 0.004347972699934572, 0.005166493265034323, 0.004321007760212431, 0.00471395535047535, 0.0032943137242381028, 0.004311655514717282, 0.003059743971269304, 0.0039670848353404575, 0.0030527470893090434, 0.003868208768115135, 0.0034133147897016363, 0.004668654355293675, 0.0059490043992545235, 0.0041872456292248, 0.0038983581991906308, 0.0037588840379914716, 0.003916245875395213, 0.0034797456036773718, 0.0029193548814658767, 0.0028640743580595858, 0.0023959889678485742, 0.0022046099687237837, 0.00213721157060805, 0.001905863403416865, 0.0018298605383502951, 0.0019732695092532088, 0.0012731390455790247, 0.0014643412322186396, 0.0014584561287045482, 0.0013225552577550437, 0.0012107872296070626, 0.0009283569928718647, 0.0009475817591004316, 0.0009087429049996629, 0.0012826446498267045, 0.0011837309814490989, 0.0007089067522449444, 0.0007332131970385923, 0.0012466143751911653, 0.0009211793556768187, 0.000789917121722373, 0.0007207691697882189, 0.0007975770474887959, 0.0006758498559978029, 0.0007351151072098131, 0.0010837652537124284, 0.000724128287233449, 0.0005810306201093711, 0.00047435187363775613, 0.0004135937659276342, 0.0007063415897789764, 0.000588239943727893, 0.0005826207090225168, 0.0003262833067903336, 0.00038663124462745416, 0.0004899335792227164, 0.00045023311883942547, 0.00032505322259691985, 0.0004240722920772437, 0.000434831311982059, 0.0005759489223388422, 0.0003049708239195287, 0.00034293277186921384, 0.00026971405763318425, 0.00031280760296981017, 0.0007162304362590164, 0.0005976533334854375, 0.00044388456952353377, 0.00032143614894833265, 0.0003041571174924992, 0.00035453209945005774, 0.00023628432779605936, 0.00022958813212190958, 0.00018880277622619602, 0.00021482868581873839, 0.0001753957263578302, 0.00041403284841927493, 0.00021361697475566445, 0.0002520289759267065, 0.00019671708842346002, 0.00019921282705291114, 0.00030435736312682684, 0.00029258786672637244, 0.00027827393721283804, 0.0002795331743087422, 0.00024584021705562536, 0.00020301578391222058, 0.00015932558792188886, 0.00035799621748254593, 0.00028251744383299383, 0.00021141435477205867, 0.00022243324366817674, 0.00020670883468984464, 0.00021545639445687408, 0.00016235478455645368, 0.00022787957680421982, 0.00016665564254608194, 0.0001477420311949244, 0.00018142510538173126, 0.00034612401611176406, 0.00015685088123029036, 0.00019157101443428062, 0.00019864877790692532, 0.00020180520096545342, 0.00012184150966041865, 0.00010955794329265264, 0.0002272417015756974, 0.00012062133251651577, 0.00024990162183020963, 0.00019493304157317115, 0.00011319477053125949, 0.0001146485327846252, 0.0001126736392463569, 0.00013831783792320434, 0.0001353729226037266, 0.0001630674412422994, 0.0001457879433627867, 0.00012657002445250193, 0.00020756496892448712, 0.0001576078423556483, 0.00016432452238864054, 0.00013326239761994157, 0.000126308732199333, 0.00011329932245867901, 9.373737983756487e-05, 0.00012264910064071485, 9.72924513225386e-05, 9.851183427198616e-05, 0.00014160107466290727, 0.00019542356384294292, 0.00010866884136099055, 0.00012103338623344784, 0.00010338596340528902, 0.00012947641171964864, 0.00016585586701756884, 0.00012378471780928916, 0.00012914159678432927, 8.873532887934217e-05, 0.00012277717895865415, 0.00010324342793536724, 0.00011429319050957435, 0.00014108263730566994, 0.00011344413554959498, 0.0001314912391754855, 0.00014366292956832224, 0.00010670398796356165, 9.395798729230545e-05, 9.690826291712445e-05, 8.27918457593515e-05, 7.49523732641198e-05, 0.000116572610751607, 0.00010861793663089236, 0.00010167052199556757, 0.0001307339418356521, 0.00010273090034757616, 0.00012697175096751327, 0.00012768910120719, 7.014640353397078e-05, 9.454710011857551e-05, 0.00011274885802570828, 0.000126904926870751, 9.48965783575255e-05, 9.193459106337249e-05, 8.93238301681306e-05, 0.00010053854063013211, 0.00010620467252830129, 0.00014532459377346714, 8.020320023135105e-05, 7.178885715230178e-05, 0.00011935103254135713, 9.011012685912722e-05, 8.608197714011839e-05, 9.837138899922847e-05, 0.00010366790116276302, 8.538921241570249e-05, 0.0001675107899030607, 7.792623628388836e-05, 6.928247518943407e-05, 8.20774587304151e-05, 0.00011248917587745207, 7.720731971381645e-05, 6.833156445040754e-05, 0.00010231887682267187, 9.609293597030557e-05, 7.292958810775106e-05, 0.00010774314482761675, 9.255914947628301e-05, 0.0001237650751620048, 9.64451171900979e-05, 0.0001169090761506665, 0.0001072614105620238, 9.686175892860217e-05, 0.00011957684801773822, 0.00011583886435356528, 0.0001275175088925282, 6.546866618231805e-05, 9.038513419941541e-05, 0.00010006681310687346, 9.007086580128472e-05, 0.00022282703456296465, 8.881661869528004e-05, 8.626907432722472e-05, 9.961434439616733e-05, 0.0001082291823644854, 0.00010509098167338485, 7.50494904148657e-05]\n","train_acc_list_300cosine = [44.7275, 63.7, 72.3575, 76.9475, 80.11, 82.24, 83.6775, 85.0225, 86.4575, 87.51, 88.3775, 89.1875, 89.8275, 90.4725, 91.27, 91.6125, 92.195, 92.6575, 93.2125, 93.6125, 93.7775, 93.95, 94.65, 94.79, 95.3675, 95.5025, 95.58, 96.0475, 96.075, 96.4175, 96.79, 96.66, 96.8425, 97.0175, 97.1425, 97.4075, 97.345, 97.375, 97.945, 97.73, 98.185, 98.1775, 98.0075, 98.175, 98.36, 98.465, 98.4525, 98.72, 98.815, 98.635, 98.6625, 98.58, 98.825, 99.075, 99.0425, 98.985, 98.965, 99.1025, 99.0875, 99.26, 99.2775, 99.1925, 99.3375, 99.1475, 99.2425, 99.425, 99.2375, 99.475, 99.38, 99.505, 99.465, 99.4675, 99.5625, 99.605, 99.64, 99.6425, 99.71, 99.66, 99.625, 99.4775, 99.625, 99.6725, 99.745, 99.7, 99.67, 99.7325, 99.785, 99.7425, 99.675, 99.6725, 99.7625, 99.83, 99.7925, 99.8025, 99.8675, 99.8425, 99.8625, 99.85, 99.905, 99.8775, 99.9, 99.8825, 99.895, 99.8625, 99.9025, 99.8625, 99.7975, 99.8725, 99.87, 99.89, 99.88, 99.87, 99.9125, 99.915, 99.9375, 99.9475, 99.94, 99.945, 99.94, 99.9425, 99.9775, 99.96, 99.9575, 99.965, 99.9725, 99.975, 99.98, 99.9825, 99.9675, 99.965, 99.9925, 99.985, 99.9675, 99.975, 99.9725, 99.975, 99.98, 99.985, 99.9875, 99.9725, 99.9825, 99.9925, 99.9925, 99.9975, 99.98, 99.99, 99.9875, 99.9975, 99.995, 99.985, 99.99, 100.0, 99.9925, 99.9875, 99.9825, 100.0, 99.9975, 99.9975, 99.9925, 99.9825, 99.9875, 99.99, 99.9975, 99.9975, 99.9925, 100.0, 99.9975, 99.9975, 100.0, 100.0, 99.985, 99.9975, 99.9975, 99.995, 99.9975, 99.9975, 99.9975, 99.9975, 99.9925, 99.995, 99.9975, 100.0, 99.9875, 99.9925, 100.0, 99.995, 100.0, 99.995, 100.0, 99.9925, 100.0, 100.0, 99.9975, 99.99, 100.0, 99.9975, 99.995, 99.995, 100.0, 100.0, 99.9925, 100.0, 99.995, 99.995, 100.0, 100.0, 100.0, 100.0, 100.0, 99.9975, 100.0, 99.9975, 99.995, 99.9975, 99.995, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.9925, 100.0, 100.0, 100.0, 99.9975, 99.9975, 100.0, 99.9975, 100.0, 99.9975, 100.0, 99.9975, 100.0, 99.9975, 99.9975, 99.9975, 100.0, 100.0, 100.0, 100.0, 100.0, 99.995, 100.0, 100.0, 100.0, 100.0, 99.9975, 100.0, 100.0, 100.0, 100.0, 99.9975, 100.0, 100.0, 100.0, 100.0, 99.9975, 99.995, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.995, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.9975, 99.9975, 100.0, 100.0, 100.0, 100.0, 99.9975, 99.9975, 100.0, 100.0, 99.9975, 100.0, 99.9925, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","test_loss_list_300cosine = [1.3360588429849358, 1.0448881915852994, 0.8597957295707509, 0.6716653414164917, 0.6908234833162042, 0.5932456066336813, 0.5461285729197007, 0.5097410641139066, 0.5401990885221506, 0.5333668193485164, 0.4556268532819386, 0.4484600973657415, 0.4620721623112884, 0.4327629621647581, 0.47597266639335245, 0.48141292925876905, 0.49725772666780255, 0.40901502231253856, 0.4323547872938687, 0.4539363452150852, 0.4590581006641629, 0.40523579641233515, 0.4201337242428261, 0.418421223005162, 0.41465936016432847, 0.43959930557993393, 0.3880773431892636, 0.397792113732688, 0.4114573869524123, 0.3806772181127645, 0.40738119260419775, 0.41724546894996983, 0.3961485907246795, 0.40635761147058463, 0.41718924026700516, 0.4624185173571864, 0.4003025793199298, 0.4194344795202907, 0.43098732470711576, 0.42882050819034817, 0.4735664082101629, 0.4482132949029343, 0.4824381698913212, 0.489483314035814, 0.42275018914590906, 0.46854421854773654, 0.46698710643037966, 0.45736848336609104, 0.48327861801732946, 0.42990076523038406, 0.4146351450228993, 0.4377061692596991, 0.4491257427991191, 0.4464895281987854, 0.5250044391502308, 0.4606155977596211, 0.48777404917946343, 0.46350483313391483, 0.45923378441152696, 0.47999939944925185, 0.4535947281725799, 0.45670295101177844, 0.4861161712604233, 0.5072417436521265, 0.45164442854591563, 0.4723219115145599, 0.465178365948834, 0.48657907800206657, 0.4763214318435403, 0.4628955114491378, 0.4531608254094667, 0.4590076025150999, 0.48202957307236105, 0.47070856392383575, 0.4524376158472858, 0.5099793840435487, 0.4644981126619291, 0.4989790280785742, 0.4910671897704088, 0.5239907608756537, 0.4774412533527688, 0.4662430659879612, 0.47549027996727183, 0.49829778188391577, 0.4727332616531396, 0.48873594582458085, 0.4645166827153556, 0.4946923785949055, 0.5139467286158211, 0.504527775924417, 0.4836999862631665, 0.4878289546770386, 0.49920391819522353, 0.48420851479602767, 0.4741327323113816, 0.4969299920374834, 0.492643963309783, 0.4669509222613105, 0.5004429721002337, 0.5008861348976062, 0.48978376954416686, 0.48975364958183676, 0.4894806569135642, 0.4939129582688778, 0.5057695177914221, 0.483693698161765, 0.49143673158899137, 0.508361778493169, 0.49146506284611136, 0.5179333079464828, 0.4985507955845398, 0.48249870953680596, 0.4882995514552804, 0.48072621575261976, 0.4871305170692975, 0.495542240859587, 0.502074130728275, 0.4848601612486417, 0.46474564952563635, 0.45505768362479876, 0.480818674534182, 0.48904268066339857, 0.48706334348343594, 0.5078222957215731, 0.48777740590180024, 0.48671044654484036, 0.4677445718759223, 0.4843851542925533, 0.47715435280830043, 0.4916676714827743, 0.48873102721534195, 0.4853220989432516, 0.495768607794484, 0.48384790348855755, 0.494273115373865, 0.520792075538937, 0.48109641991838625, 0.4784795025104209, 0.5150823619546769, 0.49928266564501994, 0.508841446871999, 0.4865191377039197, 0.49814116068278685, 0.4979177566268776, 0.509591865388653, 0.5287647111506402, 0.5030483018748367, 0.47968817134446734, 0.5014746417350406, 0.5026743098904815, 0.5065745726416383, 0.4991808756242824, 0.49776733959022956, 0.4859552224980125, 0.505850138354905, 0.507838894294787, 0.4913963109632082, 0.4985096752643585, 0.5035310268779344, 0.49438839943348606, 0.5127879598095447, 0.49104869393985484, 0.4965999275445938, 0.500093090760557, 0.5078368173747123, 0.49182856611058684, 0.4928507318225088, 0.5030448830957654, 0.4847751912436908, 0.5120558350146571, 0.4888622204336939, 0.49651806179103974, 0.49612243831912173, 0.4962354428783248, 0.513516125611112, 0.49529338731795924, 0.4980339683309386, 0.5014159933109826, 0.49898972069915337, 0.507745862573008, 0.52068718268147, 0.5003404364555697, 0.525249100938628, 0.5042423366368571, 0.5168220468714267, 0.5160682231565065, 0.5124318371467953, 0.5218248301291768, 0.4837766302914559, 0.5026627190505402, 0.5024134409201296, 0.512225415887712, 0.5186735810358313, 0.5077592483426951, 0.4826306046187123, 0.512151868848861, 0.5008148086976402, 0.4929636383924303, 0.4970756280648557, 0.5172987021977389, 0.4966934053580972, 0.5119075952451441, 0.4916618470149704, 0.5191661170389079, 0.5202390191298497, 0.5187712847432003, 0.5312336112690877, 0.5149811487409133, 0.5015346613488619, 0.4897740053225167, 0.5123436318922646, 0.4950245019001297, 0.5100116333629512, 0.517671759935874, 0.49631667703012877, 0.5063869094924082, 0.5044590200804457, 0.5116969626161116, 0.5092341914018498, 0.5033747812237921, 0.5193329711880865, 0.5127834038266653, 0.5309269350918033, 0.49558807419070716, 0.513400316049781, 0.5085111194396321, 0.510913455599471, 0.4971718424105946, 0.5032308197851423, 0.5266274438251423, 0.49809465491319005, 0.5013407922432392, 0.4893049780703798, 0.5038147557385361, 0.5071697546334206, 0.5146695088736618, 0.49518201302123976, 0.5041418398105646, 0.5182757000379925, 0.5224867431046087, 0.4978565979230253, 0.507878503939019, 0.49611272823206987, 0.5108789631837531, 0.5073691453737549, 0.5223453206163419, 0.5107548187805128, 0.5007183399004272, 0.5212629056429561, 0.49115426876122437, 0.5297577135925051, 0.5027483824310424, 0.5041316181798524, 0.4906521471618097, 0.493595665768732, 0.502438643687888, 0.4948954885896248, 0.4982064822806588, 0.5073866029328937, 0.5064849340462987, 0.5071891489662702, 0.5056039866390107, 0.5256269764673861, 0.4950309816417815, 0.5119404613594466, 0.4975051161231874, 0.4961673260866841, 0.5196594443125061, 0.4737729119914996, 0.5019824165332166, 0.4959078891367852, 0.5141448318203793, 0.49820214887208575, 0.5068159803182264, 0.4858330869221989, 0.496248337852804, 0.4940428052899204, 0.503951388069346, 0.49354483621029915, 0.4873908001788055, 0.5022429193876967, 0.50107072425794, 0.49141834751714636, 0.50169266326518, 0.4897840660584124, 0.5037467987099781, 0.501852917708928, 0.5113212121061131, 0.5046284511873994, 0.4889931109132646, 0.507928684731073, 0.4926022017681146, 0.5067250309865686, 0.510816790823695, 0.5253809748948375, 0.5128096621247786, 0.4980110616623601, 0.5035155990832969, 0.5060317163603215, 0.49634331974047646]\n","test_acc_list_300cosine = [52.55, 63.48, 70.79, 76.77, 77.07, 79.66, 81.7, 82.61, 82.36, 83.15, 84.72, 85.19, 85.13, 85.7, 85.08, 84.65, 84.64, 87.17, 86.56, 86.12, 86.83, 87.48, 87.37, 87.5, 88.14, 87.33, 89.04, 88.78, 88.32, 89.27, 88.82, 88.61, 89.75, 88.78, 89.11, 88.37, 89.51, 89.38, 88.67, 89.45, 88.48, 89.32, 89.16, 88.72, 89.82, 89.02, 88.77, 89.55, 89.58, 90.05, 90.18, 90.23, 89.78, 90.12, 89.23, 89.82, 89.9, 89.95, 89.87, 90.25, 90.38, 90.39, 90.25, 89.66, 90.88, 90.49, 90.4, 90.26, 90.13, 91.0, 90.89, 90.98, 90.93, 90.94, 91.42, 90.54, 91.11, 90.89, 90.63, 90.02, 91.17, 90.81, 91.24, 90.97, 91.14, 91.35, 91.47, 91.32, 90.83, 90.87, 91.23, 90.95, 91.06, 91.39, 91.41, 90.98, 91.19, 91.65, 91.43, 90.97, 90.93, 91.36, 91.17, 91.47, 91.56, 91.59, 91.49, 90.95, 91.39, 91.46, 91.51, 91.64, 91.6, 91.65, 91.39, 91.51, 91.58, 92.1, 91.79, 91.97, 91.75, 91.74, 91.57, 91.96, 91.91, 92.0, 92.15, 92.02, 91.96, 91.79, 91.77, 92.07, 91.99, 92.41, 92.06, 91.7, 92.06, 92.22, 91.85, 91.93, 92.2, 92.1, 92.04, 91.91, 91.85, 91.94, 91.89, 92.15, 92.18, 91.94, 92.03, 92.19, 92.17, 92.45, 92.43, 91.98, 92.28, 92.25, 92.4, 92.24, 92.02, 92.17, 92.01, 92.24, 92.28, 92.14, 92.37, 92.14, 92.25, 92.3, 92.22, 92.12, 92.18, 92.11, 92.29, 92.04, 92.02, 92.2, 92.37, 92.34, 92.25, 92.27, 91.84, 92.13, 92.18, 91.97, 92.19, 91.85, 91.98, 92.21, 92.11, 92.25, 92.17, 92.13, 92.4, 92.37, 92.21, 92.18, 92.44, 92.29, 92.36, 92.11, 92.35, 92.51, 91.96, 92.18, 92.12, 92.41, 92.3, 92.57, 92.18, 92.45, 92.11, 92.13, 92.52, 92.18, 92.1, 92.1, 92.24, 92.59, 92.23, 92.27, 92.27, 92.48, 92.31, 92.38, 92.04, 92.33, 92.33, 92.15, 92.27, 92.48, 92.52, 92.61, 92.2, 92.3, 92.31, 92.55, 92.25, 92.12, 92.24, 92.12, 92.47, 92.29, 92.22, 92.34, 92.4, 92.34, 92.23, 92.56, 92.08, 92.09, 92.33, 92.22, 92.44, 92.34, 92.41, 92.41, 92.2, 92.35, 92.42, 92.43, 91.96, 92.21, 92.27, 92.41, 92.21, 92.36, 92.66, 92.32, 92.33, 92.37, 92.2, 92.16, 92.31, 92.34, 92.35, 92.43, 92.49, 92.47, 92.15, 92.23, 92.61, 92.26, 92.76, 92.44, 92.32, 92.18, 92.38, 92.38, 92.28, 92.54, 92.5, 92.4, 92.13, 92.37, 92.31, 92.37, 92.12, 92.62]\n"],"metadata":{"id":"ilmYYfIElcAU","executionInfo":{"status":"ok","timestamp":1668313163673,"user_tz":-480,"elapsed":8,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["plt.plot(range(len(train_acc_list_01)), train_acc_list_01, 'b')\n","plt.plot(range(len(train_acc_list_001)), train_acc_list_001, 'r')\n","plt.plot(range(len(train_acc_list_0001)), train_acc_list_0001, 'g')\n","\n","plt.plot(range(len(test_acc_list_01)), test_acc_list_01, color='b', linestyle='--')\n","plt.plot(range(len(test_acc_list_001)), test_acc_list_001,color='r', linestyle='--')\n","plt.plot(range(len(test_acc_list_0001)), test_acc_list_0001, color='g', linestyle='--')\n","\n","plt.xlabel(\"Number of epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Combined accuracy\")\n","plt.legend(['train with lr = 1e-1', 'train with lr = 1e-2','train with lr = 1e-3',\n","            'test with lr = 1e-1','test with lr = 1e-2', 'test with lr = 1e-3'])\n","plt.show()"],"metadata":{"id":"ubm3Y5CSnZ0D","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1668313163674,"user_tz":-480,"elapsed":8,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}},"outputId":"8dac2bae-c976-4915-fe34-d0eddf3014bd"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["plt.plot(range(len(train_loss_list_01)), train_loss_list_01, 'b')\n","plt.plot(range(len(train_loss_list_001)), train_loss_list_001, 'r')\n","plt.plot(range(len(train_loss_list_0001)), train_loss_list_0001, 'g')\n","\n","plt.plot(range(len(test_loss_list_01)), test_loss_list_01, color='b', linestyle='--')\n","plt.plot(range(len(test_loss_list_001)), test_loss_list_001,color='r', linestyle='--')\n","plt.plot(range(len(test_loss_list_0001)), test_loss_list_0001, color='g', linestyle='--')\n","\n","plt.xlabel(\"Number of epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Combined loss\")\n","plt.legend(['train with lr = 1e-1', 'train with lr = 1e-2','train with lr = 1e-3',\n","            'test with lr = 1e-1','test with lr = 1e-2', 'test with lr = 1e-3'])\n","plt.show()"],"metadata":{"id":"QnOTaNoesBEb","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1668313163674,"user_tz":-480,"elapsed":7,"user":{"displayName":"Shunping Yang","userId":"04212212626207137664"}},"outputId":"7a97e1ca-58a3-416f-e8d7-47511ce2448d"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}