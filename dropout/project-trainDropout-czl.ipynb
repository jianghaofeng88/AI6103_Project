{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b456e27ad664c38b0b9556cb3888ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98a1d76310e04a66990a590299971985",
              "IPY_MODEL_995c31f4be894c0fa4ccfd4bab30e589",
              "IPY_MODEL_f61b221a3a334144ab1d72d3a3d3bb07"
            ],
            "layout": "IPY_MODEL_211635636d0b426f86ed3338b97de7d6"
          }
        },
        "98a1d76310e04a66990a590299971985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ad9887c9ff5431e9e2f74eaf2b1afcf",
            "placeholder": "​",
            "style": "IPY_MODEL_93126859379f4562babd40066e716fcb",
            "value": "100%"
          }
        },
        "995c31f4be894c0fa4ccfd4bab30e589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e83351e16abe4dc6adf8cabd40155b46",
            "max": 182040794,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_681d4f84c5f345ec97ca7e4e5c9da8d7",
            "value": 182040794
          }
        },
        "f61b221a3a334144ab1d72d3a3d3bb07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e93001d54b466c95d41d771bb2d0c8",
            "placeholder": "​",
            "style": "IPY_MODEL_3767951841bd46f1b99ff0656a1f48ed",
            "value": " 182040794/182040794 [00:02&lt;00:00, 113388991.68it/s]"
          }
        },
        "211635636d0b426f86ed3338b97de7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ad9887c9ff5431e9e2f74eaf2b1afcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93126859379f4562babd40066e716fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e83351e16abe4dc6adf8cabd40155b46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681d4f84c5f345ec97ca7e4e5c9da8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5e93001d54b466c95d41d771bb2d0c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3767951841bd46f1b99ff0656a1f48ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9f54f48f03f4ebb86b41130123ff75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27738e8f05a143e59125ac9b6a9abe1a",
              "IPY_MODEL_b0e928470608487098909d58a1772a6e",
              "IPY_MODEL_257a16f61d6f475b868a47acb68b5017"
            ],
            "layout": "IPY_MODEL_8c6f97c301844676a239474488e0676f"
          }
        },
        "27738e8f05a143e59125ac9b6a9abe1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4edeeec17bd84773bc99106c0780f451",
            "placeholder": "​",
            "style": "IPY_MODEL_4a4fd7e4107a4050933815ecfd91b49b",
            "value": "100%"
          }
        },
        "b0e928470608487098909d58a1772a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07d617bfbe394062b5e4918b2490caad",
            "max": 64275384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39a319cdd7fe4abfb8c97c84ad4d0e1e",
            "value": 64275384
          }
        },
        "257a16f61d6f475b868a47acb68b5017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dfd96e37745422892e65ca9d77d1d71",
            "placeholder": "​",
            "style": "IPY_MODEL_52d0f290b83746f692e814bd2e9d81e9",
            "value": " 64275384/64275384 [00:00&lt;00:00, 97922203.87it/s]"
          }
        },
        "8c6f97c301844676a239474488e0676f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4edeeec17bd84773bc99106c0780f451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a4fd7e4107a4050933815ecfd91b49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07d617bfbe394062b5e4918b2490caad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a319cdd7fe4abfb8c97c84ad4d0e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dfd96e37745422892e65ca9d77d1d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52d0f290b83746f692e814bd2e9d81e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfGrai_Qt7Ny"
      },
      "source": [
        "# import all libraries\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Source code for unpickle function: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "# def unpickle(file):\n",
        "#     import pickle\n",
        "#     with open(file, 'rb') as fo:\n",
        "#         dict = pickle.load(fo, encoding='bytes')\n",
        "#     return dict\n",
        "\n",
        "# import numpy as np\n",
        "# def get_mean_color():\n",
        "#     d=unpickle('./data/cifar-10-batches-py/data_batch_1')\n",
        "#     channels = d[b'data']\n",
        "#     for i in range(2,6):\n",
        "#         d=unpickle('./data/cifar-10-batches-py/data_batch_'+str(i))\n",
        "#         channels=np.concatenate((channels, d[b'data']), axis=0)\n",
        "#     r=np.mean(channels[:,:1024])/255  \n",
        "#     g=np.mean(channels[:,1024:2048])/255\n",
        "#     b=np.mean(channels[:,2048:])/255\n",
        "#     return(r,g,b)\n",
        "# get_mean_color()"
      ],
      "metadata": {
        "id": "8ntKy6oKQGJv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "4b456e27ad664c38b0b9556cb3888ac1",
            "98a1d76310e04a66990a590299971985",
            "995c31f4be894c0fa4ccfd4bab30e589",
            "f61b221a3a334144ab1d72d3a3d3bb07",
            "211635636d0b426f86ed3338b97de7d6",
            "4ad9887c9ff5431e9e2f74eaf2b1afcf",
            "93126859379f4562babd40066e716fcb",
            "e83351e16abe4dc6adf8cabd40155b46",
            "681d4f84c5f345ec97ca7e4e5c9da8d7",
            "e5e93001d54b466c95d41d771bb2d0c8",
            "3767951841bd46f1b99ff0656a1f48ed",
            "d9f54f48f03f4ebb86b41130123ff75a",
            "27738e8f05a143e59125ac9b6a9abe1a",
            "b0e928470608487098909d58a1772a6e",
            "257a16f61d6f475b868a47acb68b5017",
            "8c6f97c301844676a239474488e0676f",
            "4edeeec17bd84773bc99106c0780f451",
            "4a4fd7e4107a4050933815ecfd91b49b",
            "07d617bfbe394062b5e4918b2490caad",
            "39a319cdd7fe4abfb8c97c84ad4d0e1e",
            "7dfd96e37745422892e65ca9d77d1d71",
            "52d0f290b83746f692e814bd2e9d81e9"
          ]
        },
        "id": "VgAiImV0uURP",
        "outputId": "3920377b-5890-4175-b8fa-d122ae948bb6"
      },
      "source": [
        "# these are commonly used data augmentations\n",
        "# random cropping and random horizontal flip\n",
        "# lastly, we normalize each channel into zero mean and unit standard deviation\n",
        "transform_train = transforms.Compose([\n",
        "    #transforms.RandomCrop(32, padding=4),\n",
        "    #transforms.RandomHorizontalFlip(),\n",
        "    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.SVHN),\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.SVHN(\n",
        "    root='./data', split='train', download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.SVHN(\n",
        "    root='./data', split='test', download=True, transform=transform_test)\n",
        "\n",
        "# we can use a larger batch size during test, because we do not save \n",
        "# intermediate variables for gradient computation, which leaves more memory\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=256, shuffle=False, num_workers=2)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/182040794 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b456e27ad664c38b0b9556cb3888ac1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/64275384 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9f54f48f03f4ebb86b41130123ff75a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
        "print(len(trainset), len(testset))\n",
        "print(trainset[4][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO2fleA52Aex",
        "outputId": "e362c372-4b70-4517-f4ca-5e15252524be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73257 26032\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te71lQ17B1L_"
      },
      "source": [
        "#Data Augmentation\n",
        "Data augmentation performs random modifications of the image as a preprocessing step. It serves the following purposes:\n",
        "1. It increases the amount of data for training.\n",
        "2. By deleting features, it prevents the network from relying on a narrow set of features, which may not generalize.\n",
        "3. By changing features while maintaining the same output, it helps the network become tolerant of changes that do not change the image lab. \n",
        "\n",
        "In short, data augmentation desensitivizes the network, so it extracts features that are invariant to changes that should not affect the prediction. \n",
        "\n",
        "We showcase a few random data augmentation provided by PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyG26xoJC0Pa"
      },
      "source": [
        "# import torch.nn as nn\n",
        "# transforms = torch.nn.Sequential(\n",
        "#     T.Resize(256), # resize the short edge to 256.\n",
        "#     T.RandomCrop(224), #randomly crop a 224x224 region from the image\n",
        "#     T.RandomErasing(p=1, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)\n",
        "#     #T.ColorJitter(brightness=0.3, contrast=0.2, saturation=0.1, hue=0.1)\n",
        "#     #T.AutoAugment()\n",
        "# )\n",
        "\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# dog1 = dog1.to(device)\n",
        "# # dog2 = dog2.to(device)\n",
        "\n",
        "# # transformed_dog1 = transforms(dog1)\n",
        "# transformed_dog1 = transforms(dog1)\n",
        "# show([transformed_dog1])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hldipDVsv-Jt"
      },
      "source": [
        "# Training\n",
        "def train(epoch, net, criterion, trainloader, scheduler):\n",
        "    device = 'cuda'\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if (batch_idx+1) % 50 == 0:\n",
        "          print(\"iteration : %3d, loss : %0.4f, accuracy : %2.2f\" % (batch_idx+1, train_loss/(batch_idx+1), 100.*correct/total))\n",
        "\n",
        "    scheduler.step()\n",
        "    return train_loss/(batch_idx+1), 100.*correct/total"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgyCI0U08i2h"
      },
      "source": [
        "Test performance on the test set. Note the use of `torch.inference_mode()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkooK-hQu4a6"
      },
      "source": [
        "def test(epoch, net, criterion, testloader):\n",
        "    device = 'cuda'\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.inference_mode():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    return test_loss/(batch_idx+1), 100.*correct/total\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEj8J7xqwAxD"
      },
      "source": [
        "def save_checkpoint(net, acc, epoch):\n",
        "    # Save checkpoint.\n",
        "    print('Saving..')\n",
        "    state = {\n",
        "        'net': net.state_dict(),\n",
        "        'acc': acc,\n",
        "        'epoch': epoch,\n",
        "    }\n",
        "    if not os.path.isdir('checkpoint'):\n",
        "        os.mkdir('checkpoint')\n",
        "    torch.save(state, './checkpoint/ckpt.pth')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlCAjBEWwXNo"
      },
      "source": [
        "# defining resnet models\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        out = F.dropout(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        out = F.dropout(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        # This is the \"stem\"\n",
        "        # For CIFAR (32x32 images), it does not perform downsampling\n",
        "        # It should downsample for ImageNet\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        # four stages with three downsampling\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        out = F.dropout(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test_resnet18():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# partition the trainset\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "new_trainset, validationset= torch.utils.data.random_split(trainset,\n",
        "  [len(trainset)-len(testset), len(testset)], generator=torch.Generator().manual_seed(0))\n",
        "class_freq = np.zeros(10)\n",
        "for i in range(len(new_trainset)):\n",
        "  class_freq[new_trainset[i][1]]+=1\n",
        "class_prop = class_freq/(len(new_trainset))\n",
        "print(class_freq)\n",
        "print(class_prop)\n",
        "\n",
        "# plot the proportion\n",
        "ax = plt.figure(figsize=(10,5)).add_subplot(111)\n",
        "plt.plot(list(classes),class_prop, '.', ms=8)\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Proportion\")\n",
        "for i,j in zip(list(classes),class_prop):\n",
        "    ax.annotate(i+'\\n'+str(round(j*100,3))+'%',xy=(i,j))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "odLHjfkTzzaJ",
        "outputId": "e10958f4-77f5-4316-8dbc-8074e3a0caec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3234. 8926. 6868. 5501. 4828. 4429. 3753. 3516. 3233. 2937.]\n",
            "[0.06848068 0.18901006 0.14543145 0.11648491 0.10223399 0.09378507\n",
            " 0.07947062 0.07445209 0.0684595  0.06219164]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(class_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaGDVy1s3i7J",
        "outputId": "ca6c90b7-366c-4b33-e726-1334d0c8e785"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47225.0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArgupDVRwB8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b395b6a-bda5-4d64-923f-3f95a453dbb7"
      },
      "source": [
        "# main body\n",
        "config = {\n",
        "    'lr': 0.001,\n",
        "    'weight_decay': 5e-4\n",
        "}\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "        new_trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "        validationset, batch_size=128, shuffle=False, num_workers=2)\n",
        "net = ResNet18().to('cuda')\n",
        "criterion = nn.CrossEntropyLoss().to('cuda')\n",
        "optimizer = optim.Adam(net.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
        "#scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer, factor=1)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30)\n",
        "#scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, total_iters=300)\n",
        "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
        "\n",
        "train_loss_list=[] \n",
        "train_acc_list=[]\n",
        "test_loss_list=[]\n",
        "test_acc_list=[]\n",
        "\n",
        "for epoch in range(1, 301):\n",
        "    train_loss, train_acc = train(epoch, net, criterion, trainloader, scheduler)\n",
        "    test_loss, test_acc = test(epoch, net, criterion, testloader)\n",
        "    \n",
        "    train_loss_list.append(train_loss) \n",
        "    train_acc_list.append(train_acc)\n",
        "    test_loss_list.append(test_loss)\n",
        "    test_acc_list.append(test_acc)\n",
        "    print((\"Epoch : %3d, training loss : %0.4f, training accuracy : %2.2f, test loss \" + \\\n",
        "      \": %0.4f, test accuracy : %2.2f\") % (epoch, train_loss, train_acc, test_loss, test_acc))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1\n",
            "iteration :  50, loss : 2.4271, accuracy : 12.39\n",
            "iteration : 100, loss : 2.4051, accuracy : 12.67\n",
            "iteration : 150, loss : 2.3919, accuracy : 12.66\n",
            "iteration : 200, loss : 2.3747, accuracy : 12.82\n",
            "iteration : 250, loss : 2.3651, accuracy : 13.06\n",
            "iteration : 300, loss : 2.3555, accuracy : 13.26\n",
            "iteration : 350, loss : 2.3363, accuracy : 14.13\n",
            "Epoch :   1, training loss : 2.3270, training accuracy : 14.52, test loss : 2.1145, test accuracy : 23.24\n",
            "\n",
            "Epoch: 2\n",
            "iteration :  50, loss : 2.0606, accuracy : 26.62\n",
            "iteration : 100, loss : 2.0050, accuracy : 29.33\n",
            "iteration : 150, loss : 1.9596, accuracy : 30.84\n",
            "iteration : 200, loss : 1.9125, accuracy : 32.41\n",
            "iteration : 250, loss : 1.8681, accuracy : 33.95\n",
            "iteration : 300, loss : 1.8193, accuracy : 35.54\n",
            "iteration : 350, loss : 1.7788, accuracy : 36.83\n",
            "Epoch :   2, training loss : 1.7654, training accuracy : 37.16, test loss : 1.7707, test accuracy : 38.25\n",
            "\n",
            "Epoch: 3\n",
            "iteration :  50, loss : 1.4417, accuracy : 47.61\n",
            "iteration : 100, loss : 1.4495, accuracy : 47.35\n",
            "iteration : 150, loss : 1.4329, accuracy : 47.54\n",
            "iteration : 200, loss : 1.4207, accuracy : 47.86\n",
            "iteration : 250, loss : 1.4067, accuracy : 48.23\n",
            "iteration : 300, loss : 1.3995, accuracy : 48.40\n",
            "iteration : 350, loss : 1.3904, accuracy : 48.71\n",
            "Epoch :   3, training loss : 1.3875, training accuracy : 48.72, test loss : 1.3545, test accuracy : 49.44\n",
            "\n",
            "Epoch: 4\n",
            "iteration :  50, loss : 1.3115, accuracy : 50.11\n",
            "iteration : 100, loss : 1.2975, accuracy : 50.91\n",
            "iteration : 150, loss : 1.2985, accuracy : 51.10\n",
            "iteration : 200, loss : 1.2974, accuracy : 51.23\n",
            "iteration : 250, loss : 1.2939, accuracy : 51.23\n",
            "iteration : 300, loss : 1.2911, accuracy : 51.27\n",
            "iteration : 350, loss : 1.2876, accuracy : 51.28\n",
            "Epoch :   4, training loss : 1.2880, training accuracy : 51.23, test loss : 1.3742, test accuracy : 49.14\n",
            "\n",
            "Epoch: 5\n",
            "iteration :  50, loss : 1.2749, accuracy : 51.58\n",
            "iteration : 100, loss : 1.2722, accuracy : 51.95\n",
            "iteration : 150, loss : 1.2674, accuracy : 52.16\n",
            "iteration : 200, loss : 1.2698, accuracy : 51.95\n",
            "iteration : 250, loss : 1.2711, accuracy : 51.74\n",
            "iteration : 300, loss : 1.2684, accuracy : 51.85\n",
            "iteration : 350, loss : 1.2665, accuracy : 51.82\n",
            "Epoch :   5, training loss : 1.2636, training accuracy : 51.82, test loss : 1.2692, test accuracy : 51.41\n",
            "\n",
            "Epoch: 6\n",
            "iteration :  50, loss : 1.2487, accuracy : 52.94\n",
            "iteration : 100, loss : 1.2475, accuracy : 52.67\n",
            "iteration : 150, loss : 1.2471, accuracy : 52.50\n",
            "iteration : 200, loss : 1.2483, accuracy : 52.41\n",
            "iteration : 250, loss : 1.2421, accuracy : 52.58\n",
            "iteration : 300, loss : 1.2390, accuracy : 52.65\n",
            "iteration : 350, loss : 1.2380, accuracy : 52.69\n",
            "Epoch :   6, training loss : 1.2367, training accuracy : 52.71, test loss : 1.2488, test accuracy : 52.12\n",
            "\n",
            "Epoch: 7\n",
            "iteration :  50, loss : 1.2185, accuracy : 52.36\n",
            "iteration : 100, loss : 1.2274, accuracy : 52.38\n",
            "iteration : 150, loss : 1.2245, accuracy : 52.60\n",
            "iteration : 200, loss : 1.2202, accuracy : 52.89\n",
            "iteration : 250, loss : 1.2184, accuracy : 53.02\n",
            "iteration : 300, loss : 1.2158, accuracy : 53.19\n",
            "iteration : 350, loss : 1.2167, accuracy : 53.13\n",
            "Epoch :   7, training loss : 1.2146, training accuracy : 53.21, test loss : 1.3196, test accuracy : 51.33\n",
            "\n",
            "Epoch: 8\n",
            "iteration :  50, loss : 1.2304, accuracy : 52.39\n",
            "iteration : 100, loss : 1.2351, accuracy : 52.25\n",
            "iteration : 150, loss : 1.2292, accuracy : 52.43\n",
            "iteration : 200, loss : 1.2183, accuracy : 52.89\n",
            "iteration : 250, loss : 1.2204, accuracy : 52.71\n",
            "iteration : 300, loss : 1.2166, accuracy : 52.87\n",
            "iteration : 350, loss : 1.2143, accuracy : 52.99\n",
            "Epoch :   8, training loss : 1.2131, training accuracy : 53.03, test loss : 1.2091, test accuracy : 53.23\n",
            "\n",
            "Epoch: 9\n",
            "iteration :  50, loss : 1.1980, accuracy : 53.17\n",
            "iteration : 100, loss : 1.2173, accuracy : 52.67\n",
            "iteration : 150, loss : 1.2104, accuracy : 52.95\n",
            "iteration : 200, loss : 1.2083, accuracy : 53.02\n",
            "iteration : 250, loss : 1.2018, accuracy : 53.17\n",
            "iteration : 300, loss : 1.2004, accuracy : 53.17\n",
            "iteration : 350, loss : 1.2005, accuracy : 53.14\n",
            "Epoch :   9, training loss : 1.1995, training accuracy : 53.16, test loss : 1.2207, test accuracy : 52.41\n",
            "\n",
            "Epoch: 10\n",
            "iteration :  50, loss : 1.1922, accuracy : 53.28\n",
            "iteration : 100, loss : 1.2051, accuracy : 53.05\n",
            "iteration : 150, loss : 1.1998, accuracy : 53.22\n",
            "iteration : 200, loss : 1.2002, accuracy : 53.05\n",
            "iteration : 250, loss : 1.1948, accuracy : 53.28\n",
            "iteration : 300, loss : 1.1940, accuracy : 53.39\n",
            "iteration : 350, loss : 1.1934, accuracy : 53.44\n",
            "Epoch :  10, training loss : 1.1934, training accuracy : 53.44, test loss : 1.2469, test accuracy : 52.34\n",
            "\n",
            "Epoch: 11\n",
            "iteration :  50, loss : 1.1847, accuracy : 53.59\n",
            "iteration : 100, loss : 1.1758, accuracy : 53.97\n",
            "iteration : 150, loss : 1.1773, accuracy : 53.98\n",
            "iteration : 200, loss : 1.1858, accuracy : 53.65\n",
            "iteration : 250, loss : 1.1822, accuracy : 53.84\n",
            "iteration : 300, loss : 1.1816, accuracy : 53.88\n",
            "iteration : 350, loss : 1.1824, accuracy : 53.85\n",
            "Epoch :  11, training loss : 1.1808, training accuracy : 53.98, test loss : 1.2102, test accuracy : 53.13\n",
            "\n",
            "Epoch: 12\n",
            "iteration :  50, loss : 1.1981, accuracy : 53.09\n",
            "iteration : 100, loss : 1.1924, accuracy : 53.19\n",
            "iteration : 150, loss : 1.1876, accuracy : 53.46\n",
            "iteration : 200, loss : 1.1805, accuracy : 53.70\n",
            "iteration : 250, loss : 1.1769, accuracy : 53.85\n",
            "iteration : 300, loss : 1.1764, accuracy : 53.93\n",
            "iteration : 350, loss : 1.1758, accuracy : 53.96\n",
            "Epoch :  12, training loss : 1.1758, training accuracy : 53.95, test loss : 1.1897, test accuracy : 53.36\n",
            "\n",
            "Epoch: 13\n",
            "iteration :  50, loss : 1.1778, accuracy : 53.70\n",
            "iteration : 100, loss : 1.1668, accuracy : 53.93\n",
            "iteration : 150, loss : 1.1657, accuracy : 54.15\n",
            "iteration : 200, loss : 1.1716, accuracy : 54.34\n",
            "iteration : 250, loss : 1.1749, accuracy : 54.06\n",
            "iteration : 300, loss : 1.1755, accuracy : 54.05\n",
            "iteration : 350, loss : 1.1780, accuracy : 53.85\n",
            "Epoch :  13, training loss : 1.1779, training accuracy : 53.87, test loss : 1.1666, test accuracy : 54.59\n",
            "\n",
            "Epoch: 14\n",
            "iteration :  50, loss : 1.1647, accuracy : 54.36\n",
            "iteration : 100, loss : 1.1695, accuracy : 54.16\n",
            "iteration : 150, loss : 1.1596, accuracy : 54.31\n",
            "iteration : 200, loss : 1.1593, accuracy : 54.44\n",
            "iteration : 250, loss : 1.1587, accuracy : 54.49\n",
            "iteration : 300, loss : 1.1608, accuracy : 54.48\n",
            "iteration : 350, loss : 1.1602, accuracy : 54.49\n",
            "Epoch :  14, training loss : 1.1606, training accuracy : 54.52, test loss : 1.1898, test accuracy : 53.53\n",
            "\n",
            "Epoch: 15\n",
            "iteration :  50, loss : 1.1363, accuracy : 54.83\n",
            "iteration : 100, loss : 1.1544, accuracy : 54.84\n",
            "iteration : 150, loss : 1.1624, accuracy : 54.51\n",
            "iteration : 200, loss : 1.1617, accuracy : 54.41\n",
            "iteration : 250, loss : 1.1598, accuracy : 54.38\n",
            "iteration : 300, loss : 1.1568, accuracy : 54.36\n",
            "iteration : 350, loss : 1.1590, accuracy : 54.26\n",
            "Epoch :  15, training loss : 1.1601, training accuracy : 54.18, test loss : 1.1676, test accuracy : 54.08\n",
            "\n",
            "Epoch: 16\n",
            "iteration :  50, loss : 1.1674, accuracy : 53.67\n",
            "iteration : 100, loss : 1.1524, accuracy : 54.70\n",
            "iteration : 150, loss : 1.1538, accuracy : 54.61\n",
            "iteration : 200, loss : 1.1558, accuracy : 54.60\n",
            "iteration : 250, loss : 1.1513, accuracy : 54.82\n",
            "iteration : 300, loss : 1.1481, accuracy : 55.01\n",
            "iteration : 350, loss : 1.1443, accuracy : 55.06\n",
            "Epoch :  16, training loss : 1.1439, training accuracy : 55.00, test loss : 1.1819, test accuracy : 53.64\n",
            "\n",
            "Epoch: 17\n",
            "iteration :  50, loss : 1.1430, accuracy : 55.27\n",
            "iteration : 100, loss : 1.1354, accuracy : 55.35\n",
            "iteration : 150, loss : 1.1447, accuracy : 54.89\n",
            "iteration : 200, loss : 1.1422, accuracy : 54.93\n",
            "iteration : 250, loss : 1.1454, accuracy : 54.77\n",
            "iteration : 300, loss : 1.1471, accuracy : 54.64\n",
            "iteration : 350, loss : 1.1420, accuracy : 54.81\n",
            "Epoch :  17, training loss : 1.1433, training accuracy : 54.77, test loss : 1.1768, test accuracy : 53.97\n",
            "\n",
            "Epoch: 18\n",
            "iteration :  50, loss : 1.1343, accuracy : 55.47\n",
            "iteration : 100, loss : 1.1484, accuracy : 54.74\n",
            "iteration : 150, loss : 1.1517, accuracy : 54.69\n",
            "iteration : 200, loss : 1.1470, accuracy : 54.78\n",
            "iteration : 250, loss : 1.1420, accuracy : 54.82\n",
            "iteration : 300, loss : 1.1417, accuracy : 54.76\n",
            "iteration : 350, loss : 1.1429, accuracy : 54.73\n",
            "Epoch :  18, training loss : 1.1429, training accuracy : 54.69, test loss : 1.1464, test accuracy : 54.47\n",
            "\n",
            "Epoch: 19\n",
            "iteration :  50, loss : 1.1440, accuracy : 54.47\n",
            "iteration : 100, loss : 1.1341, accuracy : 54.94\n",
            "iteration : 150, loss : 1.1368, accuracy : 54.90\n",
            "iteration : 200, loss : 1.1398, accuracy : 54.77\n",
            "iteration : 250, loss : 1.1435, accuracy : 54.74\n",
            "iteration : 300, loss : 1.1413, accuracy : 54.73\n",
            "iteration : 350, loss : 1.1431, accuracy : 54.59\n",
            "Epoch :  19, training loss : 1.1426, training accuracy : 54.59, test loss : 1.1679, test accuracy : 54.11\n",
            "\n",
            "Epoch: 20\n",
            "iteration :  50, loss : 1.1581, accuracy : 54.19\n",
            "iteration : 100, loss : 1.1404, accuracy : 54.19\n",
            "iteration : 150, loss : 1.1440, accuracy : 54.22\n",
            "iteration : 200, loss : 1.1447, accuracy : 54.29\n",
            "iteration : 250, loss : 1.1368, accuracy : 54.60\n",
            "iteration : 300, loss : 1.1307, accuracy : 54.82\n",
            "iteration : 350, loss : 1.1328, accuracy : 54.76\n",
            "Epoch :  20, training loss : 1.1331, training accuracy : 54.75, test loss : 1.1287, test accuracy : 54.75\n",
            "\n",
            "Epoch: 21\n",
            "iteration :  50, loss : 1.1009, accuracy : 56.34\n",
            "iteration : 100, loss : 1.1240, accuracy : 55.54\n",
            "iteration : 150, loss : 1.1213, accuracy : 55.49\n",
            "iteration : 200, loss : 1.1218, accuracy : 55.55\n",
            "iteration : 250, loss : 1.1279, accuracy : 55.34\n",
            "iteration : 300, loss : 1.1323, accuracy : 55.10\n",
            "iteration : 350, loss : 1.1333, accuracy : 55.11\n",
            "Epoch :  21, training loss : 1.1346, training accuracy : 55.00, test loss : 1.1421, test accuracy : 54.19\n",
            "\n",
            "Epoch: 22\n",
            "iteration :  50, loss : 1.1237, accuracy : 54.66\n",
            "iteration : 100, loss : 1.1238, accuracy : 54.91\n",
            "iteration : 150, loss : 1.1332, accuracy : 54.49\n",
            "iteration : 200, loss : 1.1325, accuracy : 54.50\n",
            "iteration : 250, loss : 1.1324, accuracy : 54.65\n",
            "iteration : 300, loss : 1.1335, accuracy : 54.72\n",
            "iteration : 350, loss : 1.1339, accuracy : 54.77\n",
            "Epoch :  22, training loss : 1.1347, training accuracy : 54.74, test loss : 1.1537, test accuracy : 53.84\n",
            "\n",
            "Epoch: 23\n",
            "iteration :  50, loss : 1.1357, accuracy : 54.50\n",
            "iteration : 100, loss : 1.1263, accuracy : 55.17\n",
            "iteration : 150, loss : 1.1238, accuracy : 55.26\n",
            "iteration : 200, loss : 1.1253, accuracy : 55.30\n",
            "iteration : 250, loss : 1.1292, accuracy : 55.12\n",
            "iteration : 300, loss : 1.1301, accuracy : 54.98\n",
            "iteration : 350, loss : 1.1284, accuracy : 55.07\n",
            "Epoch :  23, training loss : 1.1272, training accuracy : 55.11, test loss : 1.1455, test accuracy : 54.61\n",
            "\n",
            "Epoch: 24\n",
            "iteration :  50, loss : 1.1213, accuracy : 54.23\n",
            "iteration : 100, loss : 1.1148, accuracy : 54.99\n",
            "iteration : 150, loss : 1.1114, accuracy : 55.31\n",
            "iteration : 200, loss : 1.1140, accuracy : 55.21\n",
            "iteration : 250, loss : 1.1175, accuracy : 55.23\n",
            "iteration : 300, loss : 1.1186, accuracy : 55.21\n",
            "iteration : 350, loss : 1.1223, accuracy : 55.06\n",
            "Epoch :  24, training loss : 1.1206, training accuracy : 55.12, test loss : 1.1280, test accuracy : 54.74\n",
            "\n",
            "Epoch: 25\n",
            "iteration :  50, loss : 1.1222, accuracy : 56.03\n",
            "iteration : 100, loss : 1.1335, accuracy : 55.33\n",
            "iteration : 150, loss : 1.1233, accuracy : 55.52\n",
            "iteration : 200, loss : 1.1260, accuracy : 55.26\n",
            "iteration : 250, loss : 1.1276, accuracy : 55.19\n",
            "iteration : 300, loss : 1.1270, accuracy : 55.22\n",
            "iteration : 350, loss : 1.1246, accuracy : 55.26\n",
            "Epoch :  25, training loss : 1.1249, training accuracy : 55.25, test loss : 1.1673, test accuracy : 53.77\n",
            "\n",
            "Epoch: 26\n",
            "iteration :  50, loss : 1.1377, accuracy : 54.64\n",
            "iteration : 100, loss : 1.1297, accuracy : 55.03\n",
            "iteration : 150, loss : 1.1316, accuracy : 54.65\n",
            "iteration : 200, loss : 1.1258, accuracy : 54.90\n",
            "iteration : 250, loss : 1.1248, accuracy : 54.98\n",
            "iteration : 300, loss : 1.1252, accuracy : 55.13\n",
            "iteration : 350, loss : 1.1251, accuracy : 55.15\n",
            "Epoch :  26, training loss : 1.1251, training accuracy : 55.10, test loss : 1.1292, test accuracy : 54.92\n",
            "\n",
            "Epoch: 27\n",
            "iteration :  50, loss : 1.1228, accuracy : 53.77\n",
            "iteration : 100, loss : 1.1149, accuracy : 54.48\n",
            "iteration : 150, loss : 1.1141, accuracy : 54.71\n",
            "iteration : 200, loss : 1.1231, accuracy : 54.60\n",
            "iteration : 250, loss : 1.1208, accuracy : 54.76\n",
            "iteration : 300, loss : 1.1210, accuracy : 54.82\n",
            "iteration : 350, loss : 1.1193, accuracy : 54.77\n",
            "Epoch :  27, training loss : 1.1194, training accuracy : 54.80, test loss : 1.1233, test accuracy : 55.24\n",
            "\n",
            "Epoch: 28\n",
            "iteration :  50, loss : 1.0971, accuracy : 55.30\n",
            "iteration : 100, loss : 1.1087, accuracy : 55.52\n",
            "iteration : 150, loss : 1.1081, accuracy : 55.35\n",
            "iteration : 200, loss : 1.1157, accuracy : 55.37\n",
            "iteration : 250, loss : 1.1154, accuracy : 55.29\n",
            "iteration : 300, loss : 1.1139, accuracy : 55.30\n",
            "iteration : 350, loss : 1.1153, accuracy : 55.29\n",
            "Epoch :  28, training loss : 1.1148, training accuracy : 55.32, test loss : 1.1227, test accuracy : 55.13\n",
            "\n",
            "Epoch: 29\n",
            "iteration :  50, loss : 1.1050, accuracy : 56.47\n",
            "iteration : 100, loss : 1.1136, accuracy : 55.80\n",
            "iteration : 150, loss : 1.1155, accuracy : 55.38\n",
            "iteration : 200, loss : 1.1137, accuracy : 55.27\n",
            "iteration : 250, loss : 1.1160, accuracy : 55.26\n",
            "iteration : 300, loss : 1.1185, accuracy : 55.18\n",
            "iteration : 350, loss : 1.1202, accuracy : 55.26\n",
            "Epoch :  29, training loss : 1.1212, training accuracy : 55.25, test loss : 1.1175, test accuracy : 55.10\n",
            "\n",
            "Epoch: 30\n",
            "iteration :  50, loss : 1.1091, accuracy : 55.84\n",
            "iteration : 100, loss : 1.1084, accuracy : 55.55\n",
            "iteration : 150, loss : 1.1039, accuracy : 55.60\n",
            "iteration : 200, loss : 1.1050, accuracy : 55.43\n",
            "iteration : 250, loss : 1.1096, accuracy : 55.43\n",
            "iteration : 300, loss : 1.1109, accuracy : 55.38\n",
            "iteration : 350, loss : 1.1111, accuracy : 55.33\n",
            "Epoch :  30, training loss : 1.1095, training accuracy : 55.40, test loss : 1.1020, test accuracy : 55.58\n",
            "\n",
            "Epoch: 31\n",
            "iteration :  50, loss : 1.1208, accuracy : 54.34\n",
            "iteration : 100, loss : 1.1237, accuracy : 54.25\n",
            "iteration : 150, loss : 1.1155, accuracy : 54.88\n",
            "iteration : 200, loss : 1.1126, accuracy : 55.21\n",
            "iteration : 250, loss : 1.1169, accuracy : 55.13\n",
            "iteration : 300, loss : 1.1154, accuracy : 55.26\n",
            "iteration : 350, loss : 1.1155, accuracy : 55.25\n",
            "Epoch :  31, training loss : 1.1144, training accuracy : 55.38, test loss : 1.1148, test accuracy : 55.09\n",
            "\n",
            "Epoch: 32\n",
            "iteration :  50, loss : 1.0667, accuracy : 56.31\n",
            "iteration : 100, loss : 1.0865, accuracy : 56.31\n",
            "iteration : 150, loss : 1.0958, accuracy : 56.10\n",
            "iteration : 200, loss : 1.1069, accuracy : 55.79\n",
            "iteration : 250, loss : 1.1046, accuracy : 55.86\n",
            "iteration : 300, loss : 1.1078, accuracy : 55.79\n",
            "iteration : 350, loss : 1.1045, accuracy : 55.79\n",
            "Epoch :  32, training loss : 1.1053, training accuracy : 55.74, test loss : 1.1578, test accuracy : 54.25\n",
            "\n",
            "Epoch: 33\n",
            "iteration :  50, loss : 1.1184, accuracy : 54.88\n",
            "iteration : 100, loss : 1.1089, accuracy : 55.12\n",
            "iteration : 150, loss : 1.1155, accuracy : 54.90\n",
            "iteration : 200, loss : 1.1138, accuracy : 55.12\n",
            "iteration : 250, loss : 1.1136, accuracy : 55.29\n",
            "iteration : 300, loss : 1.1116, accuracy : 55.38\n",
            "iteration : 350, loss : 1.1108, accuracy : 55.41\n",
            "Epoch :  33, training loss : 1.1108, training accuracy : 55.40, test loss : 1.1099, test accuracy : 55.68\n",
            "\n",
            "Epoch: 34\n",
            "iteration :  50, loss : 1.1169, accuracy : 55.05\n",
            "iteration : 100, loss : 1.1115, accuracy : 55.31\n",
            "iteration : 150, loss : 1.1114, accuracy : 55.35\n",
            "iteration : 200, loss : 1.1036, accuracy : 55.66\n",
            "iteration : 250, loss : 1.1054, accuracy : 55.52\n",
            "iteration : 300, loss : 1.1065, accuracy : 55.62\n",
            "iteration : 350, loss : 1.1077, accuracy : 55.59\n",
            "Epoch :  34, training loss : 1.1066, training accuracy : 55.63, test loss : 1.1291, test accuracy : 54.62\n",
            "\n",
            "Epoch: 35\n",
            "iteration :  50, loss : 1.0927, accuracy : 55.25\n",
            "iteration : 100, loss : 1.0834, accuracy : 55.77\n",
            "iteration : 150, loss : 1.1005, accuracy : 55.36\n",
            "iteration : 200, loss : 1.1027, accuracy : 55.36\n",
            "iteration : 250, loss : 1.1028, accuracy : 55.52\n",
            "iteration : 300, loss : 1.1030, accuracy : 55.51\n",
            "iteration : 350, loss : 1.1018, accuracy : 55.56\n",
            "Epoch :  35, training loss : 1.1010, training accuracy : 55.61, test loss : 1.1406, test accuracy : 54.73\n",
            "\n",
            "Epoch: 36\n",
            "iteration :  50, loss : 1.1237, accuracy : 54.72\n",
            "iteration : 100, loss : 1.1017, accuracy : 55.88\n",
            "iteration : 150, loss : 1.1028, accuracy : 55.67\n",
            "iteration : 200, loss : 1.0984, accuracy : 55.71\n",
            "iteration : 250, loss : 1.1034, accuracy : 55.61\n",
            "iteration : 300, loss : 1.1019, accuracy : 55.58\n",
            "iteration : 350, loss : 1.1001, accuracy : 55.74\n",
            "Epoch :  36, training loss : 1.0994, training accuracy : 55.82, test loss : 1.1035, test accuracy : 55.83\n",
            "\n",
            "Epoch: 37\n",
            "iteration :  50, loss : 1.0864, accuracy : 55.88\n",
            "iteration : 100, loss : 1.0990, accuracy : 55.51\n",
            "iteration : 150, loss : 1.0927, accuracy : 55.66\n",
            "iteration : 200, loss : 1.0981, accuracy : 55.68\n",
            "iteration : 250, loss : 1.0976, accuracy : 55.77\n",
            "iteration : 300, loss : 1.0947, accuracy : 55.91\n",
            "iteration : 350, loss : 1.0966, accuracy : 55.81\n",
            "Epoch :  37, training loss : 1.0991, training accuracy : 55.76, test loss : 1.1243, test accuracy : 55.18\n",
            "\n",
            "Epoch: 38\n",
            "iteration :  50, loss : 1.0848, accuracy : 56.86\n",
            "iteration : 100, loss : 1.0933, accuracy : 56.09\n",
            "iteration : 150, loss : 1.0959, accuracy : 56.09\n",
            "iteration : 200, loss : 1.0937, accuracy : 56.09\n",
            "iteration : 250, loss : 1.0962, accuracy : 55.81\n",
            "iteration : 300, loss : 1.0977, accuracy : 55.78\n",
            "iteration : 350, loss : 1.0986, accuracy : 55.75\n",
            "Epoch :  38, training loss : 1.0994, training accuracy : 55.79, test loss : 1.1395, test accuracy : 54.95\n",
            "\n",
            "Epoch: 39\n",
            "iteration :  50, loss : 1.0919, accuracy : 55.50\n",
            "iteration : 100, loss : 1.1091, accuracy : 55.09\n",
            "iteration : 150, loss : 1.1164, accuracy : 55.02\n",
            "iteration : 200, loss : 1.1143, accuracy : 55.07\n",
            "iteration : 250, loss : 1.1124, accuracy : 55.10\n",
            "iteration : 300, loss : 1.1109, accuracy : 55.24\n",
            "iteration : 350, loss : 1.1111, accuracy : 55.24\n",
            "Epoch :  39, training loss : 1.1092, training accuracy : 55.32, test loss : 1.1191, test accuracy : 55.00\n",
            "\n",
            "Epoch: 40\n",
            "iteration :  50, loss : 1.1100, accuracy : 55.66\n",
            "iteration : 100, loss : 1.1182, accuracy : 55.09\n",
            "iteration : 150, loss : 1.1150, accuracy : 55.20\n",
            "iteration : 200, loss : 1.1174, accuracy : 55.13\n",
            "iteration : 250, loss : 1.1104, accuracy : 55.27\n",
            "iteration : 300, loss : 1.1136, accuracy : 55.13\n",
            "iteration : 350, loss : 1.1105, accuracy : 55.15\n",
            "Epoch :  40, training loss : 1.1096, training accuracy : 55.17, test loss : 1.1265, test accuracy : 54.70\n",
            "\n",
            "Epoch: 41\n",
            "iteration :  50, loss : 1.0869, accuracy : 56.97\n",
            "iteration : 100, loss : 1.1013, accuracy : 56.44\n",
            "iteration : 150, loss : 1.1004, accuracy : 56.31\n",
            "iteration : 200, loss : 1.1025, accuracy : 56.14\n",
            "iteration : 250, loss : 1.1010, accuracy : 56.17\n",
            "iteration : 300, loss : 1.1008, accuracy : 56.17\n",
            "iteration : 350, loss : 1.1002, accuracy : 56.11\n",
            "Epoch :  41, training loss : 1.0985, training accuracy : 56.09, test loss : 1.1245, test accuracy : 55.19\n",
            "\n",
            "Epoch: 42\n",
            "iteration :  50, loss : 1.0891, accuracy : 56.50\n",
            "iteration : 100, loss : 1.0955, accuracy : 55.84\n",
            "iteration : 150, loss : 1.0994, accuracy : 55.74\n",
            "iteration : 200, loss : 1.0985, accuracy : 55.78\n",
            "iteration : 250, loss : 1.1010, accuracy : 55.58\n",
            "iteration : 300, loss : 1.1010, accuracy : 55.56\n",
            "iteration : 350, loss : 1.1016, accuracy : 55.55\n",
            "Epoch :  42, training loss : 1.1005, training accuracy : 55.59, test loss : 1.0946, test accuracy : 56.01\n",
            "\n",
            "Epoch: 43\n",
            "iteration :  50, loss : 1.0597, accuracy : 56.09\n",
            "iteration : 100, loss : 1.0907, accuracy : 55.61\n",
            "iteration : 150, loss : 1.0982, accuracy : 55.48\n",
            "iteration : 200, loss : 1.0930, accuracy : 55.85\n",
            "iteration : 250, loss : 1.0917, accuracy : 56.00\n",
            "iteration : 300, loss : 1.0936, accuracy : 55.89\n",
            "iteration : 350, loss : 1.0953, accuracy : 55.89\n",
            "Epoch :  43, training loss : 1.0962, training accuracy : 55.87, test loss : 1.1194, test accuracy : 54.79\n",
            "\n",
            "Epoch: 44\n",
            "iteration :  50, loss : 1.1074, accuracy : 55.62\n",
            "iteration : 100, loss : 1.0955, accuracy : 56.00\n",
            "iteration : 150, loss : 1.0982, accuracy : 55.64\n",
            "iteration : 200, loss : 1.0986, accuracy : 55.65\n",
            "iteration : 250, loss : 1.1012, accuracy : 55.50\n",
            "iteration : 300, loss : 1.1011, accuracy : 55.46\n",
            "iteration : 350, loss : 1.0985, accuracy : 55.60\n",
            "Epoch :  44, training loss : 1.0977, training accuracy : 55.62, test loss : 1.1165, test accuracy : 55.34\n",
            "\n",
            "Epoch: 45\n",
            "iteration :  50, loss : 1.0981, accuracy : 55.59\n",
            "iteration : 100, loss : 1.1073, accuracy : 55.84\n",
            "iteration : 150, loss : 1.1042, accuracy : 55.72\n",
            "iteration : 200, loss : 1.1005, accuracy : 55.93\n",
            "iteration : 250, loss : 1.0976, accuracy : 55.90\n",
            "iteration : 300, loss : 1.0946, accuracy : 55.86\n",
            "iteration : 350, loss : 1.0952, accuracy : 55.83\n",
            "Epoch :  45, training loss : 1.0950, training accuracy : 55.80, test loss : 1.1264, test accuracy : 55.29\n",
            "\n",
            "Epoch: 46\n",
            "iteration :  50, loss : 1.1198, accuracy : 55.17\n",
            "iteration : 100, loss : 1.1064, accuracy : 55.69\n",
            "iteration : 150, loss : 1.1045, accuracy : 56.02\n",
            "iteration : 200, loss : 1.0971, accuracy : 56.19\n",
            "iteration : 250, loss : 1.0975, accuracy : 56.12\n",
            "iteration : 300, loss : 1.0960, accuracy : 56.22\n",
            "iteration : 350, loss : 1.0956, accuracy : 56.32\n",
            "Epoch :  46, training loss : 1.0959, training accuracy : 56.28, test loss : 1.1268, test accuracy : 55.16\n",
            "\n",
            "Epoch: 47\n",
            "iteration :  50, loss : 1.1005, accuracy : 54.83\n",
            "iteration : 100, loss : 1.1086, accuracy : 54.67\n",
            "iteration : 150, loss : 1.1036, accuracy : 55.23\n",
            "iteration : 200, loss : 1.1046, accuracy : 55.17\n",
            "iteration : 250, loss : 1.0983, accuracy : 55.60\n",
            "iteration : 300, loss : 1.0978, accuracy : 55.62\n",
            "iteration : 350, loss : 1.0959, accuracy : 55.65\n",
            "Epoch :  47, training loss : 1.0962, training accuracy : 55.72, test loss : 1.1462, test accuracy : 54.09\n",
            "\n",
            "Epoch: 48\n",
            "iteration :  50, loss : 1.1149, accuracy : 55.23\n",
            "iteration : 100, loss : 1.0908, accuracy : 55.78\n",
            "iteration : 150, loss : 1.0901, accuracy : 55.80\n",
            "iteration : 200, loss : 1.0900, accuracy : 55.98\n",
            "iteration : 250, loss : 1.0880, accuracy : 55.97\n",
            "iteration : 300, loss : 1.0920, accuracy : 55.81\n",
            "iteration : 350, loss : 1.0929, accuracy : 55.81\n",
            "Epoch :  48, training loss : 1.0917, training accuracy : 55.90, test loss : 1.1140, test accuracy : 55.44\n",
            "\n",
            "Epoch: 49\n",
            "iteration :  50, loss : 1.0767, accuracy : 56.30\n",
            "iteration : 100, loss : 1.0910, accuracy : 56.27\n",
            "iteration : 150, loss : 1.0905, accuracy : 55.97\n",
            "iteration : 200, loss : 1.0944, accuracy : 55.82\n",
            "iteration : 250, loss : 1.0916, accuracy : 56.03\n",
            "iteration : 300, loss : 1.0926, accuracy : 55.89\n",
            "iteration : 350, loss : 1.0904, accuracy : 56.02\n",
            "Epoch :  49, training loss : 1.0923, training accuracy : 55.89, test loss : 1.1107, test accuracy : 55.67\n",
            "\n",
            "Epoch: 50\n",
            "iteration :  50, loss : 1.0856, accuracy : 55.78\n",
            "iteration : 100, loss : 1.0829, accuracy : 55.99\n",
            "iteration : 150, loss : 1.0804, accuracy : 55.94\n",
            "iteration : 200, loss : 1.0825, accuracy : 56.01\n",
            "iteration : 250, loss : 1.0854, accuracy : 55.87\n",
            "iteration : 300, loss : 1.0856, accuracy : 55.85\n",
            "iteration : 350, loss : 1.0842, accuracy : 55.92\n",
            "Epoch :  50, training loss : 1.0863, training accuracy : 55.87, test loss : 1.1075, test accuracy : 55.25\n",
            "\n",
            "Epoch: 51\n",
            "iteration :  50, loss : 1.0818, accuracy : 56.48\n",
            "iteration : 100, loss : 1.0751, accuracy : 56.48\n",
            "iteration : 150, loss : 1.0847, accuracy : 56.16\n",
            "iteration : 200, loss : 1.0868, accuracy : 55.91\n",
            "iteration : 250, loss : 1.0909, accuracy : 55.72\n",
            "iteration : 300, loss : 1.0938, accuracy : 55.73\n",
            "iteration : 350, loss : 1.0965, accuracy : 55.63\n",
            "Epoch :  51, training loss : 1.0949, training accuracy : 55.71, test loss : 1.1083, test accuracy : 55.72\n",
            "\n",
            "Epoch: 52\n",
            "iteration :  50, loss : 1.0764, accuracy : 56.48\n",
            "iteration : 100, loss : 1.0848, accuracy : 55.94\n",
            "iteration : 150, loss : 1.0900, accuracy : 55.93\n",
            "iteration : 200, loss : 1.0896, accuracy : 56.12\n",
            "iteration : 250, loss : 1.0913, accuracy : 56.11\n",
            "iteration : 300, loss : 1.0918, accuracy : 56.08\n",
            "iteration : 350, loss : 1.0942, accuracy : 55.98\n",
            "Epoch :  52, training loss : 1.0939, training accuracy : 55.94, test loss : 1.0944, test accuracy : 55.89\n",
            "\n",
            "Epoch: 53\n",
            "iteration :  50, loss : 1.0808, accuracy : 56.09\n",
            "iteration : 100, loss : 1.0801, accuracy : 56.13\n",
            "iteration : 150, loss : 1.0850, accuracy : 55.84\n",
            "iteration : 200, loss : 1.0863, accuracy : 55.74\n",
            "iteration : 250, loss : 1.0915, accuracy : 55.64\n",
            "iteration : 300, loss : 1.0918, accuracy : 55.71\n",
            "iteration : 350, loss : 1.0918, accuracy : 55.72\n",
            "Epoch :  53, training loss : 1.0921, training accuracy : 55.71, test loss : 1.1151, test accuracy : 55.03\n",
            "\n",
            "Epoch: 54\n",
            "iteration :  50, loss : 1.1056, accuracy : 55.12\n",
            "iteration : 100, loss : 1.0912, accuracy : 55.93\n",
            "iteration : 150, loss : 1.0898, accuracy : 55.97\n",
            "iteration : 200, loss : 1.0889, accuracy : 56.00\n",
            "iteration : 250, loss : 1.0923, accuracy : 55.90\n",
            "iteration : 300, loss : 1.0917, accuracy : 55.84\n",
            "iteration : 350, loss : 1.0929, accuracy : 55.71\n",
            "Epoch :  54, training loss : 1.0932, training accuracy : 55.74, test loss : 1.0991, test accuracy : 55.63\n",
            "\n",
            "Epoch: 55\n",
            "iteration :  50, loss : 1.0611, accuracy : 57.16\n",
            "iteration : 100, loss : 1.0682, accuracy : 56.91\n",
            "iteration : 150, loss : 1.0840, accuracy : 56.43\n",
            "iteration : 200, loss : 1.0834, accuracy : 56.41\n",
            "iteration : 250, loss : 1.0823, accuracy : 56.37\n",
            "iteration : 300, loss : 1.0830, accuracy : 56.15\n",
            "iteration : 350, loss : 1.0851, accuracy : 56.06\n",
            "Epoch :  55, training loss : 1.0864, training accuracy : 56.05, test loss : 1.0918, test accuracy : 55.77\n",
            "\n",
            "Epoch: 56\n",
            "iteration :  50, loss : 1.0763, accuracy : 56.61\n",
            "iteration : 100, loss : 1.0895, accuracy : 55.96\n",
            "iteration : 150, loss : 1.0896, accuracy : 56.02\n",
            "iteration : 200, loss : 1.0931, accuracy : 55.98\n",
            "iteration : 250, loss : 1.0937, accuracy : 56.01\n",
            "iteration : 300, loss : 1.0962, accuracy : 55.90\n",
            "iteration : 350, loss : 1.0929, accuracy : 56.07\n",
            "Epoch :  56, training loss : 1.0918, training accuracy : 56.09, test loss : 1.0943, test accuracy : 55.45\n",
            "\n",
            "Epoch: 57\n",
            "iteration :  50, loss : 1.0960, accuracy : 55.33\n",
            "iteration : 100, loss : 1.0891, accuracy : 55.72\n",
            "iteration : 150, loss : 1.0948, accuracy : 55.50\n",
            "iteration : 200, loss : 1.0881, accuracy : 55.87\n",
            "iteration : 250, loss : 1.0914, accuracy : 55.67\n",
            "iteration : 300, loss : 1.0896, accuracy : 55.77\n",
            "iteration : 350, loss : 1.0873, accuracy : 55.97\n",
            "Epoch :  57, training loss : 1.0868, training accuracy : 55.97, test loss : 1.1044, test accuracy : 55.20\n",
            "\n",
            "Epoch: 58\n",
            "iteration :  50, loss : 1.0666, accuracy : 56.91\n",
            "iteration : 100, loss : 1.0726, accuracy : 56.78\n",
            "iteration : 150, loss : 1.0698, accuracy : 56.70\n",
            "iteration : 200, loss : 1.0814, accuracy : 56.40\n",
            "iteration : 250, loss : 1.0873, accuracy : 56.04\n",
            "iteration : 300, loss : 1.0922, accuracy : 55.90\n",
            "iteration : 350, loss : 1.0899, accuracy : 56.11\n",
            "Epoch :  58, training loss : 1.0883, training accuracy : 56.17, test loss : 1.1155, test accuracy : 55.48\n",
            "\n",
            "Epoch: 59\n",
            "iteration :  50, loss : 1.0729, accuracy : 56.58\n",
            "iteration : 100, loss : 1.0676, accuracy : 56.69\n",
            "iteration : 150, loss : 1.0804, accuracy : 56.40\n",
            "iteration : 200, loss : 1.0851, accuracy : 56.20\n",
            "iteration : 250, loss : 1.0884, accuracy : 56.09\n",
            "iteration : 300, loss : 1.0887, accuracy : 56.01\n",
            "iteration : 350, loss : 1.0895, accuracy : 55.94\n",
            "Epoch :  59, training loss : 1.0884, training accuracy : 55.99, test loss : 1.0957, test accuracy : 56.08\n",
            "\n",
            "Epoch: 60\n",
            "iteration :  50, loss : 1.1080, accuracy : 55.64\n",
            "iteration : 100, loss : 1.0933, accuracy : 56.16\n",
            "iteration : 150, loss : 1.0900, accuracy : 56.15\n",
            "iteration : 200, loss : 1.0894, accuracy : 56.08\n",
            "iteration : 250, loss : 1.0861, accuracy : 56.10\n",
            "iteration : 300, loss : 1.0833, accuracy : 56.12\n",
            "iteration : 350, loss : 1.0870, accuracy : 56.03\n",
            "Epoch :  60, training loss : 1.0872, training accuracy : 56.07, test loss : 1.1110, test accuracy : 55.19\n",
            "\n",
            "Epoch: 61\n",
            "iteration :  50, loss : 1.1033, accuracy : 55.92\n",
            "iteration : 100, loss : 1.0902, accuracy : 56.41\n",
            "iteration : 150, loss : 1.0900, accuracy : 56.18\n",
            "iteration : 200, loss : 1.0912, accuracy : 55.98\n",
            "iteration : 250, loss : 1.0829, accuracy : 56.17\n",
            "iteration : 300, loss : 1.0877, accuracy : 55.99\n",
            "iteration : 350, loss : 1.0858, accuracy : 56.09\n",
            "Epoch :  61, training loss : 1.0859, training accuracy : 56.08, test loss : 1.0882, test accuracy : 56.26\n",
            "\n",
            "Epoch: 62\n",
            "iteration :  50, loss : 1.0829, accuracy : 55.39\n",
            "iteration : 100, loss : 1.0752, accuracy : 55.95\n",
            "iteration : 150, loss : 1.0764, accuracy : 56.21\n",
            "iteration : 200, loss : 1.0746, accuracy : 56.41\n",
            "iteration : 250, loss : 1.0785, accuracy : 56.36\n",
            "iteration : 300, loss : 1.0821, accuracy : 56.19\n",
            "iteration : 350, loss : 1.0831, accuracy : 56.21\n",
            "Epoch :  62, training loss : 1.0829, training accuracy : 56.17, test loss : 1.1034, test accuracy : 55.43\n",
            "\n",
            "Epoch: 63\n",
            "iteration :  50, loss : 1.1025, accuracy : 56.03\n",
            "iteration : 100, loss : 1.0970, accuracy : 55.75\n",
            "iteration : 150, loss : 1.0960, accuracy : 55.73\n",
            "iteration : 200, loss : 1.0932, accuracy : 55.84\n",
            "iteration : 250, loss : 1.0897, accuracy : 55.85\n",
            "iteration : 300, loss : 1.0857, accuracy : 55.98\n",
            "iteration : 350, loss : 1.0865, accuracy : 55.92\n",
            "Epoch :  63, training loss : 1.0858, training accuracy : 55.95, test loss : 1.1030, test accuracy : 55.77\n",
            "\n",
            "Epoch: 64\n",
            "iteration :  50, loss : 1.0790, accuracy : 56.30\n",
            "iteration : 100, loss : 1.0772, accuracy : 56.23\n",
            "iteration : 150, loss : 1.0755, accuracy : 56.46\n",
            "iteration : 200, loss : 1.0827, accuracy : 56.09\n",
            "iteration : 250, loss : 1.0866, accuracy : 55.97\n",
            "iteration : 300, loss : 1.0890, accuracy : 55.84\n",
            "iteration : 350, loss : 1.0888, accuracy : 55.82\n",
            "Epoch :  64, training loss : 1.0875, training accuracy : 55.86, test loss : 1.0979, test accuracy : 55.84\n",
            "\n",
            "Epoch: 65\n",
            "iteration :  50, loss : 1.0930, accuracy : 55.00\n",
            "iteration : 100, loss : 1.0961, accuracy : 55.54\n",
            "iteration : 150, loss : 1.0958, accuracy : 55.69\n",
            "iteration : 200, loss : 1.0900, accuracy : 55.86\n",
            "iteration : 250, loss : 1.0860, accuracy : 55.97\n",
            "iteration : 300, loss : 1.0872, accuracy : 55.90\n",
            "iteration : 350, loss : 1.0845, accuracy : 55.85\n",
            "Epoch :  65, training loss : 1.0841, training accuracy : 55.87, test loss : 1.1059, test accuracy : 55.70\n",
            "\n",
            "Epoch: 66\n",
            "iteration :  50, loss : 1.0731, accuracy : 57.11\n",
            "iteration : 100, loss : 1.0748, accuracy : 56.34\n",
            "iteration : 150, loss : 1.0746, accuracy : 56.39\n",
            "iteration : 200, loss : 1.0742, accuracy : 56.32\n",
            "iteration : 250, loss : 1.0807, accuracy : 56.25\n",
            "iteration : 300, loss : 1.0828, accuracy : 56.24\n",
            "iteration : 350, loss : 1.0805, accuracy : 56.36\n",
            "Epoch :  66, training loss : 1.0823, training accuracy : 56.31, test loss : 1.1259, test accuracy : 54.89\n",
            "\n",
            "Epoch: 67\n",
            "iteration :  50, loss : 1.0747, accuracy : 56.64\n",
            "iteration : 100, loss : 1.0635, accuracy : 56.67\n",
            "iteration : 150, loss : 1.0655, accuracy : 56.69\n",
            "iteration : 200, loss : 1.0690, accuracy : 56.44\n",
            "iteration : 250, loss : 1.0757, accuracy : 56.22\n",
            "iteration : 300, loss : 1.0802, accuracy : 56.12\n",
            "iteration : 350, loss : 1.0807, accuracy : 56.13\n",
            "Epoch :  67, training loss : 1.0801, training accuracy : 56.14, test loss : 1.0857, test accuracy : 55.91\n",
            "\n",
            "Epoch: 68\n",
            "iteration :  50, loss : 1.0634, accuracy : 57.11\n",
            "iteration : 100, loss : 1.0718, accuracy : 57.06\n",
            "iteration : 150, loss : 1.0741, accuracy : 57.04\n",
            "iteration : 200, loss : 1.0725, accuracy : 56.93\n",
            "iteration : 250, loss : 1.0779, accuracy : 56.75\n",
            "iteration : 300, loss : 1.0830, accuracy : 56.54\n",
            "iteration : 350, loss : 1.0796, accuracy : 56.45\n",
            "Epoch :  68, training loss : 1.0771, training accuracy : 56.58, test loss : 1.0889, test accuracy : 55.80\n",
            "\n",
            "Epoch: 69\n",
            "iteration :  50, loss : 1.1071, accuracy : 55.59\n",
            "iteration : 100, loss : 1.0897, accuracy : 55.67\n",
            "iteration : 150, loss : 1.0987, accuracy : 55.31\n",
            "iteration : 200, loss : 1.0896, accuracy : 55.98\n",
            "iteration : 250, loss : 1.0927, accuracy : 55.84\n",
            "iteration : 300, loss : 1.0922, accuracy : 55.82\n",
            "iteration : 350, loss : 1.0879, accuracy : 55.97\n",
            "Epoch :  69, training loss : 1.0865, training accuracy : 55.99, test loss : 1.1025, test accuracy : 55.87\n",
            "\n",
            "Epoch: 70\n",
            "iteration :  50, loss : 1.1018, accuracy : 55.73\n",
            "iteration : 100, loss : 1.0872, accuracy : 56.26\n",
            "iteration : 150, loss : 1.0828, accuracy : 56.29\n",
            "iteration : 200, loss : 1.0892, accuracy : 55.92\n",
            "iteration : 250, loss : 1.0844, accuracy : 56.09\n",
            "iteration : 300, loss : 1.0821, accuracy : 56.22\n",
            "iteration : 350, loss : 1.0843, accuracy : 56.14\n",
            "Epoch :  70, training loss : 1.0848, training accuracy : 56.08, test loss : 1.0961, test accuracy : 55.62\n",
            "\n",
            "Epoch: 71\n",
            "iteration :  50, loss : 1.0630, accuracy : 56.72\n",
            "iteration : 100, loss : 1.0781, accuracy : 56.11\n",
            "iteration : 150, loss : 1.0797, accuracy : 56.17\n",
            "iteration : 200, loss : 1.0766, accuracy : 56.13\n",
            "iteration : 250, loss : 1.0758, accuracy : 56.38\n",
            "iteration : 300, loss : 1.0748, accuracy : 56.46\n",
            "iteration : 350, loss : 1.0728, accuracy : 56.55\n",
            "Epoch :  71, training loss : 1.0737, training accuracy : 56.53, test loss : 1.0941, test accuracy : 55.68\n",
            "\n",
            "Epoch: 72\n",
            "iteration :  50, loss : 1.0859, accuracy : 55.66\n",
            "iteration : 100, loss : 1.0903, accuracy : 55.78\n",
            "iteration : 150, loss : 1.0834, accuracy : 55.99\n",
            "iteration : 200, loss : 1.0839, accuracy : 56.00\n",
            "iteration : 250, loss : 1.0797, accuracy : 56.13\n",
            "iteration : 300, loss : 1.0801, accuracy : 56.06\n",
            "iteration : 350, loss : 1.0784, accuracy : 56.11\n",
            "Epoch :  72, training loss : 1.0765, training accuracy : 56.19, test loss : 1.0913, test accuracy : 55.90\n",
            "\n",
            "Epoch: 73\n",
            "iteration :  50, loss : 1.0637, accuracy : 56.69\n",
            "iteration : 100, loss : 1.0754, accuracy : 56.33\n",
            "iteration : 150, loss : 1.0820, accuracy : 56.19\n",
            "iteration : 200, loss : 1.0816, accuracy : 56.18\n",
            "iteration : 250, loss : 1.0827, accuracy : 56.11\n",
            "iteration : 300, loss : 1.0787, accuracy : 56.28\n",
            "iteration : 350, loss : 1.0798, accuracy : 56.36\n",
            "Epoch :  73, training loss : 1.0790, training accuracy : 56.38, test loss : 1.0945, test accuracy : 55.84\n",
            "\n",
            "Epoch: 74\n",
            "iteration :  50, loss : 1.0729, accuracy : 57.03\n",
            "iteration : 100, loss : 1.0857, accuracy : 56.48\n",
            "iteration : 150, loss : 1.0827, accuracy : 56.42\n",
            "iteration : 200, loss : 1.0841, accuracy : 56.04\n",
            "iteration : 250, loss : 1.0809, accuracy : 56.11\n",
            "iteration : 300, loss : 1.0788, accuracy : 56.18\n",
            "iteration : 350, loss : 1.0796, accuracy : 56.10\n",
            "Epoch :  74, training loss : 1.0777, training accuracy : 56.22, test loss : 1.0900, test accuracy : 55.95\n",
            "\n",
            "Epoch: 75\n",
            "iteration :  50, loss : 1.0659, accuracy : 57.36\n",
            "iteration : 100, loss : 1.0733, accuracy : 56.81\n",
            "iteration : 150, loss : 1.0721, accuracy : 56.77\n",
            "iteration : 200, loss : 1.0725, accuracy : 56.69\n",
            "iteration : 250, loss : 1.0740, accuracy : 56.42\n",
            "iteration : 300, loss : 1.0770, accuracy : 56.25\n",
            "iteration : 350, loss : 1.0771, accuracy : 56.30\n",
            "Epoch :  75, training loss : 1.0763, training accuracy : 56.31, test loss : 1.0977, test accuracy : 55.82\n",
            "\n",
            "Epoch: 76\n",
            "iteration :  50, loss : 1.0664, accuracy : 56.89\n",
            "iteration : 100, loss : 1.0787, accuracy : 56.82\n",
            "iteration : 150, loss : 1.0757, accuracy : 56.72\n",
            "iteration : 200, loss : 1.0740, accuracy : 56.86\n",
            "iteration : 250, loss : 1.0757, accuracy : 56.62\n",
            "iteration : 300, loss : 1.0770, accuracy : 56.57\n",
            "iteration : 350, loss : 1.0780, accuracy : 56.54\n",
            "Epoch :  76, training loss : 1.0786, training accuracy : 56.51, test loss : 1.0728, test accuracy : 56.47\n",
            "\n",
            "Epoch: 77\n",
            "iteration :  50, loss : 1.0870, accuracy : 56.03\n",
            "iteration : 100, loss : 1.0728, accuracy : 56.37\n",
            "iteration : 150, loss : 1.0740, accuracy : 56.18\n",
            "iteration : 200, loss : 1.0768, accuracy : 56.01\n",
            "iteration : 250, loss : 1.0764, accuracy : 55.98\n",
            "iteration : 300, loss : 1.0799, accuracy : 55.81\n",
            "iteration : 350, loss : 1.0777, accuracy : 55.85\n",
            "Epoch :  77, training loss : 1.0779, training accuracy : 55.92, test loss : 1.1112, test accuracy : 55.26\n",
            "\n",
            "Epoch: 78\n",
            "iteration :  50, loss : 1.0634, accuracy : 57.66\n",
            "iteration : 100, loss : 1.0692, accuracy : 57.19\n",
            "iteration : 150, loss : 1.0768, accuracy : 56.70\n",
            "iteration : 200, loss : 1.0780, accuracy : 56.52\n",
            "iteration : 250, loss : 1.0762, accuracy : 56.43\n",
            "iteration : 300, loss : 1.0812, accuracy : 56.17\n",
            "iteration : 350, loss : 1.0787, accuracy : 56.30\n",
            "Epoch :  78, training loss : 1.0783, training accuracy : 56.27, test loss : 1.0838, test accuracy : 56.27\n",
            "\n",
            "Epoch: 79\n",
            "iteration :  50, loss : 1.0733, accuracy : 56.83\n",
            "iteration : 100, loss : 1.0716, accuracy : 56.80\n",
            "iteration : 150, loss : 1.0671, accuracy : 56.86\n",
            "iteration : 200, loss : 1.0697, accuracy : 56.55\n",
            "iteration : 250, loss : 1.0694, accuracy : 56.59\n",
            "iteration : 300, loss : 1.0711, accuracy : 56.49\n",
            "iteration : 350, loss : 1.0701, accuracy : 56.58\n",
            "Epoch :  79, training loss : 1.0697, training accuracy : 56.58, test loss : 1.0883, test accuracy : 56.22\n",
            "\n",
            "Epoch: 80\n",
            "iteration :  50, loss : 1.0509, accuracy : 57.70\n",
            "iteration : 100, loss : 1.0553, accuracy : 57.06\n",
            "iteration : 150, loss : 1.0645, accuracy : 56.67\n",
            "iteration : 200, loss : 1.0737, accuracy : 56.26\n",
            "iteration : 250, loss : 1.0751, accuracy : 56.24\n",
            "iteration : 300, loss : 1.0747, accuracy : 56.16\n",
            "iteration : 350, loss : 1.0719, accuracy : 56.27\n",
            "Epoch :  80, training loss : 1.0752, training accuracy : 56.19, test loss : 1.0816, test accuracy : 55.98\n",
            "\n",
            "Epoch: 81\n",
            "iteration :  50, loss : 1.0706, accuracy : 56.78\n",
            "iteration : 100, loss : 1.0829, accuracy : 56.04\n",
            "iteration : 150, loss : 1.0842, accuracy : 55.81\n",
            "iteration : 200, loss : 1.0803, accuracy : 55.95\n",
            "iteration : 250, loss : 1.0789, accuracy : 56.10\n",
            "iteration : 300, loss : 1.0778, accuracy : 56.17\n",
            "iteration : 350, loss : 1.0745, accuracy : 56.27\n",
            "Epoch :  81, training loss : 1.0767, training accuracy : 56.18, test loss : 1.1070, test accuracy : 55.32\n",
            "\n",
            "Epoch: 82\n",
            "iteration :  50, loss : 1.0453, accuracy : 57.66\n",
            "iteration : 100, loss : 1.0531, accuracy : 57.45\n",
            "iteration : 150, loss : 1.0544, accuracy : 57.34\n",
            "iteration : 200, loss : 1.0520, accuracy : 57.32\n",
            "iteration : 250, loss : 1.0631, accuracy : 56.88\n",
            "iteration : 300, loss : 1.0683, accuracy : 56.67\n",
            "iteration : 350, loss : 1.0694, accuracy : 56.55\n",
            "Epoch :  82, training loss : 1.0667, training accuracy : 56.63, test loss : 1.1114, test accuracy : 55.13\n",
            "\n",
            "Epoch: 83\n",
            "iteration :  50, loss : 1.0533, accuracy : 56.64\n",
            "iteration : 100, loss : 1.0473, accuracy : 56.66\n",
            "iteration : 150, loss : 1.0614, accuracy : 56.26\n",
            "iteration : 200, loss : 1.0703, accuracy : 56.04\n",
            "iteration : 250, loss : 1.0704, accuracy : 56.19\n",
            "iteration : 300, loss : 1.0737, accuracy : 56.01\n",
            "iteration : 350, loss : 1.0742, accuracy : 56.08\n",
            "Epoch :  83, training loss : 1.0750, training accuracy : 56.02, test loss : 1.0833, test accuracy : 55.88\n",
            "\n",
            "Epoch: 84\n",
            "iteration :  50, loss : 1.0488, accuracy : 56.77\n",
            "iteration : 100, loss : 1.0503, accuracy : 56.88\n",
            "iteration : 150, loss : 1.0555, accuracy : 57.07\n",
            "iteration : 200, loss : 1.0542, accuracy : 57.09\n",
            "iteration : 250, loss : 1.0616, accuracy : 56.68\n",
            "iteration : 300, loss : 1.0646, accuracy : 56.71\n",
            "iteration : 350, loss : 1.0687, accuracy : 56.62\n",
            "Epoch :  84, training loss : 1.0693, training accuracy : 56.61, test loss : 1.1154, test accuracy : 55.50\n",
            "\n",
            "Epoch: 85\n",
            "iteration :  50, loss : 1.0717, accuracy : 56.97\n",
            "iteration : 100, loss : 1.0719, accuracy : 56.82\n",
            "iteration : 150, loss : 1.0680, accuracy : 56.77\n",
            "iteration : 200, loss : 1.0722, accuracy : 56.45\n",
            "iteration : 250, loss : 1.0750, accuracy : 56.37\n",
            "iteration : 300, loss : 1.0718, accuracy : 56.44\n",
            "iteration : 350, loss : 1.0703, accuracy : 56.48\n",
            "Epoch :  85, training loss : 1.0702, training accuracy : 56.46, test loss : 1.0817, test accuracy : 56.03\n",
            "\n",
            "Epoch: 86\n",
            "iteration :  50, loss : 1.0800, accuracy : 55.53\n",
            "iteration : 100, loss : 1.0749, accuracy : 56.15\n",
            "iteration : 150, loss : 1.0715, accuracy : 56.19\n",
            "iteration : 200, loss : 1.0711, accuracy : 56.23\n",
            "iteration : 250, loss : 1.0726, accuracy : 56.14\n",
            "iteration : 300, loss : 1.0760, accuracy : 55.99\n",
            "iteration : 350, loss : 1.0740, accuracy : 56.10\n",
            "Epoch :  86, training loss : 1.0761, training accuracy : 55.97, test loss : 1.0864, test accuracy : 56.34\n",
            "\n",
            "Epoch: 87\n",
            "iteration :  50, loss : 1.0708, accuracy : 56.34\n",
            "iteration : 100, loss : 1.0684, accuracy : 56.77\n",
            "iteration : 150, loss : 1.0730, accuracy : 56.52\n",
            "iteration : 200, loss : 1.0757, accuracy : 56.38\n",
            "iteration : 250, loss : 1.0730, accuracy : 56.39\n",
            "iteration : 300, loss : 1.0729, accuracy : 56.32\n",
            "iteration : 350, loss : 1.0730, accuracy : 56.34\n",
            "Epoch :  87, training loss : 1.0733, training accuracy : 56.35, test loss : 1.0798, test accuracy : 56.04\n",
            "\n",
            "Epoch: 88\n",
            "iteration :  50, loss : 1.0659, accuracy : 56.44\n",
            "iteration : 100, loss : 1.0704, accuracy : 56.24\n",
            "iteration : 150, loss : 1.0646, accuracy : 56.79\n",
            "iteration : 200, loss : 1.0651, accuracy : 56.92\n",
            "iteration : 250, loss : 1.0658, accuracy : 56.87\n",
            "iteration : 300, loss : 1.0646, accuracy : 56.80\n",
            "iteration : 350, loss : 1.0634, accuracy : 56.72\n",
            "Epoch :  88, training loss : 1.0641, training accuracy : 56.72, test loss : 1.0766, test accuracy : 56.13\n",
            "\n",
            "Epoch: 89\n",
            "iteration :  50, loss : 1.0719, accuracy : 55.55\n",
            "iteration : 100, loss : 1.0654, accuracy : 55.58\n",
            "iteration : 150, loss : 1.0608, accuracy : 56.13\n",
            "iteration : 200, loss : 1.0618, accuracy : 56.36\n",
            "iteration : 250, loss : 1.0649, accuracy : 56.36\n",
            "iteration : 300, loss : 1.0624, accuracy : 56.47\n",
            "iteration : 350, loss : 1.0652, accuracy : 56.42\n",
            "Epoch :  89, training loss : 1.0656, training accuracy : 56.38, test loss : 1.0855, test accuracy : 55.75\n",
            "\n",
            "Epoch: 90\n",
            "iteration :  50, loss : 1.0395, accuracy : 57.03\n",
            "iteration : 100, loss : 1.0587, accuracy : 56.90\n",
            "iteration : 150, loss : 1.0601, accuracy : 56.94\n",
            "iteration : 200, loss : 1.0616, accuracy : 56.71\n",
            "iteration : 250, loss : 1.0601, accuracy : 56.87\n",
            "iteration : 300, loss : 1.0649, accuracy : 56.73\n",
            "iteration : 350, loss : 1.0664, accuracy : 56.71\n",
            "Epoch :  90, training loss : 1.0657, training accuracy : 56.70, test loss : 1.0766, test accuracy : 56.37\n",
            "\n",
            "Epoch: 91\n",
            "iteration :  50, loss : 1.0627, accuracy : 56.70\n",
            "iteration : 100, loss : 1.0577, accuracy : 56.48\n",
            "iteration : 150, loss : 1.0573, accuracy : 56.47\n",
            "iteration : 200, loss : 1.0598, accuracy : 56.68\n",
            "iteration : 250, loss : 1.0655, accuracy : 56.50\n",
            "iteration : 300, loss : 1.0690, accuracy : 56.44\n",
            "iteration : 350, loss : 1.0687, accuracy : 56.53\n",
            "Epoch :  91, training loss : 1.0675, training accuracy : 56.59, test loss : 1.0755, test accuracy : 56.07\n",
            "\n",
            "Epoch: 92\n",
            "iteration :  50, loss : 1.0298, accuracy : 57.67\n",
            "iteration : 100, loss : 1.0467, accuracy : 57.28\n",
            "iteration : 150, loss : 1.0564, accuracy : 56.86\n",
            "iteration : 200, loss : 1.0539, accuracy : 56.92\n",
            "iteration : 250, loss : 1.0596, accuracy : 56.70\n",
            "iteration : 300, loss : 1.0640, accuracy : 56.59\n",
            "iteration : 350, loss : 1.0617, accuracy : 56.78\n",
            "Epoch :  92, training loss : 1.0636, training accuracy : 56.74, test loss : 1.1024, test accuracy : 55.51\n",
            "\n",
            "Epoch: 93\n",
            "iteration :  50, loss : 1.0563, accuracy : 56.39\n",
            "iteration : 100, loss : 1.0696, accuracy : 55.96\n",
            "iteration : 150, loss : 1.0596, accuracy : 56.50\n",
            "iteration : 200, loss : 1.0666, accuracy : 56.34\n",
            "iteration : 250, loss : 1.0647, accuracy : 56.26\n",
            "iteration : 300, loss : 1.0629, accuracy : 56.54\n",
            "iteration : 350, loss : 1.0650, accuracy : 56.45\n",
            "Epoch :  93, training loss : 1.0660, training accuracy : 56.39, test loss : 1.0746, test accuracy : 56.46\n",
            "\n",
            "Epoch: 94\n",
            "iteration :  50, loss : 1.0760, accuracy : 56.22\n",
            "iteration : 100, loss : 1.0786, accuracy : 55.97\n",
            "iteration : 150, loss : 1.0810, accuracy : 55.84\n",
            "iteration : 200, loss : 1.0717, accuracy : 56.19\n",
            "iteration : 250, loss : 1.0688, accuracy : 56.20\n",
            "iteration : 300, loss : 1.0688, accuracy : 56.30\n",
            "iteration : 350, loss : 1.0686, accuracy : 56.31\n",
            "Epoch :  94, training loss : 1.0706, training accuracy : 56.24, test loss : 1.0793, test accuracy : 56.26\n",
            "\n",
            "Epoch: 95\n",
            "iteration :  50, loss : 1.0857, accuracy : 56.14\n",
            "iteration : 100, loss : 1.0630, accuracy : 56.65\n",
            "iteration : 150, loss : 1.0626, accuracy : 56.52\n",
            "iteration : 200, loss : 1.0624, accuracy : 56.30\n",
            "iteration : 250, loss : 1.0663, accuracy : 56.20\n",
            "iteration : 300, loss : 1.0654, accuracy : 56.28\n",
            "iteration : 350, loss : 1.0667, accuracy : 56.23\n",
            "Epoch :  95, training loss : 1.0645, training accuracy : 56.27, test loss : 1.0752, test accuracy : 56.19\n",
            "\n",
            "Epoch: 96\n",
            "iteration :  50, loss : 1.0623, accuracy : 55.64\n",
            "iteration : 100, loss : 1.0639, accuracy : 55.71\n",
            "iteration : 150, loss : 1.0682, accuracy : 55.65\n",
            "iteration : 200, loss : 1.0680, accuracy : 56.08\n",
            "iteration : 250, loss : 1.0672, accuracy : 56.27\n",
            "iteration : 300, loss : 1.0659, accuracy : 56.27\n",
            "iteration : 350, loss : 1.0645, accuracy : 56.32\n",
            "Epoch :  96, training loss : 1.0685, training accuracy : 56.19, test loss : 1.0846, test accuracy : 55.79\n",
            "\n",
            "Epoch: 97\n",
            "iteration :  50, loss : 1.0770, accuracy : 56.88\n",
            "iteration : 100, loss : 1.0608, accuracy : 57.12\n",
            "iteration : 150, loss : 1.0592, accuracy : 57.01\n",
            "iteration : 200, loss : 1.0608, accuracy : 56.83\n",
            "iteration : 250, loss : 1.0636, accuracy : 56.76\n",
            "iteration : 300, loss : 1.0645, accuracy : 56.60\n",
            "iteration : 350, loss : 1.0626, accuracy : 56.54\n",
            "Epoch :  97, training loss : 1.0645, training accuracy : 56.50, test loss : 1.0631, test accuracy : 56.34\n",
            "\n",
            "Epoch: 98\n",
            "iteration :  50, loss : 1.0745, accuracy : 56.50\n",
            "iteration : 100, loss : 1.0680, accuracy : 56.75\n",
            "iteration : 150, loss : 1.0677, accuracy : 56.66\n",
            "iteration : 200, loss : 1.0636, accuracy : 56.59\n",
            "iteration : 250, loss : 1.0610, accuracy : 56.61\n",
            "iteration : 300, loss : 1.0593, accuracy : 56.66\n",
            "iteration : 350, loss : 1.0610, accuracy : 56.54\n",
            "Epoch :  98, training loss : 1.0615, training accuracy : 56.46, test loss : 1.1025, test accuracy : 55.63\n",
            "\n",
            "Epoch: 99\n",
            "iteration :  50, loss : 1.0758, accuracy : 55.92\n",
            "iteration : 100, loss : 1.0548, accuracy : 56.67\n",
            "iteration : 150, loss : 1.0660, accuracy : 56.27\n",
            "iteration : 200, loss : 1.0672, accuracy : 56.27\n",
            "iteration : 250, loss : 1.0657, accuracy : 56.46\n",
            "iteration : 300, loss : 1.0663, accuracy : 56.52\n",
            "iteration : 350, loss : 1.0660, accuracy : 56.53\n",
            "Epoch :  99, training loss : 1.0653, training accuracy : 56.59, test loss : 1.0763, test accuracy : 56.35\n",
            "\n",
            "Epoch: 100\n",
            "iteration :  50, loss : 1.0490, accuracy : 57.48\n",
            "iteration : 100, loss : 1.0550, accuracy : 56.99\n",
            "iteration : 150, loss : 1.0506, accuracy : 57.09\n",
            "iteration : 200, loss : 1.0575, accuracy : 56.76\n",
            "iteration : 250, loss : 1.0543, accuracy : 56.85\n",
            "iteration : 300, loss : 1.0610, accuracy : 56.61\n",
            "iteration : 350, loss : 1.0608, accuracy : 56.68\n",
            "Epoch : 100, training loss : 1.0617, training accuracy : 56.60, test loss : 1.0680, test accuracy : 56.65\n",
            "\n",
            "Epoch: 101\n",
            "iteration :  50, loss : 1.0603, accuracy : 56.28\n",
            "iteration : 100, loss : 1.0735, accuracy : 55.97\n",
            "iteration : 150, loss : 1.0791, accuracy : 56.02\n",
            "iteration : 200, loss : 1.0736, accuracy : 56.14\n",
            "iteration : 250, loss : 1.0722, accuracy : 56.27\n",
            "iteration : 300, loss : 1.0713, accuracy : 56.35\n",
            "iteration : 350, loss : 1.0660, accuracy : 56.46\n",
            "Epoch : 101, training loss : 1.0676, training accuracy : 56.39, test loss : 1.0834, test accuracy : 55.95\n",
            "\n",
            "Epoch: 102\n",
            "iteration :  50, loss : 1.0892, accuracy : 55.81\n",
            "iteration : 100, loss : 1.0718, accuracy : 56.20\n",
            "iteration : 150, loss : 1.0666, accuracy : 56.33\n",
            "iteration : 200, loss : 1.0637, accuracy : 56.27\n",
            "iteration : 250, loss : 1.0635, accuracy : 56.31\n",
            "iteration : 300, loss : 1.0639, accuracy : 56.30\n",
            "iteration : 350, loss : 1.0633, accuracy : 56.29\n",
            "Epoch : 102, training loss : 1.0632, training accuracy : 56.33, test loss : 1.0686, test accuracy : 56.34\n",
            "\n",
            "Epoch: 103\n",
            "iteration :  50, loss : 1.0716, accuracy : 56.31\n",
            "iteration : 100, loss : 1.0592, accuracy : 56.48\n",
            "iteration : 150, loss : 1.0666, accuracy : 56.32\n",
            "iteration : 200, loss : 1.0669, accuracy : 56.24\n",
            "iteration : 250, loss : 1.0671, accuracy : 56.30\n",
            "iteration : 300, loss : 1.0672, accuracy : 56.51\n",
            "iteration : 350, loss : 1.0638, accuracy : 56.65\n",
            "Epoch : 103, training loss : 1.0612, training accuracy : 56.71, test loss : 1.0700, test accuracy : 56.42\n",
            "\n",
            "Epoch: 104\n",
            "iteration :  50, loss : 1.0523, accuracy : 57.64\n",
            "iteration : 100, loss : 1.0553, accuracy : 57.12\n",
            "iteration : 150, loss : 1.0530, accuracy : 57.08\n",
            "iteration : 200, loss : 1.0560, accuracy : 56.79\n",
            "iteration : 250, loss : 1.0565, accuracy : 56.92\n",
            "iteration : 300, loss : 1.0561, accuracy : 56.79\n",
            "iteration : 350, loss : 1.0582, accuracy : 56.85\n",
            "Epoch : 104, training loss : 1.0582, training accuracy : 56.81, test loss : 1.0781, test accuracy : 56.48\n",
            "\n",
            "Epoch: 105\n",
            "iteration :  50, loss : 1.0580, accuracy : 57.14\n",
            "iteration : 100, loss : 1.0579, accuracy : 56.59\n",
            "iteration : 150, loss : 1.0578, accuracy : 57.02\n",
            "iteration : 200, loss : 1.0594, accuracy : 56.80\n",
            "iteration : 250, loss : 1.0560, accuracy : 56.83\n",
            "iteration : 300, loss : 1.0597, accuracy : 56.77\n",
            "iteration : 350, loss : 1.0603, accuracy : 56.65\n",
            "Epoch : 105, training loss : 1.0584, training accuracy : 56.69, test loss : 1.0631, test accuracy : 56.61\n",
            "\n",
            "Epoch: 106\n",
            "iteration :  50, loss : 1.0582, accuracy : 55.95\n",
            "iteration : 100, loss : 1.0521, accuracy : 56.16\n",
            "iteration : 150, loss : 1.0544, accuracy : 56.58\n",
            "iteration : 200, loss : 1.0617, accuracy : 56.30\n",
            "iteration : 250, loss : 1.0639, accuracy : 56.29\n",
            "iteration : 300, loss : 1.0625, accuracy : 56.37\n",
            "iteration : 350, loss : 1.0663, accuracy : 56.35\n",
            "Epoch : 106, training loss : 1.0670, training accuracy : 56.36, test loss : 1.0884, test accuracy : 56.07\n",
            "\n",
            "Epoch: 107\n",
            "iteration :  50, loss : 1.0538, accuracy : 56.69\n",
            "iteration : 100, loss : 1.0537, accuracy : 56.69\n",
            "iteration : 150, loss : 1.0517, accuracy : 56.71\n",
            "iteration : 200, loss : 1.0574, accuracy : 56.59\n",
            "iteration : 250, loss : 1.0522, accuracy : 56.68\n",
            "iteration : 300, loss : 1.0543, accuracy : 56.66\n",
            "iteration : 350, loss : 1.0552, accuracy : 56.76\n",
            "Epoch : 107, training loss : 1.0533, training accuracy : 56.81, test loss : 1.0854, test accuracy : 55.44\n",
            "\n",
            "Epoch: 108\n",
            "iteration :  50, loss : 1.0593, accuracy : 57.23\n",
            "iteration : 100, loss : 1.0465, accuracy : 57.38\n",
            "iteration : 150, loss : 1.0418, accuracy : 57.32\n",
            "iteration : 200, loss : 1.0436, accuracy : 57.47\n",
            "iteration : 250, loss : 1.0498, accuracy : 57.10\n",
            "iteration : 300, loss : 1.0507, accuracy : 57.11\n",
            "iteration : 350, loss : 1.0508, accuracy : 57.08\n",
            "Epoch : 108, training loss : 1.0499, training accuracy : 57.05, test loss : 1.0706, test accuracy : 56.13\n",
            "\n",
            "Epoch: 109\n",
            "iteration :  50, loss : 1.0332, accuracy : 57.70\n",
            "iteration : 100, loss : 1.0435, accuracy : 57.27\n",
            "iteration : 150, loss : 1.0471, accuracy : 56.98\n",
            "iteration : 200, loss : 1.0521, accuracy : 56.80\n",
            "iteration : 250, loss : 1.0526, accuracy : 56.95\n",
            "iteration : 300, loss : 1.0533, accuracy : 56.94\n",
            "iteration : 350, loss : 1.0538, accuracy : 56.94\n",
            "Epoch : 109, training loss : 1.0540, training accuracy : 56.96, test loss : 1.0690, test accuracy : 56.57\n",
            "\n",
            "Epoch: 110\n",
            "iteration :  50, loss : 1.0713, accuracy : 55.81\n",
            "iteration : 100, loss : 1.0673, accuracy : 56.37\n",
            "iteration : 150, loss : 1.0653, accuracy : 56.50\n",
            "iteration : 200, loss : 1.0695, accuracy : 56.45\n",
            "iteration : 250, loss : 1.0703, accuracy : 56.50\n",
            "iteration : 300, loss : 1.0682, accuracy : 56.43\n",
            "iteration : 350, loss : 1.0643, accuracy : 56.60\n",
            "Epoch : 110, training loss : 1.0630, training accuracy : 56.67, test loss : 1.0768, test accuracy : 56.25\n",
            "\n",
            "Epoch: 111\n",
            "iteration :  50, loss : 1.0561, accuracy : 57.11\n",
            "iteration : 100, loss : 1.0528, accuracy : 57.02\n",
            "iteration : 150, loss : 1.0550, accuracy : 56.91\n",
            "iteration : 200, loss : 1.0542, accuracy : 56.92\n",
            "iteration : 250, loss : 1.0598, accuracy : 56.60\n",
            "iteration : 300, loss : 1.0585, accuracy : 56.66\n",
            "iteration : 350, loss : 1.0597, accuracy : 56.59\n",
            "Epoch : 111, training loss : 1.0592, training accuracy : 56.63, test loss : 1.0848, test accuracy : 55.65\n",
            "\n",
            "Epoch: 112\n",
            "iteration :  50, loss : 1.0512, accuracy : 57.22\n",
            "iteration : 100, loss : 1.0590, accuracy : 56.78\n",
            "iteration : 150, loss : 1.0521, accuracy : 57.02\n",
            "iteration : 200, loss : 1.0515, accuracy : 56.80\n",
            "iteration : 250, loss : 1.0503, accuracy : 56.85\n",
            "iteration : 300, loss : 1.0519, accuracy : 56.76\n",
            "iteration : 350, loss : 1.0558, accuracy : 56.62\n",
            "Epoch : 112, training loss : 1.0569, training accuracy : 56.61, test loss : 1.0811, test accuracy : 55.86\n",
            "\n",
            "Epoch: 113\n",
            "iteration :  50, loss : 1.0631, accuracy : 56.94\n",
            "iteration : 100, loss : 1.0524, accuracy : 57.15\n",
            "iteration : 150, loss : 1.0538, accuracy : 56.93\n",
            "iteration : 200, loss : 1.0582, accuracy : 56.91\n",
            "iteration : 250, loss : 1.0603, accuracy : 56.78\n",
            "iteration : 300, loss : 1.0601, accuracy : 56.72\n",
            "iteration : 350, loss : 1.0597, accuracy : 56.75\n",
            "Epoch : 113, training loss : 1.0593, training accuracy : 56.73, test loss : 1.0612, test accuracy : 57.00\n",
            "\n",
            "Epoch: 114\n",
            "iteration :  50, loss : 1.0572, accuracy : 56.28\n",
            "iteration : 100, loss : 1.0560, accuracy : 56.31\n",
            "iteration : 150, loss : 1.0536, accuracy : 56.70\n",
            "iteration : 200, loss : 1.0536, accuracy : 56.85\n",
            "iteration : 250, loss : 1.0559, accuracy : 56.74\n",
            "iteration : 300, loss : 1.0609, accuracy : 56.50\n",
            "iteration : 350, loss : 1.0607, accuracy : 56.46\n",
            "Epoch : 114, training loss : 1.0601, training accuracy : 56.48, test loss : 1.0560, test accuracy : 56.95\n",
            "\n",
            "Epoch: 115\n",
            "iteration :  50, loss : 1.0466, accuracy : 57.09\n",
            "iteration : 100, loss : 1.0510, accuracy : 57.05\n",
            "iteration : 150, loss : 1.0462, accuracy : 57.05\n",
            "iteration : 200, loss : 1.0446, accuracy : 57.00\n",
            "iteration : 250, loss : 1.0476, accuracy : 57.10\n",
            "iteration : 300, loss : 1.0486, accuracy : 57.03\n",
            "iteration : 350, loss : 1.0486, accuracy : 57.08\n",
            "Epoch : 115, training loss : 1.0488, training accuracy : 57.09, test loss : 1.0650, test accuracy : 56.32\n",
            "\n",
            "Epoch: 116\n",
            "iteration :  50, loss : 1.0579, accuracy : 57.14\n",
            "iteration : 100, loss : 1.0621, accuracy : 56.60\n",
            "iteration : 150, loss : 1.0593, accuracy : 56.73\n",
            "iteration : 200, loss : 1.0553, accuracy : 56.80\n",
            "iteration : 250, loss : 1.0528, accuracy : 56.92\n",
            "iteration : 300, loss : 1.0547, accuracy : 56.73\n",
            "iteration : 350, loss : 1.0537, accuracy : 56.70\n",
            "Epoch : 116, training loss : 1.0511, training accuracy : 56.77, test loss : 1.0634, test accuracy : 56.45\n",
            "\n",
            "Epoch: 117\n",
            "iteration :  50, loss : 1.0657, accuracy : 56.61\n",
            "iteration : 100, loss : 1.0689, accuracy : 56.51\n",
            "iteration : 150, loss : 1.0648, accuracy : 56.46\n",
            "iteration : 200, loss : 1.0614, accuracy : 56.36\n",
            "iteration : 250, loss : 1.0616, accuracy : 56.28\n",
            "iteration : 300, loss : 1.0561, accuracy : 56.59\n",
            "iteration : 350, loss : 1.0552, accuracy : 56.73\n",
            "Epoch : 117, training loss : 1.0565, training accuracy : 56.71, test loss : 1.0576, test accuracy : 56.73\n",
            "\n",
            "Epoch: 118\n",
            "iteration :  50, loss : 1.0444, accuracy : 57.94\n",
            "iteration : 100, loss : 1.0433, accuracy : 57.23\n",
            "iteration : 150, loss : 1.0448, accuracy : 57.41\n",
            "iteration : 200, loss : 1.0480, accuracy : 57.18\n",
            "iteration : 250, loss : 1.0482, accuracy : 57.15\n",
            "iteration : 300, loss : 1.0482, accuracy : 57.10\n",
            "iteration : 350, loss : 1.0488, accuracy : 57.06\n",
            "Epoch : 118, training loss : 1.0502, training accuracy : 57.00, test loss : 1.0696, test accuracy : 56.76\n",
            "\n",
            "Epoch: 119\n",
            "iteration :  50, loss : 1.0633, accuracy : 56.92\n",
            "iteration : 100, loss : 1.0525, accuracy : 56.98\n",
            "iteration : 150, loss : 1.0561, accuracy : 56.81\n",
            "iteration : 200, loss : 1.0545, accuracy : 56.83\n",
            "iteration : 250, loss : 1.0556, accuracy : 56.75\n",
            "iteration : 300, loss : 1.0577, accuracy : 56.62\n",
            "iteration : 350, loss : 1.0598, accuracy : 56.57\n",
            "Epoch : 119, training loss : 1.0589, training accuracy : 56.59, test loss : 1.0672, test accuracy : 56.28\n",
            "\n",
            "Epoch: 120\n",
            "iteration :  50, loss : 1.0633, accuracy : 56.19\n",
            "iteration : 100, loss : 1.0579, accuracy : 56.40\n",
            "iteration : 150, loss : 1.0466, accuracy : 56.96\n",
            "iteration : 200, loss : 1.0460, accuracy : 56.83\n",
            "iteration : 250, loss : 1.0445, accuracy : 56.73\n",
            "iteration : 300, loss : 1.0427, accuracy : 56.89\n",
            "iteration : 350, loss : 1.0441, accuracy : 56.89\n",
            "Epoch : 120, training loss : 1.0449, training accuracy : 56.87, test loss : 1.0621, test accuracy : 56.54\n",
            "\n",
            "Epoch: 121\n",
            "iteration :  50, loss : 1.0680, accuracy : 56.73\n",
            "iteration : 100, loss : 1.0589, accuracy : 57.13\n",
            "iteration : 150, loss : 1.0570, accuracy : 57.03\n",
            "iteration : 200, loss : 1.0532, accuracy : 56.99\n",
            "iteration : 250, loss : 1.0508, accuracy : 57.03\n",
            "iteration : 300, loss : 1.0502, accuracy : 57.00\n",
            "iteration : 350, loss : 1.0540, accuracy : 56.89\n",
            "Epoch : 121, training loss : 1.0554, training accuracy : 56.88, test loss : 1.0701, test accuracy : 56.42\n",
            "\n",
            "Epoch: 122\n",
            "iteration :  50, loss : 1.0409, accuracy : 56.77\n",
            "iteration : 100, loss : 1.0381, accuracy : 57.49\n",
            "iteration : 150, loss : 1.0423, accuracy : 57.51\n",
            "iteration : 200, loss : 1.0433, accuracy : 57.27\n",
            "iteration : 250, loss : 1.0456, accuracy : 57.07\n",
            "iteration : 300, loss : 1.0446, accuracy : 57.08\n",
            "iteration : 350, loss : 1.0493, accuracy : 57.01\n",
            "Epoch : 122, training loss : 1.0505, training accuracy : 56.92, test loss : 1.0637, test accuracy : 56.70\n",
            "\n",
            "Epoch: 123\n",
            "iteration :  50, loss : 1.0459, accuracy : 57.25\n",
            "iteration : 100, loss : 1.0526, accuracy : 56.56\n",
            "iteration : 150, loss : 1.0579, accuracy : 56.48\n",
            "iteration : 200, loss : 1.0575, accuracy : 56.51\n",
            "iteration : 250, loss : 1.0553, accuracy : 56.55\n",
            "iteration : 300, loss : 1.0491, accuracy : 56.85\n",
            "iteration : 350, loss : 1.0502, accuracy : 56.80\n",
            "Epoch : 123, training loss : 1.0517, training accuracy : 56.77, test loss : 1.0750, test accuracy : 56.20\n",
            "\n",
            "Epoch: 124\n",
            "iteration :  50, loss : 1.0410, accuracy : 56.59\n",
            "iteration : 100, loss : 1.0510, accuracy : 56.25\n",
            "iteration : 150, loss : 1.0521, accuracy : 56.36\n",
            "iteration : 200, loss : 1.0482, accuracy : 56.65\n",
            "iteration : 250, loss : 1.0491, accuracy : 56.59\n",
            "iteration : 300, loss : 1.0509, accuracy : 56.44\n",
            "iteration : 350, loss : 1.0535, accuracy : 56.42\n",
            "Epoch : 124, training loss : 1.0536, training accuracy : 56.36, test loss : 1.0670, test accuracy : 56.17\n",
            "\n",
            "Epoch: 125\n",
            "iteration :  50, loss : 1.0539, accuracy : 56.42\n",
            "iteration : 100, loss : 1.0487, accuracy : 56.70\n",
            "iteration : 150, loss : 1.0489, accuracy : 56.71\n",
            "iteration : 200, loss : 1.0498, accuracy : 56.59\n",
            "iteration : 250, loss : 1.0492, accuracy : 56.67\n",
            "iteration : 300, loss : 1.0474, accuracy : 56.67\n",
            "iteration : 350, loss : 1.0487, accuracy : 56.71\n",
            "Epoch : 125, training loss : 1.0512, training accuracy : 56.63, test loss : 1.0683, test accuracy : 56.96\n",
            "\n",
            "Epoch: 126\n",
            "iteration :  50, loss : 1.0454, accuracy : 56.56\n",
            "iteration : 100, loss : 1.0314, accuracy : 57.25\n",
            "iteration : 150, loss : 1.0380, accuracy : 57.21\n",
            "iteration : 200, loss : 1.0440, accuracy : 57.09\n",
            "iteration : 250, loss : 1.0440, accuracy : 57.07\n",
            "iteration : 300, loss : 1.0448, accuracy : 57.06\n",
            "iteration : 350, loss : 1.0445, accuracy : 57.05\n",
            "Epoch : 126, training loss : 1.0452, training accuracy : 57.06, test loss : 1.0818, test accuracy : 56.30\n",
            "\n",
            "Epoch: 127\n",
            "iteration :  50, loss : 1.0208, accuracy : 58.05\n",
            "iteration : 100, loss : 1.0379, accuracy : 57.35\n",
            "iteration : 150, loss : 1.0383, accuracy : 57.28\n",
            "iteration : 200, loss : 1.0443, accuracy : 56.98\n",
            "iteration : 250, loss : 1.0416, accuracy : 57.22\n",
            "iteration : 300, loss : 1.0464, accuracy : 56.97\n",
            "iteration : 350, loss : 1.0457, accuracy : 57.02\n",
            "Epoch : 127, training loss : 1.0444, training accuracy : 57.06, test loss : 1.0417, test accuracy : 57.33\n",
            "\n",
            "Epoch: 128\n",
            "iteration :  50, loss : 1.0361, accuracy : 56.98\n",
            "iteration : 100, loss : 1.0427, accuracy : 57.32\n",
            "iteration : 150, loss : 1.0554, accuracy : 56.73\n",
            "iteration : 200, loss : 1.0549, accuracy : 56.74\n",
            "iteration : 250, loss : 1.0541, accuracy : 56.83\n",
            "iteration : 300, loss : 1.0558, accuracy : 56.64\n",
            "iteration : 350, loss : 1.0543, accuracy : 56.67\n",
            "Epoch : 128, training loss : 1.0528, training accuracy : 56.71, test loss : 1.0600, test accuracy : 56.85\n",
            "\n",
            "Epoch: 129\n",
            "iteration :  50, loss : 1.0322, accuracy : 57.02\n",
            "iteration : 100, loss : 1.0360, accuracy : 57.35\n",
            "iteration : 150, loss : 1.0394, accuracy : 57.24\n",
            "iteration : 200, loss : 1.0359, accuracy : 57.39\n",
            "iteration : 250, loss : 1.0366, accuracy : 57.46\n",
            "iteration : 300, loss : 1.0375, accuracy : 57.42\n",
            "iteration : 350, loss : 1.0398, accuracy : 57.24\n",
            "Epoch : 129, training loss : 1.0421, training accuracy : 57.24, test loss : 1.0714, test accuracy : 56.20\n",
            "\n",
            "Epoch: 130\n",
            "iteration :  50, loss : 1.0504, accuracy : 56.69\n",
            "iteration : 100, loss : 1.0440, accuracy : 57.16\n",
            "iteration : 150, loss : 1.0434, accuracy : 57.27\n",
            "iteration : 200, loss : 1.0404, accuracy : 57.23\n",
            "iteration : 250, loss : 1.0397, accuracy : 57.42\n",
            "iteration : 300, loss : 1.0388, accuracy : 57.42\n",
            "iteration : 350, loss : 1.0398, accuracy : 57.35\n",
            "Epoch : 130, training loss : 1.0415, training accuracy : 57.26, test loss : 1.0662, test accuracy : 56.22\n",
            "\n",
            "Epoch: 131\n",
            "iteration :  50, loss : 1.0789, accuracy : 56.17\n",
            "iteration : 100, loss : 1.0427, accuracy : 57.58\n",
            "iteration : 150, loss : 1.0382, accuracy : 57.48\n",
            "iteration : 200, loss : 1.0466, accuracy : 57.21\n",
            "iteration : 250, loss : 1.0436, accuracy : 57.23\n",
            "iteration : 300, loss : 1.0421, accuracy : 57.18\n",
            "iteration : 350, loss : 1.0432, accuracy : 57.08\n",
            "Epoch : 131, training loss : 1.0445, training accuracy : 57.09, test loss : 1.0650, test accuracy : 56.29\n",
            "\n",
            "Epoch: 132\n",
            "iteration :  50, loss : 1.0550, accuracy : 56.95\n",
            "iteration : 100, loss : 1.0412, accuracy : 57.19\n",
            "iteration : 150, loss : 1.0473, accuracy : 56.95\n",
            "iteration : 200, loss : 1.0432, accuracy : 56.91\n",
            "iteration : 250, loss : 1.0449, accuracy : 56.81\n",
            "iteration : 300, loss : 1.0453, accuracy : 56.95\n",
            "iteration : 350, loss : 1.0465, accuracy : 56.87\n",
            "Epoch : 132, training loss : 1.0472, training accuracy : 56.84, test loss : 1.0572, test accuracy : 56.64\n",
            "\n",
            "Epoch: 133\n",
            "iteration :  50, loss : 1.0319, accuracy : 58.06\n",
            "iteration : 100, loss : 1.0336, accuracy : 57.84\n",
            "iteration : 150, loss : 1.0302, accuracy : 57.89\n",
            "iteration : 200, loss : 1.0378, accuracy : 57.52\n",
            "iteration : 250, loss : 1.0376, accuracy : 57.48\n",
            "iteration : 300, loss : 1.0406, accuracy : 57.41\n",
            "iteration : 350, loss : 1.0388, accuracy : 57.52\n",
            "Epoch : 133, training loss : 1.0396, training accuracy : 57.45, test loss : 1.0797, test accuracy : 55.69\n",
            "\n",
            "Epoch: 134\n",
            "iteration :  50, loss : 1.0502, accuracy : 56.12\n",
            "iteration : 100, loss : 1.0567, accuracy : 56.34\n",
            "iteration : 150, loss : 1.0526, accuracy : 56.43\n",
            "iteration : 200, loss : 1.0432, accuracy : 56.82\n",
            "iteration : 250, loss : 1.0398, accuracy : 57.01\n",
            "iteration : 300, loss : 1.0406, accuracy : 56.98\n",
            "iteration : 350, loss : 1.0425, accuracy : 56.89\n",
            "Epoch : 134, training loss : 1.0415, training accuracy : 56.95, test loss : 1.0579, test accuracy : 56.72\n",
            "\n",
            "Epoch: 135\n",
            "iteration :  50, loss : 1.0352, accuracy : 57.12\n",
            "iteration : 100, loss : 1.0447, accuracy : 56.82\n",
            "iteration : 150, loss : 1.0389, accuracy : 57.08\n",
            "iteration : 200, loss : 1.0377, accuracy : 57.09\n",
            "iteration : 250, loss : 1.0404, accuracy : 56.97\n",
            "iteration : 300, loss : 1.0403, accuracy : 56.97\n",
            "iteration : 350, loss : 1.0386, accuracy : 57.07\n",
            "Epoch : 135, training loss : 1.0392, training accuracy : 57.04, test loss : 1.0717, test accuracy : 56.23\n",
            "\n",
            "Epoch: 136\n",
            "iteration :  50, loss : 1.0210, accuracy : 57.55\n",
            "iteration : 100, loss : 1.0395, accuracy : 56.81\n",
            "iteration : 150, loss : 1.0391, accuracy : 56.69\n",
            "iteration : 200, loss : 1.0441, accuracy : 56.79\n",
            "iteration : 250, loss : 1.0432, accuracy : 56.93\n",
            "iteration : 300, loss : 1.0431, accuracy : 56.84\n",
            "iteration : 350, loss : 1.0444, accuracy : 56.85\n",
            "Epoch : 136, training loss : 1.0432, training accuracy : 56.90, test loss : 1.0618, test accuracy : 56.32\n",
            "\n",
            "Epoch: 137\n",
            "iteration :  50, loss : 1.0407, accuracy : 57.19\n",
            "iteration : 100, loss : 1.0472, accuracy : 57.11\n",
            "iteration : 150, loss : 1.0513, accuracy : 56.94\n",
            "iteration : 200, loss : 1.0401, accuracy : 57.26\n",
            "iteration : 250, loss : 1.0389, accuracy : 57.30\n",
            "iteration : 300, loss : 1.0416, accuracy : 57.17\n",
            "iteration : 350, loss : 1.0440, accuracy : 57.06\n",
            "Epoch : 137, training loss : 1.0440, training accuracy : 57.00, test loss : 1.0778, test accuracy : 55.57\n",
            "\n",
            "Epoch: 138\n",
            "iteration :  50, loss : 1.0436, accuracy : 57.03\n",
            "iteration : 100, loss : 1.0443, accuracy : 57.06\n",
            "iteration : 150, loss : 1.0460, accuracy : 56.87\n",
            "iteration : 200, loss : 1.0421, accuracy : 57.01\n",
            "iteration : 250, loss : 1.0425, accuracy : 56.97\n",
            "iteration : 300, loss : 1.0455, accuracy : 56.83\n",
            "iteration : 350, loss : 1.0428, accuracy : 57.00\n",
            "Epoch : 138, training loss : 1.0423, training accuracy : 57.01, test loss : 1.0589, test accuracy : 56.66\n",
            "\n",
            "Epoch: 139\n",
            "iteration :  50, loss : 1.0329, accuracy : 56.67\n",
            "iteration : 100, loss : 1.0381, accuracy : 56.66\n",
            "iteration : 150, loss : 1.0400, accuracy : 56.74\n",
            "iteration : 200, loss : 1.0414, accuracy : 56.66\n",
            "iteration : 250, loss : 1.0418, accuracy : 56.63\n",
            "iteration : 300, loss : 1.0424, accuracy : 56.55\n",
            "iteration : 350, loss : 1.0430, accuracy : 56.66\n",
            "Epoch : 139, training loss : 1.0431, training accuracy : 56.65, test loss : 1.0528, test accuracy : 56.80\n",
            "\n",
            "Epoch: 140\n",
            "iteration :  50, loss : 1.0649, accuracy : 55.52\n",
            "iteration : 100, loss : 1.0519, accuracy : 56.53\n",
            "iteration : 150, loss : 1.0521, accuracy : 56.49\n",
            "iteration : 200, loss : 1.0455, accuracy : 56.87\n",
            "iteration : 250, loss : 1.0407, accuracy : 57.06\n",
            "iteration : 300, loss : 1.0399, accuracy : 57.05\n",
            "iteration : 350, loss : 1.0342, accuracy : 57.27\n",
            "Epoch : 140, training loss : 1.0353, training accuracy : 57.29, test loss : 1.0593, test accuracy : 56.50\n",
            "\n",
            "Epoch: 141\n",
            "iteration :  50, loss : 1.0420, accuracy : 55.86\n",
            "iteration : 100, loss : 1.0390, accuracy : 56.86\n",
            "iteration : 150, loss : 1.0431, accuracy : 56.66\n",
            "iteration : 200, loss : 1.0425, accuracy : 56.78\n",
            "iteration : 250, loss : 1.0476, accuracy : 56.66\n",
            "iteration : 300, loss : 1.0477, accuracy : 56.78\n",
            "iteration : 350, loss : 1.0477, accuracy : 56.73\n",
            "Epoch : 141, training loss : 1.0460, training accuracy : 56.82, test loss : 1.0444, test accuracy : 57.14\n",
            "\n",
            "Epoch: 142\n",
            "iteration :  50, loss : 1.0190, accuracy : 58.19\n",
            "iteration : 100, loss : 1.0305, accuracy : 57.45\n",
            "iteration : 150, loss : 1.0345, accuracy : 57.30\n",
            "iteration : 200, loss : 1.0330, accuracy : 57.16\n",
            "iteration : 250, loss : 1.0314, accuracy : 57.12\n",
            "iteration : 300, loss : 1.0342, accuracy : 57.04\n",
            "iteration : 350, loss : 1.0356, accuracy : 56.98\n",
            "Epoch : 142, training loss : 1.0363, training accuracy : 56.97, test loss : 1.0536, test accuracy : 56.83\n",
            "\n",
            "Epoch: 143\n",
            "iteration :  50, loss : 1.0034, accuracy : 58.83\n",
            "iteration : 100, loss : 1.0268, accuracy : 57.55\n",
            "iteration : 150, loss : 1.0328, accuracy : 57.23\n",
            "iteration : 200, loss : 1.0405, accuracy : 56.98\n",
            "iteration : 250, loss : 1.0441, accuracy : 56.78\n",
            "iteration : 300, loss : 1.0394, accuracy : 57.03\n",
            "iteration : 350, loss : 1.0395, accuracy : 56.97\n",
            "Epoch : 143, training loss : 1.0380, training accuracy : 57.01, test loss : 1.0512, test accuracy : 57.01\n",
            "\n",
            "Epoch: 144\n",
            "iteration :  50, loss : 1.0156, accuracy : 58.02\n",
            "iteration : 100, loss : 1.0240, accuracy : 57.60\n",
            "iteration : 150, loss : 1.0317, accuracy : 57.47\n",
            "iteration : 200, loss : 1.0294, accuracy : 57.50\n",
            "iteration : 250, loss : 1.0369, accuracy : 57.10\n",
            "iteration : 300, loss : 1.0375, accuracy : 57.02\n",
            "iteration : 350, loss : 1.0368, accuracy : 57.06\n",
            "Epoch : 144, training loss : 1.0386, training accuracy : 56.99, test loss : 1.0718, test accuracy : 56.06\n",
            "\n",
            "Epoch: 145\n",
            "iteration :  50, loss : 1.0337, accuracy : 57.62\n",
            "iteration : 100, loss : 1.0330, accuracy : 57.28\n",
            "iteration : 150, loss : 1.0379, accuracy : 57.18\n",
            "iteration : 200, loss : 1.0356, accuracy : 57.23\n",
            "iteration : 250, loss : 1.0349, accuracy : 57.21\n",
            "iteration : 300, loss : 1.0373, accuracy : 57.10\n",
            "iteration : 350, loss : 1.0345, accuracy : 57.23\n",
            "Epoch : 145, training loss : 1.0345, training accuracy : 57.18, test loss : 1.0503, test accuracy : 56.67\n",
            "\n",
            "Epoch: 146\n",
            "iteration :  50, loss : 1.0362, accuracy : 57.14\n",
            "iteration : 100, loss : 1.0326, accuracy : 57.23\n",
            "iteration : 150, loss : 1.0395, accuracy : 56.97\n",
            "iteration : 200, loss : 1.0403, accuracy : 57.02\n",
            "iteration : 250, loss : 1.0399, accuracy : 56.95\n",
            "iteration : 300, loss : 1.0417, accuracy : 56.92\n",
            "iteration : 350, loss : 1.0433, accuracy : 56.83\n",
            "Epoch : 146, training loss : 1.0419, training accuracy : 56.85, test loss : 1.0445, test accuracy : 57.17\n",
            "\n",
            "Epoch: 147\n",
            "iteration :  50, loss : 1.0165, accuracy : 57.38\n",
            "iteration : 100, loss : 1.0254, accuracy : 57.59\n",
            "iteration : 150, loss : 1.0343, accuracy : 57.30\n",
            "iteration : 200, loss : 1.0372, accuracy : 57.34\n",
            "iteration : 250, loss : 1.0340, accuracy : 57.34\n",
            "iteration : 300, loss : 1.0361, accuracy : 57.27\n",
            "iteration : 350, loss : 1.0344, accuracy : 57.34\n",
            "Epoch : 147, training loss : 1.0342, training accuracy : 57.31, test loss : 1.0544, test accuracy : 56.68\n",
            "\n",
            "Epoch: 148\n",
            "iteration :  50, loss : 1.0504, accuracy : 56.89\n",
            "iteration : 100, loss : 1.0412, accuracy : 57.10\n",
            "iteration : 150, loss : 1.0379, accuracy : 57.06\n",
            "iteration : 200, loss : 1.0347, accuracy : 57.27\n",
            "iteration : 250, loss : 1.0339, accuracy : 57.25\n",
            "iteration : 300, loss : 1.0351, accuracy : 57.28\n",
            "iteration : 350, loss : 1.0331, accuracy : 57.33\n",
            "Epoch : 148, training loss : 1.0338, training accuracy : 57.30, test loss : 1.0401, test accuracy : 57.44\n",
            "\n",
            "Epoch: 149\n",
            "iteration :  50, loss : 1.0157, accuracy : 57.48\n",
            "iteration : 100, loss : 1.0249, accuracy : 57.17\n",
            "iteration : 150, loss : 1.0220, accuracy : 57.31\n",
            "iteration : 200, loss : 1.0214, accuracy : 57.41\n",
            "iteration : 250, loss : 1.0244, accuracy : 57.36\n",
            "iteration : 300, loss : 1.0274, accuracy : 57.25\n",
            "iteration : 350, loss : 1.0245, accuracy : 57.37\n",
            "Epoch : 149, training loss : 1.0263, training accuracy : 57.31, test loss : 1.0644, test accuracy : 56.04\n",
            "\n",
            "Epoch: 150\n",
            "iteration :  50, loss : 1.0336, accuracy : 57.25\n",
            "iteration : 100, loss : 1.0321, accuracy : 57.36\n",
            "iteration : 150, loss : 1.0314, accuracy : 57.21\n",
            "iteration : 200, loss : 1.0322, accuracy : 57.24\n",
            "iteration : 250, loss : 1.0314, accuracy : 57.24\n",
            "iteration : 300, loss : 1.0337, accuracy : 57.18\n",
            "iteration : 350, loss : 1.0346, accuracy : 57.17\n",
            "Epoch : 150, training loss : 1.0348, training accuracy : 57.19, test loss : 1.0525, test accuracy : 56.76\n",
            "\n",
            "Epoch: 151\n",
            "iteration :  50, loss : 1.0317, accuracy : 56.61\n",
            "iteration : 100, loss : 1.0212, accuracy : 57.13\n",
            "iteration : 150, loss : 1.0313, accuracy : 56.96\n",
            "iteration : 200, loss : 1.0323, accuracy : 57.24\n",
            "iteration : 250, loss : 1.0357, accuracy : 57.12\n",
            "iteration : 300, loss : 1.0342, accuracy : 57.10\n",
            "iteration : 350, loss : 1.0350, accuracy : 57.08\n",
            "Epoch : 151, training loss : 1.0326, training accuracy : 57.17, test loss : 1.0492, test accuracy : 57.13\n",
            "\n",
            "Epoch: 152\n",
            "iteration :  50, loss : 1.0582, accuracy : 56.20\n",
            "iteration : 100, loss : 1.0336, accuracy : 57.09\n",
            "iteration : 150, loss : 1.0399, accuracy : 57.08\n",
            "iteration : 200, loss : 1.0372, accuracy : 57.01\n",
            "iteration : 250, loss : 1.0339, accuracy : 57.18\n",
            "iteration : 300, loss : 1.0332, accuracy : 57.05\n",
            "iteration : 350, loss : 1.0353, accuracy : 56.96\n",
            "Epoch : 152, training loss : 1.0359, training accuracy : 56.99, test loss : 1.0453, test accuracy : 56.90\n",
            "\n",
            "Epoch: 153\n",
            "iteration :  50, loss : 1.0242, accuracy : 57.56\n",
            "iteration : 100, loss : 1.0210, accuracy : 57.92\n",
            "iteration : 150, loss : 1.0187, accuracy : 57.78\n",
            "iteration : 200, loss : 1.0219, accuracy : 57.65\n",
            "iteration : 250, loss : 1.0241, accuracy : 57.52\n",
            "iteration : 300, loss : 1.0274, accuracy : 57.49\n",
            "iteration : 350, loss : 1.0278, accuracy : 57.54\n",
            "Epoch : 153, training loss : 1.0276, training accuracy : 57.52, test loss : 1.0562, test accuracy : 56.48\n",
            "\n",
            "Epoch: 154\n",
            "iteration :  50, loss : 1.0168, accuracy : 57.78\n",
            "iteration : 100, loss : 1.0225, accuracy : 57.33\n",
            "iteration : 150, loss : 1.0345, accuracy : 56.95\n",
            "iteration : 200, loss : 1.0392, accuracy : 57.05\n",
            "iteration : 250, loss : 1.0343, accuracy : 57.08\n",
            "iteration : 300, loss : 1.0358, accuracy : 57.12\n",
            "iteration : 350, loss : 1.0335, accuracy : 57.22\n",
            "Epoch : 154, training loss : 1.0339, training accuracy : 57.19, test loss : 1.0448, test accuracy : 56.61\n",
            "\n",
            "Epoch: 155\n",
            "iteration :  50, loss : 1.0296, accuracy : 56.89\n",
            "iteration : 100, loss : 1.0447, accuracy : 56.33\n",
            "iteration : 150, loss : 1.0386, accuracy : 56.76\n",
            "iteration : 200, loss : 1.0315, accuracy : 57.18\n",
            "iteration : 250, loss : 1.0322, accuracy : 57.11\n",
            "iteration : 300, loss : 1.0300, accuracy : 57.11\n",
            "iteration : 350, loss : 1.0304, accuracy : 57.17\n",
            "Epoch : 155, training loss : 1.0280, training accuracy : 57.30, test loss : 1.0538, test accuracy : 56.65\n",
            "\n",
            "Epoch: 156\n",
            "iteration :  50, loss : 1.0199, accuracy : 57.84\n",
            "iteration : 100, loss : 1.0329, accuracy : 57.47\n",
            "iteration : 150, loss : 1.0326, accuracy : 57.26\n",
            "iteration : 200, loss : 1.0321, accuracy : 57.22\n",
            "iteration : 250, loss : 1.0308, accuracy : 57.36\n",
            "iteration : 300, loss : 1.0284, accuracy : 57.47\n",
            "iteration : 350, loss : 1.0275, accuracy : 57.46\n",
            "Epoch : 156, training loss : 1.0286, training accuracy : 57.43, test loss : 1.0566, test accuracy : 56.32\n",
            "\n",
            "Epoch: 157\n",
            "iteration :  50, loss : 1.0273, accuracy : 57.78\n",
            "iteration : 100, loss : 1.0295, accuracy : 57.24\n",
            "iteration : 150, loss : 1.0285, accuracy : 57.61\n",
            "iteration : 200, loss : 1.0325, accuracy : 57.43\n",
            "iteration : 250, loss : 1.0288, accuracy : 57.54\n",
            "iteration : 300, loss : 1.0275, accuracy : 57.55\n",
            "iteration : 350, loss : 1.0283, accuracy : 57.50\n",
            "Epoch : 157, training loss : 1.0272, training accuracy : 57.55, test loss : 1.0591, test accuracy : 56.41\n",
            "\n",
            "Epoch: 158\n",
            "iteration :  50, loss : 1.0324, accuracy : 57.25\n",
            "iteration : 100, loss : 1.0227, accuracy : 57.45\n",
            "iteration : 150, loss : 1.0277, accuracy : 57.40\n",
            "iteration : 200, loss : 1.0274, accuracy : 57.44\n",
            "iteration : 250, loss : 1.0302, accuracy : 57.27\n",
            "iteration : 300, loss : 1.0298, accuracy : 57.23\n",
            "iteration : 350, loss : 1.0271, accuracy : 57.31\n",
            "Epoch : 158, training loss : 1.0280, training accuracy : 57.26, test loss : 1.0559, test accuracy : 56.58\n",
            "\n",
            "Epoch: 159\n",
            "iteration :  50, loss : 1.0361, accuracy : 57.02\n",
            "iteration : 100, loss : 1.0318, accuracy : 56.98\n",
            "iteration : 150, loss : 1.0313, accuracy : 57.10\n",
            "iteration : 200, loss : 1.0340, accuracy : 57.08\n",
            "iteration : 250, loss : 1.0306, accuracy : 57.09\n",
            "iteration : 300, loss : 1.0301, accuracy : 57.22\n",
            "iteration : 350, loss : 1.0302, accuracy : 57.16\n",
            "Epoch : 159, training loss : 1.0284, training accuracy : 57.26, test loss : 1.0333, test accuracy : 57.38\n",
            "\n",
            "Epoch: 160\n",
            "iteration :  50, loss : 1.0143, accuracy : 58.67\n",
            "iteration : 100, loss : 1.0145, accuracy : 58.07\n",
            "iteration : 150, loss : 1.0132, accuracy : 58.07\n",
            "iteration : 200, loss : 1.0090, accuracy : 58.16\n",
            "iteration : 250, loss : 1.0162, accuracy : 57.73\n",
            "iteration : 300, loss : 1.0189, accuracy : 57.74\n",
            "iteration : 350, loss : 1.0185, accuracy : 57.77\n",
            "Epoch : 160, training loss : 1.0167, training accuracy : 57.83, test loss : 1.0375, test accuracy : 57.05\n",
            "\n",
            "Epoch: 161\n",
            "iteration :  50, loss : 1.0085, accuracy : 57.58\n",
            "iteration : 100, loss : 1.0112, accuracy : 57.63\n",
            "iteration : 150, loss : 1.0221, accuracy : 57.34\n",
            "iteration : 200, loss : 1.0267, accuracy : 57.32\n",
            "iteration : 250, loss : 1.0270, accuracy : 57.25\n",
            "iteration : 300, loss : 1.0304, accuracy : 57.08\n",
            "iteration : 350, loss : 1.0279, accuracy : 57.18\n",
            "Epoch : 161, training loss : 1.0282, training accuracy : 57.22, test loss : 1.0367, test accuracy : 57.19\n",
            "\n",
            "Epoch: 162\n",
            "iteration :  50, loss : 1.0359, accuracy : 56.72\n",
            "iteration : 100, loss : 1.0291, accuracy : 57.16\n",
            "iteration : 150, loss : 1.0323, accuracy : 57.31\n",
            "iteration : 200, loss : 1.0352, accuracy : 57.50\n",
            "iteration : 250, loss : 1.0340, accuracy : 57.53\n",
            "iteration : 300, loss : 1.0354, accuracy : 57.53\n",
            "iteration : 350, loss : 1.0322, accuracy : 57.54\n",
            "Epoch : 162, training loss : 1.0328, training accuracy : 57.48, test loss : 1.0470, test accuracy : 56.85\n",
            "\n",
            "Epoch: 163\n",
            "iteration :  50, loss : 1.0263, accuracy : 57.66\n",
            "iteration : 100, loss : 1.0187, accuracy : 57.56\n",
            "iteration : 150, loss : 1.0190, accuracy : 57.68\n",
            "iteration : 200, loss : 1.0195, accuracy : 57.67\n",
            "iteration : 250, loss : 1.0190, accuracy : 57.83\n",
            "iteration : 300, loss : 1.0208, accuracy : 57.73\n",
            "iteration : 350, loss : 1.0251, accuracy : 57.55\n",
            "Epoch : 163, training loss : 1.0253, training accuracy : 57.53, test loss : 1.0502, test accuracy : 56.61\n",
            "\n",
            "Epoch: 164\n",
            "iteration :  50, loss : 1.0316, accuracy : 57.34\n",
            "iteration : 100, loss : 1.0241, accuracy : 57.80\n",
            "iteration : 150, loss : 1.0233, accuracy : 57.63\n",
            "iteration : 200, loss : 1.0214, accuracy : 57.68\n",
            "iteration : 250, loss : 1.0224, accuracy : 57.58\n",
            "iteration : 300, loss : 1.0227, accuracy : 57.57\n",
            "iteration : 350, loss : 1.0234, accuracy : 57.63\n",
            "Epoch : 164, training loss : 1.0240, training accuracy : 57.66, test loss : 1.0362, test accuracy : 57.32\n",
            "\n",
            "Epoch: 165\n",
            "iteration :  50, loss : 0.9957, accuracy : 59.12\n",
            "iteration : 100, loss : 1.0023, accuracy : 58.66\n",
            "iteration : 150, loss : 1.0155, accuracy : 58.04\n",
            "iteration : 200, loss : 1.0198, accuracy : 57.91\n",
            "iteration : 250, loss : 1.0203, accuracy : 57.82\n",
            "iteration : 300, loss : 1.0225, accuracy : 57.70\n",
            "iteration : 350, loss : 1.0244, accuracy : 57.72\n",
            "Epoch : 165, training loss : 1.0244, training accuracy : 57.71, test loss : 1.0670, test accuracy : 56.58\n",
            "\n",
            "Epoch: 166\n",
            "iteration :  50, loss : 1.0026, accuracy : 58.08\n",
            "iteration : 100, loss : 1.0237, accuracy : 57.41\n",
            "iteration : 150, loss : 1.0217, accuracy : 57.57\n",
            "iteration : 200, loss : 1.0188, accuracy : 57.66\n",
            "iteration : 250, loss : 1.0194, accuracy : 57.59\n",
            "iteration : 300, loss : 1.0175, accuracy : 57.76\n",
            "iteration : 350, loss : 1.0165, accuracy : 57.76\n",
            "Epoch : 166, training loss : 1.0157, training accuracy : 57.80, test loss : 1.0487, test accuracy : 56.99\n",
            "\n",
            "Epoch: 167\n",
            "iteration :  50, loss : 1.0206, accuracy : 57.38\n",
            "iteration : 100, loss : 1.0217, accuracy : 57.19\n",
            "iteration : 150, loss : 1.0159, accuracy : 57.31\n",
            "iteration : 200, loss : 1.0143, accuracy : 57.54\n",
            "iteration : 250, loss : 1.0166, accuracy : 57.48\n",
            "iteration : 300, loss : 1.0201, accuracy : 57.40\n",
            "iteration : 350, loss : 1.0171, accuracy : 57.58\n",
            "Epoch : 167, training loss : 1.0168, training accuracy : 57.62, test loss : 1.0453, test accuracy : 56.71\n",
            "\n",
            "Epoch: 168\n",
            "iteration :  50, loss : 1.0287, accuracy : 57.19\n",
            "iteration : 100, loss : 1.0277, accuracy : 57.23\n",
            "iteration : 150, loss : 1.0292, accuracy : 57.30\n",
            "iteration : 200, loss : 1.0266, accuracy : 57.29\n",
            "iteration : 250, loss : 1.0284, accuracy : 57.17\n",
            "iteration : 300, loss : 1.0301, accuracy : 57.10\n",
            "iteration : 350, loss : 1.0298, accuracy : 57.13\n",
            "Epoch : 168, training loss : 1.0281, training accuracy : 57.23, test loss : 1.0442, test accuracy : 56.41\n",
            "\n",
            "Epoch: 169\n",
            "iteration :  50, loss : 0.9967, accuracy : 58.89\n",
            "iteration : 100, loss : 1.0042, accuracy : 58.64\n",
            "iteration : 150, loss : 1.0094, accuracy : 58.24\n",
            "iteration : 200, loss : 1.0148, accuracy : 57.86\n",
            "iteration : 250, loss : 1.0110, accuracy : 57.90\n",
            "iteration : 300, loss : 1.0149, accuracy : 57.79\n",
            "iteration : 350, loss : 1.0165, accuracy : 57.69\n",
            "Epoch : 169, training loss : 1.0181, training accuracy : 57.64, test loss : 1.0317, test accuracy : 57.51\n",
            "\n",
            "Epoch: 170\n",
            "iteration :  50, loss : 0.9992, accuracy : 58.45\n",
            "iteration : 100, loss : 1.0153, accuracy : 57.90\n",
            "iteration : 150, loss : 1.0139, accuracy : 57.78\n",
            "iteration : 200, loss : 1.0139, accuracy : 57.97\n",
            "iteration : 250, loss : 1.0166, accuracy : 57.81\n",
            "iteration : 300, loss : 1.0153, accuracy : 57.82\n",
            "iteration : 350, loss : 1.0148, accuracy : 57.83\n",
            "Epoch : 170, training loss : 1.0142, training accuracy : 57.85, test loss : 1.0379, test accuracy : 57.24\n",
            "\n",
            "Epoch: 171\n",
            "iteration :  50, loss : 1.0332, accuracy : 56.11\n",
            "iteration : 100, loss : 1.0263, accuracy : 57.18\n",
            "iteration : 150, loss : 1.0206, accuracy : 57.44\n",
            "iteration : 200, loss : 1.0224, accuracy : 57.46\n",
            "iteration : 250, loss : 1.0204, accuracy : 57.58\n",
            "iteration : 300, loss : 1.0200, accuracy : 57.59\n",
            "iteration : 350, loss : 1.0190, accuracy : 57.60\n",
            "Epoch : 171, training loss : 1.0197, training accuracy : 57.59, test loss : 1.0531, test accuracy : 56.33\n",
            "\n",
            "Epoch: 172\n",
            "iteration :  50, loss : 1.0036, accuracy : 57.92\n",
            "iteration : 100, loss : 1.0271, accuracy : 57.19\n",
            "iteration : 150, loss : 1.0146, accuracy : 57.67\n",
            "iteration : 200, loss : 1.0133, accuracy : 57.80\n",
            "iteration : 250, loss : 1.0157, accuracy : 57.72\n",
            "iteration : 300, loss : 1.0176, accuracy : 57.61\n",
            "iteration : 350, loss : 1.0191, accuracy : 57.60\n",
            "Epoch : 172, training loss : 1.0189, training accuracy : 57.58, test loss : 1.0378, test accuracy : 57.33\n",
            "\n",
            "Epoch: 173\n",
            "iteration :  50, loss : 0.9976, accuracy : 58.73\n",
            "iteration : 100, loss : 1.0044, accuracy : 57.95\n",
            "iteration : 150, loss : 1.0192, accuracy : 57.44\n",
            "iteration : 200, loss : 1.0158, accuracy : 57.62\n",
            "iteration : 250, loss : 1.0181, accuracy : 57.52\n",
            "iteration : 300, loss : 1.0183, accuracy : 57.61\n",
            "iteration : 350, loss : 1.0201, accuracy : 57.52\n",
            "Epoch : 173, training loss : 1.0192, training accuracy : 57.55, test loss : 1.0435, test accuracy : 57.50\n",
            "\n",
            "Epoch: 174\n",
            "iteration :  50, loss : 1.0085, accuracy : 58.36\n",
            "iteration : 100, loss : 1.0172, accuracy : 57.93\n",
            "iteration : 150, loss : 1.0102, accuracy : 57.97\n",
            "iteration : 200, loss : 1.0125, accuracy : 57.75\n",
            "iteration : 250, loss : 1.0116, accuracy : 57.62\n",
            "iteration : 300, loss : 1.0136, accuracy : 57.70\n",
            "iteration : 350, loss : 1.0123, accuracy : 57.73\n",
            "Epoch : 174, training loss : 1.0125, training accuracy : 57.71, test loss : 1.0363, test accuracy : 56.95\n",
            "\n",
            "Epoch: 175\n",
            "iteration :  50, loss : 0.9822, accuracy : 58.92\n",
            "iteration : 100, loss : 0.9896, accuracy : 58.09\n",
            "iteration : 150, loss : 0.9980, accuracy : 58.10\n",
            "iteration : 200, loss : 1.0036, accuracy : 57.92\n",
            "iteration : 250, loss : 1.0028, accuracy : 58.10\n",
            "iteration : 300, loss : 1.0038, accuracy : 58.02\n",
            "iteration : 350, loss : 1.0063, accuracy : 57.91\n",
            "Epoch : 175, training loss : 1.0061, training accuracy : 57.95, test loss : 1.0321, test accuracy : 57.44\n",
            "\n",
            "Epoch: 176\n",
            "iteration :  50, loss : 1.0154, accuracy : 58.05\n",
            "iteration : 100, loss : 1.0307, accuracy : 57.45\n",
            "iteration : 150, loss : 1.0246, accuracy : 57.58\n",
            "iteration : 200, loss : 1.0269, accuracy : 57.55\n",
            "iteration : 250, loss : 1.0193, accuracy : 57.80\n",
            "iteration : 300, loss : 1.0136, accuracy : 57.98\n",
            "iteration : 350, loss : 1.0137, accuracy : 58.04\n",
            "Epoch : 176, training loss : 1.0133, training accuracy : 58.01, test loss : 1.0365, test accuracy : 57.31\n",
            "\n",
            "Epoch: 177\n",
            "iteration :  50, loss : 1.0201, accuracy : 57.53\n",
            "iteration : 100, loss : 1.0179, accuracy : 57.17\n",
            "iteration : 150, loss : 1.0175, accuracy : 57.32\n",
            "iteration : 200, loss : 1.0209, accuracy : 57.25\n",
            "iteration : 250, loss : 1.0193, accuracy : 57.31\n",
            "iteration : 300, loss : 1.0188, accuracy : 57.36\n",
            "iteration : 350, loss : 1.0172, accuracy : 57.50\n",
            "Epoch : 177, training loss : 1.0165, training accuracy : 57.52, test loss : 1.0201, test accuracy : 57.97\n",
            "\n",
            "Epoch: 178\n",
            "iteration :  50, loss : 1.0116, accuracy : 57.80\n",
            "iteration : 100, loss : 1.0203, accuracy : 57.13\n",
            "iteration : 150, loss : 1.0210, accuracy : 57.23\n",
            "iteration : 200, loss : 1.0165, accuracy : 57.44\n",
            "iteration : 250, loss : 1.0180, accuracy : 57.30\n",
            "iteration : 300, loss : 1.0174, accuracy : 57.38\n",
            "iteration : 350, loss : 1.0151, accuracy : 57.49\n",
            "Epoch : 178, training loss : 1.0153, training accuracy : 57.56, test loss : 1.0416, test accuracy : 56.71\n",
            "\n",
            "Epoch: 179\n",
            "iteration :  50, loss : 0.9933, accuracy : 58.59\n",
            "iteration : 100, loss : 1.0107, accuracy : 57.93\n",
            "iteration : 150, loss : 1.0121, accuracy : 57.94\n",
            "iteration : 200, loss : 1.0100, accuracy : 57.89\n",
            "iteration : 250, loss : 1.0124, accuracy : 57.83\n",
            "iteration : 300, loss : 1.0140, accuracy : 57.72\n",
            "iteration : 350, loss : 1.0151, accuracy : 57.64\n",
            "Epoch : 179, training loss : 1.0133, training accuracy : 57.72, test loss : 1.0387, test accuracy : 57.14\n",
            "\n",
            "Epoch: 180\n",
            "iteration :  50, loss : 1.0339, accuracy : 57.11\n",
            "iteration : 100, loss : 1.0198, accuracy : 57.47\n",
            "iteration : 150, loss : 1.0172, accuracy : 57.54\n",
            "iteration : 200, loss : 1.0130, accuracy : 57.74\n",
            "iteration : 250, loss : 1.0118, accuracy : 57.82\n",
            "iteration : 300, loss : 1.0134, accuracy : 57.68\n",
            "iteration : 350, loss : 1.0161, accuracy : 57.60\n",
            "Epoch : 180, training loss : 1.0162, training accuracy : 57.59, test loss : 1.0305, test accuracy : 57.24\n",
            "\n",
            "Epoch: 181\n",
            "iteration :  50, loss : 1.0248, accuracy : 57.66\n",
            "iteration : 100, loss : 1.0120, accuracy : 57.79\n",
            "iteration : 150, loss : 1.0023, accuracy : 58.29\n",
            "iteration : 200, loss : 1.0053, accuracy : 58.25\n",
            "iteration : 250, loss : 1.0026, accuracy : 58.37\n",
            "iteration : 300, loss : 1.0009, accuracy : 58.47\n",
            "iteration : 350, loss : 1.0037, accuracy : 58.26\n",
            "Epoch : 181, training loss : 1.0063, training accuracy : 58.13, test loss : 1.0416, test accuracy : 56.91\n",
            "\n",
            "Epoch: 182\n",
            "iteration :  50, loss : 1.0092, accuracy : 58.02\n",
            "iteration : 100, loss : 1.0009, accuracy : 58.16\n",
            "iteration : 150, loss : 1.0058, accuracy : 58.04\n",
            "iteration : 200, loss : 1.0060, accuracy : 57.98\n",
            "iteration : 250, loss : 1.0055, accuracy : 58.02\n",
            "iteration : 300, loss : 1.0052, accuracy : 58.04\n",
            "iteration : 350, loss : 1.0026, accuracy : 58.14\n",
            "Epoch : 182, training loss : 1.0026, training accuracy : 58.11, test loss : 1.0248, test accuracy : 57.29\n",
            "\n",
            "Epoch: 183\n",
            "iteration :  50, loss : 1.0185, accuracy : 57.88\n",
            "iteration : 100, loss : 1.0120, accuracy : 58.06\n",
            "iteration : 150, loss : 1.0027, accuracy : 58.23\n",
            "iteration : 200, loss : 1.0079, accuracy : 58.26\n",
            "iteration : 250, loss : 1.0098, accuracy : 58.03\n",
            "iteration : 300, loss : 1.0087, accuracy : 58.08\n",
            "iteration : 350, loss : 1.0097, accuracy : 58.12\n",
            "Epoch : 183, training loss : 1.0090, training accuracy : 58.04, test loss : 1.0315, test accuracy : 57.19\n",
            "\n",
            "Epoch: 184\n",
            "iteration :  50, loss : 1.0020, accuracy : 59.00\n",
            "iteration : 100, loss : 1.0070, accuracy : 58.24\n",
            "iteration : 150, loss : 0.9980, accuracy : 58.38\n",
            "iteration : 200, loss : 1.0035, accuracy : 58.09\n",
            "iteration : 250, loss : 1.0052, accuracy : 58.03\n",
            "iteration : 300, loss : 1.0061, accuracy : 58.06\n",
            "iteration : 350, loss : 1.0057, accuracy : 58.08\n",
            "Epoch : 184, training loss : 1.0062, training accuracy : 57.98, test loss : 1.0360, test accuracy : 57.32\n",
            "\n",
            "Epoch: 185\n",
            "iteration :  50, loss : 1.0168, accuracy : 57.75\n",
            "iteration : 100, loss : 1.0128, accuracy : 57.72\n",
            "iteration : 150, loss : 1.0109, accuracy : 57.72\n",
            "iteration : 200, loss : 1.0061, accuracy : 57.73\n",
            "iteration : 250, loss : 1.0083, accuracy : 57.68\n",
            "iteration : 300, loss : 1.0074, accuracy : 57.66\n",
            "iteration : 350, loss : 1.0094, accuracy : 57.63\n",
            "Epoch : 185, training loss : 1.0094, training accuracy : 57.73, test loss : 1.0307, test accuracy : 57.37\n",
            "\n",
            "Epoch: 186\n",
            "iteration :  50, loss : 0.9997, accuracy : 58.62\n",
            "iteration : 100, loss : 1.0172, accuracy : 57.91\n",
            "iteration : 150, loss : 1.0074, accuracy : 58.22\n",
            "iteration : 200, loss : 1.0045, accuracy : 58.21\n",
            "iteration : 250, loss : 1.0046, accuracy : 58.12\n",
            "iteration : 300, loss : 1.0044, accuracy : 58.07\n",
            "iteration : 350, loss : 1.0073, accuracy : 57.81\n",
            "Epoch : 186, training loss : 1.0069, training accuracy : 57.83, test loss : 1.0238, test accuracy : 57.63\n",
            "\n",
            "Epoch: 187\n",
            "iteration :  50, loss : 0.9877, accuracy : 58.00\n",
            "iteration : 100, loss : 1.0046, accuracy : 57.88\n",
            "iteration : 150, loss : 1.0051, accuracy : 57.82\n",
            "iteration : 200, loss : 1.0079, accuracy : 57.65\n",
            "iteration : 250, loss : 1.0084, accuracy : 57.64\n",
            "iteration : 300, loss : 1.0113, accuracy : 57.61\n",
            "iteration : 350, loss : 1.0108, accuracy : 57.64\n",
            "Epoch : 187, training loss : 1.0114, training accuracy : 57.60, test loss : 1.0265, test accuracy : 57.38\n",
            "\n",
            "Epoch: 188\n",
            "iteration :  50, loss : 1.0133, accuracy : 57.17\n",
            "iteration : 100, loss : 1.0144, accuracy : 57.47\n",
            "iteration : 150, loss : 1.0187, accuracy : 57.17\n",
            "iteration : 200, loss : 1.0121, accuracy : 57.44\n",
            "iteration : 250, loss : 1.0138, accuracy : 57.50\n",
            "iteration : 300, loss : 1.0131, accuracy : 57.60\n",
            "iteration : 350, loss : 1.0124, accuracy : 57.59\n",
            "Epoch : 188, training loss : 1.0143, training accuracy : 57.50, test loss : 1.0306, test accuracy : 57.33\n",
            "\n",
            "Epoch: 189\n",
            "iteration :  50, loss : 1.0100, accuracy : 57.03\n",
            "iteration : 100, loss : 1.0083, accuracy : 57.29\n",
            "iteration : 150, loss : 1.0101, accuracy : 57.14\n",
            "iteration : 200, loss : 1.0105, accuracy : 57.17\n",
            "iteration : 250, loss : 1.0069, accuracy : 57.48\n",
            "iteration : 300, loss : 1.0099, accuracy : 57.58\n",
            "iteration : 350, loss : 1.0116, accuracy : 57.52\n",
            "Epoch : 189, training loss : 1.0131, training accuracy : 57.52, test loss : 1.0347, test accuracy : 56.93\n",
            "\n",
            "Epoch: 190\n",
            "iteration :  50, loss : 0.9727, accuracy : 59.09\n",
            "iteration : 100, loss : 0.9837, accuracy : 58.41\n",
            "iteration : 150, loss : 0.9897, accuracy : 58.23\n",
            "iteration : 200, loss : 0.9963, accuracy : 58.07\n",
            "iteration : 250, loss : 0.9991, accuracy : 57.95\n",
            "iteration : 300, loss : 1.0000, accuracy : 58.03\n",
            "iteration : 350, loss : 1.0015, accuracy : 58.02\n",
            "Epoch : 190, training loss : 0.9990, training accuracy : 58.16, test loss : 1.0293, test accuracy : 57.30\n",
            "\n",
            "Epoch: 191\n",
            "iteration :  50, loss : 0.9883, accuracy : 57.94\n",
            "iteration : 100, loss : 0.9936, accuracy : 58.07\n",
            "iteration : 150, loss : 1.0052, accuracy : 57.59\n",
            "iteration : 200, loss : 1.0020, accuracy : 57.76\n",
            "iteration : 250, loss : 1.0029, accuracy : 57.77\n",
            "iteration : 300, loss : 1.0029, accuracy : 57.86\n",
            "iteration : 350, loss : 1.0025, accuracy : 57.88\n",
            "Epoch : 191, training loss : 1.0039, training accuracy : 57.84, test loss : 1.0313, test accuracy : 57.02\n",
            "\n",
            "Epoch: 192\n",
            "iteration :  50, loss : 1.0071, accuracy : 57.75\n",
            "iteration : 100, loss : 0.9985, accuracy : 58.44\n",
            "iteration : 150, loss : 0.9928, accuracy : 58.33\n",
            "iteration : 200, loss : 0.9968, accuracy : 57.93\n",
            "iteration : 250, loss : 0.9924, accuracy : 58.17\n",
            "iteration : 300, loss : 0.9934, accuracy : 58.15\n",
            "iteration : 350, loss : 0.9951, accuracy : 58.11\n",
            "Epoch : 192, training loss : 0.9953, training accuracy : 58.11, test loss : 1.0293, test accuracy : 57.44\n",
            "\n",
            "Epoch: 193\n",
            "iteration :  50, loss : 1.0037, accuracy : 58.17\n",
            "iteration : 100, loss : 0.9917, accuracy : 58.23\n",
            "iteration : 150, loss : 0.9991, accuracy : 58.15\n",
            "iteration : 200, loss : 1.0002, accuracy : 58.10\n",
            "iteration : 250, loss : 1.0022, accuracy : 57.97\n",
            "iteration : 300, loss : 1.0023, accuracy : 58.00\n",
            "iteration : 350, loss : 1.0020, accuracy : 57.91\n",
            "Epoch : 193, training loss : 1.0010, training accuracy : 57.94, test loss : 1.0334, test accuracy : 57.15\n",
            "\n",
            "Epoch: 194\n",
            "iteration :  50, loss : 0.9969, accuracy : 57.28\n",
            "iteration : 100, loss : 0.9936, accuracy : 57.31\n",
            "iteration : 150, loss : 0.9967, accuracy : 57.69\n",
            "iteration : 200, loss : 1.0001, accuracy : 57.61\n",
            "iteration : 250, loss : 0.9979, accuracy : 57.69\n",
            "iteration : 300, loss : 0.9968, accuracy : 57.78\n",
            "iteration : 350, loss : 0.9987, accuracy : 57.81\n",
            "Epoch : 194, training loss : 0.9991, training accuracy : 57.82, test loss : 1.0316, test accuracy : 57.46\n",
            "\n",
            "Epoch: 195\n",
            "iteration :  50, loss : 1.0131, accuracy : 57.08\n",
            "iteration : 100, loss : 1.0172, accuracy : 57.22\n",
            "iteration : 150, loss : 1.0077, accuracy : 57.62\n",
            "iteration : 200, loss : 1.0072, accuracy : 57.69\n",
            "iteration : 250, loss : 1.0045, accuracy : 57.75\n",
            "iteration : 300, loss : 1.0071, accuracy : 57.71\n",
            "iteration : 350, loss : 1.0027, accuracy : 57.96\n",
            "Epoch : 195, training loss : 1.0022, training accuracy : 57.91, test loss : 1.0270, test accuracy : 57.39\n",
            "\n",
            "Epoch: 196\n",
            "iteration :  50, loss : 1.0100, accuracy : 57.33\n",
            "iteration : 100, loss : 1.0072, accuracy : 57.54\n",
            "iteration : 150, loss : 1.0013, accuracy : 57.90\n",
            "iteration : 200, loss : 0.9994, accuracy : 57.78\n",
            "iteration : 250, loss : 1.0017, accuracy : 57.95\n",
            "iteration : 300, loss : 1.0022, accuracy : 57.87\n",
            "iteration : 350, loss : 0.9987, accuracy : 58.00\n",
            "Epoch : 196, training loss : 0.9992, training accuracy : 58.03, test loss : 1.0262, test accuracy : 57.32\n",
            "\n",
            "Epoch: 197\n",
            "iteration :  50, loss : 1.0060, accuracy : 58.11\n",
            "iteration : 100, loss : 0.9946, accuracy : 58.39\n",
            "iteration : 150, loss : 0.9989, accuracy : 58.11\n",
            "iteration : 200, loss : 0.9928, accuracy : 58.33\n",
            "iteration : 250, loss : 0.9962, accuracy : 58.19\n",
            "iteration : 300, loss : 0.9965, accuracy : 58.11\n",
            "iteration : 350, loss : 0.9969, accuracy : 58.03\n",
            "Epoch : 197, training loss : 0.9970, training accuracy : 57.97, test loss : 1.0312, test accuracy : 57.38\n",
            "\n",
            "Epoch: 198\n",
            "iteration :  50, loss : 1.0125, accuracy : 58.03\n",
            "iteration : 100, loss : 1.0073, accuracy : 58.00\n",
            "iteration : 150, loss : 1.0057, accuracy : 57.95\n",
            "iteration : 200, loss : 0.9959, accuracy : 58.41\n",
            "iteration : 250, loss : 0.9995, accuracy : 58.12\n",
            "iteration : 300, loss : 1.0016, accuracy : 58.07\n",
            "iteration : 350, loss : 0.9999, accuracy : 58.17\n",
            "Epoch : 198, training loss : 1.0011, training accuracy : 58.08, test loss : 1.0282, test accuracy : 57.00\n",
            "\n",
            "Epoch: 199\n",
            "iteration :  50, loss : 1.0082, accuracy : 57.89\n",
            "iteration : 100, loss : 1.0064, accuracy : 57.69\n",
            "iteration : 150, loss : 1.0095, accuracy : 57.68\n",
            "iteration : 200, loss : 1.0072, accuracy : 57.77\n",
            "iteration : 250, loss : 1.0065, accuracy : 57.84\n",
            "iteration : 300, loss : 1.0039, accuracy : 57.91\n",
            "iteration : 350, loss : 1.0020, accuracy : 57.89\n",
            "Epoch : 199, training loss : 1.0011, training accuracy : 57.91, test loss : 1.0192, test accuracy : 57.43\n",
            "\n",
            "Epoch: 200\n",
            "iteration :  50, loss : 0.9865, accuracy : 58.42\n",
            "iteration : 100, loss : 0.9971, accuracy : 57.82\n",
            "iteration : 150, loss : 0.9943, accuracy : 58.04\n",
            "iteration : 200, loss : 0.9979, accuracy : 57.93\n",
            "iteration : 250, loss : 0.9932, accuracy : 58.07\n",
            "iteration : 300, loss : 0.9944, accuracy : 58.04\n",
            "iteration : 350, loss : 0.9951, accuracy : 58.04\n",
            "Epoch : 200, training loss : 0.9956, training accuracy : 58.05, test loss : 1.0326, test accuracy : 56.95\n",
            "\n",
            "Epoch: 201\n",
            "iteration :  50, loss : 0.9888, accuracy : 58.94\n",
            "iteration : 100, loss : 1.0003, accuracy : 58.09\n",
            "iteration : 150, loss : 0.9993, accuracy : 58.19\n",
            "iteration : 200, loss : 0.9954, accuracy : 58.16\n",
            "iteration : 250, loss : 1.0010, accuracy : 57.92\n",
            "iteration : 300, loss : 0.9997, accuracy : 57.96\n",
            "iteration : 350, loss : 0.9986, accuracy : 58.02\n",
            "Epoch : 201, training loss : 0.9977, training accuracy : 58.02, test loss : 1.0266, test accuracy : 57.13\n",
            "\n",
            "Epoch: 202\n",
            "iteration :  50, loss : 0.9958, accuracy : 57.83\n",
            "iteration : 100, loss : 1.0032, accuracy : 57.37\n",
            "iteration : 150, loss : 0.9929, accuracy : 57.99\n",
            "iteration : 200, loss : 0.9953, accuracy : 57.89\n",
            "iteration : 250, loss : 0.9855, accuracy : 58.36\n",
            "iteration : 300, loss : 0.9885, accuracy : 58.24\n",
            "iteration : 350, loss : 0.9911, accuracy : 58.20\n",
            "Epoch : 202, training loss : 0.9920, training accuracy : 58.14, test loss : 1.0266, test accuracy : 57.40\n",
            "\n",
            "Epoch: 203\n",
            "iteration :  50, loss : 0.9765, accuracy : 58.80\n",
            "iteration : 100, loss : 0.9873, accuracy : 58.59\n",
            "iteration : 150, loss : 0.9922, accuracy : 58.41\n",
            "iteration : 200, loss : 0.9971, accuracy : 58.05\n",
            "iteration : 250, loss : 1.0003, accuracy : 58.05\n",
            "iteration : 300, loss : 0.9999, accuracy : 57.96\n",
            "iteration : 350, loss : 0.9937, accuracy : 58.19\n",
            "Epoch : 203, training loss : 0.9937, training accuracy : 58.21, test loss : 1.0255, test accuracy : 57.32\n",
            "\n",
            "Epoch: 204\n",
            "iteration :  50, loss : 1.0007, accuracy : 56.72\n",
            "iteration : 100, loss : 0.9875, accuracy : 57.84\n",
            "iteration : 150, loss : 0.9862, accuracy : 58.12\n",
            "iteration : 200, loss : 0.9916, accuracy : 58.00\n",
            "iteration : 250, loss : 0.9975, accuracy : 57.73\n",
            "iteration : 300, loss : 0.9944, accuracy : 57.92\n",
            "iteration : 350, loss : 0.9928, accuracy : 57.98\n",
            "Epoch : 204, training loss : 0.9931, training accuracy : 57.96, test loss : 1.0193, test accuracy : 57.79\n",
            "\n",
            "Epoch: 205\n",
            "iteration :  50, loss : 0.9871, accuracy : 57.89\n",
            "iteration : 100, loss : 0.9932, accuracy : 57.90\n",
            "iteration : 150, loss : 0.9953, accuracy : 58.02\n",
            "iteration : 200, loss : 0.9930, accuracy : 58.23\n",
            "iteration : 250, loss : 0.9912, accuracy : 58.32\n",
            "iteration : 300, loss : 0.9931, accuracy : 58.10\n",
            "iteration : 350, loss : 0.9943, accuracy : 58.08\n",
            "Epoch : 205, training loss : 0.9952, training accuracy : 58.05, test loss : 1.0266, test accuracy : 57.21\n",
            "\n",
            "Epoch: 206\n",
            "iteration :  50, loss : 1.0196, accuracy : 56.66\n",
            "iteration : 100, loss : 1.0061, accuracy : 57.20\n",
            "iteration : 150, loss : 1.0018, accuracy : 57.26\n",
            "iteration : 200, loss : 0.9987, accuracy : 57.49\n",
            "iteration : 250, loss : 0.9967, accuracy : 57.61\n",
            "iteration : 300, loss : 0.9915, accuracy : 57.95\n",
            "iteration : 350, loss : 0.9946, accuracy : 57.90\n",
            "Epoch : 206, training loss : 0.9932, training accuracy : 57.97, test loss : 1.0331, test accuracy : 56.83\n",
            "\n",
            "Epoch: 207\n",
            "iteration :  50, loss : 0.9733, accuracy : 58.42\n",
            "iteration : 100, loss : 0.9840, accuracy : 58.27\n",
            "iteration : 150, loss : 0.9812, accuracy : 58.40\n",
            "iteration : 200, loss : 0.9795, accuracy : 58.43\n",
            "iteration : 250, loss : 0.9820, accuracy : 58.48\n",
            "iteration : 300, loss : 0.9815, accuracy : 58.51\n",
            "iteration : 350, loss : 0.9846, accuracy : 58.43\n",
            "Epoch : 207, training loss : 0.9841, training accuracy : 58.47, test loss : 1.0300, test accuracy : 57.44\n",
            "\n",
            "Epoch: 208\n",
            "iteration :  50, loss : 0.9994, accuracy : 57.39\n",
            "iteration : 100, loss : 1.0077, accuracy : 57.45\n",
            "iteration : 150, loss : 1.0003, accuracy : 57.69\n",
            "iteration : 200, loss : 0.9996, accuracy : 57.80\n",
            "iteration : 250, loss : 0.9953, accuracy : 58.06\n",
            "iteration : 300, loss : 0.9936, accuracy : 58.11\n",
            "iteration : 350, loss : 0.9925, accuracy : 58.13\n",
            "Epoch : 208, training loss : 0.9912, training accuracy : 58.17, test loss : 1.0329, test accuracy : 56.92\n",
            "\n",
            "Epoch: 209\n",
            "iteration :  50, loss : 0.9638, accuracy : 59.03\n",
            "iteration : 100, loss : 0.9781, accuracy : 58.23\n",
            "iteration : 150, loss : 0.9782, accuracy : 58.57\n",
            "iteration : 200, loss : 0.9790, accuracy : 58.68\n",
            "iteration : 250, loss : 0.9783, accuracy : 58.65\n",
            "iteration : 300, loss : 0.9787, accuracy : 58.56\n",
            "iteration : 350, loss : 0.9791, accuracy : 58.52\n",
            "Epoch : 209, training loss : 0.9783, training accuracy : 58.52, test loss : 1.0143, test accuracy : 57.46\n",
            "\n",
            "Epoch: 210\n",
            "iteration :  50, loss : 0.9882, accuracy : 58.66\n",
            "iteration : 100, loss : 0.9942, accuracy : 58.53\n",
            "iteration : 150, loss : 0.9998, accuracy : 58.23\n",
            "iteration : 200, loss : 1.0003, accuracy : 57.93\n",
            "iteration : 250, loss : 0.9966, accuracy : 57.98\n",
            "iteration : 300, loss : 0.9945, accuracy : 57.99\n",
            "iteration : 350, loss : 0.9950, accuracy : 58.01\n",
            "Epoch : 210, training loss : 0.9944, training accuracy : 58.02, test loss : 1.0359, test accuracy : 56.96\n",
            "\n",
            "Epoch: 211\n",
            "iteration :  50, loss : 1.0051, accuracy : 57.33\n",
            "iteration : 100, loss : 1.0055, accuracy : 57.79\n",
            "iteration : 150, loss : 0.9979, accuracy : 58.31\n",
            "iteration : 200, loss : 0.9853, accuracy : 58.68\n",
            "iteration : 250, loss : 0.9863, accuracy : 58.47\n",
            "iteration : 300, loss : 0.9862, accuracy : 58.38\n",
            "iteration : 350, loss : 0.9865, accuracy : 58.40\n",
            "Epoch : 211, training loss : 0.9869, training accuracy : 58.38, test loss : 1.0153, test accuracy : 57.48\n",
            "\n",
            "Epoch: 212\n",
            "iteration :  50, loss : 0.9710, accuracy : 58.17\n",
            "iteration : 100, loss : 0.9835, accuracy : 57.83\n",
            "iteration : 150, loss : 0.9873, accuracy : 57.65\n",
            "iteration : 200, loss : 0.9926, accuracy : 57.39\n",
            "iteration : 250, loss : 0.9911, accuracy : 57.68\n",
            "iteration : 300, loss : 0.9882, accuracy : 57.89\n",
            "iteration : 350, loss : 0.9898, accuracy : 57.83\n",
            "Epoch : 212, training loss : 0.9873, training accuracy : 57.90, test loss : 1.0162, test accuracy : 57.63\n",
            "\n",
            "Epoch: 213\n",
            "iteration :  50, loss : 0.9813, accuracy : 58.53\n",
            "iteration : 100, loss : 0.9742, accuracy : 58.87\n",
            "iteration : 150, loss : 0.9788, accuracy : 58.71\n",
            "iteration : 200, loss : 0.9835, accuracy : 58.61\n",
            "iteration : 250, loss : 0.9849, accuracy : 58.41\n",
            "iteration : 300, loss : 0.9811, accuracy : 58.61\n",
            "iteration : 350, loss : 0.9810, accuracy : 58.58\n",
            "Epoch : 213, training loss : 0.9813, training accuracy : 58.49, test loss : 1.0231, test accuracy : 57.31\n",
            "\n",
            "Epoch: 214\n",
            "iteration :  50, loss : 0.9897, accuracy : 58.67\n",
            "iteration : 100, loss : 0.9793, accuracy : 58.98\n",
            "iteration : 150, loss : 0.9875, accuracy : 58.53\n",
            "iteration : 200, loss : 0.9858, accuracy : 58.22\n",
            "iteration : 250, loss : 0.9874, accuracy : 58.14\n",
            "iteration : 300, loss : 0.9889, accuracy : 58.20\n",
            "iteration : 350, loss : 0.9884, accuracy : 58.13\n",
            "Epoch : 214, training loss : 0.9884, training accuracy : 58.19, test loss : 1.0195, test accuracy : 57.43\n",
            "\n",
            "Epoch: 215\n",
            "iteration :  50, loss : 0.9874, accuracy : 58.17\n",
            "iteration : 100, loss : 0.9855, accuracy : 58.23\n",
            "iteration : 150, loss : 0.9827, accuracy : 58.27\n",
            "iteration : 200, loss : 0.9845, accuracy : 58.30\n",
            "iteration : 250, loss : 0.9918, accuracy : 57.91\n",
            "iteration : 300, loss : 0.9894, accuracy : 57.92\n",
            "iteration : 350, loss : 0.9880, accuracy : 58.06\n",
            "Epoch : 215, training loss : 0.9876, training accuracy : 58.11, test loss : 1.0171, test accuracy : 57.30\n",
            "\n",
            "Epoch: 216\n",
            "iteration :  50, loss : 0.9852, accuracy : 57.45\n",
            "iteration : 100, loss : 0.9894, accuracy : 57.98\n",
            "iteration : 150, loss : 0.9829, accuracy : 58.35\n",
            "iteration : 200, loss : 0.9845, accuracy : 58.50\n",
            "iteration : 250, loss : 0.9841, accuracy : 58.36\n",
            "iteration : 300, loss : 0.9835, accuracy : 58.40\n",
            "iteration : 350, loss : 0.9846, accuracy : 58.31\n",
            "Epoch : 216, training loss : 0.9866, training accuracy : 58.21, test loss : 1.0134, test accuracy : 57.74\n",
            "\n",
            "Epoch: 217\n",
            "iteration :  50, loss : 0.9605, accuracy : 59.19\n",
            "iteration : 100, loss : 0.9618, accuracy : 59.39\n",
            "iteration : 150, loss : 0.9681, accuracy : 59.06\n",
            "iteration : 200, loss : 0.9702, accuracy : 58.85\n",
            "iteration : 250, loss : 0.9734, accuracy : 58.89\n",
            "iteration : 300, loss : 0.9801, accuracy : 58.61\n",
            "iteration : 350, loss : 0.9801, accuracy : 58.62\n",
            "Epoch : 217, training loss : 0.9805, training accuracy : 58.56, test loss : 1.0169, test accuracy : 57.64\n",
            "\n",
            "Epoch: 218\n",
            "iteration :  50, loss : 0.9780, accuracy : 57.91\n",
            "iteration : 100, loss : 0.9758, accuracy : 58.54\n",
            "iteration : 150, loss : 0.9740, accuracy : 58.52\n",
            "iteration : 200, loss : 0.9738, accuracy : 58.48\n",
            "iteration : 250, loss : 0.9746, accuracy : 58.50\n",
            "iteration : 300, loss : 0.9793, accuracy : 58.44\n",
            "iteration : 350, loss : 0.9824, accuracy : 58.42\n",
            "Epoch : 218, training loss : 0.9823, training accuracy : 58.42, test loss : 1.0123, test accuracy : 57.72\n",
            "\n",
            "Epoch: 219\n",
            "iteration :  50, loss : 0.9829, accuracy : 57.62\n",
            "iteration : 100, loss : 0.9816, accuracy : 57.74\n",
            "iteration : 150, loss : 0.9847, accuracy : 58.02\n",
            "iteration : 200, loss : 0.9824, accuracy : 58.27\n",
            "iteration : 250, loss : 0.9854, accuracy : 58.11\n",
            "iteration : 300, loss : 0.9860, accuracy : 57.97\n",
            "iteration : 350, loss : 0.9840, accuracy : 58.21\n",
            "Epoch : 219, training loss : 0.9848, training accuracy : 58.23, test loss : 1.0089, test accuracy : 57.64\n",
            "\n",
            "Epoch: 220\n",
            "iteration :  50, loss : 0.9705, accuracy : 59.78\n",
            "iteration : 100, loss : 0.9801, accuracy : 59.04\n",
            "iteration : 150, loss : 0.9776, accuracy : 59.12\n",
            "iteration : 200, loss : 0.9800, accuracy : 58.83\n",
            "iteration : 250, loss : 0.9774, accuracy : 58.74\n",
            "iteration : 300, loss : 0.9797, accuracy : 58.61\n",
            "iteration : 350, loss : 0.9789, accuracy : 58.67\n",
            "Epoch : 220, training loss : 0.9798, training accuracy : 58.66, test loss : 1.0165, test accuracy : 57.67\n",
            "\n",
            "Epoch: 221\n",
            "iteration :  50, loss : 0.9675, accuracy : 59.50\n",
            "iteration : 100, loss : 0.9774, accuracy : 58.81\n",
            "iteration : 150, loss : 0.9738, accuracy : 58.68\n",
            "iteration : 200, loss : 0.9698, accuracy : 58.79\n",
            "iteration : 250, loss : 0.9799, accuracy : 58.46\n",
            "iteration : 300, loss : 0.9809, accuracy : 58.48\n",
            "iteration : 350, loss : 0.9808, accuracy : 58.52\n",
            "Epoch : 221, training loss : 0.9801, training accuracy : 58.49, test loss : 1.0186, test accuracy : 57.63\n",
            "\n",
            "Epoch: 222\n",
            "iteration :  50, loss : 0.9815, accuracy : 58.62\n",
            "iteration : 100, loss : 0.9932, accuracy : 57.87\n",
            "iteration : 150, loss : 0.9945, accuracy : 57.99\n",
            "iteration : 200, loss : 0.9917, accuracy : 58.15\n",
            "iteration : 250, loss : 0.9883, accuracy : 58.17\n",
            "iteration : 300, loss : 0.9879, accuracy : 58.24\n",
            "iteration : 350, loss : 0.9895, accuracy : 58.17\n",
            "Epoch : 222, training loss : 0.9883, training accuracy : 58.16, test loss : 1.0158, test accuracy : 57.64\n",
            "\n",
            "Epoch: 223\n",
            "iteration :  50, loss : 0.9734, accuracy : 58.38\n",
            "iteration : 100, loss : 0.9708, accuracy : 58.55\n",
            "iteration : 150, loss : 0.9718, accuracy : 58.59\n",
            "iteration : 200, loss : 0.9741, accuracy : 58.62\n",
            "iteration : 250, loss : 0.9749, accuracy : 58.65\n",
            "iteration : 300, loss : 0.9745, accuracy : 58.61\n",
            "iteration : 350, loss : 0.9758, accuracy : 58.58\n",
            "Epoch : 223, training loss : 0.9745, training accuracy : 58.64, test loss : 1.0230, test accuracy : 57.46\n",
            "\n",
            "Epoch: 224\n",
            "iteration :  50, loss : 0.9826, accuracy : 58.36\n",
            "iteration : 100, loss : 0.9840, accuracy : 58.45\n",
            "iteration : 150, loss : 0.9762, accuracy : 58.77\n",
            "iteration : 200, loss : 0.9749, accuracy : 58.69\n",
            "iteration : 250, loss : 0.9744, accuracy : 58.78\n",
            "iteration : 300, loss : 0.9762, accuracy : 58.68\n",
            "iteration : 350, loss : 0.9770, accuracy : 58.65\n",
            "Epoch : 224, training loss : 0.9759, training accuracy : 58.67, test loss : 1.0123, test accuracy : 57.61\n",
            "\n",
            "Epoch: 225\n",
            "iteration :  50, loss : 0.9956, accuracy : 57.19\n",
            "iteration : 100, loss : 0.9827, accuracy : 58.41\n",
            "iteration : 150, loss : 0.9815, accuracy : 58.22\n",
            "iteration : 200, loss : 0.9775, accuracy : 58.52\n",
            "iteration : 250, loss : 0.9764, accuracy : 58.53\n",
            "iteration : 300, loss : 0.9756, accuracy : 58.56\n",
            "iteration : 350, loss : 0.9744, accuracy : 58.51\n",
            "Epoch : 225, training loss : 0.9759, training accuracy : 58.48, test loss : 1.0161, test accuracy : 57.69\n",
            "\n",
            "Epoch: 226\n",
            "iteration :  50, loss : 0.9665, accuracy : 58.78\n",
            "iteration : 100, loss : 0.9707, accuracy : 58.56\n",
            "iteration : 150, loss : 0.9727, accuracy : 58.58\n",
            "iteration : 200, loss : 0.9676, accuracy : 58.69\n",
            "iteration : 250, loss : 0.9682, accuracy : 58.67\n",
            "iteration : 300, loss : 0.9737, accuracy : 58.67\n",
            "iteration : 350, loss : 0.9732, accuracy : 58.64\n",
            "Epoch : 226, training loss : 0.9744, training accuracy : 58.54, test loss : 1.0134, test accuracy : 57.25\n",
            "\n",
            "Epoch: 227\n",
            "iteration :  50, loss : 0.9824, accuracy : 57.58\n",
            "iteration : 100, loss : 0.9793, accuracy : 58.03\n",
            "iteration : 150, loss : 0.9776, accuracy : 58.23\n",
            "iteration : 200, loss : 0.9698, accuracy : 58.55\n",
            "iteration : 250, loss : 0.9713, accuracy : 58.42\n",
            "iteration : 300, loss : 0.9739, accuracy : 58.41\n",
            "iteration : 350, loss : 0.9746, accuracy : 58.49\n",
            "Epoch : 227, training loss : 0.9746, training accuracy : 58.51, test loss : 1.0110, test accuracy : 57.40\n",
            "\n",
            "Epoch: 228\n",
            "iteration :  50, loss : 0.9812, accuracy : 58.44\n",
            "iteration : 100, loss : 0.9761, accuracy : 58.34\n",
            "iteration : 150, loss : 0.9722, accuracy : 58.63\n",
            "iteration : 200, loss : 0.9751, accuracy : 58.58\n",
            "iteration : 250, loss : 0.9724, accuracy : 58.56\n",
            "iteration : 300, loss : 0.9724, accuracy : 58.43\n",
            "iteration : 350, loss : 0.9732, accuracy : 58.52\n",
            "Epoch : 228, training loss : 0.9734, training accuracy : 58.55, test loss : 1.0045, test accuracy : 57.99\n",
            "\n",
            "Epoch: 229\n",
            "iteration :  50, loss : 0.9865, accuracy : 57.64\n",
            "iteration : 100, loss : 0.9819, accuracy : 57.72\n",
            "iteration : 150, loss : 0.9809, accuracy : 57.65\n",
            "iteration : 200, loss : 0.9779, accuracy : 57.93\n",
            "iteration : 250, loss : 0.9757, accuracy : 58.10\n",
            "iteration : 300, loss : 0.9745, accuracy : 58.18\n",
            "iteration : 350, loss : 0.9748, accuracy : 58.19\n",
            "Epoch : 229, training loss : 0.9743, training accuracy : 58.22, test loss : 1.0162, test accuracy : 57.53\n",
            "\n",
            "Epoch: 230\n",
            "iteration :  50, loss : 0.9807, accuracy : 58.06\n",
            "iteration : 100, loss : 0.9747, accuracy : 58.46\n",
            "iteration : 150, loss : 0.9741, accuracy : 58.29\n",
            "iteration : 200, loss : 0.9767, accuracy : 58.13\n",
            "iteration : 250, loss : 0.9796, accuracy : 58.08\n",
            "iteration : 300, loss : 0.9786, accuracy : 58.19\n",
            "iteration : 350, loss : 0.9750, accuracy : 58.26\n",
            "Epoch : 230, training loss : 0.9751, training accuracy : 58.26, test loss : 1.0112, test accuracy : 57.89\n",
            "\n",
            "Epoch: 231\n",
            "iteration :  50, loss : 0.9544, accuracy : 59.11\n",
            "iteration : 100, loss : 0.9562, accuracy : 59.35\n",
            "iteration : 150, loss : 0.9699, accuracy : 58.57\n",
            "iteration : 200, loss : 0.9675, accuracy : 58.83\n",
            "iteration : 250, loss : 0.9697, accuracy : 58.72\n",
            "iteration : 300, loss : 0.9731, accuracy : 58.58\n",
            "iteration : 350, loss : 0.9693, accuracy : 58.81\n",
            "Epoch : 231, training loss : 0.9707, training accuracy : 58.75, test loss : 1.0098, test accuracy : 57.89\n",
            "\n",
            "Epoch: 232\n",
            "iteration :  50, loss : 0.9550, accuracy : 58.48\n",
            "iteration : 100, loss : 0.9578, accuracy : 58.70\n",
            "iteration : 150, loss : 0.9589, accuracy : 58.62\n",
            "iteration : 200, loss : 0.9633, accuracy : 58.75\n",
            "iteration : 250, loss : 0.9656, accuracy : 58.66\n",
            "iteration : 300, loss : 0.9683, accuracy : 58.55\n",
            "iteration : 350, loss : 0.9688, accuracy : 58.57\n",
            "Epoch : 232, training loss : 0.9699, training accuracy : 58.52, test loss : 1.0131, test accuracy : 57.26\n",
            "\n",
            "Epoch: 233\n",
            "iteration :  50, loss : 0.9800, accuracy : 58.75\n",
            "iteration : 100, loss : 0.9744, accuracy : 58.44\n",
            "iteration : 150, loss : 0.9788, accuracy : 58.30\n",
            "iteration : 200, loss : 0.9724, accuracy : 58.56\n",
            "iteration : 250, loss : 0.9678, accuracy : 58.69\n",
            "iteration : 300, loss : 0.9694, accuracy : 58.59\n",
            "iteration : 350, loss : 0.9676, accuracy : 58.65\n",
            "Epoch : 233, training loss : 0.9677, training accuracy : 58.64, test loss : 1.0069, test accuracy : 57.72\n",
            "\n",
            "Epoch: 234\n",
            "iteration :  50, loss : 0.9689, accuracy : 58.33\n",
            "iteration : 100, loss : 0.9655, accuracy : 59.03\n",
            "iteration : 150, loss : 0.9652, accuracy : 59.11\n",
            "iteration : 200, loss : 0.9602, accuracy : 59.34\n",
            "iteration : 250, loss : 0.9644, accuracy : 59.23\n",
            "iteration : 300, loss : 0.9670, accuracy : 59.08\n",
            "iteration : 350, loss : 0.9653, accuracy : 59.08\n",
            "Epoch : 234, training loss : 0.9655, training accuracy : 59.05, test loss : 1.0013, test accuracy : 58.02\n",
            "\n",
            "Epoch: 235\n",
            "iteration :  50, loss : 0.9605, accuracy : 59.14\n",
            "iteration : 100, loss : 0.9740, accuracy : 58.55\n",
            "iteration : 150, loss : 0.9751, accuracy : 58.53\n",
            "iteration : 200, loss : 0.9664, accuracy : 58.70\n",
            "iteration : 250, loss : 0.9703, accuracy : 58.62\n",
            "iteration : 300, loss : 0.9697, accuracy : 58.69\n",
            "iteration : 350, loss : 0.9666, accuracy : 58.81\n",
            "Epoch : 235, training loss : 0.9678, training accuracy : 58.83, test loss : 1.0148, test accuracy : 57.71\n",
            "\n",
            "Epoch: 236\n",
            "iteration :  50, loss : 0.9573, accuracy : 58.73\n",
            "iteration : 100, loss : 0.9683, accuracy : 58.56\n",
            "iteration : 150, loss : 0.9642, accuracy : 58.81\n",
            "iteration : 200, loss : 0.9632, accuracy : 58.67\n",
            "iteration : 250, loss : 0.9609, accuracy : 58.77\n",
            "iteration : 300, loss : 0.9628, accuracy : 58.70\n",
            "iteration : 350, loss : 0.9644, accuracy : 58.72\n",
            "Epoch : 236, training loss : 0.9647, training accuracy : 58.72, test loss : 1.0092, test accuracy : 57.83\n",
            "\n",
            "Epoch: 237\n",
            "iteration :  50, loss : 0.9723, accuracy : 58.44\n",
            "iteration : 100, loss : 0.9692, accuracy : 58.48\n",
            "iteration : 150, loss : 0.9672, accuracy : 58.86\n",
            "iteration : 200, loss : 0.9677, accuracy : 58.77\n",
            "iteration : 250, loss : 0.9678, accuracy : 58.73\n",
            "iteration : 300, loss : 0.9707, accuracy : 58.75\n",
            "iteration : 350, loss : 0.9702, accuracy : 58.68\n",
            "Epoch : 237, training loss : 0.9683, training accuracy : 58.73, test loss : 1.0221, test accuracy : 57.25\n",
            "\n",
            "Epoch: 238\n",
            "iteration :  50, loss : 0.9766, accuracy : 57.66\n",
            "iteration : 100, loss : 0.9821, accuracy : 57.70\n",
            "iteration : 150, loss : 0.9759, accuracy : 58.14\n",
            "iteration : 200, loss : 0.9692, accuracy : 58.32\n",
            "iteration : 250, loss : 0.9702, accuracy : 58.43\n",
            "iteration : 300, loss : 0.9718, accuracy : 58.40\n",
            "iteration : 350, loss : 0.9710, accuracy : 58.43\n",
            "Epoch : 238, training loss : 0.9719, training accuracy : 58.39, test loss : 1.0056, test accuracy : 58.16\n",
            "\n",
            "Epoch: 239\n",
            "iteration :  50, loss : 0.9527, accuracy : 59.39\n",
            "iteration : 100, loss : 0.9524, accuracy : 59.06\n",
            "iteration : 150, loss : 0.9492, accuracy : 59.17\n",
            "iteration : 200, loss : 0.9540, accuracy : 58.89\n",
            "iteration : 250, loss : 0.9550, accuracy : 58.90\n",
            "iteration : 300, loss : 0.9563, accuracy : 58.88\n",
            "iteration : 350, loss : 0.9563, accuracy : 59.08\n",
            "Epoch : 239, training loss : 0.9585, training accuracy : 59.00, test loss : 1.0202, test accuracy : 57.38\n",
            "\n",
            "Epoch: 240\n",
            "iteration :  50, loss : 0.9693, accuracy : 58.62\n",
            "iteration : 100, loss : 0.9687, accuracy : 58.63\n",
            "iteration : 150, loss : 0.9744, accuracy : 58.53\n",
            "iteration : 200, loss : 0.9709, accuracy : 58.55\n",
            "iteration : 250, loss : 0.9668, accuracy : 58.59\n",
            "iteration : 300, loss : 0.9685, accuracy : 58.60\n",
            "iteration : 350, loss : 0.9685, accuracy : 58.59\n",
            "Epoch : 240, training loss : 0.9675, training accuracy : 58.64, test loss : 1.0140, test accuracy : 57.80\n",
            "\n",
            "Epoch: 241\n",
            "iteration :  50, loss : 0.9620, accuracy : 58.20\n",
            "iteration : 100, loss : 0.9668, accuracy : 58.46\n",
            "iteration : 150, loss : 0.9653, accuracy : 58.75\n",
            "iteration : 200, loss : 0.9581, accuracy : 58.96\n",
            "iteration : 250, loss : 0.9608, accuracy : 58.97\n",
            "iteration : 300, loss : 0.9617, accuracy : 58.91\n",
            "iteration : 350, loss : 0.9615, accuracy : 58.90\n",
            "Epoch : 241, training loss : 0.9613, training accuracy : 58.91, test loss : 1.0104, test accuracy : 57.58\n",
            "\n",
            "Epoch: 242\n",
            "iteration :  50, loss : 0.9532, accuracy : 59.50\n",
            "iteration : 100, loss : 0.9567, accuracy : 59.56\n",
            "iteration : 150, loss : 0.9537, accuracy : 59.33\n",
            "iteration : 200, loss : 0.9529, accuracy : 59.45\n",
            "iteration : 250, loss : 0.9538, accuracy : 59.41\n",
            "iteration : 300, loss : 0.9546, accuracy : 59.36\n",
            "iteration : 350, loss : 0.9564, accuracy : 59.21\n",
            "Epoch : 242, training loss : 0.9551, training accuracy : 59.24, test loss : 1.0219, test accuracy : 56.98\n",
            "\n",
            "Epoch: 243\n",
            "iteration :  50, loss : 0.9631, accuracy : 58.30\n",
            "iteration : 100, loss : 0.9634, accuracy : 58.59\n",
            "iteration : 150, loss : 0.9710, accuracy : 58.38\n",
            "iteration : 200, loss : 0.9641, accuracy : 58.57\n",
            "iteration : 250, loss : 0.9583, accuracy : 58.81\n",
            "iteration : 300, loss : 0.9599, accuracy : 58.73\n",
            "iteration : 350, loss : 0.9607, accuracy : 58.80\n",
            "Epoch : 243, training loss : 0.9609, training accuracy : 58.80, test loss : 0.9993, test accuracy : 58.28\n",
            "\n",
            "Epoch: 244\n",
            "iteration :  50, loss : 0.9569, accuracy : 59.14\n",
            "iteration : 100, loss : 0.9603, accuracy : 58.72\n",
            "iteration : 150, loss : 0.9649, accuracy : 58.64\n",
            "iteration : 200, loss : 0.9680, accuracy : 58.65\n",
            "iteration : 250, loss : 0.9649, accuracy : 58.72\n",
            "iteration : 300, loss : 0.9633, accuracy : 58.67\n",
            "iteration : 350, loss : 0.9627, accuracy : 58.87\n",
            "Epoch : 244, training loss : 0.9634, training accuracy : 58.88, test loss : 1.0109, test accuracy : 57.31\n",
            "\n",
            "Epoch: 245\n",
            "iteration :  50, loss : 0.9679, accuracy : 58.56\n",
            "iteration : 100, loss : 0.9634, accuracy : 58.87\n",
            "iteration : 150, loss : 0.9620, accuracy : 59.00\n",
            "iteration : 200, loss : 0.9616, accuracy : 58.90\n",
            "iteration : 250, loss : 0.9616, accuracy : 58.91\n",
            "iteration : 300, loss : 0.9597, accuracy : 58.99\n",
            "iteration : 350, loss : 0.9598, accuracy : 59.07\n",
            "Epoch : 245, training loss : 0.9593, training accuracy : 59.11, test loss : 1.0068, test accuracy : 57.78\n",
            "\n",
            "Epoch: 246\n",
            "iteration :  50, loss : 0.9762, accuracy : 57.95\n",
            "iteration : 100, loss : 0.9584, accuracy : 58.80\n",
            "iteration : 150, loss : 0.9669, accuracy : 58.61\n",
            "iteration : 200, loss : 0.9632, accuracy : 58.83\n",
            "iteration : 250, loss : 0.9578, accuracy : 59.05\n",
            "iteration : 300, loss : 0.9576, accuracy : 59.13\n",
            "iteration : 350, loss : 0.9549, accuracy : 59.17\n",
            "Epoch : 246, training loss : 0.9548, training accuracy : 59.16, test loss : 1.0149, test accuracy : 57.59\n",
            "\n",
            "Epoch: 247\n",
            "iteration :  50, loss : 0.9679, accuracy : 58.64\n",
            "iteration : 100, loss : 0.9549, accuracy : 58.85\n",
            "iteration : 150, loss : 0.9525, accuracy : 59.26\n",
            "iteration : 200, loss : 0.9495, accuracy : 59.35\n",
            "iteration : 250, loss : 0.9474, accuracy : 59.48\n",
            "iteration : 300, loss : 0.9502, accuracy : 59.35\n",
            "iteration : 350, loss : 0.9508, accuracy : 59.30\n",
            "Epoch : 247, training loss : 0.9505, training accuracy : 59.30, test loss : 1.0148, test accuracy : 57.56\n",
            "\n",
            "Epoch: 248\n",
            "iteration :  50, loss : 0.9852, accuracy : 58.03\n",
            "iteration : 100, loss : 0.9778, accuracy : 58.33\n",
            "iteration : 150, loss : 0.9731, accuracy : 58.53\n",
            "iteration : 200, loss : 0.9648, accuracy : 58.73\n",
            "iteration : 250, loss : 0.9616, accuracy : 58.93\n",
            "iteration : 300, loss : 0.9650, accuracy : 58.76\n",
            "iteration : 350, loss : 0.9651, accuracy : 58.74\n",
            "Epoch : 248, training loss : 0.9660, training accuracy : 58.67, test loss : 1.0152, test accuracy : 57.55\n",
            "\n",
            "Epoch: 249\n",
            "iteration :  50, loss : 0.9641, accuracy : 58.52\n",
            "iteration : 100, loss : 0.9640, accuracy : 58.79\n",
            "iteration : 150, loss : 0.9652, accuracy : 58.53\n",
            "iteration : 200, loss : 0.9595, accuracy : 58.89\n",
            "iteration : 250, loss : 0.9608, accuracy : 58.77\n",
            "iteration : 300, loss : 0.9596, accuracy : 58.76\n",
            "iteration : 350, loss : 0.9577, accuracy : 58.77\n",
            "Epoch : 249, training loss : 0.9591, training accuracy : 58.70, test loss : 1.0071, test accuracy : 58.24\n",
            "\n",
            "Epoch: 250\n",
            "iteration :  50, loss : 0.9690, accuracy : 57.59\n",
            "iteration : 100, loss : 0.9746, accuracy : 57.47\n",
            "iteration : 150, loss : 0.9703, accuracy : 57.86\n",
            "iteration : 200, loss : 0.9655, accuracy : 58.34\n",
            "iteration : 250, loss : 0.9630, accuracy : 58.64\n",
            "iteration : 300, loss : 0.9620, accuracy : 58.74\n",
            "iteration : 350, loss : 0.9613, accuracy : 58.70\n",
            "Epoch : 250, training loss : 0.9611, training accuracy : 58.69, test loss : 1.0104, test accuracy : 57.54\n",
            "\n",
            "Epoch: 251\n",
            "iteration :  50, loss : 0.9353, accuracy : 59.89\n",
            "iteration : 100, loss : 0.9454, accuracy : 59.30\n",
            "iteration : 150, loss : 0.9442, accuracy : 59.30\n",
            "iteration : 200, loss : 0.9525, accuracy : 58.98\n",
            "iteration : 250, loss : 0.9527, accuracy : 59.00\n",
            "iteration : 300, loss : 0.9522, accuracy : 59.08\n",
            "iteration : 350, loss : 0.9551, accuracy : 58.96\n",
            "Epoch : 251, training loss : 0.9559, training accuracy : 58.87, test loss : 1.0065, test accuracy : 57.94\n",
            "\n",
            "Epoch: 252\n",
            "iteration :  50, loss : 0.9352, accuracy : 59.72\n",
            "iteration : 100, loss : 0.9431, accuracy : 59.27\n",
            "iteration : 150, loss : 0.9513, accuracy : 59.09\n",
            "iteration : 200, loss : 0.9546, accuracy : 59.11\n",
            "iteration : 250, loss : 0.9565, accuracy : 59.03\n",
            "iteration : 300, loss : 0.9568, accuracy : 59.01\n",
            "iteration : 350, loss : 0.9548, accuracy : 58.96\n",
            "Epoch : 252, training loss : 0.9597, training accuracy : 58.90, test loss : 1.0153, test accuracy : 57.72\n",
            "\n",
            "Epoch: 253\n",
            "iteration :  50, loss : 0.9482, accuracy : 59.12\n",
            "iteration : 100, loss : 0.9562, accuracy : 58.70\n",
            "iteration : 150, loss : 0.9571, accuracy : 58.74\n",
            "iteration : 200, loss : 0.9579, accuracy : 58.71\n",
            "iteration : 250, loss : 0.9583, accuracy : 58.81\n",
            "iteration : 300, loss : 0.9570, accuracy : 58.90\n",
            "iteration : 350, loss : 0.9548, accuracy : 58.93\n",
            "Epoch : 253, training loss : 0.9540, training accuracy : 58.96, test loss : 1.0001, test accuracy : 58.19\n",
            "\n",
            "Epoch: 254\n",
            "iteration :  50, loss : 0.9442, accuracy : 59.09\n",
            "iteration : 100, loss : 0.9590, accuracy : 58.60\n",
            "iteration : 150, loss : 0.9558, accuracy : 58.72\n",
            "iteration : 200, loss : 0.9571, accuracy : 58.66\n",
            "iteration : 250, loss : 0.9623, accuracy : 58.48\n",
            "iteration : 300, loss : 0.9621, accuracy : 58.62\n",
            "iteration : 350, loss : 0.9604, accuracy : 58.77\n",
            "Epoch : 254, training loss : 0.9624, training accuracy : 58.72, test loss : 1.0139, test accuracy : 57.46\n",
            "\n",
            "Epoch: 255\n",
            "iteration :  50, loss : 0.9381, accuracy : 60.03\n",
            "iteration : 100, loss : 0.9458, accuracy : 59.54\n",
            "iteration : 150, loss : 0.9576, accuracy : 58.91\n",
            "iteration : 200, loss : 0.9542, accuracy : 58.84\n",
            "iteration : 250, loss : 0.9571, accuracy : 58.77\n",
            "iteration : 300, loss : 0.9581, accuracy : 58.62\n",
            "iteration : 350, loss : 0.9573, accuracy : 58.78\n",
            "Epoch : 255, training loss : 0.9561, training accuracy : 58.81, test loss : 1.0014, test accuracy : 58.06\n",
            "\n",
            "Epoch: 256\n",
            "iteration :  50, loss : 0.9466, accuracy : 59.06\n",
            "iteration : 100, loss : 0.9507, accuracy : 59.12\n",
            "iteration : 150, loss : 0.9559, accuracy : 59.09\n",
            "iteration : 200, loss : 0.9588, accuracy : 58.93\n",
            "iteration : 250, loss : 0.9597, accuracy : 58.92\n",
            "iteration : 300, loss : 0.9608, accuracy : 58.82\n",
            "iteration : 350, loss : 0.9613, accuracy : 58.83\n",
            "Epoch : 256, training loss : 0.9605, training accuracy : 58.86, test loss : 1.0104, test accuracy : 57.60\n",
            "\n",
            "Epoch: 257\n",
            "iteration :  50, loss : 0.9678, accuracy : 58.91\n",
            "iteration : 100, loss : 0.9564, accuracy : 59.27\n",
            "iteration : 150, loss : 0.9502, accuracy : 59.08\n",
            "iteration : 200, loss : 0.9448, accuracy : 59.14\n",
            "iteration : 250, loss : 0.9516, accuracy : 58.89\n",
            "iteration : 300, loss : 0.9477, accuracy : 59.11\n",
            "iteration : 350, loss : 0.9454, accuracy : 59.16\n",
            "Epoch : 257, training loss : 0.9459, training accuracy : 59.13, test loss : 0.9973, test accuracy : 57.96\n",
            "\n",
            "Epoch: 258\n",
            "iteration :  50, loss : 0.9789, accuracy : 58.45\n",
            "iteration : 100, loss : 0.9650, accuracy : 59.02\n",
            "iteration : 150, loss : 0.9607, accuracy : 58.95\n",
            "iteration : 200, loss : 0.9610, accuracy : 58.98\n",
            "iteration : 250, loss : 0.9531, accuracy : 59.19\n",
            "iteration : 300, loss : 0.9512, accuracy : 59.16\n",
            "iteration : 350, loss : 0.9494, accuracy : 59.17\n",
            "Epoch : 258, training loss : 0.9506, training accuracy : 59.07, test loss : 1.0038, test accuracy : 57.61\n",
            "\n",
            "Epoch: 259\n",
            "iteration :  50, loss : 0.9366, accuracy : 59.45\n",
            "iteration : 100, loss : 0.9416, accuracy : 59.24\n",
            "iteration : 150, loss : 0.9522, accuracy : 58.92\n",
            "iteration : 200, loss : 0.9556, accuracy : 58.66\n",
            "iteration : 250, loss : 0.9524, accuracy : 58.85\n",
            "iteration : 300, loss : 0.9503, accuracy : 58.95\n",
            "iteration : 350, loss : 0.9499, accuracy : 58.94\n",
            "Epoch : 259, training loss : 0.9481, training accuracy : 59.06, test loss : 1.0064, test accuracy : 57.69\n",
            "\n",
            "Epoch: 260\n",
            "iteration :  50, loss : 0.9600, accuracy : 58.59\n",
            "iteration : 100, loss : 0.9448, accuracy : 59.38\n",
            "iteration : 150, loss : 0.9450, accuracy : 59.26\n",
            "iteration : 200, loss : 0.9452, accuracy : 59.23\n",
            "iteration : 250, loss : 0.9463, accuracy : 59.22\n",
            "iteration : 300, loss : 0.9474, accuracy : 59.17\n",
            "iteration : 350, loss : 0.9470, accuracy : 59.14\n",
            "Epoch : 260, training loss : 0.9480, training accuracy : 59.11, test loss : 1.0098, test accuracy : 57.82\n",
            "\n",
            "Epoch: 261\n",
            "iteration :  50, loss : 0.9663, accuracy : 58.56\n",
            "iteration : 100, loss : 0.9664, accuracy : 58.30\n",
            "iteration : 150, loss : 0.9600, accuracy : 58.74\n",
            "iteration : 200, loss : 0.9568, accuracy : 58.89\n",
            "iteration : 250, loss : 0.9565, accuracy : 58.87\n",
            "iteration : 300, loss : 0.9559, accuracy : 58.88\n",
            "iteration : 350, loss : 0.9574, accuracy : 58.79\n",
            "Epoch : 261, training loss : 0.9562, training accuracy : 58.84, test loss : 1.0136, test accuracy : 57.26\n",
            "\n",
            "Epoch: 262\n",
            "iteration :  50, loss : 0.9433, accuracy : 59.25\n",
            "iteration : 100, loss : 0.9508, accuracy : 58.88\n",
            "iteration : 150, loss : 0.9528, accuracy : 58.67\n",
            "iteration : 200, loss : 0.9489, accuracy : 58.93\n",
            "iteration : 250, loss : 0.9468, accuracy : 59.05\n",
            "iteration : 300, loss : 0.9475, accuracy : 59.06\n",
            "iteration : 350, loss : 0.9482, accuracy : 59.05\n",
            "Epoch : 262, training loss : 0.9491, training accuracy : 59.03, test loss : 0.9950, test accuracy : 58.11\n",
            "\n",
            "Epoch: 263\n",
            "iteration :  50, loss : 0.9688, accuracy : 58.22\n",
            "iteration : 100, loss : 0.9459, accuracy : 59.12\n",
            "iteration : 150, loss : 0.9495, accuracy : 58.93\n",
            "iteration : 200, loss : 0.9530, accuracy : 58.74\n",
            "iteration : 250, loss : 0.9535, accuracy : 58.83\n",
            "iteration : 300, loss : 0.9522, accuracy : 58.88\n",
            "iteration : 350, loss : 0.9508, accuracy : 58.96\n",
            "Epoch : 263, training loss : 0.9500, training accuracy : 59.00, test loss : 1.0010, test accuracy : 57.87\n",
            "\n",
            "Epoch: 264\n",
            "iteration :  50, loss : 0.9435, accuracy : 58.83\n",
            "iteration : 100, loss : 0.9495, accuracy : 58.88\n",
            "iteration : 150, loss : 0.9540, accuracy : 58.79\n",
            "iteration : 200, loss : 0.9528, accuracy : 58.80\n",
            "iteration : 250, loss : 0.9510, accuracy : 58.93\n",
            "iteration : 300, loss : 0.9505, accuracy : 59.14\n",
            "iteration : 350, loss : 0.9489, accuracy : 59.17\n",
            "Epoch : 264, training loss : 0.9470, training accuracy : 59.26, test loss : 1.0014, test accuracy : 57.74\n",
            "\n",
            "Epoch: 265\n",
            "iteration :  50, loss : 0.9605, accuracy : 58.77\n",
            "iteration : 100, loss : 0.9559, accuracy : 58.46\n",
            "iteration : 150, loss : 0.9489, accuracy : 58.91\n",
            "iteration : 200, loss : 0.9480, accuracy : 59.04\n",
            "iteration : 250, loss : 0.9509, accuracy : 58.93\n",
            "iteration : 300, loss : 0.9498, accuracy : 58.99\n",
            "iteration : 350, loss : 0.9472, accuracy : 59.11\n",
            "Epoch : 265, training loss : 0.9478, training accuracy : 59.03, test loss : 1.0021, test accuracy : 58.14\n",
            "\n",
            "Epoch: 266\n",
            "iteration :  50, loss : 0.9595, accuracy : 59.64\n",
            "iteration : 100, loss : 0.9516, accuracy : 59.42\n",
            "iteration : 150, loss : 0.9562, accuracy : 58.97\n",
            "iteration : 200, loss : 0.9553, accuracy : 58.89\n",
            "iteration : 250, loss : 0.9568, accuracy : 58.88\n",
            "iteration : 300, loss : 0.9543, accuracy : 58.83\n",
            "iteration : 350, loss : 0.9539, accuracy : 58.76\n",
            "Epoch : 266, training loss : 0.9534, training accuracy : 58.76, test loss : 1.0156, test accuracy : 57.31\n",
            "\n",
            "Epoch: 267\n",
            "iteration :  50, loss : 0.9573, accuracy : 59.27\n",
            "iteration : 100, loss : 0.9537, accuracy : 58.94\n",
            "iteration : 150, loss : 0.9433, accuracy : 59.46\n",
            "iteration : 200, loss : 0.9511, accuracy : 59.04\n",
            "iteration : 250, loss : 0.9509, accuracy : 59.05\n",
            "iteration : 300, loss : 0.9484, accuracy : 59.10\n",
            "iteration : 350, loss : 0.9471, accuracy : 59.16\n",
            "Epoch : 267, training loss : 0.9472, training accuracy : 59.20, test loss : 1.0040, test accuracy : 57.54\n",
            "\n",
            "Epoch: 268\n",
            "iteration :  50, loss : 0.9309, accuracy : 60.20\n",
            "iteration : 100, loss : 0.9406, accuracy : 59.51\n",
            "iteration : 150, loss : 0.9341, accuracy : 59.82\n",
            "iteration : 200, loss : 0.9385, accuracy : 59.63\n",
            "iteration : 250, loss : 0.9439, accuracy : 59.48\n",
            "iteration : 300, loss : 0.9432, accuracy : 59.40\n",
            "iteration : 350, loss : 0.9432, accuracy : 59.39\n",
            "Epoch : 268, training loss : 0.9428, training accuracy : 59.42, test loss : 1.0013, test accuracy : 57.86\n",
            "\n",
            "Epoch: 269\n",
            "iteration :  50, loss : 0.9526, accuracy : 58.84\n",
            "iteration : 100, loss : 0.9443, accuracy : 59.44\n",
            "iteration : 150, loss : 0.9421, accuracy : 59.39\n",
            "iteration : 200, loss : 0.9452, accuracy : 59.25\n",
            "iteration : 250, loss : 0.9476, accuracy : 59.13\n",
            "iteration : 300, loss : 0.9474, accuracy : 59.08\n",
            "iteration : 350, loss : 0.9457, accuracy : 59.16\n",
            "Epoch : 269, training loss : 0.9441, training accuracy : 59.17, test loss : 0.9972, test accuracy : 58.23\n",
            "\n",
            "Epoch: 270\n",
            "iteration :  50, loss : 0.9486, accuracy : 59.55\n",
            "iteration : 100, loss : 0.9420, accuracy : 59.33\n",
            "iteration : 150, loss : 0.9344, accuracy : 59.75\n",
            "iteration : 200, loss : 0.9361, accuracy : 59.62\n",
            "iteration : 250, loss : 0.9375, accuracy : 59.57\n",
            "iteration : 300, loss : 0.9409, accuracy : 59.32\n",
            "iteration : 350, loss : 0.9397, accuracy : 59.28\n",
            "Epoch : 270, training loss : 0.9398, training accuracy : 59.26, test loss : 1.0015, test accuracy : 58.33\n",
            "\n",
            "Epoch: 271\n",
            "iteration :  50, loss : 0.9320, accuracy : 59.91\n",
            "iteration : 100, loss : 0.9342, accuracy : 59.75\n",
            "iteration : 150, loss : 0.9415, accuracy : 59.20\n",
            "iteration : 200, loss : 0.9425, accuracy : 59.14\n",
            "iteration : 250, loss : 0.9409, accuracy : 59.05\n",
            "iteration : 300, loss : 0.9403, accuracy : 59.18\n",
            "iteration : 350, loss : 0.9418, accuracy : 59.18\n",
            "Epoch : 271, training loss : 0.9412, training accuracy : 59.22, test loss : 1.0007, test accuracy : 58.08\n",
            "\n",
            "Epoch: 272\n",
            "iteration :  50, loss : 0.9460, accuracy : 59.39\n",
            "iteration : 100, loss : 0.9447, accuracy : 59.22\n",
            "iteration : 150, loss : 0.9458, accuracy : 59.05\n",
            "iteration : 200, loss : 0.9462, accuracy : 58.95\n",
            "iteration : 250, loss : 0.9463, accuracy : 58.98\n",
            "iteration : 300, loss : 0.9491, accuracy : 58.90\n",
            "iteration : 350, loss : 0.9503, accuracy : 58.89\n",
            "Epoch : 272, training loss : 0.9503, training accuracy : 58.91, test loss : 1.0047, test accuracy : 57.71\n",
            "\n",
            "Epoch: 273\n",
            "iteration :  50, loss : 0.9413, accuracy : 58.70\n",
            "iteration : 100, loss : 0.9404, accuracy : 58.62\n",
            "iteration : 150, loss : 0.9424, accuracy : 58.94\n",
            "iteration : 200, loss : 0.9405, accuracy : 59.04\n",
            "iteration : 250, loss : 0.9436, accuracy : 58.94\n",
            "iteration : 300, loss : 0.9420, accuracy : 59.12\n",
            "iteration : 350, loss : 0.9399, accuracy : 59.21\n",
            "Epoch : 273, training loss : 0.9397, training accuracy : 59.20, test loss : 0.9968, test accuracy : 58.19\n",
            "\n",
            "Epoch: 274\n",
            "iteration :  50, loss : 0.9326, accuracy : 59.42\n",
            "iteration : 100, loss : 0.9347, accuracy : 59.46\n",
            "iteration : 150, loss : 0.9417, accuracy : 59.01\n",
            "iteration : 200, loss : 0.9393, accuracy : 59.14\n",
            "iteration : 250, loss : 0.9450, accuracy : 58.97\n",
            "iteration : 300, loss : 0.9476, accuracy : 58.91\n",
            "iteration : 350, loss : 0.9457, accuracy : 59.03\n",
            "Epoch : 274, training loss : 0.9444, training accuracy : 59.10, test loss : 1.0000, test accuracy : 57.63\n",
            "\n",
            "Epoch: 275\n",
            "iteration :  50, loss : 0.9423, accuracy : 59.34\n",
            "iteration : 100, loss : 0.9505, accuracy : 58.90\n",
            "iteration : 150, loss : 0.9499, accuracy : 58.80\n",
            "iteration : 200, loss : 0.9463, accuracy : 58.93\n",
            "iteration : 250, loss : 0.9461, accuracy : 59.00\n",
            "iteration : 300, loss : 0.9438, accuracy : 59.04\n",
            "iteration : 350, loss : 0.9447, accuracy : 59.08\n",
            "Epoch : 275, training loss : 0.9479, training accuracy : 58.97, test loss : 1.0075, test accuracy : 57.98\n",
            "\n",
            "Epoch: 276\n",
            "iteration :  50, loss : 0.9631, accuracy : 57.89\n",
            "iteration : 100, loss : 0.9514, accuracy : 58.66\n",
            "iteration : 150, loss : 0.9560, accuracy : 58.31\n",
            "iteration : 200, loss : 0.9572, accuracy : 58.38\n",
            "iteration : 250, loss : 0.9534, accuracy : 58.56\n",
            "iteration : 300, loss : 0.9531, accuracy : 58.51\n",
            "iteration : 350, loss : 0.9500, accuracy : 58.73\n",
            "Epoch : 276, training loss : 0.9491, training accuracy : 58.85, test loss : 1.0021, test accuracy : 57.85\n",
            "\n",
            "Epoch: 277\n",
            "iteration :  50, loss : 0.9609, accuracy : 58.05\n",
            "iteration : 100, loss : 0.9451, accuracy : 58.98\n",
            "iteration : 150, loss : 0.9439, accuracy : 58.90\n",
            "iteration : 200, loss : 0.9425, accuracy : 58.93\n",
            "iteration : 250, loss : 0.9453, accuracy : 58.71\n",
            "iteration : 300, loss : 0.9424, accuracy : 58.95\n",
            "iteration : 350, loss : 0.9437, accuracy : 58.91\n",
            "Epoch : 277, training loss : 0.9432, training accuracy : 58.96, test loss : 1.0005, test accuracy : 58.10\n",
            "\n",
            "Epoch: 278\n",
            "iteration :  50, loss : 0.9311, accuracy : 59.48\n",
            "iteration : 100, loss : 0.9322, accuracy : 59.26\n",
            "iteration : 150, loss : 0.9312, accuracy : 59.44\n",
            "iteration : 200, loss : 0.9342, accuracy : 59.26\n",
            "iteration : 250, loss : 0.9377, accuracy : 59.18\n",
            "iteration : 300, loss : 0.9394, accuracy : 59.23\n",
            "iteration : 350, loss : 0.9389, accuracy : 59.29\n",
            "Epoch : 278, training loss : 0.9388, training accuracy : 59.25, test loss : 1.0024, test accuracy : 57.96\n",
            "\n",
            "Epoch: 279\n",
            "iteration :  50, loss : 0.9309, accuracy : 59.39\n",
            "iteration : 100, loss : 0.9322, accuracy : 59.25\n",
            "iteration : 150, loss : 0.9357, accuracy : 59.14\n",
            "iteration : 200, loss : 0.9376, accuracy : 59.07\n",
            "iteration : 250, loss : 0.9349, accuracy : 59.24\n",
            "iteration : 300, loss : 0.9337, accuracy : 59.24\n",
            "iteration : 350, loss : 0.9350, accuracy : 59.29\n",
            "Epoch : 279, training loss : 0.9347, training accuracy : 59.35, test loss : 0.9978, test accuracy : 58.19\n",
            "\n",
            "Epoch: 280\n",
            "iteration :  50, loss : 0.9292, accuracy : 59.14\n",
            "iteration : 100, loss : 0.9260, accuracy : 59.42\n",
            "iteration : 150, loss : 0.9354, accuracy : 59.34\n",
            "iteration : 200, loss : 0.9409, accuracy : 59.18\n",
            "iteration : 250, loss : 0.9432, accuracy : 59.15\n",
            "iteration : 300, loss : 0.9438, accuracy : 59.09\n",
            "iteration : 350, loss : 0.9444, accuracy : 59.04\n",
            "Epoch : 280, training loss : 0.9445, training accuracy : 59.03, test loss : 1.0001, test accuracy : 58.12\n",
            "\n",
            "Epoch: 281\n",
            "iteration :  50, loss : 0.9378, accuracy : 59.02\n",
            "iteration : 100, loss : 0.9392, accuracy : 59.20\n",
            "iteration : 150, loss : 0.9402, accuracy : 59.20\n",
            "iteration : 200, loss : 0.9377, accuracy : 59.30\n",
            "iteration : 250, loss : 0.9409, accuracy : 59.18\n",
            "iteration : 300, loss : 0.9403, accuracy : 59.29\n",
            "iteration : 350, loss : 0.9400, accuracy : 59.32\n",
            "Epoch : 281, training loss : 0.9407, training accuracy : 59.30, test loss : 1.0025, test accuracy : 57.76\n",
            "\n",
            "Epoch: 282\n",
            "iteration :  50, loss : 0.9445, accuracy : 60.00\n",
            "iteration : 100, loss : 0.9400, accuracy : 59.91\n",
            "iteration : 150, loss : 0.9379, accuracy : 59.94\n",
            "iteration : 200, loss : 0.9404, accuracy : 59.68\n",
            "iteration : 250, loss : 0.9385, accuracy : 59.67\n",
            "iteration : 300, loss : 0.9378, accuracy : 59.77\n",
            "iteration : 350, loss : 0.9373, accuracy : 59.58\n",
            "Epoch : 282, training loss : 0.9383, training accuracy : 59.48, test loss : 1.0001, test accuracy : 58.00\n",
            "\n",
            "Epoch: 283\n",
            "iteration :  50, loss : 0.9470, accuracy : 59.55\n",
            "iteration : 100, loss : 0.9404, accuracy : 59.56\n",
            "iteration : 150, loss : 0.9428, accuracy : 59.52\n",
            "iteration : 200, loss : 0.9442, accuracy : 59.56\n",
            "iteration : 250, loss : 0.9410, accuracy : 59.55\n",
            "iteration : 300, loss : 0.9444, accuracy : 59.32\n",
            "iteration : 350, loss : 0.9442, accuracy : 59.30\n",
            "iteration :  50, loss : 0.9343, accuracy : 59.50\n",
            "iteration : 100, loss : 0.9408, accuracy : 59.32\n",
            "iteration : 150, loss : 0.9447, accuracy : 59.21\n",
            "iteration : 200, loss : 0.9450, accuracy : 59.08\n",
            "iteration : 250, loss : 0.9453, accuracy : 59.09\n",
            "iteration : 300, loss : 0.9418, accuracy : 59.24\n",
            "iteration : 350, loss : 0.9406, accuracy : 59.22\n",
            "Epoch : 284, training loss : 0.9405, training accuracy : 59.22, test loss : 1.0005, test accuracy : 57.97\n",
            "\n",
            "Epoch: 285\n",
            "iteration :  50, loss : 0.9451, accuracy : 58.77\n",
            "iteration : 100, loss : 0.9579, accuracy : 58.58\n",
            "iteration : 150, loss : 0.9538, accuracy : 58.83\n",
            "iteration : 200, loss : 0.9426, accuracy : 59.23\n",
            "iteration : 250, loss : 0.9422, accuracy : 59.19\n",
            "iteration : 300, loss : 0.9419, accuracy : 59.25\n",
            "iteration : 350, loss : 0.9433, accuracy : 59.24\n",
            "Epoch : 285, training loss : 0.9463, training accuracy : 59.13, test loss : 1.0185, test accuracy : 57.51\n",
            "\n",
            "Epoch: 286\n",
            "iteration :  50, loss : 0.9524, accuracy : 58.86\n",
            "iteration : 100, loss : 0.9550, accuracy : 58.73\n",
            "iteration : 150, loss : 0.9464, accuracy : 59.15\n",
            "iteration : 200, loss : 0.9454, accuracy : 59.15\n",
            "iteration : 250, loss : 0.9434, accuracy : 59.22\n",
            "iteration : 300, loss : 0.9424, accuracy : 59.21\n",
            "iteration : 350, loss : 0.9432, accuracy : 59.06\n",
            "Epoch : 286, training loss : 0.9431, training accuracy : 59.07, test loss : 0.9983, test accuracy : 58.18\n",
            "\n",
            "Epoch: 287\n",
            "iteration :  50, loss : 0.9299, accuracy : 59.83\n",
            "iteration : 100, loss : 0.9497, accuracy : 58.96\n",
            "iteration : 150, loss : 0.9523, accuracy : 58.64\n",
            "iteration : 200, loss : 0.9420, accuracy : 58.98\n",
            "iteration : 250, loss : 0.9418, accuracy : 59.11\n",
            "iteration : 300, loss : 0.9407, accuracy : 59.08\n",
            "iteration : 350, loss : 0.9416, accuracy : 59.08\n",
            "Epoch : 287, training loss : 0.9406, training accuracy : 59.10, test loss : 0.9949, test accuracy : 58.31\n",
            "\n",
            "Epoch: 288\n",
            "iteration :  50, loss : 0.9360, accuracy : 59.94\n",
            "iteration : 100, loss : 0.9428, accuracy : 59.48\n",
            "iteration : 150, loss : 0.9416, accuracy : 59.44\n",
            "iteration : 200, loss : 0.9392, accuracy : 59.50\n",
            "iteration : 250, loss : 0.9382, accuracy : 59.58\n",
            "iteration : 300, loss : 0.9388, accuracy : 59.41\n",
            "iteration : 350, loss : 0.9355, accuracy : 59.55\n",
            "Epoch : 288, training loss : 0.9376, training accuracy : 59.44, test loss : 1.0064, test accuracy : 57.93\n",
            "\n",
            "Epoch: 289\n",
            "iteration :  50, loss : 0.9326, accuracy : 60.14\n",
            "iteration : 100, loss : 0.9396, accuracy : 59.86\n",
            "iteration : 150, loss : 0.9362, accuracy : 59.77\n",
            "iteration : 200, loss : 0.9378, accuracy : 59.49\n",
            "iteration : 250, loss : 0.9430, accuracy : 59.30\n",
            "iteration : 300, loss : 0.9415, accuracy : 59.32\n",
            "iteration : 350, loss : 0.9400, accuracy : 59.33\n",
            "Epoch : 289, training loss : 0.9383, training accuracy : 59.37, test loss : 0.9990, test accuracy : 58.11\n",
            "\n",
            "Epoch: 290\n",
            "iteration :  50, loss : 0.9358, accuracy : 59.62\n",
            "iteration : 100, loss : 0.9431, accuracy : 59.05\n",
            "iteration : 150, loss : 0.9396, accuracy : 59.51\n",
            "iteration : 200, loss : 0.9390, accuracy : 59.40\n",
            "iteration : 250, loss : 0.9409, accuracy : 59.27\n",
            "iteration : 300, loss : 0.9407, accuracy : 59.18\n",
            "iteration : 350, loss : 0.9420, accuracy : 59.15\n",
            "Epoch : 290, training loss : 0.9426, training accuracy : 59.14, test loss : 0.9955, test accuracy : 58.07\n",
            "\n",
            "Epoch: 291\n",
            "iteration :  50, loss : 0.9384, accuracy : 59.50\n",
            "iteration : 100, loss : 0.9422, accuracy : 59.29\n",
            "iteration : 150, loss : 0.9384, accuracy : 59.48\n",
            "iteration : 200, loss : 0.9328, accuracy : 59.69\n",
            "iteration : 250, loss : 0.9373, accuracy : 59.46\n",
            "iteration : 300, loss : 0.9395, accuracy : 59.39\n",
            "iteration : 350, loss : 0.9404, accuracy : 59.25\n",
            "Epoch : 291, training loss : 0.9387, training accuracy : 59.27, test loss : 1.0028, test accuracy : 58.14\n",
            "\n",
            "Epoch: 292\n",
            "iteration :  50, loss : 0.9417, accuracy : 58.84\n",
            "iteration : 100, loss : 0.9308, accuracy : 59.47\n",
            "iteration : 150, loss : 0.9329, accuracy : 59.30\n",
            "iteration : 200, loss : 0.9345, accuracy : 59.30\n",
            "iteration : 250, loss : 0.9397, accuracy : 58.98\n",
            "iteration : 300, loss : 0.9370, accuracy : 59.13\n",
            "iteration : 350, loss : 0.9381, accuracy : 59.05\n",
            "Epoch : 292, training loss : 0.9386, training accuracy : 59.03, test loss : 0.9957, test accuracy : 58.02\n",
            "\n",
            "Epoch: 293\n",
            "iteration :  50, loss : 0.9359, accuracy : 59.72\n",
            "iteration : 100, loss : 0.9408, accuracy : 59.29\n",
            "iteration : 150, loss : 0.9422, accuracy : 59.62\n",
            "iteration : 200, loss : 0.9379, accuracy : 59.59\n",
            "iteration : 250, loss : 0.9393, accuracy : 59.52\n",
            "iteration : 300, loss : 0.9372, accuracy : 59.61\n",
            "iteration : 350, loss : 0.9372, accuracy : 59.54\n",
            "Epoch : 293, training loss : 0.9368, training accuracy : 59.55, test loss : 0.9898, test accuracy : 58.37\n",
            "\n",
            "Epoch: 294\n",
            "iteration :  50, loss : 0.9391, accuracy : 59.70\n",
            "iteration : 100, loss : 0.9400, accuracy : 59.34\n",
            "iteration : 150, loss : 0.9444, accuracy : 58.89\n",
            "iteration : 200, loss : 0.9451, accuracy : 58.81\n",
            "iteration : 250, loss : 0.9394, accuracy : 59.12\n",
            "iteration : 300, loss : 0.9418, accuracy : 59.06\n",
            "iteration : 350, loss : 0.9430, accuracy : 59.03\n",
            "Epoch : 294, training loss : 0.9416, training accuracy : 59.07, test loss : 1.0070, test accuracy : 57.65\n",
            "\n",
            "Epoch: 295\n",
            "iteration :  50, loss : 0.9497, accuracy : 58.59\n",
            "iteration : 100, loss : 0.9523, accuracy : 58.74\n",
            "iteration : 150, loss : 0.9481, accuracy : 59.08\n",
            "iteration : 200, loss : 0.9454, accuracy : 59.27\n",
            "iteration : 250, loss : 0.9453, accuracy : 59.14\n",
            "iteration : 300, loss : 0.9425, accuracy : 59.16\n",
            "iteration : 350, loss : 0.9397, accuracy : 59.24\n",
            "Epoch : 295, training loss : 0.9388, training accuracy : 59.21, test loss : 0.9906, test accuracy : 58.33\n",
            "\n",
            "Epoch: 296\n",
            "iteration :  50, loss : 0.9555, accuracy : 58.70\n",
            "iteration : 100, loss : 0.9406, accuracy : 59.17\n",
            "iteration : 150, loss : 0.9359, accuracy : 59.45\n",
            "iteration : 200, loss : 0.9376, accuracy : 59.37\n",
            "iteration : 250, loss : 0.9366, accuracy : 59.27\n",
            "iteration : 300, loss : 0.9354, accuracy : 59.31\n",
            "iteration : 350, loss : 0.9378, accuracy : 59.13\n",
            "Epoch : 296, training loss : 0.9374, training accuracy : 59.13, test loss : 1.0092, test accuracy : 57.67\n",
            "\n",
            "Epoch: 297\n",
            "iteration :  50, loss : 0.9409, accuracy : 59.45\n",
            "iteration : 100, loss : 0.9352, accuracy : 59.45\n",
            "iteration : 150, loss : 0.9356, accuracy : 59.40\n",
            "iteration : 200, loss : 0.9394, accuracy : 59.20\n",
            "iteration : 250, loss : 0.9380, accuracy : 59.34\n",
            "iteration : 300, loss : 0.9380, accuracy : 59.22\n",
            "iteration : 350, loss : 0.9390, accuracy : 59.21\n",
            "Epoch : 297, training loss : 0.9390, training accuracy : 59.25, test loss : 1.0044, test accuracy : 57.94\n",
            "\n",
            "Epoch: 298\n",
            "iteration :  50, loss : 0.9299, accuracy : 60.11\n",
            "iteration : 100, loss : 0.9324, accuracy : 59.75\n",
            "iteration : 150, loss : 0.9414, accuracy : 59.39\n",
            "iteration : 200, loss : 0.9404, accuracy : 59.37\n",
            "iteration : 250, loss : 0.9414, accuracy : 59.31\n",
            "iteration : 300, loss : 0.9416, accuracy : 59.19\n",
            "iteration : 350, loss : 0.9408, accuracy : 59.24\n",
            "Epoch : 298, training loss : 0.9425, training accuracy : 59.19, test loss : 1.0068, test accuracy : 57.89\n",
            "\n",
            "Epoch: 299\n",
            "iteration :  50, loss : 0.9260, accuracy : 59.70\n",
            "iteration : 100, loss : 0.9229, accuracy : 60.08\n",
            "iteration : 150, loss : 0.9289, accuracy : 59.84\n",
            "iteration : 200, loss : 0.9313, accuracy : 59.73\n",
            "iteration : 250, loss : 0.9363, accuracy : 59.43\n",
            "iteration : 300, loss : 0.9364, accuracy : 59.40\n",
            "iteration : 350, loss : 0.9351, accuracy : 59.45\n",
            "Epoch : 299, training loss : 0.9347, training accuracy : 59.48, test loss : 1.0027, test accuracy : 58.00\n",
            "\n",
            "Epoch: 300\n",
            "iteration :  50, loss : 0.9518, accuracy : 59.02\n",
            "iteration : 100, loss : 0.9350, accuracy : 59.55\n",
            "iteration : 150, loss : 0.9362, accuracy : 59.60\n",
            "iteration : 200, loss : 0.9333, accuracy : 59.77\n",
            "iteration : 250, loss : 0.9412, accuracy : 59.50\n",
            "iteration : 300, loss : 0.9388, accuracy : 59.45\n",
            "iteration : 350, loss : 0.9384, accuracy : 59.41\n",
            "Epoch : 300, training loss : 0.9392, training accuracy : 59.34, test loss : 0.9997, test accuracy : 58.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the hold-out test set\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=256, shuffle=False, num_workers=2)\n",
        "test_loss, test_acc = test(0, net, criterion, testloader)\n",
        "test_loss, test_acc"
      ],
      "metadata": {
        "id": "iUQVIKR-X3v6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5648974-8fc8-4492-9520-8e5ea2cabeec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9476416005807764, 59.47295636140135)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(train_acc_list)), train_acc_list, 'b')\n",
        "plt.plot(range(len(test_acc_list)), test_acc_list, 'r')\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy curve : Dropout\")\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7CNz1iabSB21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "2cda1da3-91b6-4436-9c2c-67534755a597"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(train_loss_list)), train_loss_list, 'b')\n",
        "plt.plot(range(len(test_loss_list)), test_loss_list, 'r')\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss curve : Dropout\")\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E9qb9ItHSC5U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ed06b070-b8db-44f1-971e-acce1a35f54e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train_loss_list_drop = {train_loss_list}\") \n",
        "print(f\"train_acc_list_drop = {train_acc_list}\")\n",
        "print(f\"test_loss_list_drop = {test_loss_list}\")\n",
        "print(f\"test_acc_list_drop = {test_acc_list}\")"
      ],
      "metadata": {
        "id": "3eiY3bTlWipW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7a7b8b-3a55-43c3-e7a5-14875901b11f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss_list_drop = [2.3269979856847747, 1.7653623900116298, 1.3874595969673094, 1.2879569950465588, 1.2635592367590927, 1.2367184840566743, 1.2146497220204775, 1.2130844773961922, 1.199504979903782, 1.1933544463904568, 1.1808399522530677, 1.1757891002063183, 1.1778574581068706, 1.1606368593730254, 1.1600934472187425, 1.1438661821812472, 1.1432536811363407, 1.1429211870441591, 1.1426363309547507, 1.133141807747404, 1.1345912316627296, 1.1346861663549572, 1.1272323819679944, 1.1205709327850237, 1.1248636617247005, 1.1250518688018405, 1.1194298835950816, 1.114780056444287, 1.1212061199392407, 1.1095433983053296, 1.1143530374620019, 1.1052800034119832, 1.1108045892986824, 1.1065942677378977, 1.1010452583230286, 1.0994206405267484, 1.099108748804263, 1.0993594152494497, 1.1091623603489986, 1.1096312763891245, 1.0985218368894685, 1.1004681642139507, 1.096200450326046, 1.0976620978779263, 1.094955347417816, 1.0958598713241618, 1.0961977980001185, 1.0916708507511996, 1.0923026947148124, 1.0862725456232625, 1.094909934332054, 1.093874169235953, 1.0920930133279423, 1.0931878089904785, 1.086355970642431, 1.0918006407536143, 1.0867836842045875, 1.0882600700952174, 1.0883855926312083, 1.087175705407047, 1.0858582045004619, 1.0828832702908089, 1.08583508645939, 1.0874728814050112, 1.084138987510185, 1.0823427366047371, 1.0800837197600988, 1.0770875377060598, 1.0864950287632826, 1.084827565726872, 1.073665852953748, 1.0765001387777045, 1.0789985916801907, 1.0776529564120905, 1.076349344195389, 1.0786382840254765, 1.077901720677611, 1.0782686996912245, 1.0696677211823502, 1.0752064093018612, 1.0767290782799244, 1.0666720652321813, 1.0750372480893846, 1.0693097597538295, 1.0701931870080592, 1.076136302172653, 1.0733054117135563, 1.0641420357595615, 1.065630742527928, 1.0657350051047678, 1.067523883771767, 1.063597192447683, 1.0660317696853059, 1.0706347740762603, 1.0645221793231603, 1.0684885780016582, 1.064461873314245, 1.0615039595420444, 1.0653091063344382, 1.0617163404216612, 1.0675504254454842, 1.0631515193114758, 1.0612066819415829, 1.058221712829621, 1.0584084538586418, 1.0670307564541577, 1.0533388339407075, 1.0498751852570511, 1.05395630559301, 1.0629614714361464, 1.0591821676993434, 1.0568597993553492, 1.05931279620504, 1.0601192338033743, 1.0487628386918768, 1.0510774044809625, 1.0565306873825508, 1.0501588705755507, 1.058949898090466, 1.044939726510345, 1.0554435949338483, 1.0505332924163115, 1.051683856865901, 1.0536485832881153, 1.0511912296457988, 1.0452298652835008, 1.0443854107443233, 1.052779132273139, 1.0420751316437553, 1.0414705583396642, 1.0444812233532024, 1.0471862510937016, 1.0396204216047353, 1.0414724818413175, 1.03923720379832, 1.0432482720390568, 1.0439860240876837, 1.0423357339732369, 1.0430644690828919, 1.0352552113171192, 1.0460254693742044, 1.0362712912120147, 1.03799982510285, 1.0385781335959912, 1.0344820675165027, 1.0418778047329043, 1.034199855191921, 1.033808571213306, 1.0262756110206852, 1.034790510892222, 1.032612440708853, 1.0359039529552305, 1.0275757677832915, 1.033923864364624, 1.0279648560818617, 1.0285659957384352, 1.0272157080774384, 1.0279640723373185, 1.0284397287097404, 1.0167389515292677, 1.028240316282443, 1.0327637229508502, 1.0252947663550132, 1.0240331461759118, 1.024374627647038, 1.0157274292090397, 1.0168284508917067, 1.028080809568648, 1.0181243873547086, 1.0142114248056076, 1.0197146307162153, 1.0189350626979095, 1.0192417449098292, 1.0124707494970906, 1.006117636433785, 1.0133408476020584, 1.0164885971604325, 1.0152640806304083, 1.0132970919777062, 1.0161991471520608, 1.0063403848063979, 1.0026034696638422, 1.0090475037169004, 1.0062155059682645, 1.0093863816442206, 1.0068934393445974, 1.0114482490997003, 1.0143260293536716, 1.0130569900923627, 0.9989717342666171, 1.0038538991920347, 0.9952844082501523, 1.0010124690487456, 0.999101043878209, 1.0022100877309557, 0.9991934141169395, 0.9969953040120402, 1.0010999458915173, 1.0011287208818163, 0.9955835604086155, 0.9976842358183409, 0.9920098645900323, 0.9937127245473991, 0.993120821349343, 0.9951552117097022, 0.993177265171113, 0.984136873629035, 0.9912217191564359, 0.9782676732313988, 0.9944041190431693, 0.9868646126775561, 0.98730035913669, 0.9813357396177483, 0.9883824942234732, 0.9876484284556009, 0.9866081552130743, 0.9804793106831187, 0.982329702958828, 0.9847826557107734, 0.979827643248447, 0.9801138112861613, 0.9883290366105594, 0.9744695815936659, 0.9759068254855913, 0.9758978694435058, 0.9743595796871961, 0.9745533957390927, 0.973437243360814, 0.9742537187690011, 0.9750634103932678, 0.970686482866282, 0.9699480381761463, 0.9677449755552339, 0.9655040294174256, 0.967782849864908, 0.9647368157136085, 0.9682623627709179, 0.9718506287753097, 0.9585308182207226, 0.9675361998682099, 0.9612520716700773, 0.9551117786870094, 0.9608719082382636, 0.9633615604907193, 0.9592795095792631, 0.9548227001981038, 0.9505302474750736, 0.9660026182327167, 0.9591187398608138, 0.9611322548654344, 0.9559221098093482, 0.959710897468939, 0.9540097088348575, 0.9624342855399217, 0.9561364148367388, 0.9604551173484099, 0.9458873228328984, 0.9505534968402004, 0.9481128198990654, 0.9479895839846231, 0.9562433150402576, 0.9491052908626029, 0.9499763810860755, 0.9469542624504586, 0.9478379463761802, 0.9533831753381868, 0.9471941099257327, 0.942795716165527, 0.944058593049605, 0.9398068259078959, 0.9412317177467553, 0.9502919862263894, 0.9397357658642095, 0.9444108484237175, 0.9479240702419747, 0.9491396483367052, 0.9432178651737327, 0.9387787769480449, 0.9346725168589977, 0.9445450221943016, 0.9406514087020543, 0.9382828810027621, 0.9466914734866237, 0.9405026495618226, 0.9463330999945561, 0.9430602538553357, 0.9406261730000256, 0.9375631096886425, 0.9383391232348393, 0.9425545480193162, 0.9386809471499952, 0.9386361192881576, 0.9367613829571381, 0.9416064718551429, 0.93884884745771, 0.9373711018058343, 0.9390345194798498, 0.9424526292457167, 0.9347226997701134, 0.9392069563633059]\n",
            "train_acc_list_drop = [14.517734250926416, 37.158284806776074, 48.72419269454738, 51.22710428798306, 51.817893065113815, 52.71148755955532, 53.21334039174166, 53.033350979354154, 53.164637374272104, 53.44203282159873, 53.97988353626257, 53.948120698782425, 53.86553732133404, 54.51773425092642, 54.18316569613552, 54.99841185812599, 54.76971942826893, 54.69137109581789, 54.591847538380094, 54.74854420328216, 54.99629433562732, 54.7358390682901, 55.1064055055585, 55.12122816304923, 55.24827951296982, 55.10428798305982, 54.80359978824775, 55.32027527792483, 55.24827951296982, 55.396506087877185, 55.381683430386445, 55.74166225516146, 55.40497617787189, 55.63366860772896, 55.612493382742194, 55.824245632609845, 55.7564849126522, 55.7924827951297, 55.32239280042351, 55.167813658020115, 56.09317098994177, 55.591318157755424, 55.86659608258338, 55.6209634727369, 55.80307040762308, 56.283748014822656, 55.716251985177344, 55.90471148755955, 55.8920063525675, 55.86871360508206, 55.71201694017999, 55.942826892535734, 55.709899417681314, 55.73742721016411, 56.046585494970884, 56.08681842244574, 55.97035468501853, 56.169401799894125, 55.99152991000529, 56.07411328745368, 56.08046585494971, 56.167284277395446, 55.95129698253044, 55.86024351508735, 55.86659608258338, 56.31339332980413, 56.14187400741133, 56.5780836421387, 55.98517734250927, 56.08470089994706, 56.52938062466914, 56.19269454737957, 56.383271572260455, 56.21810481736368, 56.30915828480678, 56.51032292218105, 55.921651667548964, 56.26892535733192, 56.58231868713605, 56.188459502382216, 56.18422445738486, 56.63313922710429, 56.02329274748544, 56.609846479618845, 56.45738485971413, 55.97035468501853, 56.34727368978295, 56.715722604552674, 56.376919004764424, 56.700899947061934, 56.5865537321334, 56.741132874536795, 56.393859184753836, 56.2435150873478, 56.271042879830595, 56.18634197988354, 56.497617787188986, 56.46373742721016, 56.59290629962943, 56.599258867125464, 56.389624139756485, 56.32609846479619, 56.713605082053995, 56.80889359449444, 56.6860772895712, 56.364213869772364, 56.80889359449444, 57.052408681842245, 56.961355214399155, 56.67125463208047, 56.62678665960826, 56.607728957120166, 56.728427739544735, 56.4785600847009, 57.08628904182107, 56.77077818951826, 56.707252514557965, 56.99947061937533, 56.59290629962943, 56.87241926945474, 56.87877183695077, 56.91900476442562, 56.77289571201694, 56.364213869772364, 56.62678665960826, 57.058761249338275, 57.060878771836954, 56.70513499205929, 57.23875066172578, 57.2641609317099, 57.08628904182107, 56.84065643197459, 57.45262043409211, 56.952885124404446, 57.03758602435151, 56.90206458443621, 56.99947061937533, 57.00582318687136, 56.64584436209635, 57.287453679195345, 56.823716251985175, 56.96559025939651, 57.01429327686607, 56.99100052938063, 57.18369507676019, 56.851244044467975, 57.31074642668079, 57.298041291688726, 57.31286394917946, 57.187930121757546, 57.166754896770776, 56.98676548438327, 57.52249867654844, 57.19004764425622, 57.298041291688726, 57.427210164108, 57.54579142403388, 57.259925886712544, 57.2641609317099, 57.833774483853894, 57.21757543673902, 57.47803070407623, 57.53308628904182, 57.66437268395977, 57.71095817893065, 57.79989412387506, 57.615669666490206, 57.22604552673372, 57.63896241397565, 57.84647961884595, 57.592376919004764, 57.58390682901006, 57.54579142403388, 57.706723133933295, 57.950238221281104, 58.00952885124404, 57.52461619904712, 57.56273160402329, 57.723663313922714, 57.58602435150873, 58.13234515616728, 58.10693488618317, 58.04129168872419, 57.98411858125993, 57.725780836421386, 57.825304393859184, 57.60084700899947, 57.50344097406035, 57.518263631551086, 58.155637903652725, 57.84012705134992, 58.11116993118052, 57.935415563790365, 57.823186871360505, 57.90788777130757, 58.026469031233454, 57.973530968766546, 58.08152461619905, 57.90577024880889, 58.053996823716254, 58.02435150873478, 58.13658020116464, 58.20645844362096, 57.96294335627316, 58.045526733721545, 57.973530968766546, 58.47326627845421, 58.166225516146106, 58.519851773425096, 58.01799894123875, 58.382212811011115, 57.89941768131286, 58.485971413446265, 58.187400741132876, 58.10693488618317, 58.21281101111699, 58.56008470089995, 58.4203282159873, 58.23398623610376, 58.6638433033351, 58.492323980942295, 58.157755426151404, 58.64478560084701, 58.6723133933298, 58.481736368448914, 58.53679195341451, 58.513499205929065, 58.54526204340921, 58.21704605611435, 58.259396506087874, 58.75066172578084, 58.51773425092642, 58.636315510852306, 59.051349920592905, 58.829010058231866, 58.723133933298044, 58.729486500794074, 58.394917946003176, 59.00052938062467, 58.64055055584966, 58.90524086818422, 59.24192694547379, 58.80359978824775, 58.87559555320275, 59.1148755955532, 59.163578613022764, 59.299100052938066, 58.67443091582848, 58.6998411858126, 58.69348861831657, 58.8713605082054, 58.89677077818952, 58.95817893065114, 58.721016410799365, 58.80995235574378, 58.856537850714666, 59.12758073054526, 59.06829010058232, 59.055584965590256, 59.11275807305453, 58.835362625727896, 59.03440974060349, 59.00264690312335, 59.260984647961884, 59.02593965060879, 58.76124933827422, 59.19745897300159, 59.41979883536263, 59.167813658020115, 59.260984647961884, 59.22286924298571, 58.9073583906829, 59.19957649550027, 59.09581789306512, 58.96876654314452, 58.85230280571731, 58.96453149814717, 59.24616199047115, 59.34568554790895, 59.03017469560614, 59.30121757543674, 59.47697194282689, 59.174166225516146, 59.22075172048703, 59.12758073054526, 59.06829010058232, 59.10428798305982, 59.43885653785072, 59.37321334039174, 59.14452091053467, 59.273689782953944, 59.03017469560614, 59.5489677077819, 59.072525145579675, 59.214399152991, 59.12969825304394, 59.25251455796718, 59.19110640550556, 59.481206987824244, 59.34356802541027]\n",
            "test_loss_list_drop = [2.1144830187161765, 1.770705868800481, 1.354537381845362, 1.374193787574768, 1.269173956969205, 1.2487657707111508, 1.3196489787569232, 1.2091097261975794, 1.2207342497273987, 1.2468897922366273, 1.2101589245539086, 1.1896818405857272, 1.1665738452883327, 1.1898313062448127, 1.167635775956453, 1.1819146123586917, 1.1768447099363102, 1.1463913251371944, 1.1678617459301854, 1.1286959490355324, 1.142105237526052, 1.1536669786654266, 1.1455377363691144, 1.1280341978166617, 1.1673410149181591, 1.1291693218198477, 1.1233090556719725, 1.1226905750877716, 1.1175417350787742, 1.101983927044214, 1.114773612980749, 1.1577605964506374, 1.1099497921326582, 1.1291023641824722, 1.140588772647521, 1.1034612421895944, 1.1242947169378692, 1.1394709813244202, 1.119138209258809, 1.12652507073739, 1.1245381195171207, 1.094589379488253, 1.119369665781657, 1.1165281671519374, 1.1264003445120419, 1.1268001143254487, 1.1461899677912395, 1.1140161150810766, 1.1107007910807927, 1.1074825688904406, 1.108308892624051, 1.094352656135372, 1.1150785672898387, 1.0991073133898717, 1.0917623297256582, 1.0943028500267105, 1.1043529005027284, 1.1154845877020967, 1.0956647778842963, 1.1110237877742917, 1.0882367012547511, 1.1033515564951242, 1.1030048958811105, 1.0978559787366904, 1.1059362508502661, 1.1258834977360332, 1.0856871990596546, 1.0888648661328297, 1.1024866194701661, 1.0961040994700264, 1.0940976408766765, 1.091312126786101, 1.0945143512651032, 1.0899952042336558, 1.0977078103551678, 1.0727955243166756, 1.1112479231521195, 1.083779447218951, 1.0883180721133363, 1.081604456200319, 1.1069675511589236, 1.1113862325163448, 1.08329469286928, 1.1153728567502077, 1.0817266495204438, 1.0864259752572751, 1.0797949421639537, 1.0766122563212526, 1.085480871738172, 1.0766295869560802, 1.0755425443251927, 1.1023936102203293, 1.074645878053179, 1.0792558263329899, 1.0751844930882548, 1.084583418918591, 1.0630807026344187, 1.102461565358966, 1.0763371431944417, 1.0680023650912678, 1.0833880670514762, 1.0685595116194557, 1.0700204325657265, 1.0781285526121365, 1.0630561113357544, 1.088389485782268, 1.0853935868716706, 1.0706258831070918, 1.0689591449849747, 1.076810972363341, 1.0848006270095414, 1.0811175312481673, 1.0611938655960793, 1.0559648900639778, 1.0650489786091972, 1.0634413119040282, 1.0575937546935736, 1.0695800287466424, 1.067198390177652, 1.062145631687314, 1.0700830107226091, 1.0637324770876007, 1.0750169882587357, 1.06703304280253, 1.068343691966113, 1.0817719399929047, 1.0417305917716493, 1.0599698961949815, 1.071448670590625, 1.0661738950247859, 1.0650349817439622, 1.0572247689261156, 1.0796616322853987, 1.057907622234494, 1.0717077564959432, 1.0618412661201813, 1.0777777959318722, 1.058915902002185, 1.05283157322921, 1.0593377679002052, 1.0443851752024071, 1.0535672099566926, 1.051210990431262, 1.0717861929944916, 1.0503237460758172, 1.0444728504208958, 1.054432161006273, 1.0400924381672167, 1.064410779113863, 1.0525216352121503, 1.0491984489501691, 1.045340265713486, 1.0562218100416894, 1.0447716704186272, 1.0538054950097029, 1.056641648797428, 1.0590826348931182, 1.0559423729485156, 1.033347575395715, 1.0375388472103606, 1.0366858439702613, 1.0469530628008001, 1.0502466273074056, 1.036207514358502, 1.067028955209489, 1.0487351458446652, 1.0452506594798143, 1.0442006576294993, 1.0317357740565842, 1.0378813851697772, 1.0531027676428066, 1.0377793466927958, 1.0434763656527388, 1.0363010626797582, 1.032071295614336, 1.0364813147222294, 1.0200531605411978, 1.041566525312031, 1.038747032191239, 1.0305369207087685, 1.0415644949557734, 1.0248307495140563, 1.031455700303994, 1.0360358483066745, 1.0307040877786338, 1.023797578963579, 1.0264523488049413, 1.030638714923578, 1.0347188845569013, 1.0293481130810345, 1.031280215756566, 1.0292902369709576, 1.0334156865582746, 1.031577334684484, 1.0269628357069165, 1.0262205425430746, 1.0311612942639519, 1.0282401597382975, 1.01918892854569, 1.0326045102932875, 1.0266494137399338, 1.0266031354081397, 1.0255042562882106, 1.0192927028618606, 1.0265945044218325, 1.033088362684437, 1.0299573669246598, 1.0328738254074956, 1.0142579215998744, 1.0358880571290559, 1.0153153670184754, 1.016160689440428, 1.023149904959342, 1.019488983294543, 1.0170754033560847, 1.0134304808635337, 1.016931656236742, 1.012284860307095, 1.0089451068756627, 1.016482996005638, 1.0185778997108048, 1.0158315102259319, 1.023031898573333, 1.0122722004558526, 1.0160985562731237, 1.0133712399823993, 1.01100500395485, 1.0044899582862854, 1.0161759789083518, 1.0111533143356735, 1.0097735492037792, 1.0130605466809928, 1.00693079040331, 1.0013298807190913, 1.014782198211726, 1.009178220933559, 1.0220976109598197, 1.0055661785836314, 1.0202039015643738, 1.0140373724348404, 1.0104320841092689, 1.021941000924391, 0.9992682054346683, 1.0108502372807147, 1.0068416262374205, 1.014936113182236, 1.014849027874423, 1.0151805611802083, 1.0071095827163434, 1.0103699877565981, 1.0065367975655723, 1.015264817312652, 1.0000949396806604, 1.0138824883044935, 1.0014201008221681, 1.0104307102806427, 0.9973147453046313, 1.003813914516393, 1.0063805366848029, 1.0097704421655804, 1.013560435059024, 0.994986776043387, 1.0009713961797602, 1.0014018556650948, 1.0021180960477567, 1.0156038704456067, 1.0040169892942203, 1.0012714500520743, 0.9971654491097319, 1.0015128380527683, 1.000653420008865, 1.0046796012742847, 0.9967991408764147, 1.0000053013072294, 1.0075030046350815, 1.002073511481285, 1.0004754829056122, 1.002359372143652, 0.9977667007376166, 1.0001270879133075, 1.0024964450036777, 1.0000760324445426, 1.0075691716343749, 1.0004645562639423, 1.0185351894766677, 0.998321448471032, 0.994868344243835, 1.0064027674642264, 0.9990221223994797, 0.9954676566755071, 1.0027908709119349, 0.9956688986105078, 0.9898490306793475, 1.006957445951069, 0.9906078004369548, 1.0091955571197997, 1.004394779310507, 1.0068047683612973, 1.0027133614993562, 0.9996551611259872]\n",
            "test_acc_list_drop = [23.244468346650276, 38.249078057775044, 49.435310387215736, 49.13952059004303, 51.413644744929314, 52.12046711739398, 51.32529194837124, 53.234480639213274, 52.41241548862938, 52.339428395820526, 53.130762138905965, 53.35740626920713, 54.594345421020286, 53.53027043638598, 54.08343577135833, 53.63783036263061, 53.96819299323909, 54.46757836508912, 54.110325752919486, 54.7480024585126, 54.19483712354026, 53.84142593730793, 54.60586969883221, 54.74031960663798, 53.77228027043638, 54.91702519975415, 55.235863552550704, 55.132145052243395, 55.09757221880762, 55.57775046097111, 55.09373079287031, 54.24861708666257, 55.67762753534112, 54.61739397664413, 54.72879532882606, 55.82744314689613, 55.178242163491085, 54.95159803318992, 55.001536570374924, 54.701905347264905, 55.185925015365704, 56.01183159188691, 54.79409956976029, 55.33574062692071, 55.28580208973571, 55.16287645974186, 54.091118623232944, 55.43945912722803, 55.666103257529194, 55.251229256299936, 55.72372464658881, 55.88890596189305, 55.03226797787339, 55.62768899815612, 55.77366318377382, 55.45482483097726, 55.20129071911494, 55.477873386601104, 56.08097725875845, 55.185925015365704, 56.26152427781192, 55.431776275353414, 55.7659803318992, 55.84280885064536, 55.70067609096497, 54.8939766441303, 55.908113091579594, 55.796711739397665, 55.87354025814383, 55.62384757221881, 55.67762753534112, 55.904271665642284, 55.84280885064536, 55.94652735095267, 55.82360172095882, 56.465119852489245, 55.255070682237246, 56.26536570374923, 56.223110018438845, 55.977258758451136, 55.316533497234175, 55.132145052243395, 55.87738168408113, 55.50476336816226, 56.034880147510755, 56.338352796558084, 56.038721573448065, 56.13091579594345, 55.74677320221266, 56.37292562999385, 56.07329440688383, 55.51244622003688, 56.457437000614625, 56.26152427781192, 56.19237861094038, 55.792870313460355, 56.342194222495394, 55.62768899815612, 56.3460356484327, 56.645666871542716, 55.95421020282729, 56.338352796558084, 56.42286416717886, 56.48048555623848, 56.61493546404425, 56.06561155500922, 55.43945912722803, 56.12707437000615, 56.56883835279656, 56.24615857406269, 55.65457897971727, 55.858174554394594, 56.999078057775044, 56.945298094652735, 56.32298709280885, 56.45359557467732, 56.7340196681008, 56.757068223724644, 56.276889981561155, 56.5381069452981, 56.42286416717886, 56.699446834665025, 56.2039028887523, 56.17317148125384, 56.96066379840197, 56.299938537185, 57.33328211432084, 56.84542102028273, 56.19622003687769, 56.223110018438845, 56.28841425937308, 56.641825445605406, 55.68915181315304, 56.72249539028888, 56.226951444376155, 56.31530424093423, 55.5700676090965, 56.66487400122926, 56.80316533497234, 56.50353411186232, 57.137369391518135, 56.833896742470806, 57.01444376152428, 56.05792870313461, 56.66871542716657, 57.1719422249539, 56.68023970497849, 57.44084204056546, 56.038721573448065, 56.760909649661954, 57.129686539643515, 56.90304240934235, 56.48048555623848, 56.61493546404425, 56.653349723417335, 56.32298709280885, 56.407498463429626, 56.584204056545786, 57.375537799631225, 57.04901659496005, 57.187307928703135, 56.84926244622004, 56.61493546404425, 57.321757836508915, 56.576521204671174, 56.98755377996312, 56.707129686539645, 56.411339889366936, 57.506146281499696, 57.244929317762754, 56.334511370620774, 57.32559926244622, 57.502304855562386, 56.949139520590045, 57.44468346650277, 57.30639213275968, 57.96711739397664, 56.71481253841426, 57.137369391518135, 57.244929317762754, 56.91456668715427, 57.29102642901045, 57.187307928703135, 57.317916410571605, 57.371696373693915, 57.62523048555624, 57.375537799631225, 57.32944068838353, 56.9299323909035, 57.30255070682237, 57.022126613398896, 57.43700061462815, 57.15273509526736, 57.46389059618931, 57.39090350338046, 57.321757836508915, 57.37937922556853, 56.999078057775044, 57.425476336816224, 56.949139520590045, 57.129686539643515, 57.39858635525507, 57.317916410571605, 57.78657037492317, 57.20651505838968, 56.833896742470806, 57.44084204056546, 56.92224953902889, 57.460049170252, 56.96066379840197, 57.47541487400123, 57.63291333743086, 57.30639213275968, 57.433159188690844, 57.30255070682237, 57.744314689612786, 57.64059618930547, 57.71742470805163, 57.64443761524278, 57.667486170866624, 57.63291333743086, 57.64059618930547, 57.46389059618931, 57.6060233558697, 57.690534726490476, 57.252612169637366, 57.39858635525507, 57.99016594960049, 57.52919483712354, 57.89028887523049, 57.89028887523049, 57.256453595574676, 57.721266133988934, 58.02473878303626, 57.70974185617701, 57.82882606023356, 57.248770743700064, 58.163030116779346, 57.375537799631225, 57.798094652735095, 57.57529194837124, 56.98371235402581, 58.278272894898585, 57.314074984634296, 57.77504609711125, 57.59065765212047, 57.563767670559315, 57.54840196681008, 58.2360172095882, 57.54456054087277, 57.94022741241549, 57.71742470805163, 58.1860786724032, 57.460049170252, 58.05931161647204, 57.59834050399508, 57.95559311616472, 57.609864781807005, 57.690534726490476, 57.82498463429625, 57.260295021511986, 58.11309157959435, 57.87492317148126, 57.736631837738166, 58.14382298709281, 57.314074984634296, 57.54456054087277, 57.86339889366933, 58.23217578365089, 58.332052858020894, 58.08236017209588, 57.71358328211432, 58.1860786724032, 57.62523048555624, 57.982483097725876, 57.851874615857405, 58.097725875845114, 57.96327596803933, 58.19376152427781, 58.12077443146896, 57.76352181929932, 57.99784880147511, 57.613706207744315, 57.96711739397664, 57.51382913337431, 58.17839582052858, 58.31284572833436, 57.928703134603566, 58.10540872771973, 58.07083589428396, 58.13614013521819, 58.02089735709895, 58.37046711739398, 57.64827904118009, 58.32821143208359, 57.667486170866624, 57.94022741241549, 57.89413030116779, 57.99784880147511, 58.29748002458513]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list_01 = [2.3849518770770977, 2.2417600981911345, 2.2415069635644516, 2.2409557133186153, 2.2419579268147953, 2.240125378942102, 2.240931454066662, 2.2417839348800785, 2.242252948807507, 2.241471426273749, 2.241231945472035, 2.2413479971691843, 2.241036834432504, 2.2407813569717616, 2.2415969093963706]\n",
        "train_acc_list_01 = [18.56855479089465, 18.617257808364215, 18.746426680783483, 18.60243515087348, 18.61937533086289, 18.886183165696135, 18.60243515087348, 18.598200105876124, 18.604552673372154, 18.740074113287452, 18.731604023292746, 18.814187400741133, 18.848067760719957, 18.82901005823187, 18.752779248279513]\n",
        "test_loss_list_01 = [2.2387831538331273, 2.241503697984359, 2.241926829020182, 2.240557459055209, 2.2406100852816713, 2.252836311564726, 2.2468298743752873, 2.2446437150824305, 2.2425780202828203, 2.240177970306546, 2.243702617346072, 2.2441832843948815, 2.253918958645241, 2.245230858232461, 2.2435202879064224]\n",
        "test_acc_list_01 = [18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 14.27858020897357, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463, 18.95743700061463]\n",
        "train_loss_list_001 = [2.2888378896687414, 2.232192633274771, 1.4893088792236193, 0.5001831288098643, 0.3830500937251218, 0.32867970416539405, 0.29770232389774426, 0.27895135900919354, 0.2627035691970732, 0.24814978033950336, 0.23438045485475198, 0.2243682525668364, 0.21301924496848731, 0.20818865677811266, 0.1958482328166322]\n",
        "train_acc_list_001 = [18.50926416093171, 18.968766543144522, 47.80307040762308, 84.23292747485442, 88.15881418740074, 89.9142403388036, 91.04923239809423, 91.63790365272631, 92.08893594494441, 92.58020116463737, 93.03758602435151, 93.36791953414505, 93.715193223928, 93.84012705134992, 94.35044997353097]\n",
        "test_loss_list_001 = [2.2451091665847627, 2.2302937355695986, 0.684039752711268, 0.4374444575286379, 0.39873581839834943, 0.36398082489476485, 0.3313831433507742, 0.3210300371854329, 0.2847569804346445, 0.29315854806233854, 0.27853756525791157, 0.26896954926789973, 0.2596830692069203, 0.26028463620619446, 0.2491153629460171]\n",
        "test_acc_list_001 = [18.88060848186847, 19.053472649047325, 78.20759065765212, 86.33988936693301, 87.90334972341734, 88.90596189305471, 90.08143822987093, 90.81515058389674, 91.70636140135218, 91.54118008604794, 91.8638598647818, 92.2480024585126, 92.43239090350338, 92.50537799631223, 92.82037492317149]\n",
        "train_loss_list_0001 = [1.8565612323885041, 0.5532636212785715, 0.4003713336094285, 0.3402645644860539, 0.309145948165639, 0.2848975209968523, 0.262982070708501, 0.24855145600026216, 0.2386487888167221, 0.2278864942390098, 0.21327269485164788, 0.20556094100683686, 0.19517452138549268, 0.18913837452608395, 0.18232752032436653]\n",
        "train_acc_list_0001 = [34.7993647432504, 82.35468501852831, 87.65272631021705, 89.51614610905241, 90.6723133933298, 91.51932239280042, 92.26892535733192, 92.59925886712546, 92.97617787188989, 93.34674430915828, 93.69401799894123, 93.97353096876654, 94.31868713605083, 94.53255690841715, 94.71254632080466]\n",
        "test_loss_list_0001 = [1.0861167063315709, 0.46979708385233787, 0.41340532643245714, 0.3364271931350231, 0.3262409484561752, 0.34040282589986043, 0.28803076817854945, 0.2942232322678262, 0.2779932311169949, 0.27514038454083833, 0.2478603608906269, 0.2512748020463714, 0.26197264781769586, 0.2462065773194327, 0.24985540344142446]\n",
        "test_acc_list_0001 = [64.00583896742471, 85.58312845728334, 87.41933005531654, 89.81637984019667, 89.970036877689, 89.99308543331284, 91.59111862323294, 91.35295021511985, 91.82928703134604, 92.03672403196066, 92.76275353411187, 92.83574062692071, 92.90488629379226, 92.98555623847572, 92.87031346035648]\n",
        "train_loss_list_00001 = [1.2440541174192092, 0.4583125376927497, 0.36052036624613815, 0.3151768069603256, 0.2875107263081119, 0.26835051384883196, 0.25187577066948097, 0.23390740957767336, 0.22118305101950317, 0.21190600004299545, 0.20555683115350845, 0.1952596850249018, 0.18612936185546683, 0.18178928815090883, 0.17480877608181986]\n",
        "train_acc_list_00001 = [57.18581259925887, 85.53943885653786, 88.79618845950239, 90.25304393859184, 91.214399152991, 92.01058761249338, 92.36421386977237, 93.09899417681312, 93.43991529910005, 93.80412916887242, 93.86765484383271, 94.25092641609317, 94.500794070937, 94.64478560084702, 94.82477501323451]\n",
        "test_loss_list_00001 = [0.5935118007017117, 0.43328142947718207, 0.3668157114994292, 0.34575528556517526, 0.3590214093964474, 0.3134572241893586, 0.2903973020467104, 0.28062032824199573, 0.26905518266208034, 0.26447016406146917, 0.27132851287138227, 0.26421160440818936, 0.25491809147391836, 0.24584030433028353, 0.2630316608895858]\n",
        "test_acc_list_00001 = [80.93500307314075, 86.63567916410571, 88.97510755992624, 89.3438844499078, 88.99431468961278, 90.58466502765826, 91.54502151198525, 91.56422864167179, 92.02135832821143, 92.25184388444991, 91.97910264290104, 92.37861094038107, 92.72433927473878, 92.96250768285188, 92.59757221880763]\n",
        "\n",
        "\n",
        "train_loss_list_const = [1.5944857293674293, 0.4869092239677745, 0.3710624326454592, 0.3296906750215101, 0.29884549410039496, 0.27146996971633697, 0.2604337949053382, 0.24417246496532022, 0.23419785655045575, 0.22457996957751147, 0.21173857996457315, 0.20202396321425917, 0.1943116241051414, 0.18745123495052501, 0.1774632519257424, 0.17214223601650902, 0.16552220173886797, 0.15473239550866733, 0.15404348591276948, 0.14213740165398372, 0.13690419029192066, 0.13265049481779578, 0.12643728150322348, 0.1223953123176647, 0.11572830584960256, 0.10872174589453028, 0.10607895330301306, 0.10143619665729645, 0.09846852844464908, 0.09155762590831373, 0.09176684167932689, 0.08320119946962853, 0.07973214024854547, 0.07931727142424037, 0.06983993944351063, 0.07091535234995448, 0.0671700671211713, 0.06470882359558974, 0.061619590856841586, 0.061459206172131346, 0.057121708876198427, 0.053374216585170206, 0.0498615506466044, 0.05073856983490308, 0.04987424655961312, 0.046790412364042994, 0.04711244383266544, 0.04263703334889801, 0.043034394194061555, 0.04126133985860339, 0.03625233271121373, 0.03783284285014904, 0.0379838087573284, 0.03416189216178284, 0.03383261713717981, 0.03370409071676403, 0.033968668481206325, 0.03165312097212274, 0.03038872497441464, 0.02841417055683044, 0.029356409022635036, 0.02889881345480024, 0.028939039615515447, 0.02568263415692672, 0.027656220918051838, 0.026301205131101617, 0.023402816848356156, 0.024891200900357974, 0.022950206206843942, 0.022271349775869285, 0.0250707899006071, 0.022344395426495713, 0.019562920480307198, 0.022191016989943715, 0.02281398802152065, 0.0203801996838415, 0.020550807893653537, 0.02117716848076041, 0.019771566791103416, 0.022764958889409142, 0.017198871523580392, 0.02078044665365311, 0.020109122048629333, 0.01588759385191313, 0.01774437841210012, 0.020397339600326397, 0.01534856222032823, 0.016435430918308794, 0.01711455919842304, 0.01770936636729633, 0.018040290616609177, 0.01564757464108749, 0.015251886521385311, 0.01534154344099917, 0.015427147975282334, 0.01419120683843651, 0.01811075882562171, 0.016642653122089984, 0.01305790530750528, 0.013949767823940267, 0.014656124457392462, 0.013457846312966957, 0.014343252129156173, 0.013850259383991146, 0.012460459422866397, 0.012413865320129272, 0.013889214684304953, 0.01221698466477806, 0.015144580592092777, 0.010421825547786688, 0.01315658220278792, 0.014559990600058128, 0.012665790851758906, 0.01143317199561781, 0.011717887349175301, 0.011158559258571676, 0.012634062059679534, 0.011741106513152792, 0.012515452659958159, 0.011751638104695717, 0.011457235534427129, 0.011438692509360596, 0.012512708038015468, 0.008602326916451698, 0.010682771495822786, 0.011196336384384224, 0.009268063090769713, 0.009998142540840234, 0.012729091897495166, 0.010267185127698763, 0.010566324319321028, 0.010713477439735606, 0.010119398856430022, 0.012654226244056406, 0.009628543746825273, 0.0102562899387879, 0.010169452542220153, 0.011113815507671713, 0.01246779066452764, 0.007518461719419533, 0.007389902458939484, 0.011104748547043264, 0.01135712010794771, 0.008941290669380526, 0.009924649224834431, 0.009838336234147059, 0.007612355080635734, 0.009282812758648675, 0.008423602285464519, 0.009065308554876006, 0.010365516194014629, 0.006115070432431249, 0.006490228478146479, 0.011122480412586441, 0.00872685812082587, 0.008791860558152852, 0.009787340952780856, 0.008418811355189983, 0.007423892029066022, 0.009898100130695444, 0.008828991230531168, 0.007722080036888794, 0.009378696144602659, 0.00829515335842403, 0.006554383687879633, 0.006126663065066873, 0.010910632581322311, 0.007716069375264186, 0.006358072765228986, 0.007697185452836498, 0.008877029283653514, 0.008559577807589543, 0.00707696825589556, 0.00850764569837624, 0.0062317561151193695, 0.0066259507287960455, 0.008618629247509826, 0.007878521594295732, 0.007498281048782551, 0.006598806819186967, 0.006230976371933824, 0.006141664580167378, 0.007923200858393221, 0.008045455975570557, 0.00792612456981016, 0.007601726206049413, 0.007419711852838272, 0.004584900550783639, 0.00685006011318293, 0.008050930358640324, 0.008370204849807444, 0.005507358266772813, 0.006857401374734981, 0.008172955556791895, 0.004244687181667273, 0.008633549227632837, 0.008705449396538356, 0.0067560189635043925, 0.006710546794999935, 0.00550614756518684, 0.0069180619830691474, 0.00835907400430254, 0.005712247417545953, 0.006098340349643973, 0.007154704712266156, 0.0061693518397019, 0.005750073719051822, 0.005536363746094307, 0.006909997050809464, 0.006392437509654407, 0.004530645426771153, 0.00935107147158372, 0.005991038718238898, 0.004413133404240297, 0.007152540924743997, 0.006123794079590131, 0.004265024197029019, 0.007488072243164834, 0.006849384789138319, 0.006199823599835201, 0.004939858833603685, 0.006542191565922548, 0.006134184821023406, 0.006127372573951168, 0.006120713498504846, 0.005705225819374859, 0.0054501006014126396, 0.00476737067947397, 0.005204442173390228, 0.006888031104115721, 0.005438639611901732, 0.005198591940753804, 0.006226397409455738, 0.00398913007948585, 0.006725981141281091, 0.0057350191533619786, 0.004547678196042624, 0.003760278201966155, 0.004862335098237806, 0.0053206211415940214, 0.004511028374038128, 0.006714381331292853, 0.006507630908786355, 0.004150821972775074, 0.005154698122662017, 0.005662354828146746, 0.004606740834664833, 0.004731273036621596, 0.004916682220897782, 0.0048261530498232945, 0.006001339212270287, 0.007263619651073496, 0.0038986454153652154, 0.005036929771996826, 0.005049693082181207, 0.00644224065052205, 0.004578751418381182, 0.004686958738437559, 0.003585059260631736, 0.003101582141557616, 0.007221638428928184, 0.005000114876925785, 0.0051700827908760325, 0.005254589704386773, 0.00406367993565528, 0.0036232792127412505, 0.006171727926178867, 0.005875237415135579, 0.00392443083374783, 0.006561909474143628, 0.0037487958143322068, 0.004443046452993911, 0.005447318903908573, 0.004017829913798502, 0.00472008602112813, 0.0055074588290326305, 0.005279580161203713, 0.0036886348879267314, 0.0035813810519778975, 0.004883374933941502, 0.004846986711028166, 0.004054715485154408, 0.004949977601104352, 0.0046826732979178415, 0.004384392334953691, 0.004187341836835158, 0.004243570542040143, 0.005868256121943751, 0.00557879406272601, 0.0037290168971954394, 0.0024883511193469366, 0.004939023949055762, 0.004748034648033541, 0.0038421762496379727, 0.003486280636854575, 0.0036575751641310756, 0.00670746078328728, 0.004645855993902198, 0.004636629221823842, 0.004005611049817734]\n",
        "train_acc_list_const = [44.03176283748015, 84.49761778718899, 88.61196400211752, 89.87400741132875, 91.01958708311275, 91.79460031762838, 92.2350449973531, 92.80889359449444, 93.03546850185283, 93.37427210164108, 93.80412916887242, 94.0052938062467, 94.38009528851244, 94.6278454208576, 94.88618316569614, 95.01323451561673, 95.1868713605082, 95.66543144520911, 95.57226045526734, 95.91953414505029, 96.01905770248808, 96.16093170989942, 96.35150873478031, 96.54632080465855, 96.74113287453679, 96.86183165696136, 96.96347273689783, 97.10746426680784, 97.21757543673901, 97.32133403917416, 97.3276866066702, 97.63896241397565, 97.72154579142403, 97.7342509264161, 97.88883006881949, 97.87400741132875, 97.96506087877184, 98.09211222869243, 98.24245632609846, 98.17257808364214, 98.28692429857067, 98.34833245103229, 98.44997353096876, 98.49444150344097, 98.49655902593965, 98.54102699841185, 98.55796717840127, 98.67443091582848, 98.63419798835362, 98.74219163578613, 98.87559555320276, 98.77607199576495, 98.78030704076231, 98.9793541556379, 98.94970884065643, 98.9433562731604, 98.90947591318158, 98.98782424563261, 98.96453149814717, 99.08099523557438, 99.05770248808894, 99.05134992059291, 99.0428798305982, 99.1784012705135, 99.13393329804128, 99.1148755955532, 99.20381154049761, 99.18051879301217, 99.27580730545262, 99.23980942297511, 99.1784012705135, 99.25674960296453, 99.3499205929063, 99.26310217046056, 99.2503970354685, 99.32874536791954, 99.28215987294865, 99.27157226045527, 99.29486500794071, 99.24404446797247, 99.42615140285865, 99.2779248279513, 99.31180518793012, 99.46214928533615, 99.40921122286925, 99.36262572789836, 99.49602964531498, 99.43673901535203, 99.42615140285865, 99.40921122286925, 99.41132874536792, 99.47697194282689, 99.49602964531498, 99.49814716781366, 99.47273689782953, 99.5044997353097, 99.39015352038115, 99.45156167284277, 99.57649550026468, 99.55320275277924, 99.5404976177872, 99.5659078877713, 99.53414505029116, 99.54685018528322, 99.58073054526204, 99.5849655902594, 99.49391212281631, 99.58920063525674, 99.51720487030175, 99.66543144520911, 99.5574377977766, 99.56167284277396, 99.56802541026998, 99.60402329274748, 99.62519851773425, 99.6019057702488, 99.5934356802541, 99.62519851773425, 99.60402329274748, 99.61461090524087, 99.61461090524087, 99.63790365272631, 99.6019057702488, 99.70566437268396, 99.66119640021175, 99.64002117522499, 99.69507676019057, 99.68025410269983, 99.58920063525674, 99.6569613552144, 99.62519851773425, 99.6569613552144, 99.66754896770779, 99.54261514028586, 99.69719428268925, 99.63366860772896, 99.67178401270513, 99.60825833774484, 99.6019057702488, 99.75436739015352, 99.75436739015352, 99.59555320275278, 99.62731604023293, 99.6929592376919, 99.65484383271573, 99.66966649020645, 99.7289571201694, 99.71836950767602, 99.69084171519323, 99.67601905770249, 99.66119640021175, 99.79671784012704, 99.78824775013234, 99.62519851773425, 99.71836950767602, 99.72683959767072, 99.68872419269455, 99.73107464266808, 99.73107464266808, 99.67601905770249, 99.70989941768131, 99.73319216516676, 99.68025410269983, 99.7204870301747, 99.78824775013234, 99.80518793012176, 99.64849126521969, 99.73107464266808, 99.79883536262572, 99.74377977766014, 99.69719428268925, 99.69719428268925, 99.77130757014294, 99.71625198517734, 99.7924827951297, 99.784012705135, 99.70354685018528, 99.75860243515088, 99.73319216516676, 99.79036527263102, 99.78189518263632, 99.79036527263102, 99.73530968766543, 99.69719428268925, 99.75013234515616, 99.72472207517205, 99.76071995764956, 99.84330333509793, 99.784012705135, 99.73530968766543, 99.69084171519323, 99.82212811011117, 99.76919004764426, 99.73319216516676, 99.85812599258867, 99.70989941768131, 99.70142932768661, 99.76071995764956, 99.78824775013234, 99.8284806776072, 99.7924827951297, 99.7204870301747, 99.8009528851244, 99.81577554261514, 99.75436739015352, 99.7924827951297, 99.81365802011646, 99.8009528851244, 99.77554261514028, 99.77977766013764, 99.85389094759132, 99.67601905770249, 99.81789306511382, 99.86871360508205, 99.74377977766014, 99.78189518263632, 99.84965590259397, 99.77130757014294, 99.78824775013234, 99.82001058761249, 99.81365802011646, 99.77130757014294, 99.78189518263632, 99.79883536262572, 99.80730545262044, 99.82636315510852, 99.79036527263102, 99.83059820010588, 99.81154049761778, 99.7564849126522, 99.8094229751191, 99.8284806776072, 99.81154049761778, 99.88353626257279, 99.75224986765484, 99.79671784012704, 99.85389094759132, 99.88565378507147, 99.83059820010588, 99.80730545262044, 99.84118581259926, 99.77130757014294, 99.81154049761778, 99.85177342509265, 99.83271572260455, 99.8094229751191, 99.8284806776072, 99.86236103758603, 99.8369507676019, 99.82424563260984, 99.8009528851244, 99.78824775013234, 99.84330333509793, 99.82636315510852, 99.8284806776072, 99.78189518263632, 99.85812599258867, 99.85177342509265, 99.89624139756485, 99.89835892006353, 99.77130757014294, 99.84118581259926, 99.81577554261514, 99.8369507676019, 99.85600847008999, 99.86659608258337, 99.81154049761778, 99.79671784012704, 99.87718369507677, 99.79883536262572, 99.85812599258867, 99.85389094759132, 99.83906829010058, 99.88353626257279, 99.84753838009529, 99.8369507676019, 99.83906829010058, 99.88565378507147, 99.87506617257809, 99.83271572260455, 99.84330333509793, 99.85812599258867, 99.86659608258337, 99.8369507676019, 99.8284806776072, 99.84753838009529, 99.85177342509265, 99.7924827951297, 99.79671784012704, 99.88141874007411, 99.92376919004765, 99.86024351508735, 99.84753838009529, 99.85600847008999, 99.87506617257809, 99.87718369507677, 99.79671784012704, 99.86024351508735, 99.85177342509265, 99.87083112758073]\n",
        "test_loss_list_const = [0.9403148495099124, 0.46971940738605517, 0.34306909633325594, 0.3384028169892582, 0.3164549315823059, 0.31764499748162195, 0.282772644879479, 0.27239831069520876, 0.2788072020618939, 0.2605946859454407, 0.2569786167758353, 0.25151387514436946, 0.23040011815507622, 0.23389688687508597, 0.23323347488893012, 0.22432381940969065, 0.23885389055837603, 0.22965874502837075, 0.23512107754747072, 0.23369459731175618, 0.22183155821745887, 0.2491116562639089, 0.23399925456546686, 0.25359821337841304, 0.23499618255186314, 0.22481991891183106, 0.2324665375966944, 0.23745987874766192, 0.24356824685545528, 0.24952035153503804, 0.23930090873082185, 0.25436064657554325, 0.25367995643732594, 0.26609678615761156, 0.2672480665622096, 0.2746706861893044, 0.25824960023529975, 0.26025373894063863, 0.2791316908072023, 0.26918739248432366, 0.2763673086997633, 0.2997446244436444, 0.2916372886438872, 0.3003798500981693, 0.2806282534501424, 0.2931029381979184, 0.29610180335265457, 0.3087221756942716, 0.32797835285172744, 0.30948590080929445, 0.31205729929292025, 0.3264701991711798, 0.31612680869761345, 0.3249107254029927, 0.3218845636081681, 0.3128845189679779, 0.3158182442261308, 0.3337518404621412, 0.34533743259003935, 0.32409434777447116, 0.3321887091642209, 0.3324712138604738, 0.33405348602864965, 0.3346349073199592, 0.3316200801226146, 0.35435040097446274, 0.3272651647738017, 0.3605334343612377, 0.3315225986252521, 0.36446072681642633, 0.37520757036320135, 0.3792235794586732, 0.3674935271379118, 0.3611337201596767, 0.35125305392213313, 0.3664919300844856, 0.3579704279956572, 0.358177753384499, 0.37499817195074525, 0.3516562903372973, 0.36848902222061275, 0.37098927200570997, 0.37174441270968495, 0.3886868230103716, 0.36849470644751015, 0.3531273581982389, 0.3660184144471571, 0.37421249364520986, 0.3748011891273599, 0.3667490633350669, 0.3643053767691348, 0.37450089440772344, 0.37444961906465535, 0.3669995936729452, 0.37039543743080955, 0.38952702733085437, 0.39265704210208474, 0.3686957350274658, 0.3655954713695774, 0.39540933398529887, 0.37815322328870205, 0.3858970995974161, 0.37387897242682383, 0.37425000457020074, 0.38926156392941874, 0.3786647673787586, 0.37843504400156874, 0.4000659274078869, 0.38383779517721894, 0.38883355182513374, 0.38116612786189746, 0.39886108679952575, 0.4039541971048011, 0.4085461224575399, 0.4040325807553588, 0.40590017215878355, 0.38623136059180196, 0.38693335685221586, 0.41144327609343273, 0.3980357802459313, 0.4007313655798926, 0.40366758222636934, 0.38523547610669745, 0.42097171660804866, 0.4246416387294291, 0.40921079142786126, 0.4052840040850581, 0.4231068941344525, 0.38739459854824576, 0.4194799537094785, 0.41747657055327414, 0.4164134435739149, 0.3939945743985328, 0.393845445202554, 0.4172966992665155, 0.4208380446276244, 0.408174136686641, 0.43686796033608855, 0.3842315211042981, 0.4022488394277353, 0.41533097460427704, 0.4123304054533661, 0.3947430606748836, 0.4344836208585869, 0.42245670334509045, 0.4120090134880122, 0.4084896664774301, 0.4208405370477076, 0.4342218170389898, 0.4342225538966173, 0.414541769489719, 0.42016579197290554, 0.43672865715023934, 0.3970657474470927, 0.4120631425404081, 0.4072342333657777, 0.4361969401840778, 0.40728934426043256, 0.4082725720443562, 0.43000999789721533, 0.4488575828864294, 0.4490402939628956, 0.42708765610358584, 0.4119907574152903, 0.4171651719850214, 0.46127884272559017, 0.424621216852364, 0.42663686249551236, 0.443727373143238, 0.4234333980655042, 0.4163527505554478, 0.41962003758446514, 0.43725314623146666, 0.4135830312939909, 0.4485339165719993, 0.438206387026345, 0.42548432996423513, 0.4139385414218493, 0.422614497990877, 0.44258191624619797, 0.5020544356643679, 0.42181872726217207, 0.45136614169414135, 0.42586187040889817, 0.4617275644605066, 0.42785005136758236, 0.4181436715811929, 0.43456211805745376, 0.456493051905258, 0.4419752404130265, 0.439949865836431, 0.458016514120733, 0.45355927485370023, 0.4266304138993077, 0.4774111132959233, 0.43147677636942733, 0.42984621565533326, 0.4257584124226888, 0.41347907219703, 0.44227188734301165, 0.44509480125270784, 0.42359101505694435, 0.45620652116542937, 0.4532003666402078, 0.4544208156419735, 0.4288948582868804, 0.45772276510365817, 0.4652134206776014, 0.4481767811538542, 0.45044724102926387, 0.45808432965228957, 0.4832801581086481, 0.4330355538119215, 0.450099578350965, 0.44405912482818843, 0.4245691280629413, 0.47918898603130206, 0.4441465862088508, 0.4232571859679678, 0.42079631317699073, 0.46119900758140814, 0.4447093260310152, 0.45832808096619215, 0.4615354106998911, 0.46208279893970955, 0.44396297247651234, 0.44644354116719437, 0.4640259245666219, 0.466397661642701, 0.46452038604811785, 0.4498248620908342, 0.4491576017337103, 0.465446551038208, 0.47035092626716574, 0.4713521593012938, 0.4597488452506927, 0.4512224776633814, 0.48416280633240355, 0.4734927043455708, 0.46729338517887337, 0.46055449181357305, 0.44595291037751617, 0.45059747884606977, 0.4550898942740305, 0.4553583972247354, 0.484807043427638, 0.47273430763972085, 0.45941312947109636, 0.4590342458538419, 0.4751177701332113, 0.47533442642466694, 0.45637929342760175, 0.4544383191900766, 0.4463540438526109, 0.45517611408414427, 0.4642113188975582, 0.44581558580930325, 0.4676268981386195, 0.46861990691874833, 0.47670730448090565, 0.4613685188541079, 0.46828112538502203, 0.47280027833310706, 0.44121663249097764, 0.4606796685479554, 0.5259090004415781, 0.48354477134040175, 0.469667333146265, 0.4692415113266393, 0.45400641179944884, 0.47124824484846756, 0.4692198993460111, 0.44249545135900525, 0.4556816854969571, 0.4647824307538423, 0.47515893393360514, 0.44086019356972445, 0.47874322776481804, 0.48824521492911027, 0.4832109012732319, 0.45331234720138397, 0.46669590011166007, 0.4659509803990231, 0.4592359331253843, 0.4794528412395248, 0.4734935767528619, 0.4946094546649678, 0.47707713397183255, 0.4516702479244593, 0.44164761501893984, 0.48553112554637823, 0.4603754159190929, 0.4560155915005096, 0.48063205852739366, 0.4870615708185177, 0.503982417563926, 0.4785489882890354, 0.44539653152848285, 0.4539821001874539, 0.47518135870204253]\n",
        "test_acc_list_const = [71.6080208973571, 85.50245851259987, 89.67040565457899, 89.58589428395821, 90.46173939766442, 90.5577750460971, 91.50276582667486, 92.0520897357099, 91.96757836508912, 92.47464658881377, 92.6820835894284, 92.88952059004302, 93.56177012907192, 93.4580516287646, 93.66548862937923, 93.80377996312231, 93.34665027658266, 93.71158574062692, 93.5041487400123, 93.57329440688383, 94.06499692685925, 93.33896742470804, 93.72311001843885, 92.94330055316533, 93.68853718500307, 94.18792255685311, 93.96127842655194, 93.91518131530424, 93.82682851874615, 94.03042409342348, 94.1917639827904, 93.77304855562384, 93.9420712968654, 93.68853718500307, 94.08420405654579, 93.77304855562384, 93.91518131530424, 94.14566687154272, 93.93822987092808, 94.14566687154272, 94.06499692685925, 93.73079287031346, 93.8921327596804, 94.07267977873387, 94.01889981561156, 94.22633681622618, 93.86140135218193, 93.90749846342962, 93.97664413030117, 94.07652120467118, 94.03042409342348, 93.97280270436386, 94.21865396435157, 94.07267977873387, 94.09956976029503, 94.21865396435157, 94.30700676090964, 93.88444990780577, 94.06883835279656, 94.30316533497235, 94.23017824216349, 94.19944683466503, 94.05731407498463, 94.36846957590657, 94.26475107559926, 94.04578979717272, 94.31468961278426, 94.13030116779349, 94.3262138905962, 94.06499692685925, 93.98432698217579, 94.34926244622004, 94.3262138905962, 94.10341118623234, 94.35694529809466, 93.99969268592501, 94.21481253841426, 94.41840811309157, 94.13414259373079, 94.23017824216349, 94.39920098340504, 94.10341118623234, 94.0381069452981, 94.36846957590657, 94.44529809465274, 94.29548248309773, 94.39920098340504, 94.2839582052858, 94.34542102028273, 94.51444376152428, 94.34926244622004, 94.1418254456054, 94.45682237246466, 94.5221266133989, 94.41072526121697, 94.45298094652735, 93.9958512599877, 94.24938537185002, 94.57974800245852, 94.1418254456054, 94.18792255685311, 94.34926244622004, 94.48371235402581, 94.39535955746773, 94.39151813153042, 94.39535955746773, 94.41072526121697, 94.1418254456054, 94.24554394591273, 94.39535955746773, 94.49907805777505, 94.3262138905962, 94.22633681622618, 94.34542102028273, 94.42224953902888, 94.27627535341118, 94.46450522433928, 94.1840811309158, 94.1917639827904, 94.50291948371235, 94.09956976029503, 94.27243392747388, 94.38383527965581, 94.40304240934235, 94.10725261216963, 94.36462814996926, 94.52980946527352, 94.36078672403197, 94.50676090964966, 94.1917639827904, 94.25706822372464, 94.31084818684695, 94.43761524277812, 94.36462814996926, 94.42224953902888, 94.21097111247695, 94.38383527965581, 94.18023970497849, 94.21865396435157, 94.5259680393362, 94.53365089121081, 94.21865396435157, 94.56822372464659, 94.21865396435157, 94.31468961278426, 94.41072526121697, 94.50291948371235, 94.35310387215735, 94.51060233558697, 94.26090964966195, 94.3338967424708, 94.4299323909035, 94.40688383527966, 94.66425937307929, 94.41072526121697, 94.39535955746773, 94.23786109403811, 94.44145666871543, 94.30316533497235, 94.3761524277812, 94.04578979717272, 94.36846957590657, 94.3300553165335, 94.44145666871543, 94.64505224339274, 93.99200983405039, 94.53365089121081, 94.52980946527352, 94.3799938537185, 94.38767670559312, 94.54133374308543, 94.36078672403197, 94.44913952059004, 94.28779963122311, 94.48755377996312, 94.51828518746159, 94.4721880762139, 94.45682237246466, 94.39920098340504, 94.51444376152428, 94.10341118623234, 94.61432083589429, 94.41840811309157, 94.21865396435157, 94.46450522433928, 94.44913952059004, 94.4798709280885, 94.61432083589429, 94.22633681622618, 94.63352796558083, 94.51060233558697, 94.44145666871543, 94.5221266133989, 94.50291948371235, 93.93438844499079, 94.4721880762139, 94.48371235402581, 94.63736939151813, 94.5759065765212, 94.61047940995698, 94.39920098340504, 94.56822372464659, 94.21481253841426, 94.59895513214505, 94.32237246465888, 94.59127228027043, 94.25322679778733, 94.4299323909035, 94.54517516902274, 94.3338967424708, 94.40688383527966, 94.08420405654579, 94.5259680393362, 94.59895513214505, 94.6681007990166, 94.61047940995698, 94.44529809465274, 94.48371235402581, 94.48755377996312, 94.67962507682851, 94.36846957590657, 94.09572833435772, 94.35694529809466, 94.43377381684081, 94.55669944683467, 94.61047940995698, 94.36462814996926, 94.6220036877689, 94.69499078057775, 94.39535955746773, 94.47602950215119, 94.43761524277812, 94.3300553165335, 94.68730792870313, 94.56822372464659, 94.45298094652735, 94.61816226183159, 94.40304240934235, 94.48371235402581, 94.62968653964352, 94.54517516902274, 94.51828518746159, 94.60663798401967, 94.55669944683467, 94.50676090964966, 94.52980946527352, 94.59511370620774, 94.46066379840197, 94.40304240934235, 94.49139520590043, 94.4299323909035, 94.34157959434542, 94.6681007990166, 94.58358942839583, 94.61047940995698, 94.34926244622004, 94.57974800245852, 94.50676090964966, 94.71035648432698, 94.70651505838967, 94.5221266133989, 94.3761524277812, 94.50291948371235, 94.59127228027043, 94.52980946527352, 94.41456668715428, 94.53749231714812, 94.29932390903504, 94.5720651505839, 94.68730792870313, 94.61816226183159, 94.55285802089736, 94.6681007990166, 94.70651505838967, 94.59127228027043, 94.40304240934235, 94.69114935464044, 94.68730792870313, 94.5221266133989, 94.45682237246466, 94.51828518746159, 94.57974800245852, 94.61432083589429, 94.6220036877689, 94.34542102028273, 94.53749231714812, 94.40688383527966, 94.49523663183774, 94.42609096496619, 94.6757836508912, 94.42224953902888, 94.43377381684081, 94.56438229870928, 94.65273509526736, 94.49139520590043, 94.4721880762139, 94.3338967424708, 94.56054087277197, 94.70651505838967, 94.45682237246466]\n",
        "train_loss_list_cosine = [1.4922631353059113, 0.4829037673670425, 0.3722163860390826, 0.33177220926375245, 0.30060175129876227, 0.2739472426776964, 0.2571369293057499, 0.24421742562517565, 0.23246381484315323, 0.22585582048670064, 0.2115350698794776, 0.2027042203842786, 0.19336028488953586, 0.18796989869901803, 0.17635167322467335, 0.17350608562712425, 0.16392932351688705, 0.15824737119157786, 0.15103116432623812, 0.14280527628211148, 0.13911624957976465, 0.12778460819445814, 0.12645664817696503, 0.12117257786202963, 0.11404008718162048, 0.11024573898614261, 0.10301367604352918, 0.09962807324661957, 0.09590673247266429, 0.09140933892338822, 0.08890839097617563, 0.08312069913650028, 0.07912878103322049, 0.07539688910895247, 0.0703017507051307, 0.06730901317161112, 0.06545131962347604, 0.06006853946239806, 0.05934957680948644, 0.055661115047034776, 0.05501487654656535, 0.04808283364715756, 0.048917624036854686, 0.04978224897863177, 0.04599738403836765, 0.043476243917943865, 0.04154425250810538, 0.044289368833225914, 0.039924735993999975, 0.038134503976484824, 0.03573395804436448, 0.03633099462935413, 0.03407486775469762, 0.03466019954098273, 0.03175460545031914, 0.030751291346965928, 0.02861118235254312, 0.026954070920645837, 0.026345375887917098, 0.027870583739497655, 0.02564559653584358, 0.02595152790995118, 0.02664908538916373, 0.017370514487667858, 0.02682043477352759, 0.02288949422978072, 0.023653404380517905, 0.021177587269342865, 0.01825827019425427, 0.020935813946993946, 0.02142309610224594, 0.021006980622225117, 0.017297085196421504, 0.020975425832167893, 0.016085938927383088, 0.019187606733535582, 0.016529617174421272, 0.017658664713450265, 0.017461861724943822, 0.01473946469002416, 0.013888732157426767, 0.018813401251478592, 0.018245284999345322, 0.013429369967483517, 0.013213716673361565, 0.014179550147890478, 0.013165565478723676, 0.013442610755386424, 0.011938090494525969, 0.013952531346849035, 0.012777711567658235, 0.01361946394184095, 0.01415981548655886, 0.0132249127186142, 0.008202303269795845, 0.013768190907590946, 0.01187117434464689, 0.011072834069390408, 0.011375907309212407, 0.008056683960140176, 0.010813868758558904, 0.010755819991023294, 0.011055263281323623, 0.009854590676922565, 0.009897416544746738, 0.007694702545891319, 0.010974907935630917, 0.009073475042950686, 0.00957946586983009, 0.008521491170432235, 0.009181163735296882, 0.008033073926435217, 0.0075308985053745, 0.007736907337884813, 0.008905222457779166, 0.0075535059801524005, 0.008956405532912782, 0.00652504011866664, 0.007371700082288889, 0.007105531808951359, 0.009608815764438242, 0.006718999051766881, 0.006360923469938631, 0.006009158956909616, 0.005984226889401126, 0.006414240613540077, 0.008046470651133564, 0.006813095370703897, 0.004941387222356937, 0.006961080895634556, 0.0061504495415253034, 0.0044804993527444515, 0.005129817030924186, 0.0051584241011990275, 0.005904302868943308, 0.007040096893751609, 0.006497695825108162, 0.006231063241578372, 0.0045172427992303645, 0.004859256595798965, 0.005357292924210756, 0.0036115553579709734, 0.004059441841032762, 0.003976077818785122, 0.004686579279045762, 0.0047765986038821135, 0.0052203105924466305, 0.004452093922426263, 0.00366650621972908, 0.004813907496713725, 0.003619882242262452, 0.003379426909955734, 0.003642032724296165, 0.003996376050219234, 0.0027063930590780893, 0.0038246032934270147, 0.0035842454059730284, 0.0031291756938454703, 0.003011805406823518, 0.004053137657470737, 0.003489878551598058, 0.002363212944410382, 0.003003648613003568, 0.002955618500260455, 0.002723948648240625, 0.0037992216377342554, 0.0022372855783796795, 0.002972214323449715, 0.0029076020603400095, 0.002062946104120749, 0.0018581666937362376, 0.002313281514427136, 0.0030319557007007047, 0.0023327526890917524, 0.001145549262753536, 0.0016048090303144983, 0.0012414230531554533, 0.0032581396387386516, 0.0029362018629135516, 0.001846583708184242, 0.0012200965248589121, 0.001480849612214921, 0.002236391388236972, 0.0015825234965880586, 0.0009787926420108245, 0.001177633173575748, 0.0017891079141621141, 0.001687879517755926, 0.0027874750058864543, 0.0015881228617325382, 0.0013229923813940598, 0.0013549324787301051, 0.0013446073458035835, 0.0015000026920124656, 0.0012523066383357765, 0.000858102498131121, 0.001035546338261591, 0.0019881639752974524, 0.0016324728715111814, 0.001434380197954095, 0.0009871888154247414, 0.0008098082351434123, 0.0006027996978315856, 0.0008483088922217938, 0.0007788997386943644, 0.0014305688407895846, 0.0007751793022755421, 0.0005314110757599325, 0.0008008613197451418, 0.0005263145778683319, 0.0005657160187561332, 0.0008550505100606119, 0.0004061993359216422, 0.0008238756363850807, 0.0004022425374623086, 0.0007475109217440491, 0.0008010522570415786, 0.0008719455779264424, 0.0008102537067081855, 0.0006836875085969626, 0.000508847326879101, 0.00048076220441707043, 0.0003452522178527452, 0.0005887742460472115, 0.0007575123468680768, 0.0007316459814930954, 0.0006069562958639393, 0.00040482217438505993, 0.000413289390024444, 0.0002512041357034269, 0.00035321101188540014, 0.0002289985919775472, 0.00031013075728369315, 0.00048718760862263036, 0.00024815363102110633, 0.0002127035124524638, 0.00040036594692248164, 0.00022304668872061623, 0.0002539508311412804, 0.00033001078329677927, 0.0005046333238317957, 0.0002472649033615957, 0.00045928622355630194, 0.00022344069632032276, 0.00026002821110843074, 0.00015903297622683538, 0.00040398000405654787, 0.0002816041986039678, 0.00024018690979448482, 0.00029882328487923265, 0.00034577957207554183, 0.00028206157859465874, 0.00017730721445880266, 0.00011439717115794378, 0.00023043857095496602, 0.00013369225500067483, 0.00022097409422235014, 0.00013705560435689807, 0.000107482878806249, 0.0002181373778419168, 9.028549420162597e-05, 8.780925534434591e-05, 0.00015708037552040194, 0.00013996531600239778, 0.00015848159901898015, 9.64823931015096e-05, 0.00021168788567095436, 0.000136050276398834, 0.00010472044780222292, 0.0002206477002030788, 0.00013934975601720095, 0.00010074895917807085, 9.32180454911494e-05, 0.0001472607405713623, 0.00011569483834266491, 7.036176643037457e-05, 0.0001351957850342979, 0.000159376835863944, 0.00010674569268919185, 0.0001185344251126515, 8.718404802724013e-05, 0.00011900450702660869, 0.00012125460894170754, 0.00011230571605721275, 0.00010454212349596384, 0.0001487989837777661, 6.830416546227417e-05, 6.393169394098347e-05, 0.00020005663507281302, 0.00010431355027100938, 0.00017086659031600928, 7.99108349451789e-05, 0.00011386882648142751, 9.478551902827757e-05, 0.00010300004370941282, 8.344318782375742e-05, 0.0001274786575664539, 8.525987476745569e-05, 7.452874058836112e-05, 0.00011550953129777401]\n",
        "train_acc_list_cosine = [47.73742721016411, 84.54632080465855, 88.4425622022234, 89.96717840127052, 90.86712546320804, 91.64849126521969, 92.33245103229221, 92.79195341450503, 93.21757543673901, 93.32980412916888, 93.78295394388566, 94.04129168872419, 94.3928004235045, 94.53679195341451, 94.81206987824245, 95.05134992059291, 95.20169401799895, 95.48755955532027, 95.65484383271573, 95.92165166754897, 95.9640021175225, 96.39385918475384, 96.32186341979883, 96.55479089465325, 96.74748544203283, 96.74748544203283, 97.07146638433034, 97.24722075172049, 97.19640021175225, 97.32980412916888, 97.39332980412917, 97.62413975648491, 97.67496029645315, 97.79777660137638, 97.90365272631021, 97.96717840127052, 98.07940709370037, 98.21492853361568, 98.19163578613023, 98.32715722604553, 98.32292218104817, 98.55584965590259, 98.57702488088935, 98.43938591847538, 98.58973001588141, 98.68713605082054, 98.66807834833246, 98.61302276336686, 98.80359978824775, 98.78454208575967, 98.83748014822658, 98.80783483324511, 98.86077289571202, 98.89253573319216, 98.9433562731604, 99.02805717310747, 99.05982001058761, 99.13816834303864, 99.14452091053468, 99.0979354155638, 99.13393329804128, 99.1148755955532, 99.10217046056114, 99.45579671784013, 99.15510852302806, 99.22710428798305, 99.22498676548439, 99.32451032292218, 99.39650608787719, 99.32662784542086, 99.27368978295394, 99.3774483853891, 99.41132874536792, 99.29698253043938, 99.45367919534145, 99.3668607728957, 99.47061937533087, 99.43885653785071, 99.43250397035469, 99.51932239280042, 99.5404976177872, 99.33509793541556, 99.3774483853891, 99.5299100052938, 99.54473266278454, 99.5129698253044, 99.57014293276866, 99.57014293276866, 99.6294335627316, 99.48967707781895, 99.55320275277924, 99.5659078877713, 99.53202752779248, 99.58073054526204, 99.73742721016411, 99.53838009528852, 99.61461090524087, 99.6294335627316, 99.63366860772896, 99.7289571201694, 99.63155108523029, 99.64213869772367, 99.61884595023822, 99.71201694017999, 99.69084171519323, 99.74589730015882, 99.63790365272631, 99.72260455267337, 99.69719428268925, 99.72260455267337, 99.66754896770779, 99.70354685018528, 99.73954473266278, 99.72683959767072, 99.67601905770249, 99.73319216516676, 99.71625198517734, 99.80518793012176, 99.7289571201694, 99.77130757014294, 99.6929592376919, 99.7924827951297, 99.77766013763896, 99.784012705135, 99.80730545262044, 99.78613022763366, 99.76071995764956, 99.79036527263102, 99.83906829010058, 99.76707252514558, 99.7924827951297, 99.86659608258337, 99.84118581259926, 99.8284806776072, 99.79883536262572, 99.77977766013764, 99.79671784012704, 99.79671784012704, 99.83059820010588, 99.84965590259397, 99.8369507676019, 99.86871360508205, 99.89412387506617, 99.87083112758073, 99.85177342509265, 99.85177342509265, 99.81365802011646, 99.85389094759132, 99.87294865007941, 99.84118581259926, 99.87294865007941, 99.89200635256749, 99.88353626257279, 99.87294865007941, 99.90682901005823, 99.87506617257809, 99.87506617257809, 99.89624139756485, 99.90047644256221, 99.85812599258867, 99.88988883006881, 99.91953414505029, 99.90894653255691, 99.89412387506617, 99.90047644256221, 99.88988883006881, 99.92165166754897, 99.88777130757015, 99.90047644256221, 99.92588671254632, 99.93223928004235, 99.91953414505029, 99.88565378507147, 99.91953414505029, 99.95764955002647, 99.94917946003176, 99.95341450502912, 99.90471148755955, 99.91529910005293, 99.94070937003706, 99.95764955002647, 99.95764955002647, 99.93435680254103, 99.94706193753309, 99.9724722075172, 99.96611964002118, 99.9364743250397, 99.94282689253573, 99.91953414505029, 99.94706193753309, 99.94917946003176, 99.96188459502382, 99.95341450502912, 99.94917946003176, 99.95129698253044, 99.96823716251986, 99.97458973001588, 99.9364743250397, 99.9555320275278, 99.95129698253044, 99.9640021175225, 99.97458973001588, 99.97458973001588, 99.9640021175225, 99.97882477501324, 99.94706193753309, 99.97458973001588, 99.97882477501324, 99.9724722075172, 99.98094229751192, 99.98305982001058, 99.96188459502382, 99.98305982001058, 99.97035468501853, 99.98517734250926, 99.97458973001588, 99.95976707252514, 99.9640021175225, 99.9640021175225, 99.97670725251456, 99.98729486500794, 99.97670725251456, 99.98305982001058, 99.97670725251456, 99.97882477501324, 99.97882477501324, 99.97670725251456, 99.98305982001058, 99.98729486500794, 99.98517734250926, 99.98941238750662, 99.98941238750662, 99.98941238750662, 99.98729486500794, 99.98941238750662, 99.9915299100053, 99.98094229751192, 99.9915299100053, 99.98517734250926, 99.98094229751192, 99.98729486500794, 99.98941238750662, 99.98094229751192, 99.98941238750662, 99.98305982001058, 99.99364743250398, 99.98517734250926, 99.98729486500794, 99.98941238750662, 99.9915299100053, 99.98094229751192, 99.98305982001058, 99.9915299100053, 99.99576495500264, 99.98517734250926, 99.9915299100053, 99.98941238750662, 99.99576495500264, 99.99576495500264, 99.98941238750662, 99.99364743250398, 100.0, 99.9915299100053, 99.9915299100053, 99.98941238750662, 99.99576495500264, 99.98729486500794, 99.99576495500264, 99.99364743250398, 99.9915299100053, 99.99364743250398, 99.99364743250398, 99.99576495500264, 99.98941238750662, 99.9915299100053, 99.99788247750132, 99.98941238750662, 99.9915299100053, 99.99788247750132, 99.99576495500264, 99.99576495500264, 99.99364743250398, 99.9915299100053, 99.99576495500264, 99.99364743250398, 99.99364743250398, 99.99788247750132, 100.0, 99.98941238750662, 99.99576495500264, 99.99364743250398, 99.99576495500264, 99.9915299100053, 99.99576495500264, 99.99364743250398, 99.99576495500264, 99.9915299100053, 99.99788247750132, 99.99576495500264, 99.99576495500264]\n",
        "test_loss_list_cosine = [0.8128060245630788, 0.43769084055926283, 0.3670157931160693, 0.3468363919094497, 0.320717461845454, 0.29874755628407, 0.2880513122414841, 0.27089574385215254, 0.2712526289636598, 0.25813622246770296, 0.27607545629143715, 0.2508813175281473, 0.23157318663217275, 0.23963026514313385, 0.23259784851004095, 0.21799716919514478, 0.2553474395992417, 0.23297278822271847, 0.23411084861293727, 0.24059130224015782, 0.22228851220479198, 0.23491562519441633, 0.23474602972832964, 0.24284341398115253, 0.2531394691699568, 0.2231898330809439, 0.23778781842659502, 0.2260036576612323, 0.2408501879476449, 0.2531653588601187, 0.2437402953521586, 0.25621635543511195, 0.25155149374668506, 0.25073284860335143, 0.24820336959708264, 0.2527083886933385, 0.265060295743466, 0.2638632501977697, 0.27953584988911945, 0.28330178079469237, 0.2898024614425559, 0.285278165183377, 0.28805743263322203, 0.29073836449898927, 0.3027702011898452, 0.3096775676069014, 0.30173745603921515, 0.3021223259468873, 0.30385272365574745, 0.3038429137702812, 0.31642839670473455, 0.31861640270068947, 0.3238279426963452, 0.3290770745598802, 0.3349987664123011, 0.3213929162525079, 0.33029763011590524, 0.34525904689422426, 0.3447993094028503, 0.330581444653445, 0.321795464146371, 0.3393226447423883, 0.33919910747813536, 0.36219359443102983, 0.34984895151437206, 0.34508059543155717, 0.3312660858683361, 0.3478064838449891, 0.37045160054649207, 0.36637233636871563, 0.3615635437069132, 0.34741060503338483, 0.36895488022698786, 0.3510999241478595, 0.3899413192069487, 0.3609655104285362, 0.3731252212287383, 0.38873775874940203, 0.3712333329387155, 0.37048297439354894, 0.39439879441816433, 0.373478519492874, 0.36712522848564033, 0.3914665420420979, 0.38469330903471394, 0.3913668092230664, 0.38145966287337096, 0.37784753624788103, 0.38290000464036766, 0.3881754014622785, 0.39466715339279057, 0.38420211229765533, 0.3928751589150588, 0.3871026979576723, 0.39617241206852827, 0.42028651262323063, 0.38088225707521334, 0.3810242618087168, 0.38620046643978534, 0.41002833922667536, 0.40598774530157883, 0.4145270490324965, 0.4107616166036357, 0.39369509952124576, 0.3983155651949346, 0.4124191829971239, 0.40144294117778245, 0.4075972944425017, 0.41423957538791, 0.4235737093589634, 0.4338786544680011, 0.41868019625818464, 0.4211389536400983, 0.42915419865783083, 0.43854167406428973, 0.44444839669135855, 0.4239410953870153, 0.4140438513154639, 0.4214930013826519, 0.4469692508014394, 0.42807763744620425, 0.4140391830473627, 0.40559402319109616, 0.4296429092794949, 0.447968863443855, 0.4537148197985017, 0.4160180985562357, 0.42932759126757875, 0.4655364652474721, 0.44017627959450084, 0.4476152099646153, 0.45807484502666723, 0.4661675389518267, 0.46650424552624864, 0.4483312015951264, 0.43905310305839806, 0.4307253006571794, 0.4221340075886224, 0.43024291792957514, 0.4534414633743319, 0.439005637879246, 0.455770535284982, 0.4492703357884916, 0.46906485925337266, 0.4463952654680493, 0.4687405661497192, 0.4440763243108842, 0.4453616064936653, 0.466629167502819, 0.4585120371433304, 0.45512742501017, 0.4547710154278606, 0.46565503765847166, 0.47993873200361054, 0.46249571734783695, 0.47604353346076667, 0.4764781709778689, 0.4798887720623729, 0.47362343249294686, 0.477798045156341, 0.475341152007162, 0.46233028874677773, 0.47649588846765895, 0.4905768512090778, 0.49597619045023605, 0.4826731762720966, 0.46256263993963526, 0.4635071344308409, 0.4836937281412675, 0.4737923650753538, 0.47685492698641896, 0.49306667890107514, 0.5079087016615542, 0.47638218596294596, 0.47670910018496215, 0.5044073596980203, 0.5164688170211864, 0.5278736670528922, 0.4981932266542286, 0.4995226736783105, 0.5136372742845732, 0.47614785384697217, 0.5164846121424845, 0.4969261799825985, 0.504426286427998, 0.5065735648545966, 0.5321676667674682, 0.5085760319283615, 0.5058678923307133, 0.505933805387102, 0.5226816843154237, 0.5136628734705714, 0.49541927424862103, 0.5014571096729853, 0.5036171923942782, 0.4995590589264883, 0.5177521720453275, 0.5068038706028578, 0.5099713094623796, 0.4981300873846254, 0.5104206896560523, 0.5262805088377539, 0.5344062875499767, 0.5306157725908812, 0.5357992586351055, 0.5134817360370767, 0.5160781835849562, 0.5250964877469575, 0.5374465012448091, 0.5358220952946473, 0.5378625886514783, 0.5421092164064711, 0.5452210189199403, 0.5411839835076392, 0.5549019162050065, 0.5455894065546054, 0.5472353847934773, 0.5522625445497825, 0.5455132025983367, 0.538114388518985, 0.5509232937326363, 0.536594347077577, 0.5530879087015694, 0.5591187921909652, 0.5578411847065368, 0.5505201403601163, 0.564152417302716, 0.5473365803345052, 0.5458330702511411, 0.5650019636080947, 0.5671965913600562, 0.5513512968934853, 0.5562908629117552, 0.5620296227371356, 0.5617975970529312, 0.5581122653555426, 0.5675084015614736, 0.5657756982859699, 0.5526409040846606, 0.5721038452220634, 0.5690990948042942, 0.5608643038853474, 0.5609114988775556, 0.560604001846692, 0.5697500870121397, 0.5728723204822517, 0.5595448732640886, 0.5570606883866632, 0.5764513230818671, 0.556780993596048, 0.5647389884220948, 0.5543315944429624, 0.5563175826808255, 0.5460904273889301, 0.5574481183030716, 0.552725079560689, 0.5607348622220075, 0.5605667959076955, 0.5626120614498515, 0.5649992083380507, 0.5637176143309083, 0.5681553194373526, 0.5555440176634446, 0.5632415316604059, 0.5714907293874478, 0.5667051952526284, 0.5770144956528812, 0.5655391789224072, 0.57731314366444, 0.5691993516018413, 0.5740196594384079, 0.5696190810367446, 0.5625503671834332, 0.5508576962696251, 0.5676857517648708, 0.575283505166333, 0.5721206341997958, 0.5749247564988977, 0.5699750101832929, 0.580029735533411, 0.5632244463092374, 0.5753009883919731, 0.5712149130710054, 0.5708004219147066, 0.5698616763567734, 0.5771289975888495, 0.577879674463332, 0.5692181185472245, 0.591953951887102, 0.5678756476480368, 0.5756764801849118, 0.578166978474816, 0.5680953554498652, 0.5808629620039616, 0.5650976837804431, 0.5722748214018294, 0.5711645722097042, 0.5751072838172024, 0.5794820262486681, 0.5856684064892047]\n",
        "test_acc_list_cosine = [75.21511985248924, 86.48970497848802, 88.72157344806392, 89.39766441303011, 90.33113091579594, 91.21850030731407, 91.4259373079287, 92.23647818070067, 92.30562384757222, 92.6859250153657, 91.92532267977873, 92.7819606637984, 93.44652735095268, 93.21988322065151, 93.53872157344806, 93.85371850030731, 92.85494775660726, 93.56561155500921, 93.33512599877075, 93.48494161032575, 93.96896127842655, 93.75768285187462, 93.72311001843885, 93.5579287031346, 93.30439459127228, 94.19560540872772, 93.9459127228027, 94.2340196681008, 93.98048555623848, 93.700061462815, 94.24554394591273, 93.68085433312845, 93.82298709280884, 94.05731407498463, 94.24938537185002, 94.29164105716042, 93.83835279655808, 94.26090964966195, 94.03042409342348, 93.97280270436386, 94.00353411186232, 94.06883835279656, 94.13414259373079, 94.00737553779963, 94.12261831591887, 93.93822987092808, 94.16871542716656, 93.9958512599877, 93.96127842655194, 94.22249539028887, 93.93438844499079, 93.91518131530424, 94.0918869084204, 94.01121696373694, 94.15719114935465, 94.29164105716042, 94.31853103872157, 94.01889981561156, 94.15719114935465, 93.88060848186846, 94.54133374308543, 94.34542102028273, 94.14950829748003, 94.09572833435772, 94.36078672403197, 94.21481253841426, 94.3262138905962, 94.27627535341118, 93.92286416717886, 94.05731407498463, 94.09572833435772, 94.41456668715428, 94.24554394591273, 94.31853103872157, 94.24170251997542, 94.06115550092194, 94.0419483712354, 93.95359557467732, 94.30316533497235, 94.42224953902888, 94.1917639827904, 94.02274124154886, 94.43761524277812, 94.12645974185618, 94.20712968653964, 94.40304240934235, 94.35694529809466, 94.29164105716042, 94.48371235402581, 94.13030116779349, 94.31853103872157, 94.3338967424708, 94.41840811309157, 94.66041794714198, 94.48755377996312, 94.09956976029503, 94.26090964966195, 94.34157959434542, 94.38767670559312, 94.4798709280885, 94.38767670559312, 94.36078672403197, 94.16871542716656, 94.64505224339274, 94.36846957590657, 94.48371235402581, 94.28011677934849, 94.46450522433928, 94.28779963122311, 94.36078672403197, 94.35694529809466, 94.55285802089736, 94.35310387215735, 94.48755377996312, 94.34926244622004, 94.47602950215119, 94.64889366933005, 94.46450522433928, 94.44145666871543, 94.54133374308543, 94.52980946527352, 94.54901659496005, 94.69883220651506, 94.58743085433314, 94.16871542716656, 94.41456668715428, 94.56438229870928, 94.5759065765212, 94.21097111247695, 94.54517516902274, 94.44529809465274, 94.46834665027659, 94.27627535341118, 94.34157959434542, 94.71035648432698, 94.49139520590043, 94.60663798401967, 94.75645359557468, 94.74108789182544, 94.66041794714198, 94.59895513214505, 94.66041794714198, 94.57974800245852, 94.57974800245852, 94.71035648432698, 94.54901659496005, 94.7679778733866, 94.7679778733866, 94.56438229870928, 94.67194222495391, 94.66425937307929, 94.74492931776275, 94.79486785494775, 94.44529809465274, 94.73724646588813, 94.43761524277812, 94.72956361401353, 94.72572218807622, 94.74877074370006, 94.66041794714198, 94.4798709280885, 94.80639213275968, 94.61432083589429, 94.50676090964966, 94.70651505838967, 94.70651505838967, 94.59895513214505, 94.78334357713584, 94.76413644744929, 94.79870928088506, 94.69883220651506, 94.59511370620774, 94.42609096496619, 94.87169637369392, 94.86785494775661, 94.74492931776275, 94.74108789182544, 94.29932390903504, 94.86785494775661, 94.84864781807006, 94.68346650276582, 94.94852489244008, 94.69499078057775, 94.82175783650891, 94.86017209588199, 94.89090350338046, 94.6258451137062, 94.82559926244622, 94.83328211432084, 94.90242778119237, 94.88322065150584, 94.89090350338046, 94.96004917025199, 94.87553779963122, 94.9139520590043, 94.91779348494161, 94.99462200368777, 94.94852489244008, 94.85248924400737, 94.83712354025815, 94.90626920712968, 94.76029502151198, 94.78334357713584, 94.99078057775046, 94.88706207744315, 95.02151198524892, 94.97925629993854, 94.97541487400123, 94.87553779963122, 94.97541487400123, 94.88706207744315, 94.76413644744929, 94.84096496619546, 94.9638905961893, 94.96004917025199, 95.01382913337432, 94.99846342962508, 94.91011063306699, 94.92163491087892, 94.93315918869084, 94.9139520590043, 95.12907191149354, 95.03687768899816, 94.8640135218193, 94.82559926244622, 94.98693915181315, 94.90626920712968, 94.95236631837739, 94.98309772587585, 94.92931776275353, 94.74877074370006, 95.11754763368162, 95.02151198524892, 95.15596189305471, 94.98693915181315, 94.89858635525508, 94.99462200368777, 94.98693915181315, 95.07145052243392, 94.9638905961893, 94.97925629993854, 94.9638905961893, 94.98309772587585, 94.99462200368777, 94.95236631837739, 95.059926244622, 95.01767055931161, 95.11754763368162, 95.02919483712354, 95.13291333743085, 95.09834050399509, 95.109864781807, 95.159803318992, 95.16748617086662, 94.98693915181315, 95.22126613398893, 95.06376767055932, 95.12138905961893, 95.1521204671174, 95.04071911493547, 95.16364474492931, 95.17132759680393, 95.09834050399509, 95.1521204671174, 95.08681622618316, 95.059926244622, 95.20974185617702, 95.059926244622, 95.02151198524892, 95.14443761524278, 95.109864781807, 95.12907191149354, 95.17901044867855, 95.20974185617702, 95.17132759680393, 95.17132759680393, 95.19437615242778, 95.02151198524892, 95.17132759680393, 95.12907191149354, 95.19437615242778, 95.19821757836509, 95.12907191149354, 95.09449907805778, 95.109864781807, 95.24431468961278, 95.12907191149354, 95.16748617086662, 95.01382913337432, 95.22894898586355, 95.06760909649662, 95.11370620774431, 95.21742470805162, 95.159803318992, 95.22894898586355, 95.14059618930547, 95.109864781807, 95.14827904118009, 95.13675476336816, 95.09449907805778]\n",
        "train_loss_list_step = [1.5044204033810271, 0.49208608810817644, 0.37830603914209177, 0.33356322168415475, 0.30051283241529775, 0.2731129997548695, 0.25931339448464275, 0.24751879757416603, 0.23341218238762076, 0.22551919120114025, 0.21245744068246225, 0.20461816869696303, 0.19351729513385754, 0.18888680500591673, 0.1790498158513369, 0.17313903582794718, 0.16563977062863708, 0.15938490460599017, 0.1541340289319434, 0.14407484958246147, 0.13983443950815252, 0.13245242257630277, 0.12638695052443805, 0.12125968426304458, 0.11788717211605249, 0.11147532753424269, 0.10493720971996869, 0.10114793143257862, 0.0986312177905505, 0.09325535373060603, 0.06156983597173802, 0.050082290781091464, 0.04566037622696864, 0.042090283896077454, 0.037587769078418896, 0.03525592588446025, 0.034040165755286976, 0.031216950466235478, 0.030938032096463855, 0.029107897011765093, 0.02691679777953582, 0.024817724369887797, 0.02327188092970408, 0.022008026162917072, 0.021083637177603455, 0.020199724932410693, 0.020445302296316296, 0.01811823503557229, 0.016885934063002497, 0.016305384605991728, 0.015734232263797315, 0.01582022506202922, 0.01498541162761943, 0.013855328222454038, 0.012501976389670114, 0.011526370763357194, 0.012135067156394237, 0.011748958516110058, 0.01063293406628148, 0.010577014861956521, 0.009060478683824204, 0.00822005160518879, 0.007903504668233972, 0.0073660259777244665, 0.007953700653634155, 0.006759841606805863, 0.0069558188274406844, 0.007026840372753726, 0.006894602971896024, 0.0063807274687209935, 0.006584282455781946, 0.006663436767551165, 0.006154599042466102, 0.006103539849245962, 0.006048463034234704, 0.00614482418276391, 0.006322457585395453, 0.006028014029933677, 0.006245754332408476, 0.00581059281254909, 0.005709030747089944, 0.005923201890116833, 0.00537758718227695, 0.005807922808844647, 0.005243748521360034, 0.004974289045318631, 0.005323306708443634, 0.005775554073696229, 0.005093053230784864, 0.005536427160324011, 0.0052108629591284105, 0.004749226128792285, 0.005127630246161776, 0.005065120122888249, 0.004685268356975264, 0.005243820296808683, 0.0049121043785080205, 0.005093204319377071, 0.005370734221114888, 0.005008859195898547, 0.005249464887712999, 0.004638611593474268, 0.004728934781005616, 0.005035177127017733, 0.004871168427265863, 0.005197190184529169, 0.004969428170602996, 0.004836069228517858, 0.005308753678475464, 0.004877718586694237, 0.0046394178739258, 0.004715173941094246, 0.005071522070231865, 0.005326596872854554, 0.004782932753934018, 0.00452435254143787, 0.005128751716483132, 0.004405792564614916, 0.005072576416472445, 0.004683375086275378, 0.004745950062742184, 0.005199869099014116, 0.004980171865863766, 0.004840858398257126, 0.0046297258561474545, 0.004515150684752434, 0.005211585615480793, 0.0046955638231178315, 0.004485690257187711, 0.004824536544108968, 0.004908301922912914, 0.005288558260384356, 0.004324457162535601, 0.004497020012851448, 0.004832310812420976, 0.004629586771150122, 0.00469785524222389, 0.0051049072852895816, 0.004760202388700317, 0.00467975922823293, 0.004756802660750659, 0.004577458516745399, 0.0046352100029977686, 0.0045855785586362005, 0.0045302773612948275, 0.00527981271794404, 0.004842230399004512, 0.005128007588957292, 0.0047336897144657575, 0.00452429031405685, 0.004871112167589785, 0.004707888855899686, 0.004987144301444176, 0.004576647475924656, 0.0050210763291275344, 0.004869554478370365, 0.005145938421950075, 0.0049324849194394005, 0.005007630027365255, 0.004694439974090723, 0.005161294266647788, 0.005086089323139447, 0.0045723088694465674, 0.0049315163145030455, 0.005043683056833177, 0.004782498019489051, 0.005208640262013842, 0.004906343821498318, 0.004504839811582297, 0.004765471186647242, 0.004636792729359163, 0.0048650642755604795, 0.00440384292277286, 0.005331020985203442, 0.004309070902481564, 0.005132160800841049, 0.0048202084057818, 0.0042395592619208135, 0.004579358937877841, 0.004854094481356265, 0.004861267090400903, 0.004641431140822869, 0.004752275634260134, 0.005280723348089562, 0.0049866622946490744, 0.004713922302353166, 0.0049851976106240516, 0.0049522482596579456, 0.0047414097434517405, 0.005198805679831853, 0.005367297160049249, 0.004801289511232152, 0.004936103088396973, 0.004513620775553264, 0.005461517685133368, 0.005038318795404084, 0.004621399451298942, 0.004861979541443869, 0.004728190580562456, 0.00424972596940481, 0.004389661508080736, 0.004675524760544651, 0.004678315578823907, 0.005468495250993464, 0.004904287783485815, 0.004628283689890138, 0.004957924133196958, 0.004207717516179686, 0.004497190112673026, 0.0054004669855449725, 0.004738672002041044, 0.004832978636525801, 0.004593934473861766, 0.00428500973297249, 0.004800252157330026, 0.004579809123577946, 0.0047766751335504105, 0.004927973183699149, 0.003962443585616099, 0.005313499298157754, 0.005448946752569696, 0.004626204171514537, 0.00486521731347835, 0.00464669697920995, 0.00473364783223967, 0.0051715146905747635, 0.004559630797677459, 0.004807513805560901, 0.004414798407140251, 0.0055058369074104515, 0.004735360263094689, 0.00523965430700253, 0.004729446927025576, 0.0046202187999946675, 0.004473174700221971, 0.005083680975845281, 0.00473606128646736, 0.004358955291625135, 0.004462744230992882, 0.00445035025452959, 0.004661599569843557, 0.004881452044679059, 0.004753526896741532, 0.004433994836329803, 0.004789544894031266, 0.004920090539939323, 0.005374149948520697, 0.004787621462456112, 0.004773729829575745, 0.0044936602159881545, 0.004565336937149469, 0.004793149001421886, 0.004954056282359589, 0.00447947610881707, 0.004911790105014495, 0.004962967739427566, 0.004856595992693377, 0.0049429370942105965, 0.004495315723300048, 0.005116432885005868, 0.004663471084030195, 0.005105866048162296, 0.0048063792890729005, 0.004996042520567828, 0.0048235019935209174, 0.0052012274302681025, 0.004979272351725164, 0.004979745390991236, 0.005170751338667516, 0.004858217863982788, 0.004663840651548111, 0.005053441917670759, 0.004584236903877065, 0.004780888221675258, 0.004612757356412744, 0.004703525326821731, 0.005128545914503725, 0.005097627184756964, 0.004888794860495936, 0.004546376856262884, 0.0049637655482588335, 0.004738951851973477, 0.005256142429007358, 0.004507868475276601, 0.004676521270572799, 0.0042853716939203765, 0.004519075942008067, 0.004505532296253924, 0.004830542344546013, 0.004257976696643534, 0.004718432969060035, 0.004490681710655531, 0.004793198622190861, 0.004690485046958793, 0.004381172440937899, 0.004597538895479108, 0.0050219146489527905, 0.004799934776746264, 0.004984567811975109, 0.004093347564194513]\n",
        "train_acc_list_step = [47.394388565378506, 84.38962413975648, 88.32609846479619, 89.65802011646373, 90.93912122816305, 91.76071995764956, 92.30492323980943, 92.69878242456326, 93.1371095817893, 93.283218634198, 93.84859714134463, 93.97988353626258, 94.4203282159873, 94.56643726839597, 94.83324510322922, 95.06405505558496, 95.14452091053468, 95.38168343038645, 95.61461090524087, 95.86871360508205, 95.94282689253573, 96.23928004235044, 96.33456855479089, 96.51667548967708, 96.58231868713605, 96.79618845950239, 96.97829539438857, 97.11805187930122, 97.2006352567496, 97.23451561672843, 98.32927474854421, 98.71254632080466, 98.81630492323981, 98.94970884065643, 99.04499735309687, 99.05558496559026, 99.12969825304394, 99.22075172048703, 99.16993118051879, 99.24616199047115, 99.32027527792482, 99.33721545791424, 99.38168343038645, 99.40285865537321, 99.45156167284277, 99.46426680783483, 99.43885653785071, 99.49814716781366, 99.51932239280042, 99.55320275277924, 99.58073054526204, 99.56379036527264, 99.56379036527264, 99.6209634727369, 99.65907887771307, 99.68237162519851, 99.61884595023822, 99.62731604023293, 99.69507676019057, 99.72260455267337, 99.73742721016411, 99.7564849126522, 99.76919004764426, 99.79883536262572, 99.7649550026469, 99.83906829010058, 99.80307040762308, 99.81154049761778, 99.81154049761778, 99.83271572260455, 99.8009528851244, 99.82424563260984, 99.8369507676019, 99.82424563260984, 99.83906829010058, 99.83483324510323, 99.8369507676019, 99.84965590259397, 99.82636315510852, 99.83059820010588, 99.83906829010058, 99.84118581259926, 99.86236103758603, 99.85600847008999, 99.86236103758603, 99.87083112758073, 99.8369507676019, 99.8284806776072, 99.84753838009529, 99.85600847008999, 99.85389094759132, 99.87083112758073, 99.85812599258867, 99.86024351508735, 99.88353626257279, 99.85600847008999, 99.87506617257809, 99.85600847008999, 99.86236103758603, 99.84753838009529, 99.85600847008999, 99.87930121757543, 99.86236103758603, 99.8644785600847, 99.85177342509265, 99.86024351508735, 99.85389094759132, 99.85812599258867, 99.84330333509793, 99.86024351508735, 99.87718369507677, 99.86871360508205, 99.85812599258867, 99.84753838009529, 99.86659608258337, 99.87083112758073, 99.85389094759132, 99.88988883006881, 99.86024351508735, 99.87718369507677, 99.86659608258337, 99.84118581259926, 99.87083112758073, 99.85812599258867, 99.88777130757015, 99.88988883006881, 99.84542085759661, 99.87294865007941, 99.87083112758073, 99.85177342509265, 99.86024351508735, 99.86236103758603, 99.87506617257809, 99.8644785600847, 99.86024351508735, 99.86659608258337, 99.86871360508205, 99.85600847008999, 99.87083112758073, 99.87294865007941, 99.87294865007941, 99.88353626257279, 99.86236103758603, 99.87930121757543, 99.87930121757543, 99.86024351508735, 99.86024351508735, 99.83483324510323, 99.8644785600847, 99.89200635256749, 99.87083112758073, 99.84965590259397, 99.84965590259397, 99.88141874007411, 99.84753838009529, 99.87506617257809, 99.85389094759132, 99.85812599258867, 99.86236103758603, 99.85600847008999, 99.85600847008999, 99.84118581259926, 99.87930121757543, 99.86024351508735, 99.85812599258867, 99.86871360508205, 99.85389094759132, 99.86236103758603, 99.87718369507677, 99.85812599258867, 99.87083112758073, 99.85600847008999, 99.87506617257809, 99.87506617257809, 99.88777130757015, 99.85812599258867, 99.85600847008999, 99.88777130757015, 99.86659608258337, 99.87718369507677, 99.86659608258337, 99.86659608258337, 99.88141874007411, 99.85177342509265, 99.85600847008999, 99.87718369507677, 99.86236103758603, 99.87930121757543, 99.87506617257809, 99.85177342509265, 99.84118581259926, 99.86236103758603, 99.85812599258867, 99.87506617257809, 99.82636315510852, 99.85600847008999, 99.87718369507677, 99.88353626257279, 99.87294865007941, 99.89624139756485, 99.88353626257279, 99.87718369507677, 99.87083112758073, 99.84542085759661, 99.8644785600847, 99.88141874007411, 99.85600847008999, 99.89412387506617, 99.88141874007411, 99.85177342509265, 99.85389094759132, 99.87930121757543, 99.88565378507147, 99.88353626257279, 99.86871360508205, 99.86871360508205, 99.8644785600847, 99.86871360508205, 99.89624139756485, 99.84330333509793, 99.84542085759661, 99.88353626257279, 99.86236103758603, 99.87930121757543, 99.87506617257809, 99.87083112758073, 99.87294865007941, 99.87294865007941, 99.86871360508205, 99.84330333509793, 99.86659608258337, 99.84542085759661, 99.87506617257809, 99.8644785600847, 99.89200635256749, 99.84542085759661, 99.86871360508205, 99.87506617257809, 99.88141874007411, 99.87083112758073, 99.87083112758073, 99.86659608258337, 99.86659608258337, 99.86871360508205, 99.88565378507147, 99.87083112758073, 99.84753838009529, 99.88777130757015, 99.87718369507677, 99.88353626257279, 99.87083112758073, 99.86236103758603, 99.87718369507677, 99.88777130757015, 99.84965590259397, 99.85600847008999, 99.86236103758603, 99.85812599258867, 99.87718369507677, 99.8644785600847, 99.86024351508735, 99.87506617257809, 99.8644785600847, 99.8644785600847, 99.87930121757543, 99.85177342509265, 99.86024351508735, 99.85177342509265, 99.84118581259926, 99.86871360508205, 99.87718369507677, 99.86024351508735, 99.88988883006881, 99.8644785600847, 99.88141874007411, 99.87506617257809, 99.85177342509265, 99.86871360508205, 99.87506617257809, 99.87506617257809, 99.87930121757543, 99.86871360508205, 99.85812599258867, 99.88988883006881, 99.88353626257279, 99.89412387506617, 99.87930121757543, 99.86659608258337, 99.86659608258337, 99.88988883006881, 99.87083112758073, 99.87506617257809, 99.87083112758073, 99.87718369507677, 99.87930121757543, 99.87083112758073, 99.84330333509793, 99.87718369507677, 99.87294865007941, 99.88565378507147]\n",
        "test_loss_list_step = [0.7521707053278007, 0.41922322909037274, 0.3967930445191907, 0.35680990534670215, 0.3250766685049908, 0.30643289908766747, 0.27803952721696273, 0.26461896110399097, 0.26403681638047977, 0.2668783114309989, 0.2609864034708224, 0.25131638298797254, 0.24851202544774495, 0.24535505795011334, 0.23515790532909187, 0.23713360856488055, 0.2406249167215006, 0.24633904404061682, 0.22870721204169825, 0.23081522924350759, 0.23210598513776182, 0.23380596216256713, 0.23264140811036615, 0.2492445185597913, 0.24672274596477842, 0.23322659500819795, 0.2332557491848574, 0.2325650899324055, 0.2574915187433362, 0.23942345477567584, 0.21860766188953729, 0.22490006466122234, 0.22599033247588166, 0.2330661828027052, 0.23813083913980745, 0.2410290090677639, 0.25265564182408007, 0.25388093285408675, 0.25897152009694013, 0.2653597001095905, 0.267472947769634, 0.2757880237756991, 0.28352711534164116, 0.2891207381023788, 0.2937827925471699, 0.3016136303891008, 0.29683313752506296, 0.3059604737939605, 0.31242154799766986, 0.313900034299449, 0.3219801964347853, 0.33177046875889393, 0.3355082166837711, 0.33843776536192377, 0.34364481102309974, 0.3455076480613035, 0.34563379169569586, 0.35321818167051555, 0.35429473890576, 0.35551488774317297, 0.36010582940470354, 0.35364405492631096, 0.3636273516743791, 0.36364757276012327, 0.35665451670887277, 0.3549169595261999, 0.3703063836905594, 0.36219835961146246, 0.3605355029998749, 0.3578162646861564, 0.36774474406140106, 0.3633771698702784, 0.3653042366746448, 0.3691165424956411, 0.36504066177625577, 0.3715900047225695, 0.377250660302154, 0.3705682765610297, 0.3703488810170515, 0.37351591648606985, 0.37677567382343113, 0.37160208523638694, 0.3709423184650494, 0.3721590631769276, 0.3763345616011351, 0.3800408639488559, 0.37680745827874135, 0.3771674718214747, 0.3848353975142042, 0.3798498407590623, 0.3773468048494382, 0.3819653425073507, 0.3785710880149375, 0.37396970703654614, 0.37354924148131236, 0.38423583746029466, 0.3775230319622685, 0.36990976165614875, 0.3731101816017911, 0.3812584620443921, 0.3834761079017292, 0.38286398570327196, 0.3858671422372116, 0.3799955192816389, 0.3770175949378195, 0.3851937071338077, 0.38235137271968755, 0.38205398502303106, 0.38025479872400564, 0.3843826920378442, 0.38355313671533675, 0.3811237645043316, 0.37951354816665545, 0.3756716687428564, 0.38028262046110983, 0.38163883488296585, 0.38113248269712807, 0.38293040138395396, 0.38826611508414444, 0.3821931903378344, 0.3927168071534777, 0.3814124613087259, 0.38783683029788674, 0.384523262598497, 0.3777104146395098, 0.3834854347001323, 0.37351655306331083, 0.37643494215958256, 0.38091917734081837, 0.3816218973667014, 0.38416977602915436, 0.3851156278796421, 0.3824646536297366, 0.37491797317988146, 0.3818769982979432, 0.37861419655382633, 0.3842346754938583, 0.37655236199498177, 0.37527537754024654, 0.37987153332077844, 0.3830455071018899, 0.3794875234803733, 0.38347619624041457, 0.39262797689868834, 0.37537328259763764, 0.3836479137067263, 0.3833252173236699, 0.37210422399563386, 0.387080483238998, 0.3719306717816211, 0.37743640282446994, 0.3764378684846794, 0.37271541687568616, 0.37936363588361177, 0.3804472682075392, 0.371879458409168, 0.38374935142586336, 0.3781576618488294, 0.3732976428844838, 0.3825277503210065, 0.37921793430167083, 0.38190348801550034, 0.3811836604795912, 0.3839620574760963, 0.3847266497711341, 0.3755092674263698, 0.38182204500680755, 0.3782161524446279, 0.383978412504874, 0.3785792852560168, 0.37529283202728075, 0.38586872027200814, 0.37986113718144743, 0.3781509461410928, 0.385330743640296, 0.3866525995362477, 0.3780062812672672, 0.38378071400574315, 0.38093069549102115, 0.38920295537065935, 0.38671026251041424, 0.3797818386251582, 0.3798417299438049, 0.3740828680422376, 0.38145504804218516, 0.38200287843196123, 0.3875016655645096, 0.38280217152308016, 0.38698648213974984, 0.3808485120260978, 0.38649215569317924, 0.3831135995238654, 0.3805198727321683, 0.38389426964682105, 0.38486584148132336, 0.3807648518761876, 0.3849117392856701, 0.38554816227406263, 0.38357163151251333, 0.3802410184734446, 0.3815109624947403, 0.382021243195506, 0.3853015545938237, 0.377494075719048, 0.38711871966427447, 0.3774435311857173, 0.3905071147407095, 0.3806642469603057, 0.38146250298721535, 0.3838621310104488, 0.39097126777849944, 0.38649382303450625, 0.3796885114930132, 0.38229777593183895, 0.3814927838633166, 0.37877432031410874, 0.37605211639082897, 0.37402715621625676, 0.3860787514177169, 0.3734693876285033, 0.3757060868665576, 0.3836308258823028, 0.3818031575019453, 0.3754675344144012, 0.3817046451035376, 0.3788763102984019, 0.38524902579100695, 0.3789480691410455, 0.383543092720941, 0.39350814419780294, 0.3787268260402568, 0.3791520138837251, 0.3838299135951435, 0.3793616016559741, 0.3767985271874304, 0.3790097143866268, 0.37912912847583785, 0.38894346707007466, 0.3742955804382469, 0.38342078903909116, 0.3848988146238102, 0.37459168269061577, 0.38242888645561157, 0.3820874952601598, 0.38645922241951614, 0.37736037103276626, 0.37371054134450343, 0.3787742013148233, 0.3864014833873394, 0.38398269388605566, 0.3823276355716528, 0.38692381239368345, 0.38753888685731036, 0.37855833295878827, 0.37346514290673477, 0.37298866356814314, 0.3816173101830132, 0.3767242920311058, 0.3841047031056209, 0.38750297252965327, 0.369205586767445, 0.3753658247490724, 0.38275528518373475, 0.3800859667141648, 0.3870932775020015, 0.37551862878414494, 0.3840912418421723, 0.3726249620291021, 0.37941730108486454, 0.38384662088298915, 0.37976392629720707, 0.37775822057772207, 0.38208118103006306, 0.3800909294399853, 0.37907081163104844, 0.3812881442672555, 0.3761177863743083, 0.38076628101350485, 0.37963548230518607, 0.3693312196718419, 0.37269937157557875, 0.3810739266987452, 0.37098004634254705, 0.38030854867332997, 0.3809964715083148, 0.37681868622152537, 0.3750186215574835, 0.3816620926098788, 0.3736031973351012, 0.38245252669588026, 0.3819549302798787, 0.38419706475756626, 0.3735217913966991, 0.3787470100191878, 0.37715579814040195, 0.3867923977976555, 0.3815506379960068, 0.3814866198135503, 0.3853403181933305, 0.3877864530602214]\n",
        "test_acc_list_step = [75.81054087277197, 86.9660417947142, 87.58451137062077, 89.28242163491088, 90.1160110633067, 91.05331899200984, 91.73325138291334, 92.37092808850646, 92.390135218193, 92.24031960663798, 92.37092808850646, 92.9778733866011, 93.1737861094038, 93.04701905347265, 93.41963736939152, 93.37738168408113, 93.3159188690842, 93.0278119237861, 93.7077443146896, 93.72695144437616, 93.68853718500307, 93.78073140749846, 93.73847572218807, 93.26213890596189, 93.30055316533497, 93.93438844499079, 94.06883835279656, 94.11877688998156, 93.6040258143823, 94.0419483712354, 94.87553779963122, 94.83712354025815, 94.81023355869699, 94.87169637369392, 94.91779348494161, 94.89474492931777, 94.86785494775661, 94.84096496619546, 94.71419791026429, 94.56054087277197, 94.75645359557468, 94.73724646588813, 94.64889366933005, 94.64889366933005, 94.69499078057775, 94.72956361401353, 94.6757836508912, 94.74492931776275, 94.6220036877689, 94.65273509526736, 94.54901659496005, 94.53749231714812, 94.63352796558083, 94.61816226183159, 94.61432083589429, 94.5221266133989, 94.64121081745544, 94.56054087277197, 94.74492931776275, 94.61047940995698, 94.59127228027043, 94.75645359557468, 94.75645359557468, 94.66425937307929, 94.73340503995082, 94.6757836508912, 94.53365089121081, 94.64505224339274, 94.66041794714198, 94.70267363245236, 94.6258451137062, 94.75645359557468, 94.80255070682237, 94.67962507682851, 94.58358942839583, 94.54517516902274, 94.6258451137062, 94.7180393362016, 94.66425937307929, 94.6681007990166, 94.61432083589429, 94.78718500307313, 94.76029502151198, 94.68730792870313, 94.64121081745544, 94.62968653964352, 94.69114935464044, 94.58743085433314, 94.58358942839583, 94.64889366933005, 94.69114935464044, 94.70651505838967, 94.70267363245236, 94.66041794714198, 94.69883220651506, 94.61432083589429, 94.71419791026429, 94.82559926244622, 94.69883220651506, 94.72572218807622, 94.49523663183774, 94.75261216963737, 94.61047940995698, 94.64505224339274, 94.64889366933005, 94.66041794714198, 94.70267363245236, 94.55669944683467, 94.65657652120467, 94.6681007990166, 94.77566072526122, 94.85633066994468, 94.66041794714198, 94.78334357713584, 94.79102642901044, 94.63352796558083, 94.78718500307313, 94.64505224339274, 94.56438229870928, 94.73340503995082, 94.61047940995698, 94.68730792870313, 94.70267363245236, 94.61432083589429, 94.67194222495391, 94.77181929932391, 94.73724646588813, 94.64505224339274, 94.69499078057775, 94.65273509526736, 94.69883220651506, 94.6757836508912, 94.71035648432698, 94.69883220651506, 94.67194222495391, 94.66425937307929, 94.6757836508912, 94.76029502151198, 94.75645359557468, 94.70267363245236, 94.64505224339274, 94.74108789182544, 94.54133374308543, 94.54901659496005, 94.74877074370006, 94.67962507682851, 94.67194222495391, 94.67194222495391, 94.69883220651506, 94.8140749846343, 94.64121081745544, 94.7180393362016, 94.74492931776275, 94.78334357713584, 94.65273509526736, 94.5759065765212, 94.61816226183159, 94.61047940995698, 94.76413644744929, 94.79870928088506, 94.67962507682851, 94.69114935464044, 94.72572218807622, 94.60663798401967, 94.5720651505839, 94.75261216963737, 94.80255070682237, 94.70267363245236, 94.66041794714198, 94.66425937307929, 94.69114935464044, 94.72188076213891, 94.68730792870313, 94.55285802089736, 94.75645359557468, 94.64505224339274, 94.7180393362016, 94.53749231714812, 94.72572218807622, 94.65657652120467, 94.6258451137062, 94.61432083589429, 94.72188076213891, 94.77566072526122, 94.62968653964352, 94.66041794714198, 94.54901659496005, 94.6757836508912, 94.66425937307929, 94.55669944683467, 94.7679778733866, 94.74877074370006, 94.68346650276582, 94.63352796558083, 94.5759065765212, 94.61047940995698, 94.66425937307929, 94.71419791026429, 94.59895513214505, 94.61816226183159, 94.72956361401353, 94.7180393362016, 94.67194222495391, 94.68346650276582, 94.59127228027043, 94.76029502151198, 94.69499078057775, 94.66041794714198, 94.6681007990166, 94.69499078057775, 94.64889366933005, 94.67962507682851, 94.78718500307313, 94.67962507682851, 94.77950215119853, 94.6757836508912, 94.74492931776275, 94.84096496619546, 94.73340503995082, 94.72188076213891, 94.69883220651506, 94.61047940995698, 94.5720651505839, 94.72572218807622, 94.70651505838967, 94.6681007990166, 94.6258451137062, 94.64121081745544, 94.65657652120467, 94.48371235402581, 94.6757836508912, 94.73724646588813, 94.59895513214505, 94.70651505838967, 94.76029502151198, 94.75645359557468, 94.76413644744929, 94.6220036877689, 94.72188076213891, 94.7180393362016, 94.66425937307929, 94.6681007990166, 94.62968653964352, 94.71419791026429, 94.68346650276582, 94.69883220651506, 94.69114935464044, 94.70267363245236, 94.60663798401967, 94.67194222495391, 94.55285802089736, 94.59895513214505, 94.66041794714198, 94.61432083589429, 94.59895513214505, 94.73724646588813, 94.63352796558083, 94.73724646588813, 94.77566072526122, 94.60279655808236, 94.76413644744929, 94.74108789182544, 94.65273509526736, 94.58743085433314, 94.59511370620774, 94.80255070682237, 94.61047940995698, 94.71035648432698, 94.65273509526736, 94.6681007990166, 94.75261216963737, 94.72188076213891, 94.61816226183159, 94.65657652120467, 94.79870928088506, 94.64121081745544, 94.66425937307929, 94.69883220651506, 94.64889366933005, 94.83712354025815, 94.69883220651506, 94.71419791026429, 94.77181929932391, 94.63352796558083, 94.74492931776275, 94.69883220651506, 94.61816226183159, 94.73340503995082, 94.73724646588813, 94.67194222495391, 94.72956361401353, 94.69114935464044, 94.77181929932391, 94.65657652120467, 94.68346650276582, 94.60663798401967, 94.64889366933005, 94.72188076213891, 94.70651505838967, 94.70267363245236]\n",
        "train_loss_list_linear = [1.0505396097010067, 0.41031305952285363, 0.34015994405924144, 0.3038505317194029, 0.27671615290771007, 0.2539030461090044, 0.24293845730422312, 0.2313264879753919, 0.22205986383403867, 0.21279181394635177, 0.20017173882260877, 0.19267895106014196, 0.18516845405505603, 0.18218227440546844, 0.17281363284604012, 0.16757936995264475, 0.1608044776490064, 0.1526946394343363, 0.1503949542921087, 0.14460325269861435, 0.1379334318267338, 0.13074936200347212, 0.12652073063834654, 0.12361395870888137, 0.11955785878043027, 0.11495751238915171, 0.10918548092407586, 0.10549298947964741, 0.10151599690843081, 0.09746526491886312, 0.09452159306524084, 0.09095732697353857, 0.08772212413056352, 0.08348307219462667, 0.08420775942554884, 0.07539896097104885, 0.07707164484154443, 0.07315899130855473, 0.07151561531902047, 0.06873627238071506, 0.06587666986752452, 0.060232834865876696, 0.059981180607343754, 0.06175297403930204, 0.05708458852451951, 0.05296678836066225, 0.057111382709063976, 0.053133565748266894, 0.05266129370491073, 0.050845057070684346, 0.04849550221115351, 0.0469664877891379, 0.04695639163596419, 0.04652371517443136, 0.04273645039004221, 0.042981587787635805, 0.040151388551610795, 0.03779632822411049, 0.04038962408859879, 0.04276739005321198, 0.035970243897294085, 0.0389290425395164, 0.034595519276827996, 0.034754975707721986, 0.03550548981976138, 0.034968214722219, 0.033513369056052934, 0.033747713374943145, 0.03146642715614011, 0.03088276023026253, 0.03096695340504784, 0.030255960882325888, 0.029922214430077934, 0.026458163596317426, 0.030674233368527256, 0.026803990912770092, 0.028383832357679988, 0.029045142340322395, 0.026921882543196714, 0.025758919344589033, 0.027054627095336514, 0.026907914471629563, 0.02701804478293749, 0.026367548554233428, 0.0261913293705708, 0.02126370853306549, 0.023870387598386333, 0.02343241305678558, 0.026290576351723865, 0.024439686884867598, 0.02106365902915024, 0.022621461096346544, 0.022915108798849105, 0.026723837544939667, 0.021479926218290063, 0.022599881692684752, 0.02025709556021947, 0.019150306689010323, 0.0245601841217654, 0.02191897199554167, 0.01751039288937257, 0.019330726730524307, 0.019164910448808477, 0.024538845911642237, 0.015059424295682626, 0.020382445553086728, 0.022040061389306198, 0.018767614002140155, 0.019355695793985044, 0.019107737408797596, 0.017818392037986942, 0.017417942697963446, 0.021768966118750215, 0.017869346996114355, 0.017951215525590914, 0.01640004834187341, 0.01777675135988997, 0.019044938084980482, 0.015788522874557873, 0.022552578193564623, 0.019296770346089745, 0.014811130384146363, 0.015027894850487148, 0.018469126043487265, 0.018098258266041212, 0.014053442152699729, 0.015989337644331865, 0.018125206405116463, 0.016060621967932922, 0.014774189744400855, 0.01385672290374157, 0.018077892058706895, 0.01727216446030504, 0.014268980369684513, 0.015724211079724697, 0.016640492273927766, 0.014277730624145401, 0.016971004403142326, 0.014619164786088283, 0.016830329990812937, 0.01374343925469295, 0.012524507506886185, 0.01549116191725552, 0.013598875393053052, 0.0151209402418879, 0.014543565561276227, 0.01439005304061679, 0.01173475706005888, 0.016134371224896974, 0.011917180406560032, 0.012485065904832735, 0.0135999512963786, 0.01591276152397482, 0.011587380154317354, 0.009772636422980987, 0.01344329923276031, 0.015756404174912624, 0.014378462400149205, 0.014014234783006126, 0.012014912663851542, 0.01611480384725613, 0.012844832076313767, 0.013578993814619104, 0.011672752483787808, 0.014098815763512592, 0.012935566670426325, 0.015032568787632202, 0.012224024389351091, 0.014372231721552152, 0.011108738588597336, 0.011174887407980897, 0.016397042357398143, 0.007919598232576864, 0.011932518933157513, 0.012465056306042874, 0.012968409797498517, 0.012325529049170838, 0.011099239793170491, 0.011867815633636468, 0.012848886264346762, 0.012182228031996032, 0.011562556203482023, 0.010714672763688681, 0.013554639555182596, 0.012572727286869529, 0.01000095399527329, 0.011995266647266443, 0.011573533052920085, 0.012627172824654724, 0.013339461832399402, 0.010677528724291735, 0.011543188395016422, 0.010650319310586942, 0.009674460366150607, 0.010641892690030602, 0.012230279986791725, 0.01145689182891605, 0.01050705676828164, 0.00970218700554869, 0.011088927940358716, 0.010147759896973753, 0.0144252521625949, 0.009280225094541092, 0.0071248399373703905, 0.013807516299508516, 0.01255990872180107, 0.011576532107942895, 0.008876261175843192, 0.009988300831966212, 0.00985363164915767, 0.01084158176923064, 0.011923880645647825, 0.010890684340816107, 0.011154608579179295, 0.010417346872992216, 0.00848533340091224, 0.009280508183635208, 0.012399288785308195, 0.0072954312946646145, 0.007857306191068237, 0.013135696996073112, 0.007985612870672613, 0.009203406998578557, 0.011825267453099425, 0.009498726522558978, 0.010254976841146922, 0.012558721663513307, 0.007996204799592626, 0.007471766532690587, 0.01177365344033834, 0.010632048703338191, 0.01163114502161057, 0.008471069070895856, 0.008329393120841747, 0.010546008776983772, 0.007213423388353836, 0.009344507342992069, 0.01120725078885267, 0.008723668579122892, 0.008438797396795254, 0.009862698597215867, 0.011641287900165775, 0.009182740705942006, 0.00702334287046593, 0.010164535000019891, 0.008744396335386742, 0.009129313499368456, 0.008084669785307412, 0.010208096987843342, 0.011367271971373962, 0.007117051272343865, 0.008831601460626934, 0.00922884266564445, 0.009587360389017516, 0.008383878850809764, 0.007664171105706518, 0.010088089144474219, 0.007183663350923383, 0.010528553138330638, 0.010388069153280813, 0.008873608166863086, 0.007134666277026189, 0.00842848956719368, 0.008079520347828268, 0.009280271344362845, 0.008955260842407897, 0.010437573963957794, 0.007464409461843186, 0.00868264229136562, 0.008687793158964795, 0.008216140737795655, 0.007891892086514802, 0.007512410591053153, 0.008665417990315836, 0.008976994133145053, 0.008162402152780846, 0.008810677293791461, 0.006835815719566462, 0.007850608918254282, 0.010575828147088042, 0.008934358710317107, 0.0076927311314263745, 0.007455576667292384, 0.005771527193367357, 0.008088972039366073, 0.011438270648105747, 0.005829402718917685, 0.009437662637821316, 0.006043440636937449, 0.007854135620251515, 0.009180552848274084, 0.010004485826416422, 0.007954190094466415, 0.0069836680795018575, 0.006469878575636705, 0.008808609063802835, 0.007791922163181544, 0.006387679697369947, 0.009282423594551585, 0.007415674569260415]\n",
        "train_acc_list_linear = [64.05293806246691, 87.14875595553202, 89.55002646903124, 90.75913181577555, 91.62308099523557, 92.33456855479089, 92.87030174695606, 93.13922710428798, 93.25780836421387, 93.82106934886183, 94.23822128110112, 94.36315510852303, 94.60667019587083, 94.74007411328745, 95.01111699311805, 95.09158284806776, 95.25674960296453, 95.67178401270513, 95.61461090524087, 95.74377977766014, 95.9915299100053, 96.22869242985706, 96.29645314981472, 96.45526733721546, 96.42985706723134, 96.65431445209106, 96.86818422445738, 96.87241926945474, 97.08628904182108, 97.16040232927475, 97.2641609317099, 97.3361566966649, 97.35309687665432, 97.51191106405506, 97.51191106405506, 97.76601376389624, 97.7342509264161, 97.88035997882477, 97.82953943885654, 97.96717840127052, 98.00317628374802, 98.16622551614611, 98.13658020116463, 98.11540497617787, 98.1937533086289, 98.37374272101641, 98.19798835362626, 98.44150344097406, 98.33562731604023, 98.41821069348862, 98.43303335097936, 98.4923239809423, 98.5643197458973, 98.4923239809423, 98.66807834833246, 98.64902064584436, 98.69348861831656, 98.76971942826893, 98.68925357331922, 98.64690312334568, 98.82053996823716, 98.74219163578613, 98.81842244573849, 98.86500794070938, 98.88194812069878, 98.78877713075701, 98.90100582318688, 98.90312334568554, 98.96664902064585, 98.97723663313923, 98.98358920063525, 99.0428798305982, 99.01111699311805, 99.12122816304924, 98.98570672313393, 99.10852302805718, 99.09158284806776, 99.05134992059291, 99.1233456855479, 99.1868713605082, 99.0873478030704, 99.10217046056114, 99.08523028057174, 99.13181577554262, 99.11064055055584, 99.33721545791424, 99.22710428798305, 99.17628374801482, 99.0979354155638, 99.20169401799895, 99.2694547379566, 99.2419269454738, 99.25463208046585, 99.08099523557438, 99.26733721545791, 99.2419269454738, 99.30968766543144, 99.3223928004235, 99.1868713605082, 99.25463208046585, 99.40921122286925, 99.36262572789836, 99.3499205929063, 99.16357861302276, 99.52355743779778, 99.31815775542616, 99.2779248279513, 99.37109581789306, 99.3499205929063, 99.37321334039174, 99.36050820539968, 99.42826892535733, 99.22075172048703, 99.41979883536263, 99.3943885653785, 99.46426680783483, 99.39015352038115, 99.33509793541556, 99.47697194282689, 99.28427739544733, 99.36050820539968, 99.5574377977766, 99.5044997353097, 99.41556379036527, 99.38803599788248, 99.5489677077819, 99.49179460031763, 99.37956590788777, 99.47697194282689, 99.5214399152991, 99.55108523028058, 99.42403388035999, 99.45156167284277, 99.51720487030175, 99.47273689782953, 99.42403388035999, 99.5299100052938, 99.41132874536792, 99.48755955532027, 99.46638433033351, 99.53202752779248, 99.57014293276866, 99.49179460031763, 99.53626257278984, 99.50026469031233, 99.50026469031233, 99.5299100052938, 99.61884595023822, 99.45579671784013, 99.59978824775013, 99.55108523028058, 99.55532027527792, 99.47273689782953, 99.62519851773425, 99.67813658020117, 99.57437797776602, 99.45579671784013, 99.5299100052938, 99.50873478030704, 99.61672842773955, 99.46214928533615, 99.59555320275278, 99.57014293276866, 99.6209634727369, 99.53414505029116, 99.58920063525674, 99.5044997353097, 99.57014293276866, 99.53626257278984, 99.58073054526204, 99.6209634727369, 99.46850185283219, 99.72260455267337, 99.58920063525674, 99.55955532027528, 99.56379036527264, 99.60825833774484, 99.64849126521969, 99.60402329274748, 99.5574377977766, 99.60825833774484, 99.61884595023822, 99.63790365272631, 99.56802541026998, 99.58284806776072, 99.66754896770779, 99.58708311275808, 99.62519851773425, 99.57226045526734, 99.59767072525146, 99.64213869772367, 99.60614081524616, 99.63366860772896, 99.66331392271043, 99.65907887771307, 99.58920063525674, 99.61884595023822, 99.67813658020117, 99.66119640021175, 99.62731604023293, 99.68237162519851, 99.57437797776602, 99.66543144520911, 99.80307040762308, 99.5574377977766, 99.5659078877713, 99.63366860772896, 99.69931180518793, 99.66966649020645, 99.67178401270513, 99.63578613022763, 99.59767072525146, 99.63790365272631, 99.66119640021175, 99.64425622022235, 99.72683959767072, 99.68660667019587, 99.61249338274219, 99.7734250926416, 99.7480148226575, 99.56379036527264, 99.74589730015882, 99.67813658020117, 99.62731604023293, 99.69931180518793, 99.65484383271573, 99.59767072525146, 99.7649550026469, 99.73319216516676, 99.61037586024352, 99.65060878771837, 99.62731604023293, 99.72260455267337, 99.73107464266808, 99.66543144520911, 99.76071995764956, 99.71413446267867, 99.62731604023293, 99.74166225516146, 99.71201694017999, 99.67178401270513, 99.58708311275808, 99.69507676019057, 99.73954473266278, 99.68025410269983, 99.71836950767602, 99.70566437268396, 99.73107464266808, 99.65272631021705, 99.61037586024352, 99.79460031762838, 99.71201694017999, 99.68872419269455, 99.70778189518263, 99.7564849126522, 99.7564849126522, 99.66543144520911, 99.76919004764426, 99.64213869772367, 99.66966649020645, 99.71836950767602, 99.76071995764956, 99.73319216516676, 99.75224986765484, 99.6929592376919, 99.67813658020117, 99.65907887771307, 99.72472207517205, 99.68872419269455, 99.71413446267867, 99.72472207517205, 99.76071995764956, 99.7924827951297, 99.69719428268925, 99.68448914769719, 99.73107464266808, 99.73742721016411, 99.76283748014822, 99.75224986765484, 99.66543144520911, 99.70354685018528, 99.7564849126522, 99.76283748014822, 99.79460031762838, 99.72260455267337, 99.64002117522499, 99.79036527263102, 99.69084171519323, 99.8009528851244, 99.75860243515088, 99.73107464266808, 99.6569613552144, 99.75013234515616, 99.77977766013764, 99.79883536262572, 99.70142932768661, 99.69507676019057, 99.7734250926416, 99.70989941768131, 99.7480148226575]\n",
        "test_loss_list_linear = [0.6001535044873462, 0.4386981564993952, 0.32313791202271686, 0.3436826935001448, 0.3047397654576629, 0.28500792238057826, 0.26378655251042515, 0.2683426228297107, 0.27285771396960695, 0.2532431707516605, 0.25363739693135606, 0.25782927618745494, 0.2381599084200228, 0.24098271157081222, 0.23853215436432876, 0.22876223501767598, 0.2459365823762674, 0.24074384005849853, 0.23645990466078123, 0.23522190126937395, 0.23930488064812094, 0.23977934446770185, 0.22856533881642072, 0.2503986795633739, 0.2523015177096514, 0.2286284007497278, 0.2522817155821066, 0.23435633048853455, 0.25106761294106644, 0.23668714861075082, 0.25767872133748787, 0.2464016547937896, 0.24990028208669493, 0.25964026233437015, 0.2509775684014255, 0.25643125852095144, 0.25149472640352505, 0.2636343431750349, 0.2690670864802657, 0.2728121512952973, 0.2877597091719508, 0.2628066184400928, 0.289077399882908, 0.2637001336643509, 0.2718517802947876, 0.30822780637034014, 0.2853905560412243, 0.3029168626914422, 0.2886001042948634, 0.30125397385335434, 0.2918206257928236, 0.31290997323744435, 0.3016124471894228, 0.3364011060409978, 0.30226883032888757, 0.30097986143264993, 0.3160975992350894, 0.324009220079318, 0.2896068644545534, 0.28848243194321793, 0.30809056048518885, 0.31027250127026845, 0.31317287329219134, 0.3204711799728958, 0.323861251740406, 0.30745547297684583, 0.313345615642474, 0.31225476020435783, 0.32664194748755176, 0.3649349614393477, 0.3289772248781268, 0.34484266127715363, 0.34519970382326376, 0.3562348909566508, 0.34551431653181125, 0.3507686852495752, 0.3557186407749267, 0.34874562685396154, 0.3626312471414898, 0.32565479080977977, 0.3328241787111277, 0.3502718099739914, 0.35965223179436195, 0.33991847547026827, 0.32748869253212914, 0.3568636128751963, 0.366436490642966, 0.36107295554350405, 0.34370773008056715, 0.343383331070928, 0.3387923375794701, 0.33830804925631075, 0.3589262347485797, 0.3675877243079537, 0.3818419510498643, 0.35536084654649686, 0.35281344309595286, 0.3716038850629154, 0.35846942082485733, 0.34315043032242387, 0.36869288876871853, 0.3778895241226636, 0.38406652862242624, 0.352233542257226, 0.3620971898712656, 0.37449508531055614, 0.37493528568131085, 0.36601132105159406, 0.36861560567665624, 0.3717369966793294, 0.369726698087784, 0.3781300349087984, 0.35664984070714195, 0.3536169459751132, 0.406203392372631, 0.3737115380445532, 0.36973171939562055, 0.37459768973948326, 0.40706704461983606, 0.3881958369896108, 0.37344259142364356, 0.3670044747710812, 0.3696818688847855, 0.37015472998952165, 0.38189552233134416, 0.3749138325744984, 0.3891030573742647, 0.3678013856029686, 0.36681280497863306, 0.3926687809620418, 0.4037954283184281, 0.4014408321065061, 0.3803745116673264, 0.38791271775741787, 0.37617705127808687, 0.3729255223537193, 0.36608954668775495, 0.3800407153572522, 0.37864029130843635, 0.3903196998415332, 0.39593674976597815, 0.4233312764953749, 0.41837985076092404, 0.4037898524353902, 0.39368393412772934, 0.40711697678574743, 0.3831657852119237, 0.39936033349630295, 0.4122653530234946, 0.4055917443908459, 0.391819414573119, 0.3998463283493823, 0.3856644867325896, 0.38932094629853964, 0.45811930652159977, 0.4117749379582557, 0.3846923142269838, 0.38948512334814844, 0.3886060610632686, 0.4141315968488069, 0.39312611405244646, 0.40893315564037536, 0.3917342342217179, 0.4033093715232669, 0.40686407040658534, 0.402124198153615, 0.3760559221218322, 0.41189432279298116, 0.3945868524777539, 0.4064665962668026, 0.4281328501380688, 0.3944055610610282, 0.4145982712644207, 0.39619766517231864, 0.4008463170269833, 0.4100334781368135, 0.3959438812681565, 0.4048078361277779, 0.3898382809506181, 0.3940078625638111, 0.41857934771699135, 0.40016016322553305, 0.42573420590191496, 0.4076968614815497, 0.40349324788971275, 0.41680151768320917, 0.4404344489323158, 0.4126104597257925, 0.41489401694464806, 0.39322311091510687, 0.39995222047482637, 0.4001541677862406, 0.40168759471955984, 0.4003755842317261, 0.4116448443930815, 0.3964004161512004, 0.40526396525092423, 0.40040231844885094, 0.436148803023731, 0.42100324081804824, 0.42921065237811384, 0.4016612854548821, 0.4237121128860642, 0.439825722326835, 0.40309608828586835, 0.4022408921143734, 0.40526854241376414, 0.4139130270638156, 0.42377193091327653, 0.4159748113506437, 0.43089511207140546, 0.41587188575124623, 0.42511460325662415, 0.42877695572507735, 0.4061464395730154, 0.4108063448129185, 0.4237177971266575, 0.4147245909142144, 0.4100258317867331, 0.44727529514599224, 0.40763759292552576, 0.4096112189969669, 0.4398777195818576, 0.4397024883450392, 0.42169872507014694, 0.4525160300362782, 0.4039532243748944, 0.42747145336048276, 0.41558541071500776, 0.4243580105614063, 0.4347197997529863, 0.40417124533697085, 0.4213481634563091, 0.42768024219492196, 0.41689553120922224, 0.42403014976640835, 0.43499788091353636, 0.40865986559576556, 0.39625785907949596, 0.41788156942793114, 0.42710175029203, 0.39860118992453186, 0.40182735008534554, 0.43774937425612237, 0.4086107819651564, 0.42035614554861594, 0.42495340735231546, 0.42730405055943477, 0.41829457241749646, 0.4210991954211803, 0.39986408456210415, 0.43789072635163573, 0.4252349973893633, 0.4179426681058591, 0.4189265777229094, 0.42167082347327334, 0.4152061831133038, 0.4278368429582128, 0.42154261065354826, 0.39703031598279875, 0.42471260858663157, 0.4301079974747172, 0.4101321147526523, 0.4378960633869557, 0.412081252308745, 0.4338206772089881, 0.4061669551530013, 0.4237026169088067, 0.4324107744557527, 0.4283796655671561, 0.4480068746077664, 0.42207027151815446, 0.4178310304186216, 0.42660820346289113, 0.423226847276822, 0.44835605301127274, 0.4472741484733335, 0.4282900923771747, 0.4323618656535651, 0.4345184702519784, 0.4196194001455225, 0.4023636024691822, 0.4263699218977754, 0.45100487594940136, 0.4451090616046214, 0.4251364004779972, 0.4428678105822673, 0.42934233425459, 0.4463761615374025, 0.42917647955519167, 0.43650849757935195, 0.40754444616865, 0.4072841090405835, 0.43068673907249583, 0.42376545924857695, 0.4177722467438263, 0.41679786920105794, 0.4319006550381435, 0.42252690807057947, 0.4652784176572573]\n",
        "test_acc_list_linear = [81.16548862937923, 86.56653349723418, 90.2581438229871, 89.47065150583897, 90.86893054701905, 91.77934849416103, 92.38629379225569, 92.26336816226183, 92.23263675476336, 92.60525507068223, 92.71665642286416, 92.73586355255071, 93.29287031346036, 93.27366318377382, 93.4081130915796, 93.58481868469576, 93.13921327596803, 93.3620159803319, 93.6078672403196, 93.46957590657652, 93.5540872771973, 93.73847572218807, 93.77688998156115, 93.21220036877689, 93.30055316533497, 94.06883835279656, 93.46957590657652, 94.04963122311001, 93.73847572218807, 93.8959741856177, 93.44652735095268, 93.91518131530424, 93.73847572218807, 93.6578057775046, 93.9881684081131, 93.98432698217579, 93.95743700061463, 93.98432698217579, 93.8921327596804, 93.92670559311617, 93.68469575906576, 94.3338967424708, 93.6040258143823, 94.10341118623234, 94.14950829748003, 93.79609711124769, 94.17255685310387, 93.64244007375538, 93.9958512599877, 93.56945298094652, 94.00353411186232, 93.67317148125385, 93.96127842655194, 93.50799016594961, 93.99969268592501, 94.3300553165335, 93.97664413030117, 93.78457283343577, 94.16871542716656, 94.10341118623234, 94.16103257529196, 94.16487400122925, 94.05731407498463, 94.11877688998156, 94.12645974185618, 94.16487400122925, 94.17639827904118, 94.17639827904118, 94.18792255685311, 94.02658266748617, 94.1379840196681, 93.90365703749232, 93.80762138905962, 93.93054701905348, 94.00353411186232, 93.98432698217579, 93.97280270436386, 94.06499692685925, 93.99969268592501, 94.25706822372464, 94.41840811309157, 94.01505838967425, 93.78457283343577, 94.14566687154272, 94.25706822372464, 94.04963122311001, 93.8959741856177, 93.97280270436386, 94.13030116779349, 94.41072526121697, 94.20712968653964, 94.31084818684695, 93.77304855562384, 93.85755992624462, 93.78073140749846, 94.21865396435157, 94.3262138905962, 93.96896127842655, 94.20328826060233, 94.43377381684081, 94.19944683466503, 94.17639827904118, 93.82298709280884, 94.3761524277812, 94.31084818684695, 94.13030116779349, 94.18023970497849, 94.27627535341118, 94.14950829748003, 94.30700676090964, 94.41456668715428, 94.35310387215735, 94.10341118623234, 94.3262138905962, 93.75, 94.23786109403811, 94.28779963122311, 93.94975414874001, 93.8921327596804, 93.83066994468346, 94.08420405654579, 94.37231100184388, 94.17255685310387, 94.44913952059004, 94.14950829748003, 94.3761524277812, 94.22249539028887, 94.21865396435157, 94.53365089121081, 94.14566687154272, 94.16487400122925, 93.91133988936693, 93.98432698217579, 94.2839582052858, 94.19944683466503, 94.21481253841426, 94.3338967424708, 93.98432698217579, 94.18792255685311, 94.03042409342348, 94.27627535341118, 93.83066994468346, 94.12261831591887, 94.02274124154886, 94.13030116779349, 94.0880454824831, 94.52980946527352, 94.0880454824831, 94.02658266748617, 94.3262138905962, 94.31084818684695, 94.42609096496619, 94.39535955746773, 94.42224953902888, 93.99969268592501, 94.16871542716656, 94.35310387215735, 94.23017824216349, 94.26475107559926, 94.39535955746773, 94.49139520590043, 94.26090964966195, 94.51444376152428, 94.40304240934235, 94.15719114935465, 94.16103257529196, 94.41840811309157, 94.17639827904118, 94.31853103872157, 94.31853103872157, 94.00737553779963, 94.3338967424708, 94.34926244622004, 94.3338967424708, 94.24554394591273, 94.51060233558697, 94.39151813153042, 94.27243392747388, 94.43377381684081, 94.3262138905962, 94.23017824216349, 94.24170251997542, 93.86908420405655, 94.13030116779349, 94.29164105716042, 94.35694529809466, 94.19560540872772, 94.3799938537185, 94.3338967424708, 94.25322679778733, 94.2839582052858, 94.2340196681008, 94.26859250153657, 94.69114935464044, 94.16487400122925, 94.46834665027659, 94.27243392747388, 94.36846957590657, 94.10725261216963, 94.43377381684081, 94.23786109403811, 94.46450522433928, 94.32237246465888, 94.28779963122311, 94.11493546404425, 94.16871542716656, 94.4299323909035, 94.30700676090964, 94.19560540872772, 94.46066379840197, 94.17639827904118, 94.53365089121081, 94.16871542716656, 94.29164105716042, 94.29548248309773, 94.49523663183774, 94.25706822372464, 94.10341118623234, 94.64889366933005, 94.30316533497235, 94.42609096496619, 94.44529809465274, 94.19944683466503, 94.1917639827904, 94.44529809465274, 94.16103257529196, 94.3338967424708, 94.54901659496005, 94.4721880762139, 94.31084818684695, 94.39920098340504, 94.49139520590043, 94.3761524277812, 94.45298094652735, 94.31468961278426, 94.45682237246466, 94.30316533497235, 94.55285802089736, 94.4299323909035, 94.40688383527966, 94.34542102028273, 94.4299323909035, 94.49139520590043, 94.27243392747388, 94.47602950215119, 94.26090964966195, 94.24554394591273, 94.54517516902274, 94.3300553165335, 94.29548248309773, 94.61432083589429, 94.11877688998156, 94.40304240934235, 94.27243392747388, 94.59511370620774, 94.2839582052858, 94.39151813153042, 94.39535955746773, 94.21865396435157, 94.49523663183774, 94.24554394591273, 94.51060233558697, 94.59127228027043, 94.43377381684081, 94.31853103872157, 94.46834665027659, 94.43761524277812, 94.43761524277812, 94.37231100184388, 94.34157959434542, 94.00353411186232, 94.38383527965581, 94.58358942839583, 94.5759065765212, 94.41840811309157, 94.07652120467118, 94.09956976029503, 94.3799938537185, 94.30700676090964, 94.29932390903504, 94.38383527965581, 94.5259680393362, 94.26859250153657, 94.35310387215735, 94.36462814996926, 94.37231100184388, 94.38767670559312, 94.35694529809466, 94.36846957590657, 94.34542102028273, 94.40304240934235, 94.28779963122311, 94.46834665027659, 94.56054087277197, 94.62968653964352, 94.35310387215735, 94.43761524277812, 94.39535955746773, 94.26475107559926, 93.79609711124769]\n",
        "train_loss_list_exp = [1.5108453227575556, 0.45569133027620756, 0.38955149030297753, 0.38201055714108434, 0.3791554563736851, 0.37846633355791975, 0.37789585104156637, 0.37833547551780533, 0.37885424543202406, 0.3798585463830126, 0.3801606303146538, 0.3785690202864851, 0.380058984244419, 0.38191306041831247, 0.3755665107309657, 0.37845069464790787, 0.3810173268240642, 0.37906573632060675, 0.38025176412044825, 0.37710853672124506, 0.37910957913088605, 0.3795646985129612, 0.37768419939004955, 0.37915716253645054, 0.3763544963304266, 0.37615088787343764, 0.3767496614356028, 0.3780435439209305, 0.37970296291477956, 0.3768931365190806, 0.3782231926433439, 0.37863624968179843, 0.3801447201146666, 0.38008787327504095, 0.3784985868184547, 0.3775513489152681, 0.3797982176387213, 0.378436125835106, 0.37775709227656284, 0.3784049479618951, 0.3812676381047179, 0.377607957215167, 0.37778531927564923, 0.3785970114110931, 0.3763440459320539, 0.37659880587563604, 0.38260392961786366, 0.3788121801404772, 0.3782783241937477, 0.37851579224837184, 0.37789375260270386, 0.37802613358995135, 0.3780238080800064, 0.38144587775879113, 0.3779912972595634, 0.3791698661600025, 0.3766854087996289, 0.37804330437163997, 0.3786587099718854, 0.37654282059772876, 0.3787634488609102, 0.3799068733524824, 0.37713607115958764, 0.37751451530430696, 0.3801226066299247, 0.37911422368956776, 0.3805197463610631, 0.37700172774190827, 0.3788724349847008, 0.3784166157326401, 0.38057625192775313, 0.37780569122251134, 0.38091700400924944, 0.3794297932528545, 0.3814112742338077, 0.37960589101644066, 0.37835461256626823, 0.37888884483798735, 0.3795582245439695, 0.37849634607148364, 0.37682519744082194, 0.37698636250444223, 0.3814956169464401, 0.3775139360570003, 0.379286357057773, 0.37696852730864755, 0.3763741816123973, 0.37921798265561824, 0.3787178158921601, 0.3787029756682352, 0.37783306570557074, 0.3772085670452454, 0.377733004771597, 0.3765660253401371, 0.3802021978912638, 0.37975252381346736, 0.3792028047528047, 0.3785102287039847, 0.3774594428739574, 0.3806928960773034, 0.3792232088441771, 0.37827566011649805, 0.38008303063994825, 0.3778988100325835, 0.3803016372974003, 0.3791544923614357, 0.38108806501882186, 0.37818956795100594, 0.37843327103106955, 0.38068289166382013, 0.38067130910025704, 0.37755737811084683, 0.37938234137325755, 0.3798758971497295, 0.37914535011540906, 0.37674440685811084, 0.37839110369281714, 0.3803737539505248, 0.3769939240966709, 0.37618244623104086, 0.3802966764625818, 0.376914295521855, 0.38093100847590583, 0.3785027291797364, 0.38015424458153524, 0.3799492670753138, 0.3770360491140102, 0.3781222916311688, 0.37643939103214397, 0.37902817707559283, 0.37899113222350916, 0.3788869072428241, 0.37866583002130516, 0.38024979207896925, 0.37998249028433306, 0.37665241209633626, 0.3791340853221371, 0.3768656629776244, 0.3781943121738227, 0.37956079872966136, 0.3790555945660687, 0.3767165967280949, 0.3785593254860178, 0.3785436793071468, 0.3786095209157241, 0.37977585394369556, 0.37895426606421223, 0.37726105127715803, 0.3811360982456181, 0.3777372095239195, 0.37985739951857384, 0.3775850888190231, 0.37942486108964696, 0.3774096647575296, 0.37866538746893247, 0.37956950698441605, 0.37765448986676325, 0.3765703885535884, 0.37493878506063444, 0.3787174464322041, 0.3790939331539278, 0.3798395115024029, 0.3802033216972661, 0.3778447469237051, 0.37922620373528176, 0.3788863822696655, 0.3776389633010073, 0.37965354569720705, 0.37847416466329153, 0.38210083584636856, 0.3769269231858292, 0.376283608316406, 0.3791458204105941, 0.3800827085891067, 0.3800524467940576, 0.379729083156198, 0.3786869500145357, 0.37784998191566, 0.37798632447150987, 0.37959555187199495, 0.3772686913326827, 0.37737370587299834, 0.3774894487647829, 0.3773925192149351, 0.37866038096144916, 0.3799699583673865, 0.37930802181161194, 0.37929151229419034, 0.37872534558217374, 0.38051237880699035, 0.3785012537224829, 0.37907243408969427, 0.3786347356188265, 0.3772817448306536, 0.37789186423386983, 0.377803510807071, 0.37891541296227516, 0.3768928705596019, 0.3764786839808229, 0.37735731827049723, 0.37620092403436417, 0.37594923223583354, 0.37946950848186567, 0.37934725721515616, 0.3799315985383057, 0.37742675118006985, 0.3800657158137014, 0.38043200723362486, 0.3790072623468673, 0.37812678907621844, 0.380248889528962, 0.3795400029679301, 0.37716066687895355, 0.37926767851279036, 0.3811982564002195, 0.3785968935344277, 0.37829239452434427, 0.3791591095003655, 0.37750050801087204, 0.3755794913788152, 0.37707439347657407, 0.3798365030023787, 0.37901620768757693, 0.3787338199815776, 0.3768027005237616, 0.378330920527621, 0.3773879486774688, 0.37904529988281127, 0.3793277707364824, 0.37877471587522243, 0.3773436505135482, 0.38000925620235404, 0.37747299065434836, 0.3783611831707037, 0.38008849536823386, 0.3802644786069064, 0.37820831300604957, 0.37898807813158525, 0.37832132050500006, 0.37651883493755567, 0.3780955279745707, 0.3794448867157546, 0.37681427719147226, 0.37846876878725483, 0.37892088152690306, 0.3757547806433546, 0.3790287462272618, 0.3771775669764051, 0.37960463952081314, 0.38023487892415786, 0.3773157599818739, 0.3790636116734688, 0.37847773605568946, 0.3790109474969104, 0.3778621018094422, 0.3795850692483468, 0.38052020777208695, 0.3777503734681664, 0.38023589062819957, 0.37878056504539037, 0.3778544519813403, 0.3769152445117956, 0.37817029428837423, 0.3794189135879682, 0.3814815942268708, 0.3767595124357761, 0.376037456559618, 0.3787438214067521, 0.37781988387185383, 0.3780568046621514, 0.3789186481295562, 0.3792363849031893, 0.3795603767723895, 0.38027571985715125, 0.37710057130350977, 0.37790428061633896, 0.3758348726887044, 0.37957349484205893, 0.3801340398184329, 0.37570041014250055, 0.37696901714898706, 0.3780564808748602, 0.37865450675409984, 0.37989892315896867, 0.37623435913062675, 0.3776249932402841, 0.3777484252120098, 0.37681428954853274, 0.3777670302203677, 0.37880285431537525, 0.3775242522641572, 0.37820892516513505, 0.37701137581976446, 0.378751233704691, 0.37953954490865793, 0.3773617081364319, 0.3809620241324107, 0.37960273697770386, 0.3808248356428896, 0.37698043551709914]\n",
        "train_acc_list_exp = [47.21651667548968, 85.66437268395977, 87.928004235045, 88.11858125992589, 88.25410269984118, 88.07623080995235, 88.23928004235044, 88.18422445738486, 88.14187400741133, 88.09740603493913, 88.06564319745897, 88.14399152991001, 88.0084700899947, 87.9915299100053, 88.28163049232398, 88.06776071995765, 88.09105346744309, 88.11434621492853, 87.96188459502382, 88.11222869242985, 88.12916887241927, 88.13975648491265, 88.2435150873478, 88.16728427739545, 88.09105346744309, 88.20116463737428, 88.20328215987296, 88.01482265749074, 88.0084700899947, 88.20116463737428, 88.15034409740603, 88.22445738485972, 88.04870301746956, 88.06776071995765, 88.28586553732133, 88.19269454737956, 88.11011116993119, 88.18422445738486, 88.20539968237162, 88.08046585494971, 88.071995764955, 88.23292747485442, 88.23292747485442, 88.15881418740074, 88.26680783483324, 88.32398094229751, 88.06140815246162, 88.18210693488618, 88.17363684489148, 88.15881418740074, 88.13975648491265, 88.15034409740603, 88.12281630492323, 88.01694017998942, 88.19481206987824, 88.18634197988354, 88.3070407623081, 88.16093170989942, 88.16516675489677, 88.19481206987824, 88.25622022233986, 88.12493382742191, 88.1355214399153, 88.16093170989942, 88.09105346744309, 88.24563260984648, 88.11858125992589, 88.10799364743251, 88.09317098994177, 88.09528851244045, 88.0359978824775, 88.17787188988883, 88.10375860243515, 88.1355214399153, 88.08470089994707, 88.09105346744309, 88.23928004235044, 88.12916887241927, 88.10375860243515, 88.26045526733722, 88.24775013234516, 88.16093170989942, 88.05717310746427, 88.11858125992589, 88.15034409740603, 88.24563260984648, 88.14822657490735, 88.05293806246691, 88.1630492323981, 88.12281630492323, 88.32821598729487, 88.21386977236634, 88.23928004235044, 88.26892535733192, 88.23928004235044, 87.91529910005293, 88.05293806246691, 88.16093170989942, 88.26892535733192, 88.10587612493383, 88.13128639491795, 88.28374801482266, 88.21810481736368, 88.20328215987296, 88.18422445738486, 88.09740603493913, 88.00635256749602, 88.08681842244575, 88.10375860243515, 88.09528851244045, 88.06140815246162, 88.16093170989942, 88.10799364743251, 88.12493382742191, 88.08681842244575, 88.29433562731604, 88.08258337744839, 88.0084700899947, 88.17363684489148, 88.27527792482795, 88.10587612493383, 88.12069878242457, 87.98941238750662, 88.22022233986236, 88.12916887241927, 88.12281630492323, 88.14399152991001, 88.16516675489677, 88.14399152991001, 88.09528851244045, 88.18845950238222, 88.19692959237692, 88.15246161990471, 88.06564319745897, 88.12069878242457, 88.25833774483854, 88.15246161990471, 88.25622022233986, 88.11646373742721, 88.10375860243515, 88.11434621492853, 88.18422445738486, 88.14610905240868, 88.27316040232928, 88.15881418740074, 88.16728427739545, 88.13763896241397, 88.08681842244575, 88.03811540497618, 88.15457914240339, 88.15034409740603, 88.28586553732133, 88.13975648491265, 88.29010058231869, 88.25622022233986, 88.21810481736368, 88.22445738485972, 88.27316040232928, 88.2710428798306, 88.11222869242985, 88.02541026998412, 88.02541026998412, 88.08258337744839, 88.14610905240868, 88.09740603493913, 88.18634197988354, 88.18634197988354, 88.17998941238751, 88.11646373742721, 88.06140815246162, 88.05293806246691, 88.2710428798306, 88.071995764955, 88.22233986236104, 88.09317098994177, 88.12493382742191, 88.18634197988354, 88.11434621492853, 88.21810481736368, 88.00211752249868, 88.11858125992589, 88.27527792482795, 88.30280571731075, 88.24563260984648, 88.15246161990471, 88.12493382742191, 88.11434621492853, 88.02117522498676, 88.24563260984648, 88.06987824245633, 88.23716251985178, 88.0635256749603, 88.14399152991001, 88.22445738485972, 88.19269454737956, 88.26045526733722, 88.1630492323981, 88.1990471148756, 88.14399152991001, 88.27527792482795, 88.24563260984648, 88.32609846479619, 88.02117522498676, 88.15669666490207, 88.071995764955, 88.16728427739545, 88.15034409740603, 88.12281630492323, 88.15881418740074, 88.17787188988883, 88.06987824245633, 88.08470089994707, 88.11646373742721, 88.13763896241397, 88.1355214399153, 88.18845950238222, 88.18845950238222, 88.14399152991001, 88.25410269984118, 88.22445738485972, 88.17998941238751, 88.07623080995235, 88.14187400741133, 88.09952355743779, 88.31127580730545, 88.19481206987824, 88.2265749073584, 88.10164107993647, 88.12705134992059, 88.1905770248809, 88.11434621492853, 88.13128639491795, 88.22233986236104, 88.17998941238751, 88.13128639491795, 88.12705134992059, 88.24563260984648, 88.16940179989412, 88.06987824245633, 88.24986765484384, 88.12493382742191, 88.15457914240339, 88.22869242985706, 88.06987824245633, 88.08470089994707, 88.23928004235044, 88.07411328745368, 88.215987294865, 88.15881418740074, 88.14822657490735, 88.12069878242457, 88.10799364743251, 88.27527792482795, 88.00423504499736, 88.17363684489148, 88.18422445738486, 88.1355214399153, 88.18634197988354, 88.08893594494441, 88.11011116993119, 88.09105346744309, 88.2265749073584, 88.20539968237162, 88.13763896241397, 88.11646373742721, 88.29221810481737, 88.20116463737428, 88.18845950238222, 88.14399152991001, 88.0359978824775, 88.15246161990471, 88.14399152991001, 88.07834833245103, 88.30068819481207, 88.21386977236634, 88.1715193223928, 88.34515616728427, 87.99788247750132, 87.91106405505559, 88.15034409740603, 88.15669666490207, 88.1630492323981, 88.13975648491265, 88.08470089994707, 88.3705664372684, 88.22869242985706, 88.1355214399153, 88.17787188988883, 88.14610905240868, 88.18210693488618, 88.27527792482795, 88.17363684489148, 88.15034409740603, 88.26469031233457, 88.14187400741133, 88.26045526733722, 88.08681842244575, 88.09952355743779, 88.16728427739545, 88.12916887241927]\n",
        "test_loss_list_exp = [0.7599668520338395, 0.41391250622623105, 0.392150557216476, 0.3908533724207504, 0.3910430484980929, 0.3915113131059151, 0.3893689420439449, 0.39278720669886646, 0.3913472319642703, 0.3898209324654411, 0.3919214537622882, 0.3930370972729197, 0.3875842901567618, 0.3887199363579937, 0.3931986349178295, 0.3915082841527228, 0.39034265929869577, 0.38962281656031517, 0.39410267273585003, 0.3923792628680958, 0.3913208600498882, 0.3940731910806076, 0.3901035269978, 0.3910912872091228, 0.38958175787154364, 0.3905664257266942, 0.3923723243323027, 0.3930160653795682, 0.3910279740013328, 0.39261947053612445, 0.39096589437594603, 0.391885179076709, 0.3932027472730945, 0.39465218753206965, 0.38952960351518556, 0.3913427036182553, 0.39291733357251857, 0.38893387598149914, 0.3907097995865579, 0.39178018352272465, 0.38997077613192443, 0.38897235888768644, 0.39309656094102297, 0.3918713939686616, 0.38930126476813764, 0.3919200319431576, 0.3909892667742336, 0.3936515018782195, 0.3921337866900014, 0.3897011807444049, 0.389769053050116, 0.3902200594106141, 0.38991651070468564, 0.3911624582228707, 0.3900841569491461, 0.38808364508783116, 0.39078373330480914, 0.3911517692693308, 0.3905084923494096, 0.392090796986047, 0.3915708720245782, 0.3868667685664168, 0.3898552243469977, 0.3904008638186782, 0.38936665559224054, 0.3908520120323873, 0.3909977381574173, 0.3894340494538055, 0.3913114227938886, 0.38867319550584345, 0.3922208594340904, 0.39250611046365663, 0.3933124074748918, 0.3923281282916957, 0.3923263843445217, 0.3901771641537255, 0.39134884019400556, 0.38913627334085166, 0.39259269424513277, 0.39072176375809836, 0.3921530346806143, 0.39100976697370116, 0.39079241250075547, 0.3899397780643959, 0.3929170014373228, 0.3889102427398457, 0.38894158966985404, 0.39256049473496046, 0.3897372295020842, 0.39233241295989824, 0.39279353041567056, 0.394793822411813, 0.3923672336865874, 0.38789207575952306, 0.391120845853698, 0.3914312515042576, 0.3890334714715387, 0.38947177671042144, 0.3914659348334752, 0.39052898429480254, 0.38922284959870224, 0.3926088816541083, 0.3930806327684253, 0.392626012584158, 0.3940140974580073, 0.3908073946687521, 0.3892480945762466, 0.3914746798428835, 0.3904998555925547, 0.39119182118013796, 0.39440940546931, 0.39126060596283746, 0.39380357363352586, 0.3891267492344566, 0.3960636570027061, 0.3884448780879086, 0.39201007885675804, 0.3887008518418845, 0.3946489935704306, 0.39012787235425966, 0.3926868131201641, 0.391174876587648, 0.39185114438627283, 0.3916316426121721, 0.39595334516728625, 0.3925237079315326, 0.3923376457510041, 0.3896145831574412, 0.3903454670719072, 0.38917045835770814, 0.3901947463552157, 0.38894958538459795, 0.39138510881685745, 0.3923698270729944, 0.391075956543871, 0.3886808121905607, 0.3895190705855687, 0.3937717227666986, 0.3892171628334943, 0.3928420579462659, 0.3929640487128613, 0.39179296280239145, 0.39022867213569434, 0.3915944700585861, 0.3908092556338684, 0.38998721832153843, 0.3919305083360158, 0.38930609106433156, 0.3915616778620318, 0.39198073642510994, 0.3898476078083702, 0.3942314390750492, 0.39122209778311207, 0.39321639089315547, 0.39556199356037025, 0.39069073004465477, 0.3901906652631713, 0.3918502590089452, 0.3921655998656563, 0.3897442833027419, 0.39050330440787706, 0.39026205139417275, 0.3908781868716081, 0.39245978443353785, 0.3903481831007144, 0.39445868105280635, 0.3892170712351799, 0.390042986282531, 0.3925706706941128, 0.39200084298556925, 0.3911351076528138, 0.39240403268851487, 0.3938527383348521, 0.3900003031480546, 0.3922225654709573, 0.3932921053001694, 0.39253465655971975, 0.3926194997540876, 0.3874349548097919, 0.39200115612908903, 0.3948955665908608, 0.3898700127998988, 0.38938687602971117, 0.3864065995257275, 0.39098570473930416, 0.3909385864641152, 0.3916171494067884, 0.39381099733359676, 0.3898175518740626, 0.3911994169740116, 0.39155133265782804, 0.39230194549058, 0.39114902234252763, 0.39017920955723406, 0.3944379236622184, 0.3916288679283039, 0.39200210498244153, 0.39363550146420795, 0.3911365672361617, 0.39186333141782703, 0.39117470471297994, 0.38984077394593, 0.39264219977399883, 0.3900822729018389, 0.38898184559508864, 0.3910406724202867, 0.3907987319809549, 0.39212526841198697, 0.39124271427007284, 0.3914998725202738, 0.38839635442869336, 0.3937654222781752, 0.3902626017875531, 0.3955241435883092, 0.39323169840317146, 0.39330630157800284, 0.38655056892072454, 0.39017754106544983, 0.3952399448436849, 0.39261257144458156, 0.3932858498073092, 0.39499423879326556, 0.3910665978111473, 0.3922448316041161, 0.39132243789294185, 0.3905644398547855, 0.39066209877822916, 0.39234474681171716, 0.3916584701806891, 0.39128884439374884, 0.38904376978091165, 0.39183107588221044, 0.3900741520611679, 0.3930635173969409, 0.38995324082526506, 0.39311547854951784, 0.3887742017121876, 0.3909773443113355, 0.38996322007448064, 0.38965144855718986, 0.39268765284442436, 0.390111534545819, 0.3925885803559247, 0.39064669915858435, 0.3895316495030534, 0.3907163414154567, 0.3907886814399093, 0.39067917981860684, 0.3914143468673323, 0.39072976911477014, 0.39038341521632436, 0.39487345085716713, 0.39242782728636966, 0.39340144921751585, 0.391638440317383, 0.38982952050134245, 0.39072682591629965, 0.39341319571523103, 0.39195014886996327, 0.3917578032203749, 0.38969211536003096, 0.3894471714601797, 0.3898716885961738, 0.39170538400318106, 0.39051353675769823, 0.39179608466870647, 0.3921622397998969, 0.39439454747765673, 0.39445579307628614, 0.39132673534400325, 0.3867330071972866, 0.3894542139388767, 0.39122700530524346, 0.3883669243431559, 0.38984382444737004, 0.3917064682817927, 0.3907441727670969, 0.39336200226463525, 0.3893578349083078, 0.3913763885696729, 0.3897980788320887, 0.3937839002293699, 0.39068301957027585, 0.3921215317997278, 0.39208485865417647, 0.3916279115513259, 0.3911278141918136, 0.39544760121726524, 0.38938475297946556, 0.39043475139667005, 0.39209672136634005, 0.39414026142627584, 0.3913420901871195, 0.39028101735839654, 0.3931575333516972, 0.39237413212072614, 0.38880399651094977, 0.3887612786801422, 0.3894933131979961, 0.3917112931901333]\n",
        "test_acc_list_exp = [75.58773816840811, 87.06976029502151, 87.53073140749846, 87.8918254456054, 87.76889981561156, 87.74969268592501, 87.98786109403811, 87.76121696373694, 87.87645974185618, 87.71896127842655, 87.74969268592501, 87.79578979717272, 87.96481253841426, 87.81115550092194, 87.81499692685925, 87.80731407498463, 87.9417639827904, 87.93023970497849, 87.76505838967425, 87.78042409342348, 87.66133988936693, 87.7458512599877, 87.7458512599877, 87.85725261216963, 87.66518131530424, 87.71127842655194, 87.65365703749232, 87.66133988936693, 87.74200983405039, 87.7458512599877, 87.85725261216963, 87.89566687154272, 87.64981561155501, 87.61140135218193, 88.02243392747388, 87.85725261216963, 87.50384142593731, 87.91871542716656, 87.82652120467118, 87.80731407498463, 87.82652120467118, 87.93792255685311, 87.6920712968654, 87.72280270436386, 87.82267977873387, 87.81499692685925, 87.87645974185618, 87.66133988936693, 87.8418869084204, 87.76889981561156, 87.88030116779349, 87.78042409342348, 87.7919483712354, 87.79963122311001, 87.81883835279656, 87.8918254456054, 87.92639827904118, 87.94944683466503, 87.78426551936079, 87.8918254456054, 87.7881069452981, 88.00322679778733, 87.87645974185618, 87.7881069452981, 87.68054701905348, 87.81499692685925, 87.71896127842655, 87.82267977873387, 87.7919483712354, 87.81883835279656, 87.83036263060848, 87.78042409342348, 87.78042409342348, 87.71511985248924, 87.72664413030117, 87.82267977873387, 87.80731407498463, 87.88030116779349, 87.83036263060848, 87.84956976029503, 87.91487400122925, 87.73048555623848, 87.81115550092194, 87.73048555623848, 87.7381684081131, 87.72664413030117, 87.8918254456054, 87.66518131530424, 87.8418869084204, 87.7919483712354, 87.69975414874001, 87.79578979717272, 87.77658266748617, 87.90334972341734, 87.75353411186232, 87.83036263060848, 87.86877688998156, 87.86877688998156, 87.7919483712354, 87.84572833435772, 87.91871542716656, 87.84956976029503, 87.83036263060848, 87.80347264904732, 87.70743700061463, 87.75353411186232, 87.9840196681008, 87.70359557467732, 87.84956976029503, 87.87645974185618, 87.7381684081131, 87.81115550092194, 87.6459741856177, 87.7458512599877, 87.51920712968654, 88.05700676090964, 87.79578979717272, 87.91871542716656, 87.56914566687155, 87.82267977873387, 87.73432698217579, 87.75737553779963, 87.81115550092194, 87.85341118623234, 87.74969268592501, 87.68054701905348, 87.63444990780577, 87.83420405654579, 87.91103257529196, 87.76505838967425, 87.80731407498463, 88.04548248309773, 87.81883835279656, 87.82652120467118, 87.6920712968654, 87.76121696373694, 87.74200983405039, 87.80347264904732, 87.96481253841426, 87.8380454824831, 87.6459741856177, 87.85341118623234, 87.92255685310387, 87.68438844499079, 87.7458512599877, 87.78426551936079, 87.81883835279656, 87.98017824216349, 87.88030116779349, 87.6421327596804, 87.9340811309158, 87.65365703749232, 87.68438844499079, 87.60371850030731, 87.66133988936693, 87.6459741856177, 87.78042409342348, 87.77658266748617, 87.58451137062077, 87.97633681622618, 87.83420405654579, 87.73048555623848, 87.84572833435772, 87.75737553779963, 87.76121696373694, 87.63829133374308, 87.91103257529196, 87.75353411186232, 87.57298709280884, 87.70743700061463, 87.73048555623848, 87.77658266748617, 87.76505838967425, 88.02243392747388, 87.84572833435772, 87.73048555623848, 87.88414259373079, 87.69975414874001, 87.88030116779349, 87.88030116779349, 87.68054701905348, 87.92639827904118, 87.95712968653964, 87.91103257529196, 87.68054701905348, 87.76121696373694, 87.78426551936079, 87.67286416717886, 87.67670559311617, 87.88414259373079, 87.79578979717272, 87.66133988936693, 87.83036263060848, 87.86493546404425, 87.78426551936079, 87.67286416717886, 87.81115550092194, 87.6421327596804, 87.70359557467732, 87.71127842655194, 87.84956976029503, 87.82267977873387, 87.7919483712354, 87.71127842655194, 87.83036263060848, 87.8879840196681, 87.76121696373694, 87.73048555623848, 87.76121696373694, 87.8380454824831, 87.75353411186232, 87.72280270436386, 87.84956976029503, 87.59987707437, 87.6959127228027, 87.62292562999386, 88.03779963122311, 87.77658266748617, 87.7381684081131, 87.80731407498463, 87.56530424093424, 87.63060848186846, 87.69975414874001, 87.71896127842655, 87.89566687154272, 87.83420405654579, 87.76121696373694, 87.63060848186846, 87.79578979717272, 87.65365703749232, 87.82267977873387, 87.85341118623234, 87.85341118623234, 87.80347264904732, 87.87645974185618, 87.84572833435772, 87.96097111247695, 87.84572833435772, 87.71511985248924, 87.85725261216963, 87.78426551936079, 87.78426551936079, 87.61908420405655, 87.86493546404425, 87.96097111247695, 87.86109403810694, 87.75737553779963, 87.84956976029503, 87.7881069452981, 87.84572833435772, 87.70359557467732, 87.71127842655194, 87.65749846342962, 87.62292562999386, 87.71896127842655, 87.96865396435157, 87.97633681622618, 87.76121696373694, 87.75353411186232, 87.81115550092194, 87.8879840196681, 87.82652120467118, 87.87645974185618, 87.68438844499079, 87.8918254456054, 87.63060848186846, 87.76505838967425, 87.5960356484327, 87.66133988936693, 87.9840196681008, 87.88030116779349, 87.86877688998156, 87.77274124154886, 87.9417639827904, 87.90719114935465, 87.7881069452981, 87.69975414874001, 87.77658266748617, 87.84572833435772, 87.67286416717886, 87.80731407498463, 87.74200983405039, 87.71896127842655, 87.6459741856177, 87.68438844499079, 87.86877688998156, 87.82267977873387, 87.78426551936079, 87.72664413030117, 87.98017824216349, 87.66518131530424, 87.6959127228027, 87.75353411186232, 87.91487400122925, 87.89566687154272, 87.72280270436386, 87.91487400122925, 87.88030116779349, 87.91103257529196, 87.75353411186232]\n",
        "\n",
        "train_loss_list_5e4 = [1.4802386524877573, 0.5145602391825782, 0.4270873037860969, 0.3911595640143728, 0.3666531684275888, 0.3449077741482717, 0.3271806535278232, 0.31609291052269095, 0.30408265799041684, 0.29365021432560634, 0.28160075124524797, 0.2770334360439603, 0.26884961707724464, 0.2641961875202533, 0.25375436896554177, 0.2502837141112583, 0.2470766868048567, 0.23852058467745457, 0.23988390942091542, 0.23230066057546997, 0.2278682370051782, 0.22565480602304464, 0.22504844034953816, 0.2194394195467476, 0.2184035734028674, 0.21561946675464067, 0.21413457837854297, 0.21124843120332656, 0.21243113762923696, 0.20603898459374098, 0.20471800083350036, 0.20373490892936222, 0.20350655851769578, 0.20246598469774899, 0.1970768437334677, 0.1986252810896897, 0.19743034299109685, 0.19816612322034874, 0.19047524803254987, 0.19524715533909112, 0.19178811626301873, 0.1882726750904467, 0.19070912812783467, 0.18814858636720394, 0.18752294930258417, 0.1876332449012494, 0.18488309697972405, 0.1866223762634647, 0.1871858422712582, 0.18362822461378606, 0.18218793275798886, 0.18321568313935585, 0.17826895162382422, 0.18373284461658176, 0.17807404935198426, 0.1832454036466959, 0.17776847138072094, 0.17643137354918612, 0.17395331942776676, 0.17643668946777255, 0.17554401157065458, 0.17678272510124093, 0.17290620969199552, 0.16925092947575943, 0.16994382533923721, 0.17394802385189023, 0.17083977395037647, 0.16816641190430012, 0.16901177336489606, 0.17049305643734894, 0.1686860634806518, 0.16724471368279237, 0.16594552272945884, 0.16281739412365245, 0.16591493490588696, 0.16363012161721704, 0.1613770334055107, 0.1623856468898494, 0.16301845652139607, 0.162652157650892, 0.1592392718626393, 0.15867647268180926, 0.16240244100329676, 0.15764614089636944, 0.15857719487654484, 0.1579075544810069, 0.15415261916028775, 0.15517796557850955, 0.15625821325554434, 0.15458142586799495, 0.15438464393985626, 0.1572210744003132, 0.15048929238262862, 0.14945686451060985, 0.1505291250440971, 0.15305787657556658, 0.14894246368550348, 0.147898023902643, 0.15114493573180382, 0.14610998743897693, 0.15086569631002783, 0.1484981526729214, 0.1449999701039901, 0.14578966223975506, 0.14083756948631954, 0.14295084347448697, 0.14506198940319098, 0.14481029806905968, 0.14044388525470647, 0.13931026286508655, 0.13716323383980328, 0.14206144404484006, 0.14102018442822667, 0.13867486305635796, 0.13811369409385896, 0.1344010781062651, 0.13408899530364568, 0.1343176202560828, 0.13219609678417524, 0.13159260965459715, 0.13269671327295665, 0.13183512560377114, 0.12735726753487012, 0.12682472022002952, 0.12942703321656884, 0.1311747801154448, 0.12721967680990534, 0.1226911582961315, 0.12565258846474373, 0.12294719365695467, 0.12425805079601807, 0.12707497591410227, 0.12184429030895717, 0.11833101225799823, 0.11996741157762081, 0.12062076490806532, 0.11433951715184099, 0.11977466401267989, 0.11421744397217988, 0.11513779362345614, 0.11420854406688756, 0.11369123289659418, 0.11147084164869818, 0.10956912912014458, 0.10847692516680332, 0.10791541966369886, 0.11187728162006877, 0.1076874076956656, 0.10829882281340235, 0.10742072247190851, 0.10462035163530328, 0.10231590462308428, 0.10307718535789306, 0.10392249831399782, 0.10356237866277214, 0.10049116989057562, 0.10070552909620571, 0.10252807007188881, 0.0956033191373597, 0.09626625927523545, 0.09980903398548442, 0.09713503368814705, 0.09384269924546645, 0.0914715800489877, 0.08955621895276838, 0.09167020563995289, 0.090305259370505, 0.09060482793616328, 0.08901907593203673, 0.08711527488610851, 0.08550666729467833, 0.08462664417589341, 0.08277387312313082, 0.0831775262416782, 0.08437745708992407, 0.07903462006309168, 0.08039322875561268, 0.08088428793136827, 0.07809663470834494, 0.07452205053169714, 0.07565905422547727, 0.07784699146360724, 0.07322079027046356, 0.07456694824272782, 0.07434099188786213, 0.07195496950349026, 0.06945457162340563, 0.06995407763495032, 0.06968635793139295, 0.06799854681420779, 0.0665388950500082, 0.06632828803324117, 0.06345813088421899, 0.06316864148266917, 0.06253555392074149, 0.06164193874588463, 0.0611763400048381, 0.06035886153573711, 0.05943589109351965, 0.05881024452638093, 0.05468251183250449, 0.0560565908366264, 0.05653399054899933, 0.05562049048248588, 0.051311384115448895, 0.052225344276767435, 0.05155897112739926, 0.049526256553293645, 0.0512430043146519, 0.04822691060415896, 0.047050642753196606, 0.04643308828764047, 0.04417288107519873, 0.04520953228056108, 0.04404221094140233, 0.04265529490744841, 0.042559341516164015, 0.04379070952893071, 0.03938076019963517, 0.03966092142758532, 0.04086068194664934, 0.03843482981150753, 0.03796145588356426, 0.03604420552757091, 0.03480926173332786, 0.035225326502645204, 0.032808877683565184, 0.03266389738152505, 0.03565281066162698, 0.03340759336365372, 0.031172389340609674, 0.030425866454685747, 0.03243158847853279, 0.028973121385324777, 0.026384176789886422, 0.026978798047197744, 0.026420692340937774, 0.0263953241601657, 0.024609150329029293, 0.025792538209220138, 0.02489618113110483, 0.02391088762519967, 0.023590878200172107, 0.023072245570535704, 0.021719697244505735, 0.01978167379306513, 0.0224422716837235, 0.01906526322807198, 0.02043990451882929, 0.0194835271951326, 0.01808247663810102, 0.018989686450673657, 0.019306088054456765, 0.017153792940761622, 0.016933396825223636, 0.015568477072599054, 0.015502154842576865, 0.016233396913596307, 0.015708776872332502, 0.01585502114947027, 0.014598894385724433, 0.013940555258366332, 0.013421826192990531, 0.013425068274836957, 0.011932213828257893, 0.013165008134731069, 0.012398852705501201, 0.013773291333588622, 0.011650380652604831, 0.011782062857671765, 0.011110670982890316, 0.011588883696175698, 0.011087752127802874, 0.010806514879342845, 0.009987936503137777, 0.01071135072052721, 0.010115013357193833, 0.010417424021213035, 0.010015223428940142, 0.009483683681138224, 0.008984847573833514, 0.009285728387196414, 0.009138723183864965, 0.009764598564845498, 0.00961481691192997, 0.009357751404228027, 0.009121658366620237, 0.00870354351181244, 0.008720945385802124, 0.008100192143321845, 0.008175653403910094, 0.008284241586373387, 0.008199483759103085, 0.008166708315275913, 0.008518998447406865, 0.008448232254922026, 0.009054402698987343, 0.008894852471574484, 0.008632234484777561, 0.008205045137029434]\n",
        "train_acc_list_5e4 = [48.277395447326626, 83.64002117522499, 86.79724722075171, 88.12493382742191, 88.89147697194282, 89.55214399152992, 89.9947061937533, 90.69772366331392, 90.96029645314981, 91.36050820539968, 91.55955532027528, 91.68660667019587, 92.08046585494971, 92.15457914240339, 92.65643197458974, 92.62466913710958, 92.80254102699841, 93.1011116993118, 93.08840656431974, 93.11593435680254, 93.28110111169931, 93.37850714663843, 93.46956061408153, 93.68131286394917, 93.59661196400212, 93.65166754896771, 93.93118051879301, 93.87612493382743, 93.82953943885654, 94.09846479618847, 94.14716781365802, 94.02858655373214, 94.13022763366861, 94.16410799364743, 94.31445209105347, 94.212811011117, 94.20434092112228, 94.25939650608788, 94.53255690841715, 94.46056114346214, 94.500794070937, 94.56855479089465, 94.40974060349392, 94.58125992588671, 94.53255690841715, 94.62361037586024, 94.77183695076761, 94.66807834833246, 94.64690312334568, 94.67866596082584, 94.7443091582848, 94.71042879830598, 94.96029645314981, 94.68290100582318, 94.88406564319746, 94.70619375330863, 94.8268925357332, 94.91371095817892, 94.92429857067232, 94.99417681312865, 94.94759131815776, 94.89253573319216, 95.142403388036, 95.1148755955532, 95.13816834303864, 94.97511911064055, 95.08946532556908, 95.23133933298041, 95.18475383800953, 95.00264690312335, 95.13393329804128, 95.06617257808364, 95.18475383800953, 95.32874536791954, 95.26521969295923, 95.21651667548967, 95.358390682901, 95.29274748544204, 95.39862361037586, 95.3223928004235, 95.47908946532557, 95.358390682901, 95.3499205929063, 95.42826892535733, 95.46638433033351, 95.43462149285337, 95.57014293276866, 95.4219163578613, 95.45579671784013, 95.63366860772896, 95.55532027527792, 95.5214399152991, 95.74166225516146, 95.71836950767602, 95.66543144520911, 95.5849655902594, 95.67178401270513, 95.75860243515088, 95.6569613552144, 95.80518793012176, 95.6929592376919, 95.71836950767602, 95.84542085759661, 95.8644785600847, 95.95764955002647, 95.92165166754897, 95.84965590259397, 95.78613022763366, 96.01694017998942, 95.98941238750662, 96.02117522498676, 95.97670725251456, 95.93859184753838, 96.09317098994177, 96.00211752249868, 96.11858125992589, 96.14822657490735, 96.15669666490207, 96.22022233986236, 96.18845950238222, 96.2075172048703, 96.16516675489677, 96.35997882477501, 96.38538909475913, 96.26257278983589, 96.2350449973531, 96.36421386977237, 96.56961355214399, 96.3790365272631, 96.54843832715723, 96.38750661725781, 96.3430386447856, 96.56749602964531, 96.65431445209106, 96.64584436209634, 96.6056114346215, 96.66490206458444, 96.52302805717311, 96.76654314452091, 96.68395976707252, 96.72631021704606, 96.67337215457914, 96.80254102699841, 96.92535733192165, 96.93170989941768, 96.84277395447327, 96.79195341450503, 96.9020645844362, 96.929592376919, 96.86394917946004, 97.01429327686607, 97.07146638433034, 97.05452620434092, 96.98041291688725, 97.05029115934357, 97.19428268925357, 97.12228692429856, 97.07993647432504, 97.32556908417152, 97.30227633668608, 97.18581259925887, 97.25357331921651, 97.28533615669666, 97.3446267866596, 97.43991529910005, 97.44415034409741, 97.41450502911593, 97.43144520910535, 97.46744309158285, 97.45262043409211, 97.56484912652196, 97.57755426151402, 97.60508205399682, 97.66225516146109, 97.53732133403918, 97.7067231339333, 97.66013763896241, 97.65378507146639, 97.76601376389624, 97.87612493382743, 97.8507146638433, 97.80836421386977, 97.89306511381683, 97.83800952885125, 97.86553732133405, 97.91847538380095, 98.0052938062467, 97.92906299629433, 97.97141344626786, 98.07517204870302, 98.04552673372154, 98.08152461619905, 98.14505029115935, 98.18951826363156, 98.1852832186342, 98.24033880359978, 98.18316569613552, 98.27633668607729, 98.26786659608258, 98.24669137109582, 98.44150344097406, 98.41821069348862, 98.30598200105877, 98.37374272101641, 98.54314452091053, 98.52196929592377, 98.51561672842774, 98.61725780836422, 98.53890947591319, 98.66807834833246, 98.59820010587613, 98.64690312334568, 98.74854420328217, 98.68925357331922, 98.70407623080995, 98.74642668078349, 98.76548438327157, 98.67019587083112, 98.89677077818952, 98.80359978824775, 98.77818951826363, 98.854420328216, 98.86924298570672, 98.94123875066173, 98.97511911064055, 98.97511911064055, 99.07252514557968, 99.06617257808364, 98.96029645314981, 99.04711487559555, 99.09158284806776, 99.08523028057174, 99.02593965060879, 99.16569613552144, 99.26098464796189, 99.214399152991, 99.2419269454738, 99.2503970354685, 99.31604023292748, 99.22498676548439, 99.30333509793542, 99.29062996294336, 99.28427739544733, 99.32874536791954, 99.36897829539438, 99.44944415034409, 99.34568554790894, 99.46638433033351, 99.40709370037057, 99.43673901535203, 99.47273689782953, 99.44944415034409, 99.46003176283747, 99.50661725780836, 99.51085230280572, 99.56167284277396, 99.58708311275808, 99.5299100052938, 99.56379036527264, 99.56802541026998, 99.59978824775013, 99.61461090524087, 99.65272631021705, 99.62519851773425, 99.7204870301747, 99.63578613022763, 99.67813658020117, 99.64002117522499, 99.69931180518793, 99.69719428268925, 99.72472207517205, 99.68448914769719, 99.70566437268396, 99.7204870301747, 99.76283748014822, 99.71625198517734, 99.75860243515088, 99.72683959767072, 99.74377977766014, 99.76707252514558, 99.78613022763366, 99.78189518263632, 99.7564849126522, 99.75224986765484, 99.75224986765484, 99.75436739015352, 99.7649550026469, 99.79460031762838, 99.7924827951297, 99.7924827951297, 99.81154049761778, 99.82424563260984, 99.79460031762838, 99.82001058761249, 99.80307040762308, 99.7649550026469, 99.73954473266278, 99.77766013763896, 99.78613022763366, 99.81365802011646]\n",
        "test_loss_list_5e4 = [0.8332259766027039, 0.6243491267748907, 0.4589659714815663, 0.4804437569543427, 0.427488262965983, 0.4090569673800001, 0.3808782717906961, 0.35566168862814995, 0.33532728992548644, 0.3060293437949583, 0.3283534451734786, 0.2954925663184886, 0.28179204358043625, 0.30891463029034, 0.3015652174750964, 0.28739879868340257, 0.30414057471880723, 0.2780561326254232, 0.2854650225125107, 0.2774708117632305, 0.2591885347649747, 0.2489084253343297, 0.26453685285706147, 0.2969295278775926, 0.2676425111644408, 0.24623633818883522, 0.2657030882569505, 0.2502379405367024, 0.2519026789814234, 0.24595809209288336, 0.2657459572907172, 0.24606278589835354, 0.26561722005991373, 0.26659162207415293, 0.27839325434144807, 0.24987868000479305, 0.24812665541528486, 0.24487176610558642, 0.2487423630321727, 0.2408910162162547, 0.23539556405853992, 0.24755567443721435, 0.24770869559371003, 0.24718565263730638, 0.239624624816226, 0.24662797083603402, 0.2383566615445649, 0.2449228444374075, 0.23434106121752776, 0.2598630274627723, 0.2621555033998162, 0.23332552688525005, 0.23622890707908892, 0.24026584826117636, 0.2526375870494282, 0.23738020169092158, 0.2334751014177706, 0.2508628443796553, 0.2439220617068749, 0.23279762205978236, 0.24812749104903026, 0.23510865852528928, 0.24088096268036785, 0.2441782963772615, 0.2372785997120481, 0.2591664406160514, 0.24067971285651713, 0.2356143380497016, 0.22471256245512003, 0.23980964548593642, 0.22926432496922858, 0.22651415298163308, 0.23500783566166372, 0.24451460265645794, 0.24563370374780075, 0.238621749385607, 0.24734771609598516, 0.24317575092701352, 0.2357527948002897, 0.23691468079592667, 0.2317277501318969, 0.2389378704167172, 0.2415773031100923, 0.22682394105575832, 0.24305828332024462, 0.23989992117618814, 0.24055047181672326, 0.2310189416851191, 0.2320305799663651, 0.24022304533305122, 0.23773051294333794, 0.23404084142370551, 0.22795141963105575, 0.24373077162924936, 0.2519711878004612, 0.24464675623412227, 0.24204467719092088, 0.23641339631057254, 0.22852404189168238, 0.23696348417148577, 0.23560348832431963, 0.2293583228636314, 0.22483952014761813, 0.2419880603750547, 0.24878904088308998, 0.23500451945937148, 0.23449834377742282, 0.23925709554596858, 0.22304683715543328, 0.23272172509528258, 0.23005880462918796, 0.2274422672230239, 0.24031657513742352, 0.23025121483221359, 0.23231310611042907, 0.23103023649138563, 0.23504440533910312, 0.23217533609154178, 0.24353400623316274, 0.23417713490369566, 0.23423893881194732, 0.228971739591775, 0.23540909750861863, 0.22729575031382196, 0.24729683045663087, 0.23187032206824013, 0.23728142879611136, 0.2368104361983783, 0.23822332604550847, 0.24225895598019456, 0.24053165952072425, 0.23070352232339336, 0.23100480022748895, 0.23646043049281135, 0.2497626494835405, 0.2328693575280554, 0.2476191526169286, 0.24926081999186792, 0.22955395642887144, 0.23540200713072337, 0.24256359033432662, 0.23535256659356402, 0.22585722259884955, 0.23929224061030968, 0.2362090051356776, 0.2323842137759807, 0.23957762155024445, 0.23328206293723164, 0.24211033893858686, 0.24111823025433457, 0.2357599771234627, 0.23172222019410602, 0.23386546501926347, 0.2514914059828894, 0.2433166304037121, 0.2378106768261276, 0.22987670018611586, 0.230959424767278, 0.23733513216104576, 0.24432600466717108, 0.23943918337132417, 0.24938077077853912, 0.24655740848724164, 0.2478333150456641, 0.25572608141045944, 0.24093728490612087, 0.24338949404145574, 0.24488756612089335, 0.2545141223452839, 0.24692704464655882, 0.2547990579669382, 0.2425614733468084, 0.24526120959689804, 0.2513910967254025, 0.24536202011593417, 0.24960096059914896, 0.24901917171390617, 0.24787598632860416, 0.25261163421194344, 0.24638482389569866, 0.2529066298522201, 0.24463685903259935, 0.2410413659926431, 0.2477684386403245, 0.2515937814708142, 0.25298880261606443, 0.2537755832423036, 0.24700629240011468, 0.25862112336372045, 0.2538327400974345, 0.25513705633142414, 0.25248319325128604, 0.25129741044970705, 0.25710856879823935, 0.2602397995252235, 0.2535753774401896, 0.25966272229219184, 0.26258349593947916, 0.2575982420467863, 0.25366368794850275, 0.26840075843182265, 0.2604089367623423, 0.26335741690926107, 0.26115994502370266, 0.27586783806556, 0.2699058622340946, 0.2690262606038767, 0.26124058914023873, 0.2695645693068703, 0.269948998539179, 0.2699922961274199, 0.2781037180410588, 0.26918452950742316, 0.2656496547746892, 0.27793413524826366, 0.2727473574854872, 0.26761945906807394, 0.28111935063612226, 0.2739635939691581, 0.2791407521741063, 0.27640176702327296, 0.27548765678269166, 0.2720885994460653, 0.2716641928087555, 0.29375703590830754, 0.2741913403402649, 0.2834579655352761, 0.2800045997799173, 0.2746915383556602, 0.28199352176093, 0.2871078792502921, 0.2875168366430729, 0.2797919814200962, 0.2876746460211043, 0.2826278824541791, 0.2888666771662732, 0.28122600651912244, 0.2926978058565189, 0.2832188007111351, 0.2851658707082856, 0.2897379945543613, 0.2852640647404626, 0.29130700086334754, 0.29031389254127066, 0.301364694575907, 0.29234155917576715, 0.30245087251943703, 0.29240411739138994, 0.2921989212068273, 0.29711635103997064, 0.30123716481395213, 0.29383554357085745, 0.2976747955944316, 0.2940556710385078, 0.29956718912238584, 0.2989022258906534, 0.3001505616760137, 0.29694770219023614, 0.296321282619793, 0.30678381798241067, 0.2958103663415885, 0.29974740378412545, 0.29243658106847137, 0.29601444117724895, 0.2992933266522253, 0.3056794012914978, 0.3159245145963688, 0.3084262056714472, 0.3033023014774217, 0.2999487395635715, 0.305078714501624, 0.29950604752144394, 0.3001469790424202, 0.3019553049303153, 0.3047376123220459, 0.30005093909087865, 0.2961901391984201, 0.3029952965421127, 0.2991081877867235, 0.3034919787508746, 0.30540474100659293, 0.29712304374312654, 0.304328731279455, 0.30321371049492385, 0.3067686218019648, 0.30573491976760764, 0.30279137281810536, 0.304144932066693, 0.3118132336941712, 0.3035398056803673, 0.3062666428193231, 0.3056575841106036, 0.30131836995190264, 0.3063342159285265, 0.31325177424678613, 0.2976547159327596, 0.3059330361475255, 0.2988617525655119, 0.29846939126796584, 0.3085705796804498]\n",
        "test_acc_list_5e4 = [73.40580823601721, 79.92086662569146, 86.0479409956976, 85.25276582667486, 87.02750460971113, 87.60755992624462, 88.40273509526736, 89.31699446834665, 89.8740012292563, 90.96496619545175, 90.20052243392747, 91.4259373079287, 91.59496004917025, 91.09557467732022, 91.30301167793485, 91.72172710510141, 91.09557467732022, 91.82928703134604, 91.69483712354025, 91.82160417947142, 92.55147510755992, 92.82805777504609, 92.3939766441303, 91.19161032575292, 92.22111247695145, 92.82037492317149, 92.24031960663798, 92.8242163491088, 92.70513214505225, 92.94330055316533, 92.41318377381684, 92.88952059004302, 92.42086662569146, 92.1980639213276, 92.02519975414874, 92.71665642286416, 92.86647203441917, 92.96250768285188, 92.83958205285802, 93.14305470190534, 93.32744314689613, 92.98939766441303, 93.01244622003688, 93.0278119237861, 93.2160417947142, 92.97019053472648, 93.29287031346036, 93.04317762753534, 93.25829748002458, 92.65903503380454, 92.59373079287032, 93.4119545175169, 93.1238475722188, 93.28134603564843, 92.85494775660726, 93.31207744314689, 93.42347879532882, 93.00476336816226, 93.08927473878303, 93.51951444376152, 93.00860479409957, 93.36585740626921, 93.20835894283958, 92.98555623847572, 93.39274738783037, 92.60141364474492, 93.18146896127843, 93.35049170251997, 93.68469575906576, 93.27750460971113, 93.51951444376152, 93.6578057775046, 93.51951444376152, 93.1238475722188, 92.98555623847572, 93.27366318377382, 93.15457897971727, 93.38890596189306, 93.45421020282728, 93.32360172095882, 93.44268592501537, 93.38122311001844, 93.4618930547019, 93.59634296250768, 93.42347879532882, 93.34665027658266, 93.31976029502151, 93.7077443146896, 93.42347879532882, 93.34665027658266, 93.49646588813768, 93.48110018438844, 93.6578057775046, 93.37354025814382, 93.1238475722188, 93.1737861094038, 93.24677320221267, 93.45421020282728, 93.71542716656423, 93.39658881376766, 93.5041487400123, 93.58097725875845, 93.9881684081131, 93.26982175783651, 93.0201290719115, 93.61555009219423, 93.52335586969883, 93.39274738783037, 93.91518131530424, 93.71926859250154, 93.86140135218193, 93.77688998156115, 93.37354025814382, 93.69237861094038, 93.6578057775046, 93.80762138905962, 93.49262446220037, 93.66548862937923, 93.40427166564228, 93.6578057775046, 93.68469575906576, 93.66548862937923, 93.61939151813154, 94.08420405654579, 93.59634296250768, 93.65012292563, 93.6539643515673, 93.61939151813154, 93.61170866625692, 93.48878303626306, 93.58097725875845, 93.73847572218807, 93.73079287031346, 93.66164720344192, 93.4119545175169, 93.75, 93.48110018438844, 93.58097725875845, 93.86524277811924, 93.73079287031346, 93.47725875845114, 93.90749846342962, 94.19944683466503, 93.66933005531654, 93.66933005531654, 93.79609711124769, 93.700061462815, 93.88060848186846, 93.80762138905962, 93.76920712968654, 93.75, 93.86524277811924, 93.88829133374308, 93.6078672403196, 93.75768285187462, 93.76152427781193, 93.87292562999386, 94.0419483712354, 93.93054701905348, 93.85371850030731, 93.91902274124155, 93.6539643515673, 93.9881684081131, 93.66548862937923, 93.53872157344806, 93.89981561155501, 94.01505838967425, 94.06115550092194, 93.7077443146896, 93.799938537185, 93.59250153657038, 93.91902274124155, 94.02658266748617, 93.82298709280884, 94.01505838967425, 93.90749846342962, 93.96511985248924, 93.91133988936693, 93.76536570374923, 94.0918869084204, 93.78841425937308, 93.96896127842655, 94.09956976029503, 94.14566687154272, 93.8921327596804, 93.91518131530424, 93.8921327596804, 94.26090964966195, 93.80762138905962, 93.88060848186846, 94.01889981561156, 94.07652120467118, 94.14566687154272, 94.10341118623234, 93.8460356484327, 94.02658266748617, 93.91902274124155, 93.86908420405655, 94.12645974185618, 94.1379840196681, 93.93822987092808, 94.07652120467118, 94.08420405654579, 94.0381069452981, 93.85755992624462, 94.02658266748617, 94.00353411186232, 94.18792255685311, 94.02274124154886, 94.0918869084204, 94.21865396435157, 93.99200983405039, 94.06499692685925, 94.28011677934849, 93.99969268592501, 93.96896127842655, 94.28011677934849, 93.97664413030117, 94.22633681622618, 94.24170251997542, 94.05731407498463, 94.13414259373079, 94.1917639827904, 94.49139520590043, 93.99200983405039, 94.28779963122311, 94.03042409342348, 94.38767670559312, 94.19944683466503, 94.1840811309158, 94.11109403810694, 94.07267977873387, 94.23017824216349, 94.38383527965581, 94.32237246465888, 94.21481253841426, 94.22249539028887, 94.24938537185002, 94.31853103872157, 94.34926244622004, 94.21865396435157, 94.29932390903504, 94.25322679778733, 94.26090964966195, 94.29548248309773, 94.41840811309157, 94.17639827904118, 94.36078672403197, 94.37231100184388, 94.13414259373079, 94.19944683466503, 94.34157959434542, 94.34157959434542, 94.36846957590657, 94.35310387215735, 94.24170251997542, 94.37231100184388, 94.36462814996926, 94.39920098340504, 94.25706822372464, 94.43761524277812, 94.50676090964966, 94.53749231714812, 94.40304240934235, 94.40688383527966, 94.24554394591273, 94.41072526121697, 94.35310387215735, 94.45298094652735, 94.41072526121697, 94.36846957590657, 94.35310387215735, 94.34926244622004, 94.48755377996312, 94.30316533497235, 94.5259680393362, 94.54133374308543, 94.36846957590657, 94.4299323909035, 94.4299323909035, 94.34157959434542, 94.45682237246466, 94.36462814996926, 94.5259680393362, 94.38383527965581, 94.34542102028273, 94.43761524277812, 94.35694529809466, 94.34157959434542, 94.35310387215735, 94.39920098340504, 94.3761524277812, 94.44913952059004, 94.39920098340504, 94.25706822372464, 94.40688383527966, 94.40304240934235, 94.53749231714812, 94.49139520590043, 94.39920098340504]\n",
        "train_loss_list_1e2 = [1.5527255651427478, 0.7627066397246952, 0.6569193178399145, 0.5921073180388629, 0.546498658453546, 0.5105415238597528, 0.47226018775607836, 0.45309981219167633, 0.43924911138488026, 0.43100208492298436, 0.4212728382610693, 0.41300465610776815, 0.4045538008213043, 0.4054832284043475, 0.3981784124603763, 0.3888350862070797, 0.39557689973493904, 0.3849596505565695, 0.38653959386393955, 0.3762374546146651, 0.3782367709529432, 0.378456503718203, 0.3755849917245105, 0.3749620059560631, 0.36809034039819144, 0.36870617429576913, 0.3730806762448494, 0.36712608452088785, 0.36660385567967485, 0.36959863246133334, 0.3632444916217308, 0.3644418810118182, 0.36485538633696757, 0.36698362255484107, 0.3613756539295036, 0.35718589920177046, 0.36429271227137505, 0.36132887983063694, 0.3543453055022532, 0.3603528007097684, 0.3564891892720044, 0.35404422895372073, 0.35419524224793036, 0.35227534304143293, 0.3567796440790016, 0.3542361634614345, 0.35447870001075715, 0.34879108730370434, 0.3530310347958955, 0.3487641865887293, 0.3490374646778029, 0.34873911532444685, 0.34579125224413265, 0.3513515398592807, 0.3442573002602673, 0.3463528130435685, 0.3472748042606726, 0.3470753237483947, 0.34206526155071204, 0.3467505073482751, 0.34544345078268024, 0.3452807960067661, 0.34138486039670823, 0.3389452373997629, 0.3426176652029601, 0.34132564726076153, 0.3424493167296981, 0.3418385875095843, 0.3418787742856395, 0.34008422926027926, 0.339485853748916, 0.33518301576456727, 0.3393149601653985, 0.34077820496830513, 0.33797502247137107, 0.3379082687017394, 0.33854370699503883, 0.34068398940853956, 0.3345345121815922, 0.3382403756464077, 0.3322211721644492, 0.3343696817957612, 0.33672725802999204, 0.33137381682551004, 0.33107420422520417, 0.33307342098011233, 0.3294808776559545, 0.33175269314428657, 0.33532339277952344, 0.3320228717514493, 0.3307226697200036, 0.32816360587996196, 0.32942063278622097, 0.32721746008247543, 0.3277757565584286, 0.3272739693643601, 0.32677768360631576, 0.32788037005963366, 0.3252505469855254, 0.323792631427447, 0.3279054834025339, 0.324119375973213, 0.3267514456093796, 0.31973684213671905, 0.3212464982416572, 0.3202035142800349, 0.32931598875580764, 0.32346599341084964, 0.32207406047721543, 0.3172987587245176, 0.3217875505204446, 0.31829690812079886, 0.31830294115271995, 0.31893069468701113, 0.31877699518591407, 0.312669252032833, 0.31463882803593873, 0.31603938769195783, 0.3125667206155575, 0.3170066020756879, 0.31546638635438956, 0.31003526991944974, 0.31431218396195876, 0.3105714437034395, 0.30887893088626345, 0.3134051806881499, 0.31058979543243964, 0.30319389363695287, 0.3121243864701692, 0.3095417679325352, 0.30828995017339866, 0.3101163512565256, 0.3107531458381715, 0.3027265773717627, 0.3056968258325323, 0.3024863699668145, 0.30128581620005734, 0.3016197922107004, 0.299526641968143, 0.2986661980387964, 0.2984643379645296, 0.29741050064725283, 0.2990728767745217, 0.2990959255191369, 0.29619891364076917, 0.29736113919798274, 0.2955238256593384, 0.29230425500772833, 0.2962869802706933, 0.29052087436442775, 0.29694146858805887, 0.29178089206296254, 0.29490946855163835, 0.29239766099830955, 0.2924875763212116, 0.28727431777046947, 0.2880558754168552, 0.2857201242753807, 0.2816028292909224, 0.2807034290014567, 0.28417113209319955, 0.28439420837212387, 0.2830575307008374, 0.2813569333777841, 0.27838333346817873, 0.27398664932344663, 0.2771222206958264, 0.27646606219654807, 0.2802742558927717, 0.2772935264034646, 0.2740311811004228, 0.2723778088483707, 0.2723173482752428, 0.2726296799858088, 0.27150820464218856, 0.26980353556674347, 0.26999763235813234, 0.271178680888521, 0.2675590464052792, 0.2703916107816748, 0.266955815921954, 0.2677417722982443, 0.2664734733096629, 0.2616598152007837, 0.2618987378348826, 0.26313713015256535, 0.2639927453182254, 0.259921546025974, 0.258447800689758, 0.25932324954326236, 0.25735331044045245, 0.2553924481841284, 0.2541026953193877, 0.25215241785456494, 0.2530908481013484, 0.25340088620418455, 0.25041529901709336, 0.2508946477478436, 0.2468922998766266, 0.2466819979311005, 0.24553922820220472, 0.24616448865915702, 0.24352020812713035, 0.245112945454392, 0.24095632723434185, 0.23944184220418696, 0.2382999281007746, 0.23802665427206007, 0.23865492385496614, 0.23545282233132903, 0.2377435686142464, 0.23764096109605418, 0.2318824281900879, 0.23145699398062095, 0.23044203516590564, 0.22966974194295361, 0.2281639202823484, 0.22935683029857754, 0.2232396638974911, 0.22491911413062232, 0.22704380019731962, 0.2246162830410288, 0.22387785173770858, 0.22307075927574138, 0.21958557272022008, 0.21611802863477045, 0.2176091348737236, 0.21643275698914438, 0.21815684972820568, 0.21690630444343173, 0.2144953469596904, 0.21045533636317343, 0.21018598590116838, 0.20738654356540703, 0.21073267158615558, 0.20730509647347417, 0.20378858273026096, 0.2044903948034859, 0.20360999324215137, 0.1994028746233723, 0.20446652236588925, 0.20125386017932478, 0.19629940685379474, 0.19656375153520242, 0.19888904985535114, 0.19253174583036403, 0.19341871907636726, 0.1911584874236487, 0.19066347582593843, 0.19120384700253082, 0.18559699137076777, 0.1865291543365494, 0.18703436189227635, 0.18597213580679442, 0.1833313486076952, 0.18305706753721082, 0.1841687772897524, 0.18172660851623954, 0.17979243877255496, 0.1783425477017878, 0.17759921925702715, 0.17537852715912874, 0.1756007778571873, 0.17712873846373262, 0.1747176744104401, 0.17266693390239546, 0.16993015551268248, 0.17234542241022194, 0.17027409417115577, 0.17333801079612116, 0.16846228924991316, 0.16776102249255673, 0.17062995226442976, 0.169317345773463, 0.16778956143675136, 0.16644412503252184, 0.16641084437932424, 0.16423629589762467, 0.16514317738775638, 0.16319842011665264, 0.16312887173317636, 0.16379846247836827, 0.16102075314295647, 0.16114530194459892, 0.16031344735687017, 0.1607335551180006, 0.1630021522381926, 0.1587733793246552, 0.16005276916876718, 0.15837314123222176, 0.1588358394296835, 0.1603796430699386, 0.16015164662142434, 0.15751453530457285, 0.15853346335047952, 0.15670412618333732, 0.16078843703357185, 0.15981154410335108, 0.1568133581258094, 0.1594764508286789]\n",
        "train_acc_list_1e2 = [46.18951826363155, 75.3859184753838, 79.5214399152991, 82.13446267866595, 83.8369507676019, 84.98676548438327, 86.23186871360508, 86.93276866066702, 87.21651667548967, 87.58284806776072, 87.91953414505029, 88.02541026998412, 88.43620963472736, 88.48914769719428, 88.59925886712546, 88.89994706193754, 88.69666490206458, 89.00582318687135, 88.91053467443092, 89.20910534674431, 89.17734250926416, 89.13075701429328, 89.19428268925357, 89.38909475913182, 89.55637903652726, 89.499205929063, 89.42721016410799, 89.4907358390683, 89.41450502911593, 89.40603493912123, 89.69401799894123, 89.6156696664902, 89.5436739015352, 89.5796717840127, 89.7427210164108, 89.89306511381683, 89.7511911064055, 89.74483853890948, 89.93965060878772, 89.74060349391212, 89.93118051879301, 89.99682371625198, 89.97564849126522, 89.99258867125464, 89.88459502382213, 90.10693488618317, 90.01588141874008, 90.13234515616729, 89.9777660137639, 90.18316569613552, 90.14716781365802, 90.19163578613023, 90.26151402858656, 90.0582318687136, 90.34409740603493, 90.23186871360508, 90.30174695606141, 90.29539438856538, 90.37162519851773, 90.16410799364743, 90.25092641609317, 90.20434092112228, 90.40338803599788, 90.49867654843833, 90.26151402858656, 90.33774483853891, 90.25092641609317, 90.47750132345156, 90.31021704605611, 90.4372683959767, 90.39491794600318, 90.67866596082584, 90.47114875595553, 90.35044997353097, 90.40550555849656, 90.57278983589201, 90.46691371095818, 90.46056114346214, 90.64902064584436, 90.43091582848068, 90.65749073583906, 90.53890947591319, 90.6003176283748, 90.6807834833245, 90.61302276336686, 90.65325569084172, 90.62996294335628, 90.7993647432504, 90.58337744838539, 90.66807834833246, 90.716781365802, 90.78242456326099, 90.7993647432504, 90.81842244573849, 90.94123875066173, 90.78454208575967, 90.83748014822658, 90.72313393329804, 90.87347803070408, 90.8628904182107, 90.74642668078349, 91.11064055055584, 90.8798305982001, 91.0619375330863, 90.98570672313393, 91.02805717310747, 90.86924298570672, 90.98782424563261, 91.01535203811541, 91.1784012705135, 90.95606140815246, 91.12122816304924, 91.19745897300159, 91.08523028057174, 91.12758073054526, 91.27157226045527, 91.08523028057174, 91.14452091053468, 91.28851244044468, 91.07676019057702, 91.21863419798835, 91.36897829539438, 91.16146109052409, 91.29486500794071, 91.27368978295394, 91.19534145050291, 91.23133933298041, 91.56167284277396, 91.24827951296983, 91.33933298041292, 91.43250397035469, 91.41556379036527, 91.32027527792482, 91.68025410269983, 91.61672842773955, 91.68448914769719, 91.64002117522499, 91.61249338274219, 91.63790365272631, 91.7564849126522, 91.73954473266278, 91.7289571201694, 91.77977766013764, 91.66966649020645, 91.83059820010588, 91.80518793012176, 91.76919004764426, 91.96823716251986, 91.82636315510852, 92.06776071995765, 91.928004235045, 91.95129698253044, 91.87294865007941, 91.93435680254103, 91.9724722075172, 92.0635256749603, 92.14822657490735, 92.10164107993647, 92.33245103229221, 92.26257278983589, 92.11858125992589, 92.11858125992589, 92.2795129698253, 92.27527792482795, 92.4955002646903, 92.51032292218105, 92.36633139227104, 92.41926945473796, 92.2435150873478, 92.47220751720486, 92.55690841715193, 92.66913710958178, 92.55267337215457, 92.52726310217047, 92.55902593965061, 92.69242985706722, 92.6945473795659, 92.57384859714135, 92.76019057702489, 92.68395976707252, 92.78348332451033, 92.67972472207518, 92.69878242456326, 92.93170989941768, 92.92535733192165, 92.81948120698783, 92.6945473795659, 92.91688724192694, 92.95288512440445, 93.0291159343568, 93.07146638433034, 93.11805187930122, 93.10322922181048, 93.13499205929062, 93.12652196929592, 93.19216516675489, 93.25145579671783, 93.10958178930652, 93.24510322922181, 93.37427210164108, 93.38485971413446, 93.37003705664372, 93.54155637903652, 93.41450502911593, 93.60084700899947, 93.55214399152992, 93.7067231339333, 93.63472736897829, 93.67284277395447, 93.7702488088936, 93.63260984647962, 93.65590259396507, 93.86341979883537, 93.8147167813658, 93.86130227633669, 93.92694547379566, 94.01164637374272, 94.00952885124404, 94.08364213869773, 94.02646903123346, 93.92482795129698, 94.01799894123874, 94.11752249867655, 94.21069348861832, 94.17046056114346, 94.36315510852303, 94.39068290100582, 94.32292218104817, 94.20434092112228, 94.24669137109582, 94.3928004235045, 94.56643726839597, 94.54102699841185, 94.59820010587613, 94.54102699841185, 94.72101641079936, 94.72948650079407, 94.6998411858126, 94.67654843832716, 94.84171519322393, 94.716781365802, 94.9348861831657, 94.98147167813659, 94.98147167813659, 94.87347803070408, 95.05558496559026, 95.16569613552144, 95.06405505558496, 95.21228163049233, 95.14875595553202, 95.23557437797777, 95.23980942297511, 95.30333509793542, 95.25886712546321, 95.39650608787719, 95.40921122286925, 95.44944415034409, 95.40497617787189, 95.54261514028586, 95.56802541026998, 95.59131815775542, 95.58920063525674, 95.61037586024352, 95.6019057702488, 95.64637374272101, 95.76707252514558, 95.84330333509793, 95.68872419269455, 95.80518793012176, 95.64002117522499, 95.86659608258337, 95.90047644256221, 95.7924827951297, 95.80730545262044, 95.92165166754897, 95.91318157755425, 95.91741662255161, 95.99576495500264, 95.9364743250397, 96.02117522498676, 96.10587612493383, 95.99576495500264, 96.09105346744309, 96.06140815246162, 96.1905770248809, 96.06564319745897, 95.94070937003706, 96.08893594494441, 96.11858125992589, 96.20963472736898, 96.23716251985178, 96.15669666490207, 96.11858125992589, 96.215987294865, 96.13340391741663, 96.22445738485972, 96.09105346744309, 96.1630492323981, 96.2519851773425, 96.12916887241927]\n",
        "test_loss_list_1e2 = [1.3247391093595355, 1.4372946111594929, 1.221768849620632, 1.04543336437029, 0.5333422891357366, 0.5233590896515286, 0.49802757405182896, 0.527402958010926, 0.4824988966186841, 0.4684229656761768, 0.49865198369119684, 0.47028423013056025, 0.4917339387477613, 0.4712933559774184, 0.4579176530241966, 0.4159662657800843, 0.4274352864891875, 0.4261161432254548, 0.4882675524727971, 0.4069283462914766, 0.5291290985895138, 0.43474191529493705, 0.4278999815384547, 0.39875933359943183, 0.4106285313473028, 0.43170712793282434, 0.41362819207065243, 0.3644701678524999, 0.3623922984389698, 0.40609714147799153, 0.4058787767939708, 0.3751636910087922, 0.4418983731199713, 0.4179941722575356, 0.41956588603994427, 0.46951715706610214, 0.3965024639140157, 0.5922169619623352, 0.40990259790537403, 0.4151836939009966, 0.42209712372106667, 0.41093988658166397, 0.35882656948239194, 0.4029843812333603, 0.43423887977705283, 0.38498282746649254, 0.39403144240963695, 0.4007577213148276, 0.3736706005007613, 0.37586646884971975, 0.3973163742499024, 0.6469484598321074, 0.40791156398607237, 0.3950306963832939, 0.3600991340536697, 0.3767053528013183, 0.3982468478965993, 0.4106949169700052, 0.43118151138518374, 0.38861456491491375, 0.3672837637657044, 0.39455970508210797, 0.39955709195312333, 0.4675620217241493, 0.4306795852733593, 0.36596085978489296, 0.35671870439660314, 0.36200251970805375, 0.3765243383160993, 0.34345025160149034, 0.3757677159326918, 0.5893007164784506, 0.40471649535146415, 0.3984757918937534, 0.4169327455262343, 0.5200155050146813, 0.3654365451896892, 0.3924478087939468, 0.35877613043960405, 0.5022338476835513, 0.38222038358742116, 0.3505580706485346, 0.3415709840608578, 0.3706067300894681, 0.377026793492191, 0.35964643889490294, 0.39072127464939566, 0.4306023905382437, 0.3463652852703543, 0.4006179951715703, 0.3697551385883023, 0.3627208395331514, 0.3898671181032471, 0.4780514804171581, 0.3634938892780566, 0.5188167922052682, 0.3604150237698181, 0.35250089288342235, 0.3252626089196579, 0.3479796185651246, 0.3554346494961019, 0.3606822587111417, 0.3899602895127792, 0.40885376608839225, 0.3573276655492829, 0.350634348816147, 0.3364679439395082, 0.3656962395590894, 0.5394042597389689, 0.3279435099193863, 0.3306477459184095, 0.3268139467519872, 0.36625869447986287, 0.39838596696362777, 0.381319522857666, 0.351467617002188, 0.33824310422528026, 0.34666523709893227, 0.45219722740790425, 0.31658349412621234, 0.3582795552325015, 0.3590943407924736, 0.34482148333507423, 0.33396274413840443, 0.34916307185502615, 0.4292598191429587, 0.32467805952125905, 0.3357189829443015, 0.4115390076356776, 0.31629938288938764, 0.39742738264156324, 0.3100176707786672, 0.30909344707341757, 0.412040871074971, 0.31328197568655014, 0.31859667730682034, 0.3150135146490499, 0.31053604923334777, 0.3349029737360337, 0.5725868261035751, 0.33193637963895706, 0.3257182556770596, 0.3234951227319007, 0.33131444804808674, 0.32013773888933894, 0.3087677399755693, 0.31707401840271904, 0.3055169947226258, 0.30974703742300763, 0.32284443306864474, 0.3504650902514364, 0.30639906819252405, 0.32764800407868977, 0.34437243019541103, 0.3272252177783087, 0.3307260185041848, 0.30390654708824905, 0.30922777417535874, 0.29515569072728065, 0.30915866412368476, 0.30551093005958724, 0.3073367017741297, 0.30962466521590365, 0.31125049318606945, 0.3018519765898293, 0.3057772036568791, 0.30710070960077585, 0.3110234323231613, 0.3019946907080856, 0.30974323379204555, 0.3310978485673082, 0.3041924396712406, 0.28668475308108565, 0.29636092403647946, 0.3006317568029843, 0.2844046983940929, 0.35042893543255094, 0.2765379489636889, 0.2871919143579754, 0.30185085483918, 0.2806559734265594, 0.29328389626507667, 0.2850948043313681, 0.34038400401671726, 0.29658816148545225, 0.2900318577885628, 0.3164708414936767, 0.2704349430460556, 0.28909379587161776, 0.2766348912070195, 0.2954838537410194, 0.2803557366132736, 0.2698567771151954, 0.28018723702167764, 0.2962662287275581, 0.27532919876131356, 0.2694316993595338, 0.2662475112022138, 0.28343176304855766, 0.29671202501391664, 0.27179979993139997, 0.28223006507637455, 0.2900701365707552, 0.2721700471844159, 0.26092747346881556, 0.26539998760848654, 0.26519521442698496, 0.27638812151317504, 0.2700666151575598, 0.2631940585652403, 0.2667978351533997, 0.2727283788662331, 0.26423550035585375, 0.2590555296297751, 0.27035205230555115, 0.26533449850246016, 0.2622304866273029, 0.2551094347282368, 0.26004181678096455, 0.27162871688750445, 0.24523562127176454, 0.2569774056912637, 0.251955021099717, 0.25539296215363577, 0.25087627918258604, 0.25988455777805225, 0.26432519333035337, 0.25944741738631444, 0.2533169457068046, 0.2480630805606351, 0.2482597777145166, 0.24768747327228388, 0.2565581485921261, 0.27113300364683657, 0.24470692774390473, 0.24457374613220786, 0.24245896723632718, 0.24782768728248045, 0.24563301789263883, 0.25142964742639484, 0.24496393921036347, 0.24507040318612958, 0.2429210834716465, 0.24630526723522767, 0.24146442790972253, 0.24734521755839095, 0.24448578213067615, 0.24797514888147512, 0.24284489299444592, 0.24469150555338345, 0.24450236584479904, 0.24315517479736432, 0.2357017386741206, 0.24220527233738526, 0.23520723346839933, 0.23920954018831253, 0.23878256140240267, 0.23733027867388493, 0.23719553802819812, 0.24080834782444963, 0.23478803265036322, 0.23879089633769848, 0.23768455305081956, 0.24077472737168565, 0.23638445438415395, 0.23551501680676842, 0.24104665650748738, 0.2356582859202343, 0.23666301727587102, 0.23688774943059565, 0.23403703056129754, 0.235051355598604, 0.23781126664549695, 0.23505273757173734, 0.2296296937719864, 0.23563272381822267, 0.2333506334609553, 0.23327350784458367, 0.2340209804037038, 0.23465112187698775, 0.23493007486503498, 0.2349644734652019, 0.2349888317506103, 0.2317731349783785, 0.2339920843129649, 0.23434527083208748, 0.23276801688560084, 0.23693077834140436, 0.2345955311959865, 0.23683660813406401, 0.23327333925693644, 0.23412100777176081, 0.23264528898631825, 0.23628339854379496, 0.23472745530307293, 0.23727154311742268, 0.23173269472431904, 0.23639510246906795, 0.23554416570593328, 0.23380914703011513]\n",
        "test_acc_list_1e2 = [56.81084818684696, 54.15258143822987, 59.11954517516902, 67.14428395820529, 85.01843884449907, 85.47172710510141, 85.13368162261831, 84.16564228641671, 86.33988936693301, 86.0978795328826, 85.54087277197296, 86.13245236631838, 85.2681315304241, 86.41287645974185, 86.75476336816226, 87.79963122311001, 87.76121696373694, 88.2221880762139, 85.62538414259373, 88.20298094652735, 84.53826060233558, 87.7458512599877, 87.51920712968654, 89.18638598647819, 88.2721266133989, 87.17732022126613, 87.8418869084204, 89.44376152427782, 89.52827289489859, 88.41425937307929, 88.28749231714812, 89.37461585740627, 87.20421020282728, 87.83036263060848, 87.66133988936693, 86.71250768285188, 88.33358942839583, 82.68669330055316, 88.54870928088506, 87.51152427781193, 87.83420405654579, 88.10310387215735, 89.62814996926859, 88.24523663183774, 87.93792255685311, 89.12492317148126, 88.72157344806392, 88.62553779963122, 89.69345421020283, 89.18638598647819, 88.24907805777505, 80.7659803318992, 88.48724646588813, 88.57559926244622, 89.98924400737553, 89.1479717271051, 88.84449907805778, 88.09157959434542, 87.25799016594961, 88.89059618930547, 89.37461585740627, 88.57944068838353, 88.48724646588813, 87.0582360172096, 87.6421327596804, 89.19406883835279, 90.0660725261217, 89.82022126613398, 88.93669330055316, 90.22357098955132, 89.32467732022127, 83.88137676705593, 88.01090964966195, 89.02120467117393, 88.24523663183774, 84.43070067609096, 89.69345421020283, 88.7062077443147, 90.0660725261217, 85.70221266133989, 88.79840196681008, 89.91241548862938, 90.34265519360787, 89.30931161647203, 89.48217578365089, 90.0660725261217, 88.67163491087892, 87.88414259373079, 90.2158881376767, 88.36432083589429, 89.48217578365089, 89.68961278426552, 88.49492931776275, 86.10556238475722, 89.4860172095882, 85.2220344191764, 89.60510141364475, 89.93930547019053, 90.77289489858636, 90.18131530424094, 89.85479409956976, 89.64351567301783, 88.859864781807, 87.96481253841426, 89.85095267363245, 89.98156115550093, 90.58082360172097, 89.44760295021511, 83.9582052858021, 90.56545789797173, 90.71527350952674, 90.63460356484327, 89.3899815611555, 88.23755377996312, 88.84449907805778, 89.64735709895513, 90.29655808236018, 90.08143822987093, 86.79317762753534, 91.07636754763368, 89.51290719114935, 89.83942839582053, 90.20052243392747, 90.61155500921942, 90.20436385986478, 87.51920712968654, 90.85740626920713, 90.80746773202213, 88.31822372464659, 91.16087891825445, 88.64090350338046, 91.20697602950216, 91.18776889981561, 88.29901659496005, 91.08789182544561, 91.02258758451137, 90.99569760295022, 91.32221880762138, 90.33497234173325, 83.41272280270437, 90.75368776889981, 90.65381069452981, 90.89966195451751, 90.79978488014751, 90.9419176398279, 91.30301167793485, 91.03027043638599, 91.64874001229256, 91.40288875230486, 90.91886908420406, 90.13905961893055, 91.13014751075599, 90.70374923171481, 90.13905961893055, 90.51551936078673, 90.67685925015365, 91.379840196681, 91.22234173325138, 91.6180086047941, 91.24923171481254, 91.329901659496, 91.28380454824831, 91.45282728948986, 90.97264904732637, 91.51044867854948, 91.3759987707437, 91.38752304855562, 91.16856177012907, 91.57191149354641, 91.18776889981561, 90.64228641671788, 91.29917025199754, 91.88306699446835, 91.58343577135832, 91.50660725261217, 91.91763982790411, 89.92393976644131, 92.40550092194222, 91.87922556853104, 91.72940995697603, 92.17885679164105, 92.0098340503995, 91.98294406883835, 90.3119237861094, 91.68715427166565, 91.76782421634911, 91.08020897357099, 92.5361094038107, 91.83312845728334, 92.08282114320836, 91.83696988322065, 92.11739397664412, 92.65903503380454, 92.23263675476336, 91.71788567916411, 92.31714812538414, 92.50921942224954, 92.65519360786725, 92.14044253226798, 91.75245851259987, 92.42086662569146, 92.15964966195452, 91.71788567916411, 92.55531653349723, 92.84726490473264, 92.57452366318377, 92.5860479409957, 92.32483097725876, 92.52842655193608, 92.68976644130301, 92.58220651505839, 92.440073755378, 92.74738783036263, 92.8242163491088, 92.59757221880763, 92.5361094038107, 92.7819606637984, 92.86647203441917, 92.79732636754764, 92.46696373693915, 93.28134603564843, 92.98555623847572, 93.04701905347265, 93.26213890596189, 93.1737861094038, 92.78580208973571, 92.80885064535956, 92.91256914566686, 93.11616472034419, 93.13153042409343, 93.15457897971727, 93.3581745543946, 92.99323909035034, 92.47848801475108, 93.25061462814998, 93.39658881376766, 93.43116164720344, 93.28134603564843, 93.37738168408113, 93.15457897971727, 93.24677320221267, 93.23524892440074, 93.30055316533497, 93.2160417947142, 93.44652735095268, 93.26982175783651, 93.39658881376766, 93.31976029502151, 93.51567301782421, 93.25061462814998, 93.42347879532882, 93.29671173939767, 93.6539643515673, 93.4081130915796, 93.72311001843885, 93.65012292563, 93.53103872157345, 93.37738168408113, 93.57329440688383, 93.62707437000614, 93.6578057775046, 93.63475722188076, 93.63091579594345, 93.61170866625692, 93.63475722188076, 93.69237861094038, 93.55024585125999, 93.75768285187462, 93.71158574062692, 93.66933005531654, 93.85755992624462, 93.71158574062692, 93.58097725875845, 93.5579287031346, 93.7922556853104, 93.61939151813154, 93.799938537185, 93.8921327596804, 93.75, 93.88829133374308, 93.88444990780577, 93.77688998156115, 93.77304855562384, 93.87676705593117, 93.83066994468346, 93.81146281499693, 93.97280270436386, 93.72311001843885, 93.75, 93.70390288875231, 93.76920712968654, 93.75768285187462, 93.82682851874615, 93.78073140749846, 93.88829133374308, 93.74231714812538, 93.87676705593117, 93.81530424093424, 93.80762138905962, 93.8460356484327]\n",
        "\n",
        "train_loss_list_rand = [1.3079642264985134, 0.41276279398742405, 0.3641065050996739, 0.33621111706020385, 0.32227574123276603, 0.3105190498880578, 0.2985378698645245, 0.2845963137703859, 0.27256943354115576, 0.2628671395867498, 0.25574022410361746, 0.24721774489172105, 0.23312961429276763, 0.2307181321791194, 0.22826595868925414, 0.21507334950453222, 0.21533063833468005, 0.20384218360027323, 0.20217743917774703, 0.2004433953503606, 0.18824751913385987, 0.1920065844285133, 0.187250267825314, 0.18458147579173084, 0.17769597254713698, 0.17646904064589722, 0.17025284326779164, 0.17242334513523713, 0.16955551344568168, 0.1653165416766796, 0.16184331506975297, 0.16270417981556437, 0.15991212547754208, 0.15523525618198442, 0.15527952850107254, 0.158528862697726, 0.15280010509822103, 0.15449475903861568, 0.15078019666760595, 0.15182626324132853, 0.1501983254340283, 0.1461215344810389, 0.14986899500172635, 0.14550365379892874, 0.1403558284175509, 0.14542140672361947, 0.1405470239094441, 0.14365218938669053, 0.13810036563110062, 0.14059043776617464, 0.13908706698819065, 0.13695130306409625, 0.1333991897300007, 0.1321409744359452, 0.13560862030561377, 0.1312812770133823, 0.13144924573923353, 0.13186921439257257, 0.1303779829020907, 0.12855140429727108, 0.12881272610751432, 0.12862061339160452, 0.12293643534668093, 0.12759860502530726, 0.12760409868264264, 0.12412538664127754, 0.12261246541025354, 0.12362489930598879, 0.11684692019046483, 0.12635664669115368, 0.11725350842889408, 0.1202228733800291, 0.11977898440043616, 0.11819690775863201, 0.11406317815124019, 0.12160748152975952, 0.1135327710257717, 0.11757346191178493, 0.11692589301827962, 0.11527446912838837, 0.11390696881909357, 0.11128266612547362, 0.1084120699525041, 0.11216231442604285, 0.10896211025383333, 0.1105140705963945, 0.11013614156139576, 0.11042292131146361, 0.1066427088511709, 0.10727387718190022, 0.10637671745768408, 0.10528922357614125, 0.10317711308497562, 0.10493126684209196, 0.10703022915839665, 0.10020091456328305, 0.10443359014747265, 0.10327813833911567, 0.10253999184887745, 0.10005321747151413, 0.09775119930818717, 0.09895929236590943, 0.09956198874457177, 0.09663621041176684, 0.09820591854966348, 0.0958199133102083, 0.09834191584227693, 0.10007545721734847, 0.09484737071645293, 0.09604210347482343, 0.09365542412440224, 0.09515454136037084, 0.0915899477939457, 0.08897347942620597, 0.09372411305867237, 0.09134252944855185, 0.08858357435016613, 0.08518513028073278, 0.08997638049083674, 0.09038671507906461, 0.08876956635101782, 0.08737949878330718, 0.08710510870769902, 0.08606145591512929, 0.0835256307994124, 0.08409009710317705, 0.08514642417632791, 0.08500815152889749, 0.07965256468592298, 0.08329004821365038, 0.07942846951738687, 0.08278998299463977, 0.08198488589507455, 0.07826127050075993, 0.07908188051930289, 0.076796955444161, 0.07810755274674999, 0.07818539347499609, 0.07601612444643971, 0.07647686129875057, 0.07603131658915016, 0.07302434632913045, 0.07223893472354426, 0.07550516255391726, 0.07080602620634929, 0.07053892541585899, 0.07113152286315433, 0.07030726358708408, 0.07296305139193206, 0.0674845933848563, 0.0666364010973634, 0.06634756198864643, 0.06508453956080808, 0.06460393779358364, 0.06859736059486947, 0.06357380861875811, 0.06576774500532526, 0.06143479931816903, 0.06113883249491938, 0.05898804291527526, 0.06436446549870618, 0.062575965680606, 0.05618904328710705, 0.06056681182614066, 0.057390773533856076, 0.055834507522978354, 0.05655236725839294, 0.05552395822626708, 0.058229990793154815, 0.05438301761743176, 0.05628294004304057, 0.05478681649300989, 0.05533521129878435, 0.052947258238546895, 0.0534550957836029, 0.052291425183506275, 0.052318296121398045, 0.04810188965604396, 0.04881041513397522, 0.05085457057558344, 0.04860204716054041, 0.04748570773344194, 0.04570310991030277, 0.050219918913548676, 0.04907680233577039, 0.046715650073982026, 0.0483139068832202, 0.0456187082542899, 0.039992414365666425, 0.04334353352707576, 0.04216374684476008, 0.042458749894900776, 0.04058421820687347, 0.04625414172692229, 0.03840240793173936, 0.04297558541174948, 0.0419943235463748, 0.039768285462557056, 0.037575757089335984, 0.04107870026378006, 0.03676055792433924, 0.03773308889296784, 0.03924703417941524, 0.03560067948615204, 0.035394394668046295, 0.034579224325464106, 0.034057870963436924, 0.034051362065431794, 0.036438416197471984, 0.034808342434657705, 0.03285826306012749, 0.03179724503189911, 0.03259620334458384, 0.03070403641180658, 0.030086495885802155, 0.0316626976205031, 0.03077701206708978, 0.026507464029288632, 0.030121172760641024, 0.028750687549244057, 0.029356615014656934, 0.025606725985805195, 0.026744502662809762, 0.029752478933878, 0.028448736762342757, 0.02331312912987005, 0.024699779668429154, 0.022614457626854823, 0.023837428991455675, 0.02521528576773296, 0.023793862451771453, 0.024236088944220444, 0.021694000673778153, 0.021232543444717783, 0.02092921472063697, 0.021585240682491118, 0.023119772801132806, 0.01890946720092025, 0.0209501470829711, 0.019511741401153165, 0.018914120605588967, 0.02016598089796246, 0.021338878327231036, 0.01794326564027022, 0.017943615567060263, 0.01755146857011599, 0.01759808525054395, 0.016239320796215276, 0.018075850542677633, 0.019246497568182225, 0.015080467639124994, 0.016554365190424955, 0.017023207680991064, 0.01558076386462372, 0.0157793698015908, 0.015399959696164017, 0.014076877912559464, 0.013944049486650664, 0.015304512502676063, 0.015483319247015286, 0.014038200535607047, 0.012375226085008625, 0.014426614435485546, 0.011954178459132166, 0.012934604996618458, 0.012563755948078846, 0.013720255432181, 0.012539297958449802, 0.012156369318544542, 0.0137886715602372, 0.010996153222921943, 0.012231470978513442, 0.011482611671153223, 0.012633665982850885, 0.0108387998392336, 0.01094505579263189, 0.012128652638798644, 0.011514820721313398, 0.011337356862415203, 0.01035400173881755, 0.010573380134891223, 0.01104129131234738, 0.011334962008059085, 0.010769810515574525, 0.010359876090660691, 0.010690325047684515, 0.009734501771636428, 0.010143442243321225, 0.010232979197024815, 0.010022813219231298, 0.010693188950729867, 0.010847516659505887, 0.009985776471894053, 0.010729328628886885, 0.011304906725903676, 0.011516948485163957, 0.010286911307117298, 0.011423589299851902, 0.010949008481963196, 0.008929194090320024]\n",
        "train_acc_list_rand = [54.77395447326628, 87.3943885653785, 88.9655902593965, 89.9142403388036, 90.33986236103759, 90.63419798835362, 91.13393329804128, 91.6209634727369, 91.94706193753309, 92.18634197988354, 92.53149814716781, 92.69878242456326, 93.09052408681842, 93.29380624669137, 93.34886183165696, 93.76813128639492, 93.82742191635786, 94.04552673372154, 94.03705664372684, 94.13658020116463, 94.56855479089465, 94.44997353096876, 94.61725780836422, 94.51773425092641, 94.82265749073584, 94.97723663313923, 95.03652726310217, 95.01111699311805, 95.08099523557438, 95.28215987294865, 95.36897829539438, 95.29062996294336, 95.37321334039174, 95.57861302276336, 95.57649550026468, 95.43038644785601, 95.65272631021705, 95.46426680783483, 95.62308099523557, 95.6019057702488, 95.74166225516146, 95.8009528851244, 95.74166225516146, 95.8369507676019, 95.97035468501853, 95.8094229751191, 95.88777130757015, 95.784012705135, 95.9915299100053, 95.86024351508735, 95.95341450502912, 96.09952355743779, 96.12493382742191, 96.19481206987824, 95.99576495500264, 96.2710428798306, 96.1990471148756, 96.22022233986236, 96.10799364743251, 96.27527792482795, 96.24563260984648, 96.28163049232398, 96.47432503970354, 96.18845950238222, 96.31974589730017, 96.4065643197459, 96.3980942297512, 96.42773954473266, 96.70301746956062, 96.21386977236634, 96.51879301217575, 96.52302805717311, 96.52302805717311, 96.54843832715723, 96.70513499205929, 96.4700899947062, 96.67548967707782, 96.54843832715723, 96.63949179460032, 96.66913710958178, 96.67125463208046, 96.68395976707252, 96.8131286394918, 96.74748544203283, 96.79407093700371, 96.76230809952355, 96.85971413446268, 96.74536791953415, 96.80465854949709, 96.81736368448915, 96.89782953943886, 96.86818422445738, 96.99735309687665, 96.94229751191106, 96.84489147697194, 97.12228692429856, 96.83853890947591, 96.91688724192694, 97.01852832186341, 97.09687665431446, 97.10322922181048, 97.1011116993118, 97.13499205929062, 97.07358390682901, 97.17734250926416, 97.20275277924829, 97.03335097935415, 97.0206458443621, 97.13922710428798, 97.18581259925887, 97.27898358920064, 97.2006352567496, 97.28533615669666, 97.35733192165166, 97.23875066172577, 97.30227633668608, 97.41238750661726, 97.5796717840127, 97.3276866066702, 97.28110111169931, 97.41238750661726, 97.3996823716252, 97.3446267866596, 97.4356802541027, 97.56484912652196, 97.5076760190577, 97.41662255161461, 97.47379565907887, 97.59025939650608, 97.57543673901536, 97.66649020645845, 97.499205929063, 97.53943885653786, 97.61778718898888, 97.63472736897829, 97.73213340391742, 97.66013763896241, 97.70248808893595, 97.77448385389094, 97.76601376389624, 97.68554790894653, 97.8147167813658, 97.87188988883007, 97.7427210164108, 97.86341979883537, 97.89306511381683, 97.8507146638433, 97.95235574377978, 97.78930651138168, 97.9777660137639, 97.94600317628375, 98.03282159872948, 98.10058231868713, 98.04552673372154, 97.90577024880889, 98.07728957120169, 97.9502382212811, 98.21492853361568, 98.12175754367391, 98.23610375860244, 98.08999470619375, 98.06670195870831, 98.34833245103229, 98.18951826363156, 98.2657490735839, 98.31021704605611, 98.25304393859184, 98.29115934356803, 98.26151402858656, 98.35256749602965, 98.27845420857597, 98.39491794600318, 98.38009528851244, 98.47961884595024, 98.3928004235045, 98.40762308099524, 98.48173636844892, 98.50291159343568, 98.53890947591319, 98.44362096347274, 98.55584965590259, 98.53679195341451, 98.56643726839597, 98.48385389094759, 98.54949708840657, 98.54737956590789, 98.5283218634198, 98.65113816834304, 98.79724722075171, 98.68501852832186, 98.74642668078349, 98.72525145579672, 98.79089465325569, 98.62572789835892, 98.85653785071466, 98.74007411328745, 98.74219163578613, 98.8798305982001, 98.9348861831657, 98.75277924827951, 98.93700370566437, 98.9073583906829, 98.85865537321334, 98.94970884065643, 98.93700370566437, 98.9518263631551, 98.96876654314453, 99.05770248808894, 98.89465325569084, 99.02170460561143, 99.05558496559026, 99.0619375330863, 99.05770248808894, 99.12546320804658, 99.12969825304394, 99.07464266807835, 99.08311275807306, 99.26521969295923, 99.16146109052409, 99.17628374801482, 99.1508734780307, 99.22710428798305, 99.23980942297511, 99.1233456855479, 99.18051879301217, 99.35415563790366, 99.28427739544733, 99.36474325039704, 99.31180518793012, 99.2779248279513, 99.28215987294865, 99.32451032292218, 99.33721545791424, 99.39015352038115, 99.46426680783483, 99.40709370037057, 99.33086289041822, 99.49179460031763, 99.41132874536792, 99.43885653785071, 99.45579671784013, 99.45579671784013, 99.42403388035999, 99.48755955532027, 99.48755955532027, 99.4854420328216, 99.50238221281101, 99.52355743779778, 99.48332451032292, 99.44944415034409, 99.6019057702488, 99.5214399152991, 99.5489677077819, 99.61461090524087, 99.55320275277924, 99.6019057702488, 99.62308099523557, 99.6209634727369, 99.60402329274748, 99.5934356802541, 99.61037586024352, 99.67178401270513, 99.60825833774484, 99.65907887771307, 99.65272631021705, 99.65484383271573, 99.62731604023293, 99.67601905770249, 99.69084171519323, 99.64213869772367, 99.69931180518793, 99.68237162519851, 99.70354685018528, 99.65060878771837, 99.71201694017999, 99.72260455267337, 99.69507676019057, 99.68025410269983, 99.71836950767602, 99.76283748014822, 99.7480148226575, 99.70566437268396, 99.69084171519323, 99.7289571201694, 99.7289571201694, 99.74589730015882, 99.75013234515616, 99.75860243515088, 99.73319216516676, 99.73319216516676, 99.71625198517734, 99.72260455267337, 99.76071995764956, 99.73319216516676, 99.70989941768131, 99.7204870301747, 99.73107464266808, 99.69084171519323, 99.72472207517205, 99.79036527263102]\n",
        "test_loss_list_rand = [1.2242924027583177, 0.4766860316489257, 0.4852036163210869, 0.4449080118507731, 0.3844677253681071, 0.3908769353201576, 0.33308059773316573, 0.3329603055528566, 0.3105304033002433, 0.2816346858208086, 0.2945175337806052, 0.277948475059341, 0.3032138998455861, 0.2831221893429756, 0.27575827159864064, 0.26203144776324433, 0.31333797563816984, 0.26917517349562226, 0.253851704628152, 0.2555090201032512, 0.2524060876492192, 0.2693595473161515, 0.2468755625042261, 0.24303570393399865, 0.29847537346330344, 0.23665455542504787, 0.24601385775296128, 0.26269593287040205, 0.241777080385124, 0.2399024426498834, 0.2372869025258457, 0.238308228114072, 0.2611099873468572, 0.2243046425100343, 0.24302090302694077, 0.2619777427730607, 0.23600055122127137, 0.2472808970247998, 0.23857459320011093, 0.23040143489910692, 0.23448149746685637, 0.23396167033078039, 0.23945477546430102, 0.24786251283013352, 0.24238866938314602, 0.23962249183187298, 0.25362784189044263, 0.22922139680560896, 0.2559051115211903, 0.23962331296620415, 0.23080364543506326, 0.22837937785787324, 0.247460591625057, 0.24376308035982006, 0.2347778041353997, 0.24077762334662325, 0.23032311426804347, 0.23188659777024798, 0.23087097901631803, 0.2372709251575026, 0.23744144363730563, 0.2374997875634946, 0.2297166377744254, 0.26560663293097536, 0.23270482321580252, 0.23472226854852019, 0.23707742974454282, 0.24279768688275533, 0.23788784751120737, 0.2408738124239094, 0.23345124054992317, 0.23940513425451868, 0.23605135612774128, 0.25073060765862465, 0.24483406474339028, 0.2369142651704012, 0.23664433430588128, 0.23283696320711397, 0.2526469752009885, 0.2293763486303243, 0.2379093081051228, 0.24137731407787286, 0.22815602656234713, 0.23056939514536484, 0.23905373445036365, 0.23256402484634342, 0.2537045240511789, 0.25104906607200117, 0.24098055192506782, 0.23426727585348428, 0.24968813399912096, 0.2255474401491822, 0.25570899116642337, 0.2658700168351917, 0.22768254453937212, 0.24381475685639123, 0.2371177078023845, 0.24363475305703924, 0.23996025838834398, 0.2301647606141427, 0.2312738028373204, 0.23250958069647645, 0.2470913831436751, 0.24546197549823454, 0.23853133864445136, 0.23482449931622135, 0.23961933846494146, 0.2363752949453306, 0.2366328848452837, 0.25023742631881263, 0.2523412738433656, 0.23386995731761642, 0.2235797121207796, 0.24124343740735568, 0.23789687029213882, 0.25894979935358553, 0.2407712943705858, 0.2473073466041801, 0.24556619305090577, 0.23585436084106856, 0.23382639826512805, 0.24988360268374285, 0.24265338982656307, 0.2321539395762717, 0.24257982144241824, 0.2509613745827593, 0.264335074900266, 0.2360795667102816, 0.24269597353778927, 0.2401655425920206, 0.2393073042964234, 0.24763254971042567, 0.23858816633183583, 0.2453654737704817, 0.24818577219312096, 0.2519976277379136, 0.24066407218867658, 0.24328664805301847, 0.2436335614754581, 0.23726862157676734, 0.2504358967291374, 0.24724281604821777, 0.24097077188757704, 0.23132461413521976, 0.24096911921001532, 0.23906312499414473, 0.23964464410628175, 0.2407097773553402, 0.24008852922741106, 0.24373903726318888, 0.24455829663202167, 0.25426618283724084, 0.24766666304283574, 0.24456659613140658, 0.23325322789377442, 0.2446374527050876, 0.24081618506826608, 0.2533364076824749, 0.2727439739083981, 0.2566343823301734, 0.24697071872651577, 0.25414097462506857, 0.25726331458153096, 0.24916001133547694, 0.24456613417714834, 0.24002879870799826, 0.23932889017148637, 0.24253216307318093, 0.24666448398584537, 0.24409404376923455, 0.2470602400820045, 0.24511258984806344, 0.24469052970993752, 0.24681322200808162, 0.2418613201737696, 0.2395190042717492, 0.25079511499543694, 0.24951477871075564, 0.24402216294159493, 0.23870123306051919, 0.23937643794160263, 0.2437281411360292, 0.2480512512665169, 0.25320648938855705, 0.2562090756517707, 0.23295449858129608, 0.24561562255828404, 0.24209332596693262, 0.2466022344853948, 0.24022627408232758, 0.24576352584157504, 0.25353608178157433, 0.2395598959068165, 0.24042998858745776, 0.23662985444945447, 0.23703962266810386, 0.235718719916893, 0.2613097871562429, 0.2468722050863446, 0.24700676372238234, 0.2492630069929303, 0.2531062271811214, 0.2422399223946473, 0.2507193155732809, 0.24836585325572422, 0.2427369980506745, 0.24839953073829996, 0.24479242154926645, 0.24397121939588995, 0.23672433973600468, 0.23719421193441925, 0.2379821332938531, 0.24366306029625384, 0.24493778684158243, 0.2369944912600605, 0.24019140792170576, 0.2482641932152796, 0.23967477823516317, 0.24958386357791504, 0.2367109964492128, 0.25533891494805905, 0.24639802287314452, 0.23953964434308456, 0.24597930709155752, 0.24053751825190642, 0.24633424845980664, 0.22887894597050606, 0.24372562420937946, 0.2494921569949856, 0.2383151944525832, 0.24101026823707655, 0.23164858017116785, 0.24176706885005914, 0.24208627506981, 0.24435219391449994, 0.23975776935763218, 0.23425774537392108, 0.24447299043337503, 0.24938677952570074, 0.23728075723949016, 0.24136556608273702, 0.2378267114982009, 0.24595940985954276, 0.24221335073896483, 0.23467198031607503, 0.23794158814730598, 0.2411233695023054, 0.23995255867895834, 0.2407341397221328, 0.24021167078000658, 0.2400192185305059, 0.23594458068848825, 0.23809927128547548, 0.2379592138470388, 0.2380814891052889, 0.23737910618165545, 0.24371199371001007, 0.23417508491661912, 0.24041478861780727, 0.2377036967333041, 0.2333276258671985, 0.2338991296824579, 0.23701730861748552, 0.23940507240374298, 0.2372228802893968, 0.23878907943235747, 0.22658240720720998, 0.23505923559195271, 0.23041910179616773, 0.23255765283315935, 0.23369695666227855, 0.23989456293501837, 0.2277499797626161, 0.23583768852347253, 0.2377351895339933, 0.24077455684378304, 0.2367346158853787, 0.23311336334867805, 0.2341520840064714, 0.23782339239693887, 0.233605924838533, 0.23291249989586718, 0.23535046233868628, 0.2341424756473405, 0.23586027203219048, 0.2356172766098205, 0.2329787541655641, 0.23569418476693624, 0.23289725104091213, 0.23461141331376983, 0.2339027374434997, 0.23413826437557445, 0.24099776943615986, 0.23312585029349314, 0.23334580722867565, 0.23665643463312996, 0.22950803500819295, 0.23740327323549518, 0.23103500169464478, 0.23477486165368236]\n",
        "test_acc_list_rand = [63.2759680393362, 85.48325138291334, 85.77519975414874, 86.6740934234788, 88.42962507682851, 88.21834665027659, 89.89320835894284, 90.08143822987093, 90.69606637984019, 91.61032575291948, 91.36447449293178, 91.82544560540873, 91.16856177012907, 91.79471419791027, 91.80623847572218, 92.490012292563, 91.03027043638599, 92.30946527350953, 92.62062077443147, 92.64751075599263, 92.9240934234788, 92.35556238475722, 93.00092194222495, 93.06622618315919, 91.64105716041794, 93.3082360172096, 93.09311616472034, 92.47080516287646, 93.21988322065151, 93.03549477566072, 93.44652735095268, 93.35049170251997, 92.45159803318992, 93.64244007375538, 93.43884449907806, 92.70129071911494, 93.63475722188076, 93.02397049784881, 93.28902888752305, 93.3620159803319, 93.28518746158574, 93.45036877688999, 93.42732022126613, 93.21220036877689, 93.40043023970497, 93.38506453595575, 92.9740319606638, 93.5118315918869, 92.77043638598647, 93.39274738783037, 93.73079287031346, 93.69237861094038, 93.28134603564843, 93.27366318377382, 93.5118315918869, 93.5118315918869, 93.75, 93.76152427781193, 93.63475722188076, 93.39658881376766, 93.48878303626306, 93.58097725875845, 93.56945298094652, 92.59757221880763, 93.69622003687769, 93.58866011063307, 93.65012292563, 93.31207744314689, 93.60018438844499, 93.53103872157345, 93.71926859250154, 93.6539643515673, 93.700061462815, 93.39658881376766, 93.33512599877075, 93.69622003687769, 93.67701290719116, 93.799938537185, 93.22756607252612, 93.78841425937308, 93.72695144437616, 93.52719729563614, 93.9420712968654, 93.81146281499693, 93.66933005531654, 93.82298709280884, 93.21988322065151, 93.3159188690842, 93.63859864781807, 93.75768285187462, 93.33512599877075, 93.93054701905348, 93.02397049784881, 92.98555623847572, 93.98432698217579, 93.37738168408113, 93.91902274124155, 93.76152427781193, 93.75384142593731, 93.91518131530424, 94.01505838967425, 93.8959741856177, 93.57329440688383, 93.56945298094652, 93.87292562999386, 93.89981561155501, 93.58866011063307, 93.76536570374923, 93.66548862937923, 93.4618930547019, 93.4618930547019, 93.86140135218193, 94.14950829748003, 93.92286416717886, 93.79609711124769, 93.34665027658266, 93.74231714812538, 93.71542716656423, 93.64244007375538, 93.83451137062077, 93.98048555623848, 93.44268592501537, 93.80762138905962, 94.0419483712354, 93.68085433312845, 93.4580516287646, 93.49646588813768, 94.05731407498463, 93.65012292563, 93.66548862937923, 93.92670559311617, 93.9958512599877, 93.92286416717886, 93.85371850030731, 93.79609711124769, 93.799938537185, 93.93054701905348, 93.57329440688383, 93.84987707437, 94.07652120467118, 93.68469575906576, 93.82682851874615, 94.20328826060233, 94.23786109403811, 93.88444990780577, 93.99969268592501, 94.03426551936079, 94.0918869084204, 93.93438844499079, 93.88060848186846, 93.8421942224954, 94.11109403810694, 94.03042409342348, 94.19560540872772, 94.16103257529196, 94.05731407498463, 94.11877688998156, 93.8921327596804, 93.18146896127843, 93.98048555623848, 94.03426551936079, 93.76920712968654, 93.75384142593731, 94.13414259373079, 93.8959741856177, 94.26859250153657, 94.16487400122925, 94.00737553779963, 94.11493546404425, 94.1418254456054, 94.01121696373694, 94.25706822372464, 94.1840811309158, 94.13030116779349, 94.25322679778733, 94.21865396435157, 94.07652120467118, 94.10725261216963, 94.31468961278426, 94.26859250153657, 94.34157959434542, 94.38383527965581, 94.1418254456054, 93.93054701905348, 93.98432698217579, 94.42609096496619, 94.0918869084204, 94.37231100184388, 94.15334972341734, 94.1917639827904, 94.07267977873387, 94.1379840196681, 94.41456668715428, 94.21097111247695, 94.42609096496619, 94.23786109403811, 94.44913952059004, 93.75384142593731, 94.24554394591273, 94.34926244622004, 94.17639827904118, 94.04578979717272, 94.41456668715428, 94.31853103872157, 94.29164105716042, 94.42224953902888, 94.16871542716656, 94.4798709280885, 94.37231100184388, 94.55285802089736, 94.57974800245852, 94.4721880762139, 94.40688383527966, 94.3761524277812, 94.57974800245852, 94.49523663183774, 94.39151813153042, 94.64505224339274, 94.31084818684695, 94.5720651505839, 94.06499692685925, 94.4721880762139, 94.48371235402581, 94.41456668715428, 94.51828518746159, 94.46450522433928, 94.75645359557468, 94.60663798401967, 94.35310387215735, 94.68730792870313, 94.42224953902888, 94.80639213275968, 94.49139520590043, 94.61047940995698, 94.52980946527352, 94.69114935464044, 94.69114935464044, 94.52980946527352, 94.4299323909035, 94.68730792870313, 94.68346650276582, 94.68346650276582, 94.72572218807622, 94.71419791026429, 94.8140749846343, 94.75645359557468, 94.71035648432698, 94.68730792870313, 94.71419791026429, 94.7180393362016, 94.76029502151198, 94.74492931776275, 94.63352796558083, 94.8140749846343, 94.77950215119853, 94.77950215119853, 94.63352796558083, 94.72572218807622, 94.76413644744929, 94.74877074370006, 94.86785494775661, 94.9139520590043, 94.89090350338046, 94.7180393362016, 94.82944068838353, 94.87553779963122, 95.14059618930547, 94.8179164105716, 94.97157344806392, 94.90242778119237, 94.77950215119853, 94.79486785494775, 95.059926244622, 94.89474492931777, 94.88322065150584, 94.65273509526736, 94.87553779963122, 94.9562077443147, 95.0560848186847, 94.85633066994468, 95.02535341118623, 94.94468346650277, 94.94468346650277, 94.89090350338046, 94.99078057775046, 94.9139520590043, 95.08297480024585, 94.8640135218193, 95.009987707437, 94.85633066994468, 94.92931776275353, 94.91779348494161, 94.89474492931777, 95.03303626306085, 95.01382913337432, 94.8640135218193, 95.059926244622, 94.91011063306699, 95.02535341118623, 94.93315918869084]\n",
        "train_loss_list_auto = [1.233994613171916, 0.4539226504360757, 0.39892785723616436, 0.36951946796278967, 0.3572437209165516, 0.3364686794720368, 0.3232357050304813, 0.3139158589891625, 0.3026524600459308, 0.2874533208566629, 0.2781618708961701, 0.2686093915607225, 0.2590999076481111, 0.2540124244685095, 0.24861641480589947, 0.24399951269956138, 0.23923811831367695, 0.23367213850543106, 0.22791126531960196, 0.22499188158893327, 0.2189200812683196, 0.21588786823680084, 0.2124546934878277, 0.21025256699501338, 0.20572112148329819, 0.20327270222792457, 0.20072129237538755, 0.19866017976064024, 0.1968877356711442, 0.19574071886901287, 0.1951820781923891, 0.19288266742940194, 0.18784783969363222, 0.18916413984526464, 0.1828709624929803, 0.18385730885716312, 0.1843048237102626, 0.18300333889680825, 0.17988054518938712, 0.181258858744368, 0.178542331658647, 0.17391858212548866, 0.1761636258706168, 0.17584359522171944, 0.1711982707808496, 0.17569120711871603, 0.17175773992569143, 0.173915388350322, 0.16686817361571923, 0.17225952138543776, 0.16737438036699281, 0.1673657556839267, 0.16454098701759728, 0.16573736306814965, 0.1634644942918444, 0.1624382801535653, 0.16135445509741947, 0.16131306556747535, 0.16117559352177915, 0.15914395086083633, 0.1600172953392432, 0.16101780488865, 0.15760242929909288, 0.15396898807730616, 0.15771295737000662, 0.15534843960751685, 0.1561997470756372, 0.1591509728664709, 0.15701023427653443, 0.15164943112105858, 0.15431425330761647, 0.14900664126041135, 0.153352343944232, 0.1493505515198559, 0.14911859873732738, 0.14959679384460942, 0.14878295808222883, 0.15090822231599954, 0.14857992124024447, 0.1422798229043238, 0.14566040609466027, 0.14016860803251022, 0.14411792125764902, 0.1434947282459516, 0.14285532939361362, 0.13819237505678886, 0.1414163154436321, 0.14048225328144504, 0.14184128016556505, 0.13658087189766127, 0.1371091021209713, 0.13647958469705854, 0.14030104450033448, 0.1342820566864356, 0.132460017448801, 0.13510010811452297, 0.13437728684264308, 0.13391815061330148, 0.13526999323974617, 0.1319109741446933, 0.12862556951680804, 0.1311150672050511, 0.12895138073601536, 0.1280926277502604, 0.1246583734444648, 0.1258313457928295, 0.13119039074252775, 0.12371570407476044, 0.12365666381146527, 0.127088230446506, 0.12291975324938129, 0.12026552173503369, 0.12566383413687793, 0.11908095294665191, 0.11616113810701584, 0.12035970375709094, 0.11933369983522711, 0.12039770268226865, 0.11876794354621634, 0.11601000496244365, 0.11410852625643012, 0.1143225629872019, 0.11847472557833363, 0.11505588743492436, 0.11526977998232292, 0.10887061650069749, 0.11221126501314685, 0.1130289217270406, 0.10819881202193699, 0.10785190677800315, 0.10976265016993694, 0.10722535189372415, 0.11091778569710933, 0.1037355175993953, 0.10539038995720022, 0.10725624183934879, 0.10473110441492017, 0.10524187781431568, 0.10344582266580606, 0.10046376290965855, 0.10230541636102244, 0.10104834323188638, 0.09822337343016775, 0.09643481571358556, 0.09879150071501894, 0.09910423679120818, 0.09642951638213179, 0.09388373310609562, 0.09664719413996227, 0.09291944237360301, 0.09731551465454706, 0.09393294235100834, 0.0910643270961072, 0.09272648085686087, 0.09104305285162881, 0.08955065546138338, 0.0918019543374134, 0.0893830211510059, 0.08985447149400708, 0.08418837443579665, 0.08402341892968025, 0.08872269753487856, 0.08367900030440108, 0.08263780010818708, 0.08400570419503421, 0.08226117769352143, 0.07964462621849243, 0.07838223139732713, 0.08443687432180576, 0.07623482352440678, 0.0776083698258975, 0.07838072785779551, 0.0768121676771904, 0.07604568784546642, 0.0725143459350436, 0.07393465473551333, 0.07306322548538446, 0.07240707697952545, 0.07385282045316083, 0.07343979802507615, 0.07113057270969156, 0.06896691102797019, 0.06815409484296674, 0.07009156708804977, 0.0681532467273758, 0.06728222967456107, 0.06581138744748381, 0.06558232954362543, 0.06402831394629184, 0.06333761556619187, 0.06604849166542211, 0.0629559245281083, 0.06010610925356749, 0.058980082528953384, 0.06005086182922044, 0.060824787476400376, 0.05992534698989131, 0.05643098939306085, 0.057716956475704184, 0.05659668708124216, 0.053585430908806846, 0.055033171598655665, 0.05309754107929867, 0.055382789058363455, 0.05485604374056182, 0.05092235739269675, 0.05250531846346954, 0.05053107007873575, 0.0519121534665567, 0.05268361157520616, 0.0467233537332859, 0.05134408576742097, 0.04966532168808951, 0.04662036005569102, 0.0450139503640837, 0.04866801698750193, 0.04202018051501616, 0.04554983728052922, 0.04452912419968787, 0.04304213310670118, 0.04245415255982621, 0.043207022256715105, 0.03915923756804711, 0.04125189706607441, 0.04201531324972245, 0.038168357637885016, 0.03893532040768725, 0.03796733750174261, 0.03782938735188568, 0.037471614144540574, 0.03584066027936937, 0.03475043938310973, 0.0372414168192523, 0.0349701477995844, 0.032000547232671685, 0.036324127803135126, 0.03360092840889383, 0.03376660571619111, 0.03266529707985155, 0.03031955579255372, 0.029453861048233096, 0.03147298792379638, 0.02912828978151083, 0.02919105650051964, 0.028830317497697627, 0.029499432632982287, 0.026986113937475735, 0.02733181188448375, 0.025803588209598046, 0.02681095107315931, 0.026404689203034126, 0.026050992537829974, 0.024809241716038224, 0.024545829161385774, 0.023867841801785316, 0.02437650318747149, 0.024598442087124094, 0.02184943623618705, 0.02212401709032212, 0.024020484405087666, 0.02130729546814622, 0.020725422284217566, 0.02076827016183324, 0.02384621110337163, 0.01958747187485479, 0.021904331655620137, 0.019382887802573884, 0.02201010962111527, 0.02058606615812495, 0.021179698650891764, 0.019447557968882527, 0.020201372229405816, 0.01894510081315509, 0.019270095492140225, 0.019144803218715156, 0.018824441063149674, 0.01760245234608337, 0.017825258844961136, 0.01776745569889704, 0.017674809900367364, 0.015994397650768117, 0.01700054095782905, 0.016447655360661145, 0.017156456882351137, 0.01641642231447496, 0.018059637108855556, 0.017820714128034588, 0.017028371335592797, 0.017178229659197596, 0.016597093391827834, 0.015798507185733616, 0.018355573935441793, 0.018139768882747993, 0.01748620302146326, 0.017001588801414197, 0.016481924058458084, 0.016723642519140127, 0.018721227355233235, 0.01641849956732637, 0.015901307702231093]\n",
        "train_acc_list_auto = [57.69825304393859, 85.86977236633139, 87.68872419269455, 88.7580730545262, 89.19428268925357, 89.96294335627316, 90.42668078348332, 90.6193753308629, 91.05134992059291, 91.40921122286925, 91.68448914769719, 91.92376919004765, 92.38327157226045, 92.51032292218105, 92.7580730545262, 92.83642138697724, 92.9571201694018, 93.145579671784, 93.35097935415564, 93.40391741662255, 93.63684489147697, 93.787188988883, 93.67707781895183, 93.92059290629963, 93.98200105876126, 94.0307040762308, 94.1492853361567, 94.34621492853361, 94.2572789835892, 94.38644785600847, 94.23822128110112, 94.46903123345686, 94.59820010587613, 94.54526204340921, 94.68925357331922, 94.60455267337215, 94.61302276336686, 94.66807834833246, 94.65749073583906, 94.71889888830069, 94.78877713075701, 94.89677077818952, 94.80783483324511, 94.89253573319216, 94.97300158814187, 94.88618316569614, 95.06405505558496, 94.9708840656432, 95.24404446797247, 94.94123875066173, 95.18898888300689, 95.11275807305452, 95.25886712546321, 95.18898888300689, 95.26521969295923, 95.19745897300159, 95.30121757543674, 95.23980942297511, 95.36262572789836, 95.39650608787719, 95.29910005293806, 95.28427739544733, 95.36897829539438, 95.47273689782953, 95.39015352038115, 95.56379036527264, 95.47061937533087, 95.29062996294336, 95.47485442032821, 95.60614081524616, 95.55532027527792, 95.58920063525674, 95.47061937533087, 95.62308099523557, 95.68237162519851, 95.7289571201694, 95.68025410269983, 95.69719428268925, 95.61672842773955, 95.87718369507677, 95.78824775013234, 95.94706193753309, 95.81365802011646, 95.784012705135, 95.80518793012176, 95.98094229751192, 95.8284806776072, 95.80518793012176, 95.79671784012704, 96.06564319745897, 95.98305982001058, 95.98729486500794, 95.95341450502912, 96.04235044997353, 96.07834833245103, 95.97882477501324, 96.10164107993647, 96.04235044997353, 95.92165166754897, 96.11222869242985, 96.22445738485972, 96.13128639491795, 96.25622022233986, 96.24563260984648, 96.35574377977765, 96.23080995235574, 96.01482265749074, 96.3790365272631, 96.32186341979883, 96.30068819481207, 96.36633139227104, 96.42350449973532, 96.23928004235044, 96.42773954473266, 96.73901535203811, 96.37691900476443, 96.52302805717311, 96.3705664372684, 96.49973530968767, 96.51244044467973, 96.60349391212281, 96.67125463208046, 96.48914769719428, 96.57173107464267, 96.56749602964531, 96.78771836950767, 96.71995764955003, 96.53361566966649, 96.87030174695606, 96.88300688194812, 96.74748544203283, 96.76866066701959, 96.74113287453679, 96.9380624669137, 96.94229751191106, 96.8406564319746, 96.87877183695076, 96.91476971942826, 96.91688724192694, 97.1371095817893, 96.88935944944416, 96.98676548438327, 97.05876124933827, 97.13922710428798, 97.00370566437269, 97.03970354685019, 97.0926416093171, 97.23451561672843, 97.21334039174167, 97.25145579671783, 97.10322922181048, 97.23451561672843, 97.31286394917946, 97.2641609317099, 97.27898358920064, 97.39544732662785, 97.24510322922181, 97.35097935415564, 97.34250926416094, 97.571201694018, 97.43779777660137, 97.34250926416094, 97.4907358390683, 97.58178930651138, 97.46109052408681, 97.51402858655374, 97.66225516146109, 97.62202223398624, 97.39544732662785, 97.7787188988883, 97.65802011646373, 97.61990471148756, 97.76177871889888, 97.68554790894653, 97.77236633139228, 97.82530439385918, 97.82953943885654, 97.83377448385389, 97.74483853890948, 97.76389624139756, 97.88671254632081, 97.9692959237692, 97.96294335627316, 97.99682371625198, 97.99258867125464, 97.98411858125992, 98.05611434621493, 98.05187930121758, 98.05399682371625, 98.06670195870831, 98.01588141874008, 98.06034939121228, 98.22763366860772, 98.26363155108523, 98.1577554261514, 98.23186871360508, 98.25304393859184, 98.31233456855479, 98.28268925357332, 98.30174695606141, 98.356802541027, 98.35256749602965, 98.40762308099524, 98.32715722604553, 98.36739015352038, 98.4647961884595, 98.37374272101641, 98.43303335097936, 98.47114875595553, 98.45420857596612, 98.54737956590789, 98.45209105346744, 98.500794070937, 98.6553732133404, 98.65749073583906, 98.59396506087877, 98.72313393329804, 98.67866596082584, 98.65960825833774, 98.68713605082054, 98.7358390682901, 98.68925357331922, 98.77183695076761, 98.81418740074113, 98.69772366331392, 98.85865537321334, 98.8438327157226, 98.83748014822658, 98.86077289571202, 98.80571731074643, 98.9793541556379, 99.00052938062467, 98.90312334568554, 98.96029645314981, 99.04923239809423, 98.91371095817892, 99.03652726310217, 99.00899947061937, 99.00052938062467, 99.14663843303335, 99.13605082053996, 99.070407623081, 99.1064055055585, 99.11275807305452, 99.16357861302276, 99.1508734780307, 99.20169401799895, 99.17416622551615, 99.28427739544733, 99.214399152991, 99.23133933298041, 99.214399152991, 99.29486500794071, 99.29062996294336, 99.31815775542616, 99.29698253043938, 99.30333509793542, 99.3499205929063, 99.36050820539968, 99.31604023292748, 99.38803599788248, 99.41344626786659, 99.40074113287454, 99.33298041291688, 99.45367919534145, 99.37533086289042, 99.44732662784543, 99.37533086289042, 99.41979883536263, 99.3859184753838, 99.4219163578613, 99.43038644785601, 99.47697194282689, 99.42826892535733, 99.47485442032821, 99.50661725780836, 99.50661725780836, 99.50026469031233, 99.51085230280572, 99.48332451032292, 99.56379036527264, 99.53838009528852, 99.57437797776602, 99.55955532027528, 99.52779248279514, 99.50238221281101, 99.50661725780836, 99.55955532027528, 99.52779248279514, 99.54685018528322, 99.57861302276336, 99.51508734780307, 99.52567496029646, 99.52567496029646, 99.51932239280042, 99.56802541026998, 99.55955532027528, 99.51720487030175, 99.53414505029116, 99.57014293276866]\n",
        "test_loss_list_auto = [0.854697944048573, 0.6584666724882874, 0.44419189148089466, 0.368239817227803, 0.4940592580858399, 0.3690771728607954, 0.3589504133982986, 0.38058222209413844, 0.34228865349409626, 0.335723892000376, 0.3109845759383604, 0.29928872741612733, 0.31392319905845556, 0.27485897220378996, 0.29255017404462774, 0.29240670237763255, 0.29151450864532413, 0.31001000624953534, 0.27774785678176317, 0.2716419890376867, 0.26590198022769945, 0.2805121213416843, 0.2706572686632474, 0.2468469972703971, 0.26480546842018765, 0.2728810971054961, 0.2413128849995487, 0.2660955771365586, 0.2647931940634461, 0.2645452043370289, 0.25069177731433334, 0.2604605190309824, 0.2517391454574524, 0.24074612459277406, 0.24114863044929272, 0.23866420425474644, 0.2425372660817469, 0.23938925549680112, 0.2456162325015255, 0.24643426432329066, 0.2441049038487322, 0.2694204639205161, 0.2634314925720294, 0.25292548164725304, 0.23815971517971918, 0.23908892777912757, 0.25206760996404814, 0.24280147584995218, 0.2520727869488445, 0.24506068306372447, 0.24997088634500317, 0.2430651504546404, 0.23414121728901768, 0.22213738378794753, 0.247228968632864, 0.2360824038658072, 0.23799972842429198, 0.23885504494183787, 0.2358027821151065, 0.24082540213039108, 0.2557054047710171, 0.23378647274027267, 0.23469267157362958, 0.23138651949371777, 0.24428480978616895, 0.24390636994412132, 0.2296548501095351, 0.2494744443718125, 0.23908411262228207, 0.25455430325339823, 0.23804409528041587, 0.23210003986662509, 0.2522754323687039, 0.24094025425466836, 0.2353047978352098, 0.22578220312282735, 0.22642643833715542, 0.23648040128104827, 0.234295295368807, 0.23118343532961957, 0.243452065167766, 0.2479072526535567, 0.23031508502568684, 0.2307430071865811, 0.24165107517996254, 0.24791739840863966, 0.2356352105225418, 0.24240106997974947, 0.23156126701802598, 0.2280945602950512, 0.23597690470370591, 0.22922540408577405, 0.23591952800166374, 0.2404799498617649, 0.2431817608063712, 0.2453049985947562, 0.23956574037598044, 0.2583299451964159, 0.2395639850338008, 0.23400587027928993, 0.23422996013187894, 0.23995153374020375, 0.2439286811825107, 0.2674359942183775, 0.22688387820095407, 0.23382534689324744, 0.23335401259143562, 0.22591980135835268, 0.24091479602251567, 0.25041070262737136, 0.23992513426963022, 0.246772261190356, 0.2418343970077295, 0.23178920693987726, 0.24677032612118066, 0.2287094014532426, 0.23909340462848253, 0.23326664954862175, 0.23168033502046384, 0.2456203530743426, 0.235371302448067, 0.23657854840013326, 0.23801417038867287, 0.24392543954080811, 0.23823796327718916, 0.24473854583487206, 0.2388810735999369, 0.24342903593445525, 0.23894497259136507, 0.24675732284930407, 0.23822559116809977, 0.24382309390998938, 0.233994769516821, 0.2258786432828535, 0.23459827412358103, 0.2277108756277491, 0.22413930849300004, 0.23876028571862215, 0.2331210555435688, 0.23749786916681948, 0.23940081419605835, 0.23199230918259012, 0.2248807309432795, 0.2320321638356237, 0.24623563007323765, 0.2446849833370424, 0.21816706947763176, 0.23581119864156433, 0.23456720739383907, 0.23432794914526098, 0.23122229463621682, 0.23320124464511288, 0.2409158118945711, 0.23544718715928348, 0.23912205432048617, 0.24141824647199875, 0.24010024325666474, 0.23027214853494776, 0.23587687485212205, 0.23447171204230366, 0.23573052238526881, 0.22679930932673753, 0.23788673353984074, 0.2422654035811623, 0.23406771814231486, 0.24568954926422415, 0.23444239714858578, 0.24608345859337086, 0.23077788804749064, 0.24224108709570238, 0.24521961490459301, 0.23251463422624796, 0.23764923413959788, 0.23524608099650518, 0.24019971548342237, 0.24640236853384503, 0.2417017009072736, 0.23782137799642833, 0.2321096704633651, 0.23188522421554023, 0.2366727679310476, 0.23386354640345364, 0.23581221812934267, 0.2355241840340051, 0.24134659725150057, 0.23631648153212725, 0.24496783960756718, 0.23486665660040637, 0.24513840322912323, 0.24078461396343567, 0.23950668804201425, 0.23140845239600716, 0.23399199486034467, 0.24893675214957958, 0.24671873864809088, 0.2451156622127575, 0.24195303742353821, 0.23557983760667198, 0.2421512438678274, 0.2412950030948017, 0.24542047667737102, 0.24159109972271264, 0.24468982922753282, 0.23934249762518733, 0.23897204303420058, 0.24556210668136677, 0.2388775425725708, 0.23601807960692575, 0.22987533620029105, 0.246987152406398, 0.24375060487392486, 0.24201714165289612, 0.24381259923764304, 0.23624742922245287, 0.2411629831162738, 0.23951337353655083, 0.24577452823081436, 0.2465735137937408, 0.23719464980211913, 0.2379434087185883, 0.24825760760508916, 0.24059011924135335, 0.2505442435287085, 0.24614961039932334, 0.24116307924337246, 0.24537831190608295, 0.24592128061853788, 0.2437269031161479, 0.24327192477443638, 0.2411747233686494, 0.24220603216877756, 0.2415566837743801, 0.24126598647996492, 0.23794463349908007, 0.2413742526744803, 0.24037200650748083, 0.2412653976467018, 0.24241722687421477, 0.2416582004368013, 0.24397952188098548, 0.24545666710564903, 0.24501819806356057, 0.238878321870431, 0.248782909119173, 0.24211586062230317, 0.24884491410179466, 0.24774682367512701, 0.2402858989331506, 0.2464034580169063, 0.2420361806255053, 0.24698023514493422, 0.24638258141702882, 0.2440691111819344, 0.24283416516275383, 0.25251583178874615, 0.24522095931438254, 0.2505062839162408, 0.24517181726610837, 0.2511264611327765, 0.24910575721193762, 0.24469954134238994, 0.2462432504467228, 0.2518011958374843, 0.24128046771511436, 0.24614255446210212, 0.23931376788509534, 0.23999540297789315, 0.23831663229594044, 0.24262406715356252, 0.24283856312360833, 0.24234587159555623, 0.24248098625856288, 0.2431600397525757, 0.2497850547763793, 0.2420718543523667, 0.2455297116664987, 0.2453975499078047, 0.25367831595826384, 0.24988036927328827, 0.2441944194884569, 0.2475952035382244, 0.24913023439619472, 0.2496498769934417, 0.2486914823233497, 0.2396043237463078, 0.24878114394332265, 0.250280501229652, 0.24539401237944178, 0.24746752302984104, 0.24443048573391257, 0.24588232408916832, 0.24387701142433227, 0.24820849407172085, 0.24091276705411135, 0.24957285682195982, 0.2468200375179888, 0.2454140442880053, 0.24415877538130565, 0.24864615638758622, 0.2471419099864422]\n",
        "test_acc_list_auto = [72.76044867854948, 79.30623847572218, 86.36677934849416, 88.89827904118009, 84.18484941610326, 88.76382913337432, 89.1479717271051, 88.55255070682237, 89.66656422864168, 90.23509526736325, 90.95344191763982, 90.95728334357713, 90.68070067609096, 91.9061155500922, 91.58343577135832, 91.4259373079287, 91.60264290104487, 91.08789182544561, 91.74093423478796, 92.12891825445605, 92.2979409956976, 91.75245851259987, 92.26336816226183, 92.83574062692071, 92.39781807006761, 92.07513829133374, 93.09311616472034, 92.47464658881377, 92.490012292563, 92.46696373693915, 92.9279348494161, 92.42086662569146, 92.87031346035648, 93.23909035033805, 93.34665027658266, 93.1661032575292, 93.21220036877689, 93.28134603564843, 93.1238475722188, 93.08927473878303, 93.13153042409343, 92.52842655193608, 92.76659496004918, 92.74738783036263, 93.25829748002458, 93.3581745543946, 92.96250768285188, 93.02397049784881, 93.00092194222495, 92.85878918254456, 92.7819606637984, 93.14689612784265, 93.42732022126613, 93.8421942224954, 93.05470190534726, 93.23909035033805, 93.4580516287646, 93.38890596189306, 93.30055316533497, 93.13921327596803, 92.91256914566686, 93.53488014751076, 93.4618930547019, 93.53872157344806, 93.24293177627536, 93.1737861094038, 93.66548862937923, 93.14689612784265, 93.36585740626921, 92.81653349723418, 93.38506453595575, 93.57329440688383, 92.79348494161033, 93.21988322065151, 93.4580516287646, 93.79609711124769, 93.82682851874615, 93.49262446220037, 93.3159188690842, 93.700061462815, 93.46573448063921, 93.10848186846958, 93.70390288875231, 93.63859864781807, 93.38506453595575, 93.26213890596189, 93.41963736939152, 93.31207744314689, 93.75384142593731, 93.80762138905962, 93.58481868469576, 93.6078672403196, 93.4618930547019, 93.40043023970497, 93.2160417947142, 93.10848186846958, 93.49262446220037, 92.96634910878919, 93.53103872157345, 93.48110018438844, 93.63475722188076, 93.46957590657652, 93.35433312845728, 92.67440073755378, 93.82298709280884, 93.799938537185, 93.73463429625077, 93.95743700061463, 93.4618930547019, 93.20835894283958, 93.50799016594961, 93.34280885064535, 93.38890596189306, 93.69622003687769, 93.45036877688999, 93.84987707437, 93.61170866625692, 93.66164720344192, 93.75768285187462, 93.5041487400123, 93.6040258143823, 93.72311001843885, 93.53488014751076, 93.51951444376152, 93.82682851874615, 93.5579287031346, 93.71542716656423, 93.55024585125999, 93.5579287031346, 93.59250153657038, 93.62323294406883, 93.5540872771973, 93.88829133374308, 94.15719114935465, 93.73463429625077, 94.05731407498463, 94.15334972341734, 93.62323294406883, 94.02658266748617, 93.88060848186846, 93.67701290719116, 93.68469575906576, 94.18792255685311, 93.92670559311617, 93.56561155500921, 93.63475722188076, 94.15719114935465, 93.70390288875231, 93.85371850030731, 93.91518131530424, 93.95359557467732, 93.83451137062077, 93.81146281499693, 93.93054701905348, 93.87292562999386, 93.68085433312845, 93.7077443146896, 94.11877688998156, 93.98432698217579, 94.05731407498463, 94.02658266748617, 94.08420405654579, 93.91518131530424, 93.73079287031346, 93.8921327596804, 93.91902274124155, 93.9459127228027, 93.77304855562384, 94.04578979717272, 93.83835279655808, 94.04578979717272, 94.24170251997542, 94.0918869084204, 94.06115550092194, 93.93822987092808, 93.83066994468346, 94.01505838967425, 94.1379840196681, 94.32237246465888, 94.20712968653964, 94.1917639827904, 93.97664413030117, 94.23786109403811, 94.16103257529196, 94.22633681622618, 94.22249539028887, 94.01121696373694, 94.2340196681008, 94.13414259373079, 94.09956976029503, 94.19944683466503, 94.27627535341118, 94.36846957590657, 93.9958512599877, 94.07267977873387, 94.02274124154886, 94.25322679778733, 94.31084818684695, 94.11109403810694, 94.24170251997542, 94.20328826060233, 94.25706822372464, 94.19944683466503, 94.20328826060233, 94.2839582052858, 94.42224953902888, 94.2340196681008, 94.31468961278426, 94.45298094652735, 94.15334972341734, 94.11493546404425, 94.29932390903504, 94.20328826060233, 94.51060233558697, 94.50676090964966, 94.3300553165335, 94.30700676090964, 94.3262138905962, 94.53749231714812, 94.4299323909035, 94.29548248309773, 94.42609096496619, 94.38767670559312, 94.49907805777505, 94.42224953902888, 94.31084818684695, 94.40304240934235, 94.42609096496619, 94.39151813153042, 94.39151813153042, 94.55669944683467, 94.51060233558697, 94.61816226183159, 94.64121081745544, 94.47602950215119, 94.53749231714812, 94.4721880762139, 94.42224953902888, 94.62968653964352, 94.49523663183774, 94.55285802089736, 94.6258451137062, 94.66425937307929, 94.43377381684081, 94.64889366933005, 94.57974800245852, 94.4721880762139, 94.59127228027043, 94.54901659496005, 94.65657652120467, 94.7180393362016, 94.69883220651506, 94.58743085433314, 94.67194222495391, 94.54133374308543, 94.80255070682237, 94.50291948371235, 94.74108789182544, 94.62968653964352, 94.58358942839583, 94.87169637369392, 94.64889366933005, 94.71035648432698, 94.64889366933005, 94.67194222495391, 94.76029502151198, 94.80255070682237, 94.84480639213275, 94.76029502151198, 94.72572218807622, 94.77181929932391, 94.73340503995082, 94.79870928088506, 94.72572218807622, 94.7679778733866, 94.79870928088506, 94.77566072526122, 94.6681007990166, 94.69883220651506, 94.91779348494161, 94.89474492931777, 94.83328211432084, 94.7180393362016, 94.74108789182544, 94.95236631837739, 94.66041794714198, 94.80639213275968, 94.89474492931777, 94.76029502151198, 94.84480639213275, 94.79870928088506, 94.82559926244622, 94.79486785494775, 94.93315918869084, 94.77181929932391, 94.73724646588813, 94.82944068838353, 94.86017209588199, 94.68346650276582, 94.76029502151198]\n",
        "train_loss_list_mix = [0.9938080568462206, 0.35387038586908565, 0.31415230790935555, 0.2923403612683782, 0.27419339736221926, 0.26117862579299184, 0.2533990740776062, 0.23811954647544922, 0.22444075424739016, 0.2126544232815908, 0.20220531072962253, 0.1921394082508113, 0.17919883605466302, 0.16964546475953202, 0.15979611703010432, 0.1510940795426123, 0.14491855573706672, 0.13836499743749134, 0.1309642790435614, 0.12873398524716617, 0.12111276983306175, 0.11748368124449803, 0.11389688689130431, 0.11343211955756838, 0.10908843426987892, 0.10161420127482919, 0.10613548600172931, 0.09860493359345246, 0.09852099015824194, 0.09253312145337099, 0.09571743579606619, 0.0894239721163542, 0.09043425027795923, 0.08437888851000606, 0.08734228457185392, 0.08459739824681263, 0.08603016985201739, 0.08408435344630423, 0.0842538814143679, 0.08313639493290648, 0.07915610890976862, 0.08019161985828706, 0.07934672697409381, 0.07348008640615275, 0.07512537754698578, 0.07437080344523438, 0.07162883216489944, 0.0783673867578227, 0.07318035851871256, 0.0718035651370883, 0.07133971100425736, 0.07315107509948132, 0.06907403099585355, 0.06669923856723195, 0.07077471686522085, 0.07059726227317156, 0.07259669639220648, 0.06424928312682039, 0.06816990300129624, 0.07005442472220194, 0.06414420206761012, 0.06591054424138734, 0.067448822017961, 0.06368785791684618, 0.06911977814121782, 0.061097499508117915, 0.0654788069770265, 0.06277953536529851, 0.06540644472227672, 0.06547933941338524, 0.05982598949344904, 0.06166121948555839, 0.06178239522865269, 0.0624033973292324, 0.06242782084730663, 0.06412811665152146, 0.058263260732356936, 0.05578944062546582, 0.06216381148998007, 0.059200966200692866, 0.0591901072205062, 0.056872100685407635, 0.05843282742350082, 0.0572318464333348, 0.05414615397853903, 0.058493246657516415, 0.054253520179025044, 0.05435604806408932, 0.05502198836046869, 0.057328540733371805, 0.05369477488509402, 0.05310384723229137, 0.052687724674913054, 0.05150350224009657, 0.053693892988237506, 0.05677452959943068, 0.05102892336624909, 0.049259034192396536, 0.0598858642962264, 0.05066231658510601, 0.050952362551588595, 0.04916074803997548, 0.048183402951382764, 0.04758161058154735, 0.049602617113409325, 0.05060552086726558, 0.05222517778582084, 0.048518680028496235, 0.04943236661191555, 0.047581606836696745, 0.045368864389040524, 0.04489896042451646, 0.04670504703587754, 0.04741490361101542, 0.045931538310770174, 0.05050023533479591, 0.04482567616988246, 0.04641831352256824, 0.04533794787548341, 0.04535460998973024, 0.04252487677591159, 0.04374113354357439, 0.04545966434976475, 0.0439752453312197, 0.04567845454906444, 0.04052308556777715, 0.042460269868868555, 0.04470255330323587, 0.03780500727092347, 0.039394413955196696, 0.041715514285838216, 0.04243160037924523, 0.04460260131949089, 0.03893550564497104, 0.04060774496163375, 0.0392627027302193, 0.03932004146527771, 0.03701888793021905, 0.038655105051975745, 0.03664332534991669, 0.03777366958124447, 0.03629977536655276, 0.0370603178433448, 0.03480971295343646, 0.036863508949757914, 0.036259976162658476, 0.0348965569795551, 0.037977313778683706, 0.03366919478457068, 0.037030147160794634, 0.037005113133009734, 0.03459730316369938, 0.03465932765962975, 0.03426345206196432, 0.031120636634816363, 0.031996667062040914, 0.03282833266700429, 0.033598321229396114, 0.03170881769935371, 0.030779237351014323, 0.03284029248120077, 0.028771491670163303, 0.03136438176636572, 0.03139654590008745, 0.02833839970310206, 0.031977539331220634, 0.0312720158529849, 0.027770824104466737, 0.02705349339371633, 0.031242900163308794, 0.02964044412090708, 0.027261546995935, 0.029478413548174143, 0.025900761455835062, 0.02524898826084062, 0.030148965941974262, 0.026517891811540094, 0.0267597234878578, 0.02813903715645738, 0.025121289003150776, 0.027856107311560532, 0.024366022234020356, 0.026482225155336707, 0.023338035278421067, 0.023866847919383486, 0.026543004754400714, 0.02394126550872434, 0.024592813269707164, 0.022726859586303272, 0.024343733735089784, 0.023029831621094246, 0.02211659858356606, 0.022111268837741883, 0.02589301477933459, 0.022846899337329595, 0.01829227261266704, 0.02427225847296962, 0.01970740448529542, 0.021607845043637323, 0.02081029445341811, 0.02079579379374217, 0.019704281869861815, 0.020279064681444085, 0.018792231148235035, 0.020250071839588445, 0.02139727115065748, 0.0197049227466196, 0.018660546160242483, 0.018084673524574255, 0.018957647942334697, 0.01931706416076125, 0.01777278999880027, 0.01756590040183568, 0.015129794698551823, 0.016428295707489115, 0.016727321038873196, 0.017704555430376353, 0.016021391709693543, 0.01640474740958452, 0.016935019902153025, 0.015831608947386666, 0.016178442318583043, 0.016684757473974472, 0.01505513205085717, 0.016159819172150116, 0.015077039387410248, 0.015197812229695257, 0.014000309425845318, 0.015123876789395462, 0.014679165285391113, 0.012634015024695192, 0.014364219435016173, 0.014739077076691942, 0.013465223549663273, 0.014016012728358127, 0.013800337897086148, 0.012497749787232861, 0.012516363376882786, 0.009907300361598714, 0.013667509257591514, 0.011486864030401557, 0.011876725475619318, 0.010641783018101784, 0.011468470570136639, 0.011481490557531253, 0.011336377388065767, 0.01226908068247089, 0.010469431545002371, 0.012306197240713954, 0.009624016467421278, 0.010600388426141848, 0.010997156687976848, 0.009556004850428582, 0.012064924670274806, 0.010308084436528243, 0.011091969076286607, 0.010341640694955299, 0.009817854730982768, 0.010156398601224267, 0.010387308722700127, 0.009045329112130492, 0.009465475142668418, 0.00877862685482424, 0.009081994435752472, 0.009157319344658415, 0.0088296683156878, 0.008334625229052695, 0.00961835922415906, 0.008183363720340538, 0.008775008815217027, 0.007791329284077435, 0.009641242586454846, 0.008015534814654125, 0.00867622388087637, 0.008515111755940628, 0.00922561221286594, 0.008882333553550123, 0.008829943086134225, 0.007059801428270877, 0.009350860031412505, 0.007657677646938379, 0.008748184417268427, 0.008469099999811793, 0.008482573831549827, 0.007719665183054743, 0.007240170458657288, 0.007590437193746934, 0.0068299245801665956, 0.007549433960127556, 0.007730878702791402, 0.007419600550887909, 0.007170365307464953, 0.007350631618208496, 0.008344900159564041, 0.007527452433888162, 0.007712224023265204, 0.007403429063178377, 0.00781597496738511, 0.00748860295596949, 0.007374107671098981]\n",
        "train_acc_list_mix = [66.52408681842245, 89.18581259925887, 90.52620434092113, 91.24827951296983, 91.84330333509793, 92.22022233986236, 92.6056114346215, 92.97617787188989, 93.47803070407623, 93.7787188988883, 94.10905240868185, 94.37797776601376, 94.85018528321864, 95.10005293806246, 95.41556379036527, 95.74377977766014, 95.87930121757543, 96.071995764955, 96.215987294865, 96.27316040232928, 96.44679724722076, 96.6225516146109, 96.74325039703547, 96.73689782953944, 96.77077818951827, 97.05876124933827, 96.83218634197988, 97.09687665431446, 97.07570142932768, 97.35309687665432, 97.18581259925887, 97.31286394917946, 97.36791953414505, 97.5796717840127, 97.37003705664372, 97.44626786659609, 97.39332980412917, 97.4907358390683, 97.50132345156167, 97.4356802541027, 97.643197458973, 97.6156696664902, 97.71942826892536, 97.80201164637374, 97.70460561143462, 97.75754367390154, 97.88671254632081, 97.66437268395977, 97.81259925886712, 97.85706723133933, 97.88035997882477, 97.8422445738486, 97.95659078877713, 98.07093700370567, 97.91212281630493, 97.84647961884595, 97.84436209634727, 98.05611434621493, 97.92271042879831, 97.84012705134992, 98.0857596611964, 97.9777660137639, 97.96294335627316, 98.07517204870302, 97.93118051879301, 98.16410799364743, 98.0307040762308, 98.1492853361567, 98.07940709370037, 97.9862361037586, 98.21492853361568, 98.04340921122287, 98.13234515616729, 98.18104817363684, 98.0582318687136, 98.0857596611964, 98.24033880359978, 98.36527263102171, 98.09846479618847, 98.22763366860772, 98.17257808364214, 98.27210164107994, 98.212811011117, 98.25304393859184, 98.42456326098464, 98.19163578613023, 98.36739015352038, 98.38644785600847, 98.36950767601905, 98.32080465854949, 98.4203282159873, 98.39915299100053, 98.41609317098994, 98.45209105346744, 98.42668078348332, 98.25092641609317, 98.51561672842774, 98.5092641609317, 98.1852832186342, 98.57278983589201, 98.5283218634198, 98.58337744838539, 98.53255690841715, 98.67019587083112, 98.55373213340391, 98.45420857596612, 98.47961884595024, 98.55373213340391, 98.53043938591847, 98.59608258337745, 98.64266807834834, 98.66172578083642, 98.63208046585495, 98.69772366331392, 98.72525145579672, 98.48385389094759, 98.69560614081524, 98.62572789835892, 98.6553732133404, 98.71889888830069, 98.78242456326099, 98.73372154579143, 98.71254632080466, 98.6913710958179, 98.67443091582848, 98.80783483324511, 98.81842244573849, 98.68713605082054, 98.96029645314981, 98.87347803070408, 98.78665960825833, 98.76336686077289, 98.73795659078878, 98.86500794070938, 98.8353626257279, 98.85230280571731, 98.87559555320276, 98.9348861831657, 98.86077289571202, 98.95817893065114, 98.90947591318158, 99.01323451561673, 98.95606140815246, 99.03229221810481, 98.93065113816834, 98.98570672313393, 99.03864478560085, 98.90312334568554, 99.08946532556908, 98.9158284806776, 98.91371095817892, 99.00052938062467, 99.0344097406035, 99.06829010058232, 99.14452091053468, 99.1233456855479, 99.03864478560085, 99.06405505558496, 99.12122816304924, 99.19745897300159, 99.11699311805188, 99.22075172048703, 99.12546320804658, 99.11911064055056, 99.20592906299629, 99.11699311805188, 99.17204870301747, 99.22075172048703, 99.2503970354685, 99.13393329804128, 99.15722604552673, 99.29698253043938, 99.16357861302276, 99.30121757543674, 99.31180518793012, 99.18051879301217, 99.2779248279513, 99.23980942297511, 99.20804658549497, 99.3223928004235, 99.23980942297511, 99.41344626786659, 99.28215987294865, 99.37109581789306, 99.38168343038645, 99.29486500794071, 99.34780307040762, 99.35415563790366, 99.41344626786659, 99.37533086289042, 99.45156167284277, 99.43250397035469, 99.40285865537321, 99.29062996294336, 99.43038644785601, 99.5574377977766, 99.37321334039174, 99.49814716781366, 99.43038644785601, 99.47273689782953, 99.47908946532557, 99.49602964531498, 99.45367919534145, 99.51508734780307, 99.50873478030704, 99.46426680783483, 99.51932239280042, 99.5299100052938, 99.57649550026468, 99.50661725780836, 99.45791424033881, 99.55320275277924, 99.55955532027528, 99.5934356802541, 99.57861302276336, 99.59131815775542, 99.5849655902594, 99.60402329274748, 99.58708311275808, 99.5659078877713, 99.60614081524616, 99.59978824775013, 99.57861302276336, 99.64849126521969, 99.62308099523557, 99.63790365272631, 99.63578613022763, 99.64002117522499, 99.64849126521969, 99.66966649020645, 99.69084171519323, 99.66543144520911, 99.64849126521969, 99.68025410269983, 99.66331392271043, 99.67601905770249, 99.71413446267867, 99.69719428268925, 99.77766013763896, 99.68237162519851, 99.73319216516676, 99.72260455267337, 99.7480148226575, 99.7480148226575, 99.71201694017999, 99.73107464266808, 99.73107464266808, 99.784012705135, 99.73530968766543, 99.784012705135, 99.74377977766014, 99.76283748014822, 99.77554261514028, 99.71836950767602, 99.7734250926416, 99.76283748014822, 99.76919004764426, 99.7734250926416, 99.74377977766014, 99.75860243515088, 99.77554261514028, 99.79460031762838, 99.78613022763366, 99.80307040762308, 99.8094229751191, 99.80518793012176, 99.83059820010588, 99.78613022763366, 99.82001058761249, 99.80307040762308, 99.84542085759661, 99.76283748014822, 99.82424563260984, 99.82212811011117, 99.8369507676019, 99.81577554261514, 99.8094229751191, 99.79671784012704, 99.86236103758603, 99.79671784012704, 99.84542085759661, 99.81577554261514, 99.82001058761249, 99.83059820010588, 99.82424563260984, 99.85389094759132, 99.84542085759661, 99.84753838009529, 99.83059820010588, 99.81789306511382, 99.82636315510852, 99.84542085759661, 99.82636315510852, 99.8094229751191, 99.8369507676019, 99.84542085759661, 99.84330333509793, 99.84118581259926, 99.8369507676019, 99.82636315510852]\n",
        "test_loss_list_mix = [0.4968765592750381, 0.4496412401398023, 0.39002737402915955, 0.3806089258515367, 0.3204718660198006, 0.3915786291016083, 0.3204018429798238, 0.27567775876206513, 0.297381679728335, 0.28301442688440576, 0.28070780485138, 0.2833815569459808, 0.26925351503579054, 0.26673262694156635, 0.2499614215510733, 0.26110943147510873, 0.2559659517571038, 0.24042939486018583, 0.24612251061069615, 0.25121348559418144, 0.2554320693381277, 0.24982432885935493, 0.26238466039592145, 0.25014860489789176, 0.27063990981482405, 0.25935193300977644, 0.25238811593575805, 0.26022648216024336, 0.24298064929305338, 0.2627089251855425, 0.27986022293129387, 0.27539388061154124, 0.26327539124873045, 0.2683038656398946, 0.28468784642424066, 0.28231597783080503, 0.2648708233061959, 0.2511889289553259, 0.2871778339658882, 0.26883744331551535, 0.2730213494277468, 0.28196089287452836, 0.2727588803379559, 0.2716984305275129, 0.28908429240040917, 0.27025664857059134, 0.28404617488530337, 0.2796709204056099, 0.28010478157404006, 0.2852920090925752, 0.2734685718428855, 0.2916511903498687, 0.27724011083517003, 0.2940135949528685, 0.2814183736986974, 0.2895678594051039, 0.3044459021778083, 0.2729633482830489, 0.2753490212683876, 0.2902740286845787, 0.2641575384665938, 0.29541431860450434, 0.2934904679765596, 0.2973368406003597, 0.3145442524851829, 0.2842784762820777, 0.2945947372811098, 0.2840387991574757, 0.2869349299181326, 0.27243131910469015, 0.29096475291047613, 0.29465110983480425, 0.2751436970908852, 0.29335411254535704, 0.30367974758002103, 0.2629663415399252, 0.2774942562933646, 0.2887668024529429, 0.2783941021371706, 0.2701931654603458, 0.2921381458347919, 0.2950442577255707, 0.28360421898975674, 0.27811501302993763, 0.29225470819601823, 0.2879698169326373, 0.2802756140191181, 0.2898149842250289, 0.3028535102950592, 0.2814833966686445, 0.28412492144122425, 0.2813930624328992, 0.27925870720954504, 0.2858440491060416, 0.29389001138727455, 0.30059922844463705, 0.2825733188028429, 0.2835676666787442, 0.2877841207618807, 0.29116936455316406, 0.28830072700100784, 0.285358795932695, 0.28429602919255986, 0.2773189860049124, 0.27414730530889597, 0.2898979450703836, 0.31280472980556534, 0.29734473288351415, 0.2825610628899406, 0.2763801336507587, 0.277620185458777, 0.30638950756367517, 0.2807564251855308, 0.282097570561603, 0.3035717385948873, 0.30351242861327005, 0.2829094833749182, 0.2905926219753775, 0.2816025845560373, 0.2773329648280553, 0.2836565510826368, 0.3049090450227845, 0.2853395010837737, 0.3026421479150361, 0.2882088396661714, 0.2714636234164822, 0.2923690947137919, 0.2785814857183426, 0.28070347221093433, 0.2958538033725584, 0.2875262723103458, 0.29740006582555817, 0.2820720241642466, 0.2911566118253212, 0.27959447470950144, 0.3113881464609328, 0.2879708492580582, 0.2911304790234449, 0.30164744040253116, 0.28354411742047353, 0.27903590285602736, 0.28088901288734347, 0.27327312507173596, 0.2879488106963097, 0.28996947509985344, 0.2830904172733426, 0.29018380200746013, 0.28617805264451923, 0.28362530970252026, 0.2815610739566824, 0.2880097535968411, 0.28445453794819175, 0.28255120502310055, 0.2700368627431054, 0.2868249623433632, 0.2987582326191021, 0.28800590190232966, 0.27571498953244267, 0.2802151000017629, 0.2834977245816559, 0.2834719321233969, 0.28607808749246244, 0.2878175952161352, 0.2777362868701126, 0.29719853200310586, 0.2828675587022421, 0.2720199037416309, 0.27524494520370285, 0.2827897258742037, 0.28359566126749214, 0.2779345959698891, 0.27804525879522163, 0.28059227344598253, 0.29605638752600144, 0.2847536772160846, 0.28240000672054055, 0.2913353420501831, 0.29991633287977937, 0.2821591763355422, 0.28840978052832333, 0.2816306263683181, 0.280769894867405, 0.28257956050847677, 0.2740063602104783, 0.2721924037471706, 0.280458538354758, 0.2804504399206124, 0.2803858033582276, 0.28368200007460864, 0.27371273335872914, 0.2791220264819761, 0.27405345537608455, 0.2753484202366249, 0.2904026607307149, 0.2743520236154105, 0.2717200533906911, 0.27128687258079354, 0.2693210001487066, 0.2743913666345179, 0.2700155303977868, 0.26815189790966754, 0.26675478429259625, 0.2739511370914532, 0.2709468726214825, 0.27877162732914385, 0.2767229562113975, 0.27129210420318095, 0.27698782736472055, 0.26407752993206185, 0.2678539391844442, 0.27572355346352445, 0.2688033563066639, 0.273533514582132, 0.26681174989789724, 0.27152517490892436, 0.2680956854612804, 0.26951589610646753, 0.2725548438508721, 0.2685760261819643, 0.2753346236970495, 0.2654521403122036, 0.27330513671040535, 0.26338427238093287, 0.26901105538412345, 0.26318498032496257, 0.2679282346849932, 0.27139169043477845, 0.2661011636841531, 0.2567788078175748, 0.26415850057759704, 0.26049654120031523, 0.26823244156206355, 0.2683363047008421, 0.2627703683523863, 0.2564784280645351, 0.25979823937785684, 0.26836607398867024, 0.2646418652661583, 0.27362839380900067, 0.25775680436259685, 0.2622781395546946, 0.2577361859308154, 0.259969442242793, 0.2670592286934455, 0.25948775546880914, 0.2614140360177878, 0.2559678828453316, 0.25749495658366117, 0.2589990839398667, 0.25487637667752366, 0.2578467573678377, 0.25440817833969404, 0.2581749869254874, 0.2548055907565297, 0.25454593778533097, 0.256248529982187, 0.2540844309454163, 0.25549203602998866, 0.24818837269227587, 0.24607416837220536, 0.2469723666013748, 0.24849579098415286, 0.2506902605231267, 0.248916748399828, 0.24932225204675512, 0.2515677338210391, 0.248076570895957, 0.25269879287510527, 0.2470587625661317, 0.24636757936255604, 0.24355621403083205, 0.24634781338311001, 0.24613529066646508, 0.24289194699011596, 0.2443599361268913, 0.24590234871150232, 0.2470326214553971, 0.24292154000688562, 0.24474981166057141, 0.24522259354810505, 0.2442855668692466, 0.24541391723551878, 0.2444736195600354, 0.24036579289674467, 0.24579018818251058, 0.24510042405888147, 0.2416404786647535, 0.24342773950147426, 0.24383827958109916, 0.2404104194640383, 0.24592714732987622, 0.2404489804278402, 0.24246013735183605, 0.2407533844805085, 0.24311559112267753, 0.24433566783280933, 0.24052496796802564, 0.23717293172946893, 0.2407319616416798, 0.239128411491858]\n",
        "test_acc_list_mix = [84.63045482483098, 85.73678549477566, 87.94944683466503, 88.44499078057775, 90.46558082360173, 88.45651505838967, 90.52320221266135, 91.9099569760295, 91.23386601106331, 91.67947141979103, 92.0098340503995, 91.64874001229256, 91.91763982790411, 92.12891825445605, 92.94714197910264, 92.58220651505839, 92.93177627535341, 93.30439459127228, 93.14305470190534, 93.27366318377382, 92.96250768285188, 93.08159188690843, 92.94714197910264, 93.03933620159803, 92.74738783036263, 93.20067609096496, 93.10848186846958, 93.04317762753534, 93.6578057775046, 93.28902888752305, 92.57068223724647, 92.79732636754764, 93.15073755377996, 92.90872771972957, 92.62830362630608, 92.60141364474492, 92.95098340503995, 93.35049170251997, 92.79732636754764, 93.05854333128457, 92.9279348494161, 92.84342347879533, 92.94714197910264, 92.96250768285188, 92.72433927473878, 93.20451751690227, 92.93561770129072, 92.92025199754148, 93.1200061462815, 92.65903503380454, 93.11232329440688, 92.80116779348494, 93.01244622003688, 92.75122925629994, 92.99708051628765, 92.76275353411187, 92.37092808850646, 93.19683466502765, 93.1200061462815, 92.70129071911494, 93.2659803318992, 92.8318992009834, 92.57452366318377, 92.60909649661954, 92.06361401352181, 92.86647203441917, 92.65903503380454, 93.00476336816226, 92.81269207129687, 92.93177627535341, 92.91641057160417, 92.74738783036263, 93.25061462814998, 92.91256914566686, 92.27105101413645, 93.39274738783037, 93.1737861094038, 92.9740319606638, 93.00476336816226, 93.18146896127843, 92.81269207129687, 92.96250768285188, 92.98939766441303, 93.24677320221267, 92.75122925629994, 92.76659496004918, 93.15842040565458, 92.93945912722803, 92.8779963122311, 93.06622618315919, 93.20451751690227, 93.34280885064535, 93.25829748002458, 93.1661032575292, 92.6820835894284, 92.67055931161647, 93.15073755377996, 93.03549477566072, 92.86647203441917, 92.89336201598033, 93.1699446834665, 92.91256914566686, 93.17762753534112, 93.28902888752305, 93.38890596189306, 93.01628764597419, 92.69360786724032, 92.70513214505225, 93.05086047940996, 93.20835894283958, 93.39658881376766, 92.8318992009834, 93.21988322065151, 93.33128457283344, 92.79732636754764, 92.88183773816841, 93.3082360172096, 93.1238475722188, 93.32744314689613, 93.32744314689613, 93.30439459127228, 92.82037492317149, 93.23909035033805, 92.91256914566686, 92.99323909035034, 93.59250153657038, 92.88952059004302, 93.50030731407499, 93.37738168408113, 92.93945912722803, 93.1238475722188, 93.0278119237861, 93.26982175783651, 93.13153042409343, 93.36969883220651, 92.69360786724032, 93.18146896127843, 93.21988322065151, 92.85110633066995, 93.28134603564843, 93.51567301782421, 93.38122311001844, 93.43116164720344, 93.28518746158574, 93.39658881376766, 93.33512599877075, 93.34280885064535, 93.2160417947142, 93.49262446220037, 93.43884449907806, 93.3581745543946, 93.1661032575292, 93.57329440688383, 93.74615857406269, 93.21220036877689, 93.18146896127843, 93.18531038721574, 93.40043023970497, 93.48110018438844, 93.4119545175169, 93.32744314689613, 93.48110018438844, 93.25445605408727, 93.56561155500921, 93.25061462814998, 93.46957590657652, 93.58866011063307, 93.66548862937923, 93.59634296250768, 93.3159188690842, 93.63475722188076, 93.68085433312845, 93.62707437000614, 93.37738168408113, 93.59634296250768, 93.73463429625077, 93.08159188690843, 93.39274738783037, 93.5579287031346, 93.41963736939152, 93.4618930547019, 93.53103872157345, 93.58866011063307, 93.69622003687769, 93.8959741856177, 93.51567301782421, 93.68085433312845, 93.59250153657038, 93.51951444376152, 93.71542716656423, 93.66548862937923, 93.63091579594345, 93.73847572218807, 93.15457897971727, 93.65012292563, 93.78457283343577, 93.70390288875231, 93.69237861094038, 93.64628149969269, 93.96896127842655, 93.73847572218807, 93.99200983405039, 93.79609711124769, 93.90365703749232, 93.73463429625077, 93.49262446220037, 93.88060848186846, 93.66933005531654, 94.00737553779963, 93.88444990780577, 93.59250153657038, 93.70390288875231, 93.88444990780577, 94.0419483712354, 93.8959741856177, 93.99969268592501, 93.96511985248924, 93.99200983405039, 93.98048555623848, 93.88060848186846, 93.86524277811924, 93.73463429625077, 93.99200983405039, 93.93822987092808, 94.04578979717272, 93.8460356484327, 93.90749846342962, 93.95359557467732, 94.06883835279656, 94.04963122311001, 94.12645974185618, 93.90749846342962, 93.88829133374308, 94.01889981561156, 94.30700676090964, 94.00353411186232, 94.10341118623234, 94.0880454824831, 93.96511985248924, 94.0918869084204, 94.05731407498463, 94.16871542716656, 94.09956976029503, 94.02658266748617, 94.1379840196681, 94.17639827904118, 94.29164105716042, 94.18792255685311, 94.12645974185618, 94.26859250153657, 94.10341118623234, 94.29164105716042, 94.31084818684695, 94.20328826060233, 94.21481253841426, 94.06883835279656, 94.21481253841426, 94.31468961278426, 94.41456668715428, 94.49139520590043, 94.34926244622004, 94.45298094652735, 94.36462814996926, 94.27243392747388, 94.41840811309157, 94.36462814996926, 94.42224953902888, 94.22633681622618, 94.39151813153042, 94.29548248309773, 94.50676090964966, 94.39920098340504, 94.4798709280885, 94.43377381684081, 94.5221266133989, 94.43377381684081, 94.52980946527352, 94.46450522433928, 94.5221266133989, 94.41072526121697, 94.52980946527352, 94.5259680393362, 94.45298094652735, 94.57974800245852, 94.4798709280885, 94.37231100184388, 94.4721880762139, 94.53365089121081, 94.54517516902274, 94.5759065765212, 94.53365089121081, 94.59127228027043, 94.5259680393362, 94.46066379840197, 94.44913952059004, 94.39920098340504, 94.57974800245852, 94.58358942839583, 94.58743085433314, 94.61047940995698]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ilmYYfIElcAU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(train_acc_list_5e4)), train_acc_list_5e4, 'b')\n",
        "plt.plot(range(len(train_acc_list_auto)), train_acc_list_auto, 'r')\n",
        "plt.plot(range(len(train_acc_list_rand)), train_acc_list_rand, 'g')\n",
        "plt.plot(range(len(train_acc_list_mix)), train_acc_list_mix, 'y')\n",
        "#plt.plot(range(len(train_acc_list_exp)), train_acc_list_exp, 'purple')\n",
        "\n",
        "plt.plot(range(len(test_acc_list_5e4)), test_acc_list_5e4, color='b', linestyle='--')\n",
        "plt.plot(range(len(test_acc_list_auto)), test_acc_list_auto,color='r', linestyle='--')\n",
        "plt.plot(range(len(test_acc_list_rand)), test_acc_list_rand, color='g', linestyle='--')\n",
        "plt.plot(range(len(test_acc_list_mix)), test_acc_list_mix, color='y', linestyle='--')\n",
        "#plt.plot(range(len(test_acc_list_exp)), test_acc_list_exp, color='purple', linestyle='--')\n",
        "\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim([85, 101])\n",
        "plt.title(\"Combined accuracy\")\n",
        "plt.legend(['train with default augmentation', 'train with AutoAugment','train with RandAugment','train with AugMix',\n",
        "            'test with default augmentation', 'test with AutoAugment','test with RandAugment','test with AugMix'], loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ubm3Y5CSnZ0D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5dffbde7-6fa7-45ba-aa65-600d088a9eff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(train_loss_list_5e4)), train_loss_list_5e4, 'b')\n",
        "plt.plot(range(len(train_loss_list_auto)), train_loss_list_auto, 'r')\n",
        "plt.plot(range(len(train_loss_list_rand)), train_loss_list_rand, 'g')\n",
        "plt.plot(range(len(train_loss_list_mix)), train_loss_list_mix, 'y')\n",
        "#plt.plot(range(len(train_loss_list_exp)), train_loss_list_exp, 'purple')\n",
        "\n",
        "plt.plot(range(len(test_loss_list_5e4)), test_loss_list_5e4, color='b', linestyle='--')\n",
        "plt.plot(range(len(test_loss_list_auto)), test_loss_list_auto,color='r', linestyle='--')\n",
        "plt.plot(range(len(test_loss_list_rand)), test_loss_list_rand, color='g', linestyle='--')\n",
        "plt.plot(range(len(test_loss_list_mix)), test_loss_list_mix, color='y', linestyle='--')\n",
        "#plt.plot(range(len(test_loss_list_exp)), test_loss_list_exp, color='purple', linestyle='--')\n",
        "\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "#plt.ylim([85, 101])\n",
        "plt.title(\"Combined loss\")\n",
        "plt.legend(['train with default augmentation', 'train with AutoAugment','train with RandAugment','train with AugMix',\n",
        "            'test with default augmentation', 'test with AutoAugment','test with RandAugment','test with AugMix'], loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QnOTaNoesBEb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f24261db-4bfa-4230-d364-03236e7a29d3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}